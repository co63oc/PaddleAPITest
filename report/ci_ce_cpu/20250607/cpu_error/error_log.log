2025-06-09 23:16:05.160023 GPU 7 128187 test begin: paddle.Tensor.__mul__(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 1, 128],"bfloat16"), )
[accuracy error] backward  paddle.Tensor.__mul__(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 1, 128],"bfloat16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 118 / 131072 (0.1%)
Greatest absolute difference: 0.0390625 at index (0, 471, 0, 46) (up to 0.01 allowed)
Greatest relative difference: 0.4482758641242981 at index (0, 17, 0, 72) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1024, 1, 128]), dtype=torch.float32)
tensor([[[[-0.3086, -0.6797, -0.1216,  ..., -0.3398, -0.3066,  0.3457]],

         [[ 0.2539, -0.1406, -0.1943,  ..., -0.9141,  0.6445, -0.2949]],

         [[ 0.4473, -0.1904,  0.2988,  ..., -0.4102, -0.1582,  0.3145]],

         ...,

         [[-0.0615, -0.2061, -0.1562,  ..., -0.2051, -0.0039,  0.4258]],

         [[-0.1797,  0.1602, -0.5508,  ...,  1.1797,  0.7461, -0.3906]],

         [[ 0.0505, -0.2256, -0.4531,  ...,  0.2676,  0.4141,  0.1660]]]])
DESIRED: (shape=torch.Size([1, 1024, 1, 128]), dtype=torch.float32)
tensor([[[[-0.3066, -0.6836, -0.1230,  ..., -0.3398, -0.3086,  0.3477]],

         [[ 0.2520, -0.1377, -0.1934,  ..., -0.9219,  0.6445, -0.2988]],

         [[ 0.4512, -0.1885,  0.3027,  ..., -0.4102, -0.1582,  0.3145]],

         ...,

         [[-0.0615, -0.2061, -0.1572,  ..., -0.2051, -0.0040,  0.4277]],

         [[-0.1787,  0.1592, -0.5469,  ...,  1.1719,  0.7500, -0.3887]],

         [[ 0.0474, -0.2266, -0.4551,  ...,  0.2715,  0.4160,  0.1689]]]])

2025-06-09 23:16:05.221544 GPU 4 128181 test begin: paddle.Tensor.__mul__(Tensor([8, 8],"float16"), 1000000.0, )
[accuracy error] paddle.Tensor.__mul__(Tensor([8, 8],"float16"), 1000000.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 10 / 64 (15.6%)
Greatest absolute difference: inf at index (2, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8, 8]), dtype=torch.float16)
tensor([[-inf, -inf, inf, -inf, inf, -inf, inf, inf],
        [inf, -inf, -inf, -inf, inf, -inf, inf, inf],
        [inf, inf, -inf, -inf, inf, inf, -inf, inf],
        [-inf, inf, inf, inf, -inf, inf, -inf, inf],
        [-inf, inf, inf, -inf, inf, inf, -inf, -inf],
        [inf, -inf, -inf, inf, inf, -inf, inf, -inf],
        [-inf, inf, -inf, -inf, inf, inf, -inf, -inf],
        [inf, inf, -inf, -inf, inf, inf, -inf, -inf]], dtype=torch.float16)
DESIRED: (shape=torch.Size([8, 8]), dtype=torch.float16)
tensor([[   -inf,    -inf,     inf,    -inf,     inf,    -inf,     inf,     inf],
        [    inf,    -inf,    -inf,    -inf,     inf,    -inf,     inf,     inf],
        [    inf,  61696.,    -inf, -26832.,     inf,     inf,    -inf,  62432.],
        [   -inf,     inf,     inf,     inf,    -inf,     inf,    -inf,     inf],
        [   -inf,     inf,  29520.,    -inf,  43328.,     inf,    -inf,    -inf],
        [    inf, -54432., -56256.,     inf,     inf,    -inf,     inf,    -inf],
        [   -inf,     inf,    -inf,  -5012.,  31456.,     inf,    -inf,    -inf],
        [    inf,     inf,    -inf,    -inf,     inf,  58368.,    -inf,    -inf]], dtype=torch.float16)

2025-06-09 23:16:06.648431 GPU 4 128186 test begin: paddle.Tensor.astype(Tensor([32, 128],"int64"), Dtype(float16), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.astype(Tensor([32, 128],"int64"), Dtype(float16), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 4096 (0.1%)
Greatest absolute difference: inf at index (10, 13) (up to 0.01 allowed)
Greatest relative difference: inf at index (10, 13) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([32, 128]), dtype=torch.float16)
tensor([[-39616., -20048.,  -7280.,  ..., -13032., -60800., -54432.],
        [-40576., -44000.,  45888.,  ...,  39456.,  -9696.,  41440.],
        [ 47136.,  42816., -56640.,  ...,  26896., -28640.,  55776.],
        ...,
        [-14672.,  11848.,  44384.,  ...,  -9992., -61984., -55168.],
        [-55328., -62880.,  -1887.,  ...,  36416., -41824., -55040.],
        [-53760.,  54080., -30672.,  ..., -58240.,  56096.,  28656.]], dtype=torch.float16)
DESIRED: (shape=torch.Size([32, 128]), dtype=torch.float16)
tensor([[-39616., -20064.,  -7280.,  ..., -13040., -60832., -54432.],
        [-40608., -44000.,  45888.,  ...,  39488.,  -9696.,  41440.],
        [ 47136.,  42848., -56672.,  ...,  26896., -28656.,  55808.],
        ...,
        [-14680.,  11848.,  44416.,  ..., -10000., -62016., -55200.],
        [-55328., -62880.,  -1887.,  ...,  36448., -41824., -55072.],
        [-53792.,  54080., -30672.,  ..., -58240.,  56128.,  28656.]], dtype=torch.float16)

2025-06-09 23:16:06.758850 GPU 4 128204 test begin: paddle.Tensor.astype(Tensor([32, 16, 1024],"int64"), Dtype(float16), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.astype(Tensor([32, 16, 1024],"int64"), Dtype(float16), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 119 / 524288 (0.0%)
Greatest absolute difference: inf at index (0, 0, 715) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 715) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([32, 16, 1024]), dtype=torch.float16)
tensor([[[-54784.,  47968.,  37632.,  ..., -49664.,  65088., -30064.],
         [-48384., -41024., -30688.,  ...,   3852., -22384., -10784.],
         [-55424., -61920.,  18000.,  ..., -62080.,  26928.,  14720.],
         ...,
         [-59296., -19344.,  27456.,  ...,  61312., -45568., -14704.],
         [ 63040.,  -6876., -22384.,  ...,  59936., -20448.,  -3478.],
         [ 13280.,  -3648.,  21088.,  ...,  39712., -62720., -18688.]],

        [[ 53568.,  19872., -63936.,  ..., -63488.,  52352.,  16784.],
         [ -9800., -59264.,  31952.,  ...,  39040.,   1598., -27728.],
         [-28768., -20096., -22624.,  ...,  21952.,  49600., -64896.],
         ...,
         [-37824.,   7576.,  41600.,  ..., -34112., -24496.,  45376.],
         [ 31920.,  19280., -38720.,  ..., -26112., -39904.,  46016.],
         [-35264., -35072., -52416.,  ..., -29520.,  49600.,  47680.]],

        [[-50080., -43168.,  40224.,  ...,  32064.,  47264.,  43648.],
         [-26624.,  51104.,  28080.,  ..., -47136., -45312.,  36960.],
         [-41952., -23104., -65120.,  ..., -17056., -21520., -26016.],
         ...,
         [ 41440., -15944., -54048.,  ...,  14776., -30960.,  34400.],
         [  6436., -63232., -52192.,  ...,  59744.,  -1891.,  52640.],
         [ 13120.,  61696., -20464.,  ...,  60960., -11616., -31536.]],

        ...,

        [[ 15992.,  39520.,  48352.,  ...,  34336., -45536., -32864.],
         [-20976., -54752.,  54176.,  ..., -44288., -65312., -49248.],
         [ 49536.,  17968.,  20560.,  ...,  54656., -58080.,  42112.],
         ...,
         [  1235.,  37984., -53920.,  ..., -20704.,   9224., -22752.],
         [-33248., -57120., -28592.,  ...,  37536., -48672.,   -695.],
         [ 40352.,  60288., -58368.,  ...,  61504.,   7100., -44384.]],

        [[-56256.,  -4476.,  18352.,  ...,  44960., -54400.,   6276.],
         [-25856., -64704.,  37440.,  ..., -35680.,  38304., -35872.],
         [ 18880.,  50240.,  39488.,  ..., -37504., -51104.,  14200.],
         ...,
         [ 33408.,   -778.,  55232.,  ...,   1072.,   1986., -16416.],
         [ -3678., -64224., -12112.,  ..., -49504.,  11328., -19712.],
         [ 25056.,  31120.,  62560.,  ..., -16592.,  11056.,  29504.]],

        [[-49088.,  51648., -42880.,  ..., -56320., -26656.,  32896.],
         [-29648., -13328.,  47104.,  ..., -64608.,  32480.,  62528.],
         [ 30496., -59040.,  44736.,  ...,  41760.,  26304.,  16112.],
         ...,
         [  -965.,  43680.,  23536.,  ...,  14272., -55680.,  50112.],
         [-11936., -52544., -20288.,  ...,  21760.,   4800.,  42304.],
         [ 52032.,  -9680.,  15520.,  ...,  43872.,  -5688., -13120.]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([32, 16, 1024]), dtype=torch.float16)
tensor([[[-54816.,  48000.,  37632.,  ..., -49696.,  65120., -30064.],
         [-48416., -41056., -30688.,  ...,   3852., -22400., -10784.],
         [-55424., -61952.,  18016.,  ..., -62080.,  26944.,  14720.],
         ...,
         [-59296., -19360.,  27472.,  ...,  61312., -45568., -14712.],
         [ 63040.,  -6880., -22400.,  ...,  59936., -20448.,  -3480.],
         [ 13288.,  -3648.,  21088.,  ...,  39744., -62720., -18688.]],

        [[ 53568.,  19872., -63936.,  ..., -63520.,  52352.,  16800.],
         [ -9800., -59264.,  31952.,  ...,  39040.,   1598., -27728.],
         [-28784., -20096., -22624.,  ...,  21968.,  49600., -64928.],
         ...,
         [-37856.,   7576.,  41600.,  ..., -34112., -24512.,  45376.],
         [ 31920.,  19296., -38720.,  ..., -26128., -39904.,  46016.],
         [-35264., -35104., -52448.,  ..., -29536.,  49632.,  47680.]],

        [[-50112., -43168.,  40256.,  ...,  32080.,  47296.,  43680.],
         [-26640.,  51136.,  28080.,  ..., -47168., -45344.,  36992.],
         [-41984., -23120., -65120.,  ..., -17056., -21520., -26032.],
         ...,
         [ 41440., -15952., -54080.,  ...,  14784., -30976.,  34432.],
         [  6436., -63232., -52192.,  ...,  59744.,  -1891.,  52672.],
         [ 13128.,  61696., -20464.,  ...,  60992., -11616., -31552.]],

        ...,

        [[ 15992.,  39520.,  48352.,  ...,  34336., -45536., -32896.],
         [-20976., -54752.,  54176.,  ..., -44320., -65344., -49248.],
         [ 49536.,  17984.,  20576.,  ...,  54656., -58112.,  42144.],
         ...,
         [  1235.,  37984., -53952.,  ..., -20704.,   9232., -22752.],
         [-33280., -57152., -28592.,  ...,  37568., -48672.,   -695.],
         [ 40352.,  60320., -58368.,  ...,  61536.,   7100., -44416.]],

        [[-56256.,  -4480.,  18352.,  ...,  44960., -54400.,   6280.],
         [-25872., -64704.,  37440.,  ..., -35712.,  38336., -35872.],
         [ 18880.,  50272.,  39488.,  ..., -37536., -51136.,  14208.],
         ...,
         [ 33408.,   -778.,  55264.,  ...,   1072.,   1986., -16416.],
         [ -3680., -64224., -12120.,  ..., -49536.,  11336., -19712.],
         [ 25072.,  31136.,  62560.,  ..., -16592.,  11064.,  29504.]],

        [[-49088.,  51680., -42880.,  ..., -56352., -26672.,  32928.],
         [-29648., -13328.,  47136.,  ..., -64640.,  32496.,  62528.],
         [ 30496., -59040.,  44768.,  ...,  41760.,  26320.,  16112.],
         ...,
         [  -965.,  43712.,  23536.,  ...,  14272., -55680.,  50144.],
         [-11936., -52576., -20288.,  ...,  21760.,   4800.,  42304.],
         [ 52064.,  -9680.,  15520.,  ...,  43904.,  -5688., -13120.]]], dtype=torch.float16)

2025-06-09 23:16:06.851764 GPU 5 128179 test begin: paddle.Tensor.astype(Tensor([32, 3, 1024],"int64"), Dtype(float16), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.astype(Tensor([32, 3, 1024],"int64"), Dtype(float16), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 17 / 98304 (0.0%)
Greatest absolute difference: inf at index (0, 0, 715) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 715) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([32, 3, 1024]), dtype=torch.float16)
tensor([[[-40608.,  48096., -46688.,  ..., -56832., -30416.,  29360.],
         [ -4804.,  15048.,  28272.,  ..., -43136., -31088., -42432.],
         [  2192., -65408.,    707.,  ...,  -4644.,  -3738., -41760.]],

        [[-14768.,  14008., -37696.,  ..., -30976., -48800.,  37536.],
         [ 16384.,  49664., -33120.,  ..., -37792., -19344.,   4024.],
         [ 23040.,  57856., -57504.,  ..., -26096.,  -8280.,  47552.]],

        [[ 19120.,  18512.,  30000.,  ...,  24304.,  21488.,  -6520.],
         [ 50560., -60608., -40160.,  ...,  35008.,   -435.,  19184.],
         [ 21392., -10840., -49280.,  ...,  47296., -11384.,  18400.]],

        ...,

        [[-22224.,  33056.,  52384.,  ...,  27952., -31456.,  61792.],
         [-64256., -46496.,  38048.,  ...,  53408.,   9032.,  60224.],
         [-62496.,  30320.,  15616.,  ...,  37248.,  -5988.,  40736.]],

        [[ -4108.,  38848.,  13400.,  ...,  41600., -28432., -53440.],
         [-58144.,  27008., -37632.,  ..., -35456., -43488., -16864.],
         [ 21856.,  41728.,  -1779.,  ...,  -4328., -61568., -57440.]],

        [[-50880.,   6680.,  -6200.,  ...,  63712.,   -984.,   2810.],
         [-53408., -12736.,  43904.,  ...,  -7472., -16736.,  18208.],
         [-52832., -13552., -46496.,  ...,   4164.,  20944., -33312.]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([32, 3, 1024]), dtype=torch.float16)
tensor([[[-40608.,  48096., -46688.,  ..., -56832., -30432.,  29360.],
         [ -4808.,  15056.,  28272.,  ..., -43168., -31104., -42464.],
         [  2192., -65408.,    707.,  ...,  -4644.,  -3738., -41792.]],

        [[-14768.,  14016., -37696.,  ..., -30992., -48832.,  37568.],
         [ 16384.,  49696., -33152.,  ..., -37824., -19344.,   4024.],
         [ 23056.,  57856., -57536.,  ..., -26096.,  -8280.,  47584.]],

        [[ 19120.,  18528.,  30000.,  ...,  24320.,  21504.,  -6520.],
         [ 50560., -60640., -40192.,  ...,  35040.,   -435.,  19184.],
         [ 21408., -10840., -49312.,  ...,  47296., -11384.,  18416.]],

        ...,

        [[-22240.,  33056.,  52416.,  ...,  27968., -31472.,  61792.],
         [-64256., -46496.,  38080.,  ...,  53440.,   9040.,  60256.],
         [-62528.,  30320.,  15616.,  ...,  37248.,  -5992.,  40736.]],

        [[ -4112.,  38880.,  13400.,  ...,  41632., -28432., -53472.],
         [-58176.,  27008., -37632.,  ..., -35456., -43520., -16864.],
         [ 21856.,  41728.,  -1779.,  ...,  -4332., -61568., -57472.]],

        [[-50912.,   6680.,  -6200.,  ...,  63712.,   -984.,   2812.],
         [-53440., -12736.,  43936.,  ...,  -7476., -16736.,  18224.],
         [-52864., -13552., -46528.,  ...,   4168.,  20944., -33312.]]], dtype=torch.float16)

2025-06-09 23:16:06.909147 GPU 7 128205 test begin: paddle.Tensor.cast(Tensor([2, 3, 32, 128],"int32"), Dtype(float16), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.cast(Tensor([2, 3, 32, 128],"int32"), Dtype(float16), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 24576 (0.0%)
Greatest absolute difference: inf at index (0, 1, 17, 34) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 1, 17, 34) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 32, 128]), dtype=torch.float16)
tensor([[[[-8.8400e+03,  2.4032e+04, -4.6048e+04,  ...,  2.6112e+04,  5.4944e+04,  6.0192e+04],
          [-3.5800e+03, -2.3088e+04,  2.4416e+04,  ...,  5.2544e+04,  1.0056e+04,  2.1600e+03],
          [-6.1400e+03,  6.1400e+02,  5.8432e+04,  ..., -2.1900e+03,  5.8840e+03,  4.8384e+04],
          ...,
          [ 7.0200e+03, -3.0384e+04, -6.1504e+04,  ..., -3.4720e+04, -2.3248e+04, -6.0288e+04],
          [ 7.5480e+03, -5.6416e+04,  6.0224e+04,  ..., -1.1944e+04, -1.2620e+03,  2.4608e+04],
          [ 2.9648e+04,  3.5808e+04,  6.2304e+04,  ..., -1.8528e+04,  5.6352e+04,  5.0880e+04]],

         [[ 9.8480e+03,  8.5760e+03, -4.0352e+04,  ...,  4.1568e+04, -3.7248e+04,  5.9872e+04],
          [-1.4912e+04, -3.7792e+04, -5.9712e+04,  ...,  5.4784e+04,  3.7780e+03,  2.8960e+04],
          [ 1.2680e+04, -2.0260e+03,  3.4432e+04,  ...,  5.9968e+04,  1.0000e+04,  5.7984e+04],
          ...,
          [ 5.1968e+04,  4.5000e+01,  2.2900e+03,  ...,  4.9320e+03,  7.4520e+03, -2.1696e+04],
          [-5.2608e+04,  4.7296e+04, -6.0608e+04,  ...,  9.8480e+03, -2.9216e+04, -4.4384e+04],
          [ 3.4368e+04, -2.2992e+04,  2.7968e+04,  ...,  2.6420e+03,  6.0352e+04,  5.8592e+04]],

         [[ 1.6360e+04, -4.6016e+04, -5.5072e+04,  ..., -5.0176e+04, -2.0480e+04,  1.8336e+04],
          [-2.3488e+04, -1.6200e+02, -3.0928e+04,  ...,  4.7360e+04,  3.8432e+04,  2.3408e+04],
          [ 5.7376e+04,  1.9680e+04, -6.2624e+04,  ...,  4.0512e+04,  2.0480e+04,  5.8688e+04],
          ...,
          [ 5.1456e+04,  1.0456e+04, -1.6328e+04,  ...,  2.8256e+04,  3.3792e+04, -4.3840e+04],
          [-1.2016e+04,  3.3312e+04,  5.7888e+04,  ..., -2.8064e+04,  4.5664e+04, -3.4784e+04],
          [ 2.5168e+04, -6.5248e+04,  5.2384e+04,  ..., -4.9184e+04, -7.6640e+03, -3.2400e+04]]],


        [[[ 2.7680e+04,  9.8160e+03, -3.7600e+04,  ...,  1.9408e+04,  2.3024e+04, -5.5072e+04],
          [-5.7824e+04,  3.7100e+02, -3.6416e+04,  ...,  1.3712e+04, -2.0960e+04,  1.8208e+04],
          [ 3.0784e+04,  1.9904e+04, -3.9104e+04,  ...,  2.2448e+04,  5.8480e+03, -2.8960e+04],
          ...,
          [-4.8768e+04, -6.3520e+04, -2.2416e+04,  ..., -8.6480e+03, -1.7392e+04, -1.8240e+04],
          [-3.6192e+04,  3.5648e+04,  1.1880e+04,  ...,  3.5648e+04,  3.7376e+04, -6.1248e+04],
          [-3.2720e+03, -9.5760e+03,  1.0864e+04,  ..., -4.1720e+03,  2.7040e+04,  6.0768e+04]],

         [[-2.6960e+04, -6.0416e+04,  2.9840e+04,  ..., -6.1888e+04,  6.0544e+04,  2.7488e+04],
          [-1.8416e+04, -1.4704e+04, -6.4096e+04,  ...,  4.1312e+04,  5.7984e+04, -2.2128e+04],
          [-6.5152e+04, -6.4288e+04, -5.2064e+04,  ..., -1.9568e+04, -3.6928e+04, -2.6672e+04],
          ...,
          [ 6.0128e+04, -5.3560e+03,  2.5504e+04,  ..., -5.9120e+03,  4.4720e+03, -6.4960e+03],
          [ 4.9568e+04,  6.0960e+04,  4.2848e+04,  ...,  2.2512e+04,  3.0208e+04,  2.6096e+04],
          [ 5.8176e+04,  3.8304e+04,  2.4544e+04,  ...,  5.6448e+04,  6.0672e+04, -2.0000e+04]],

         [[-8.8560e+03,  6.0160e+03, -6.0768e+04,  ..., -1.6576e+04, -1.3136e+04, -2.1648e+04],
          [-3.3380e+03, -4.6784e+04,  6.4576e+04,  ...,  4.1408e+04,  5.4720e+04,  6.1888e+04],
          [-1.9328e+04,  3.9264e+04,  4.6480e+03,  ...,  5.0688e+04, -6.1472e+04, -4.2304e+04],
          ...,
          [-2.7328e+04, -1.6070e+03, -4.8224e+04,  ..., -8.6480e+03,  3.2540e+03,  2.2080e+04],
          [-3.3344e+04,  6.3296e+04, -3.9968e+04,  ..., -2.9472e+04,  1.5760e+04,  6.5216e+04],
          [-4.8576e+04,  6.0416e+04, -2.3840e+04,  ...,  4.6496e+04,  4.3520e+04, -4.6432e+04]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 3, 32, 128]), dtype=torch.float16)
tensor([[[[-8.8480e+03,  2.4032e+04, -4.6048e+04,  ...,  2.6128e+04,  5.4976e+04,  6.0192e+04],
          [-3.5800e+03, -2.3104e+04,  2.4416e+04,  ...,  5.2544e+04,  1.0064e+04,  2.1600e+03],
          [-6.1400e+03,  6.1400e+02,  5.8464e+04,  ..., -2.1920e+03,  5.8880e+03,  4.8384e+04],
          ...,
          [ 7.0200e+03, -3.0400e+04, -6.1536e+04,  ..., -3.4752e+04, -2.3248e+04, -6.0288e+04],
          [ 7.5520e+03, -5.6416e+04,  6.0256e+04,  ..., -1.1952e+04, -1.2620e+03,  2.4624e+04],
          [ 2.9664e+04,  3.5840e+04,  6.2304e+04,  ..., -1.8528e+04,  5.6352e+04,  5.0912e+04]],

         [[ 9.8560e+03,  8.5840e+03, -4.0352e+04,  ...,  4.1568e+04, -3.7248e+04,  5.9872e+04],
          [-1.4912e+04, -3.7824e+04, -5.9712e+04,  ...,  5.4816e+04,  3.7780e+03,  2.8960e+04],
          [ 1.2680e+04, -2.0260e+03,  3.4432e+04,  ...,  6.0000e+04,  1.0000e+04,  5.7984e+04],
          ...,
          [ 5.1968e+04,  4.5000e+01,  2.2920e+03,  ...,  4.9360e+03,  7.4520e+03, -2.1696e+04],
          [-5.2640e+04,  4.7296e+04, -6.0608e+04,  ...,  9.8560e+03, -2.9216e+04, -4.4384e+04],
          [ 3.4368e+04, -2.3008e+04,  2.7968e+04,  ...,  2.6440e+03,  6.0384e+04,  5.8592e+04]],

         [[ 1.6360e+04, -4.6048e+04, -5.5104e+04,  ..., -5.0208e+04, -2.0496e+04,  1.8336e+04],
          [-2.3504e+04, -1.6200e+02, -3.0928e+04,  ...,  4.7392e+04,  3.8464e+04,  2.3408e+04],
          [ 5.7408e+04,  1.9680e+04, -6.2656e+04,  ...,  4.0512e+04,  2.0480e+04,  5.8720e+04],
          ...,
          [ 5.1488e+04,  1.0464e+04, -1.6328e+04,  ...,  2.8256e+04,  3.3824e+04, -4.3872e+04],
          [-1.2016e+04,  3.3312e+04,  5.7920e+04,  ..., -2.8064e+04,  4.5664e+04, -3.4784e+04],
          [ 2.5168e+04, -6.5248e+04,  5.2416e+04,  ..., -4.9216e+04, -7.6640e+03, -3.2416e+04]]],


        [[[ 2.7680e+04,  9.8240e+03, -3.7632e+04,  ...,  1.9424e+04,  2.3040e+04, -5.5104e+04],
          [-5.7824e+04,  3.7100e+02, -3.6448e+04,  ...,  1.3712e+04, -2.0960e+04,  1.8208e+04],
          [ 3.0800e+04,  1.9904e+04, -3.9136e+04,  ...,  2.2448e+04,  5.8480e+03, -2.8976e+04],
          ...,
          [-4.8800e+04, -6.3552e+04, -2.2416e+04,  ..., -8.6560e+03, -1.7408e+04, -1.8256e+04],
          [-3.6192e+04,  3.5680e+04,  1.1888e+04,  ...,  3.5648e+04,  3.7376e+04, -6.1280e+04],
          [-3.2720e+03, -9.5760e+03,  1.0864e+04,  ..., -4.1760e+03,  2.7056e+04,  6.0768e+04]],

         [[-2.6960e+04, -6.0416e+04,  2.9840e+04,  ..., -6.1888e+04,  6.0544e+04,  2.7504e+04],
          [-1.8416e+04, -1.4704e+04, -6.4096e+04,  ...,  4.1312e+04,  5.7984e+04, -2.2128e+04],
          [-6.5184e+04, -6.4288e+04, -5.2096e+04,  ..., -1.9584e+04, -3.6960e+04, -2.6672e+04],
          ...,
          [ 6.0160e+04, -5.3560e+03,  2.5504e+04,  ..., -5.9120e+03,  4.4720e+03, -6.4960e+03],
          [ 4.9568e+04,  6.0960e+04,  4.2880e+04,  ...,  2.2512e+04,  3.0224e+04,  2.6112e+04],
          [ 5.8208e+04,  3.8304e+04,  2.4544e+04,  ...,  5.6448e+04,  6.0704e+04, -2.0016e+04]],

         [[-8.8560e+03,  6.0160e+03, -6.0800e+04,  ..., -1.6592e+04, -1.3144e+04, -2.1664e+04],
          [-3.3380e+03, -4.6816e+04,  6.4576e+04,  ...,  4.1408e+04,  5.4752e+04,  6.1888e+04],
          [-1.9328e+04,  3.9264e+04,  4.6480e+03,  ...,  5.0720e+04, -6.1472e+04, -4.2336e+04],
          ...,
          [-2.7344e+04, -1.6070e+03, -4.8224e+04,  ..., -8.6560e+03,  3.2560e+03,  2.2080e+04],
          [-3.3376e+04,  6.3328e+04, -3.9968e+04,  ..., -2.9472e+04,  1.5768e+04,  6.5216e+04],
          [-4.8576e+04,  6.0416e+04, -2.3856e+04,  ...,  4.6496e+04,  4.3552e+04, -4.6432e+04]]]], dtype=torch.float16)

2025-06-09 23:16:06.934610 GPU 6 128192 test begin: paddle.Tensor.expand(Tensor([1, 1, 1, 4096],"float16"), list[2,1,4096,4096,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 1, 1, 4096],"float16"), list[2,1,4096,4096,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4086 / 4096 (99.8%)
Greatest absolute difference: 75.875 at index (0, 0, 0, 542) (up to 0.01 allowed)
Greatest relative difference: 2882.0 at index (0, 0, 0, 2522) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 1, 4096]), dtype=torch.float16)
tensor([[[[-8.7422, 16.3906, -8.9453,  ...,  3.7715,  5.3008, -0.8511]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 1, 4096]), dtype=torch.float16)
tensor([[[[-27.0938,  52.6562, -19.0469,  ...,   4.5742, -11.4844,   6.2891]]]], dtype=torch.float16)

2025-06-09 23:16:06.937445 GPU 6 128197 test begin: paddle.Tensor.expand(Tensor([1, 1, 192],"float16"), tuple(128,-1,-1,), )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 1, 192],"float16"), tuple(128,-1,-1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 135 / 192 (70.3%)
Greatest absolute difference: 0.19140625 at index (0, 0, 71) (up to 0.01 allowed)
Greatest relative difference: 0.7470703125 at index (0, 0, 104) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 192]), dtype=torch.float16)
tensor([[[-2.3926,  3.1816, -1.1289,  ...,  2.2129,  2.3555,  2.6191]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 192]), dtype=torch.float16)
tensor([[[-2.3926,  3.2617, -1.1396,  ...,  2.2227,  2.4023,  2.6895]]], dtype=torch.float16)

2025-06-09 23:16:06.941129 GPU 4 128193 test begin: paddle.Tensor.expand(Tensor([1, 1, 384],"float16"), tuple(64,-1,-1,), )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 1, 384],"float16"), tuple(64,-1,-1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 103 / 384 (26.8%)
Greatest absolute difference: 0.08984375 at index (0, 0, 103) (up to 0.01 allowed)
Greatest relative difference: 1.0146484375 at index (0, 0, 90) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 384]), dtype=torch.float16)
tensor([[[ 3.0215,  0.3542,  3.0898,  ...,  2.3223, -0.1421,  2.2617]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 384]), dtype=torch.float16)
tensor([[[ 3.0566,  0.3469,  3.1172,  ...,  2.3418, -0.1599,  2.3008]]], dtype=torch.float16)

2025-06-09 23:16:06.964677 GPU 6 128183 test begin: paddle.Tensor.expand(Tensor([1, 1, 768],"float16"), tuple(112,-1,-1,), )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 1, 768],"float16"), tuple(112,-1,-1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 492 / 768 (64.1%)
Greatest absolute difference: 0.185546875 at index (0, 0, 705) (up to 0.01 allowed)
Greatest relative difference: 3.134765625 at index (0, 0, 557) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 768]), dtype=torch.float16)
tensor([[[ 1.3799,  3.6680,  4.8906,  ...,  0.1831,  0.4709, -0.9751]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 768]), dtype=torch.float16)
tensor([[[ 1.4082,  3.7520,  5.0117,  ...,  0.2030,  0.4207, -0.9624]]], dtype=torch.float16)

2025-06-09 23:16:07.058069 GPU 5 128191 test begin: paddle.Tensor.expand(Tensor([1, 1, 768],"float16"), tuple(128,-1,-1,), )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 1, 768],"float16"), tuple(128,-1,-1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 534 / 768 (69.5%)
Greatest absolute difference: 0.2578125 at index (0, 0, 440) (up to 0.01 allowed)
Greatest relative difference: 3.84375 at index (0, 0, 263) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 768]), dtype=torch.float16)
tensor([[[-3.2988, -3.2012, -2.7266,  ..., -1.7568,  0.2246, -6.9219]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 768]), dtype=torch.float16)
tensor([[[-3.3633, -3.2656, -2.7969,  ..., -1.8066,  0.2135, -7.0430]]], dtype=torch.float16)

2025-06-09 23:16:07.205292 GPU 4 128195 test begin: paddle.Tensor.expand(Tensor([1, 1, 768],"float16"), tuple(64,-1,-1,), )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 1, 768],"float16"), tuple(64,-1,-1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 175 / 768 (22.8%)
Greatest absolute difference: 0.1015625 at index (0, 0, 465) (up to 0.01 allowed)
Greatest relative difference: 3.220703125 at index (0, 0, 573) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 768]), dtype=torch.float16)
tensor([[[ 1.4365, -0.3784, -3.3672,  ..., -2.8691,  2.3223,  0.0347]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 768]), dtype=torch.float16)
tensor([[[ 1.4404, -0.3955, -3.4160,  ..., -2.9160,  2.3516,  0.0473]]], dtype=torch.float16)

2025-06-09 23:16:07.228595 GPU 5 128201 test begin: paddle.Tensor.expand(Tensor([1, 2048, 1, 1],"float16"), list[1,2048,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 2048, 1, 1],"float16"), list[1,2048,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 511 / 2048 (25.0%)
Greatest absolute difference: 0.09765625 at index (0, 235, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 9.484375 at index (0, 456, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2048, 1, 1]), dtype=torch.float16)
tensor([[[[-0.1262]],

         [[-1.2197]],

         [[-0.2986]],

         ...,

         [[ 0.3093]],

         [[ 0.7554]],

         [[ 2.3750]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 2048, 1, 1]), dtype=torch.float16)
tensor([[[[-0.1399]],

         [[-1.2432]],

         [[-0.3145]],

         ...,

         [[ 0.3076]],

         [[ 0.7607]],

         [[ 2.4277]]]], dtype=torch.float16)

2025-06-09 23:16:07.345246 GPU 6 128199 test begin: paddle.Tensor.expand(Tensor([1, 35, 1, 1],"float16"), list[2,35,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 35, 1, 1],"float16"), list[2,35,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 26 / 35 (74.3%)
Greatest absolute difference: 0.1640625 at index (0, 19, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.60791015625 at index (0, 5, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 35, 1, 1]), dtype=torch.float16)
tensor([[[[-0.5977]],

         [[ 5.7383]],

         [[-1.5098]],

         [[ 3.5820]],

         [[-3.0703]],

         [[-0.0710]],

         [[ 1.5391]],

         [[-0.0302]],

         [[ 0.8447]],

         [[ 0.1550]],

         [[-3.9199]],

         [[ 3.0273]],

         [[-1.8877]],

         [[ 3.4043]],

         [[ 4.9648]],

         [[ 4.3320]],

         [[ 0.9180]],

         [[ 3.1914]],

         [[-1.0029]],

         [[-3.6797]],

         [[ 0.6777]],

         [[ 0.6050]],

         [[ 1.3389]],

         [[-4.1367]],

         [[-1.3652]],

         [[ 0.1721]],

         [[ 4.4688]],

         [[ 4.5234]],

         [[ 0.9390]],

         [[-1.3086]],

         [[ 2.9375]],

         [[-0.1514]],

         [[-1.7979]],

         [[ 4.0078]],

         [[ 2.8340]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 35, 1, 1]), dtype=torch.float16)
tensor([[[[-0.5908]],

         [[ 5.8477]],

         [[-1.4766]],

         [[ 3.6152]],

         [[-3.1191]],

         [[-0.0442]],

         [[ 1.6357]],

         [[-0.0437]],

         [[ 0.8599]],

         [[ 0.1161]],

         [[-3.9902]],

         [[ 3.0645]],

         [[-1.8936]],

         [[ 3.4512]],

         [[ 4.9609]],

         [[ 4.3633]],

         [[ 1.0684]],

         [[ 3.2480]],

         [[-1.0352]],

         [[-3.8438]],

         [[ 0.6797]],

         [[ 0.5786]],

         [[ 1.3682]],

         [[-4.2383]],

         [[-1.3340]],

         [[ 0.1539]],

         [[ 4.6250]],

         [[ 4.6250]],

         [[ 0.9668]],

         [[-1.3408]],

         [[ 3.0410]],

         [[-0.1765]],

         [[-1.9365]],

         [[ 4.1055]],

         [[ 2.8496]]]], dtype=torch.float16)

2025-06-09 23:16:07.353618 GPU 7 128206 test begin: paddle.Tensor.expand(Tensor([1, 37, 1, 1],"float16"), list[2,37,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 37, 1, 1],"float16"), list[2,37,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 26 / 37 (70.3%)
Greatest absolute difference: 0.296875 at index (0, 4, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.8076171875 at index (0, 7, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 37, 1, 1]), dtype=torch.float16)
tensor([[[[ -3.8750]],

         [[  5.7188]],

         [[ -1.8730]],

         [[  4.9883]],

         [[-11.2422]],

         [[  2.0645]],

         [[  0.4453]],

         [[  0.1072]],

         [[ -2.4883]],

         [[  2.4004]],

         [[  7.6445]],

         [[ -0.6855]],

         [[ -5.5312]],

         [[ -0.5146]],

         [[  1.8457]],

         [[ -2.6484]],

         [[  1.4346]],

         [[  0.4673]],

         [[  2.7461]],

         [[ -1.4414]],

         [[ -0.9019]],

         [[  1.2461]],

         [[ -1.9863]],

         [[  5.5703]],

         [[  0.1301]],

         [[ -3.5312]],

         [[  3.5156]],

         [[ -1.7520]],

         [[  4.7109]],

         [[  0.8149]],

         [[  4.0820]],

         [[  3.0586]],

         [[ -1.2637]],

         [[  1.6133]],

         [[  0.4370]],

         [[  5.6875]],

         [[ -0.7573]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 37, 1, 1]), dtype=torch.float16)
tensor([[[[ -3.9961]],

         [[  5.8008]],

         [[ -1.8604]],

         [[  5.1016]],

         [[-11.5391]],

         [[  2.0645]],

         [[  0.4680]],

         [[  0.0593]],

         [[ -2.5664]],

         [[  2.4219]],

         [[  7.7734]],

         [[ -0.6494]],

         [[ -5.6211]],

         [[ -0.5586]],

         [[  1.9160]],

         [[ -2.7754]],

         [[  1.3730]],

         [[  0.4299]],

         [[  2.7793]],

         [[ -1.4658]],

         [[ -0.9502]],

         [[  1.2891]],

         [[ -2.0527]],

         [[  5.6172]],

         [[  0.1573]],

         [[ -3.5781]],

         [[  3.5605]],

         [[ -1.7988]],

         [[  4.8906]],

         [[  0.9053]],

         [[  4.0898]],

         [[  3.0859]],

         [[ -1.3311]],

         [[  1.6377]],

         [[  0.4333]],

         [[  5.8477]],

         [[ -0.7310]]]], dtype=torch.float16)

2025-06-09 23:16:07.380426 GPU 7 128200 test begin: paddle.Tensor.expand(Tensor([1, 38, 1, 1],"float16"), list[2,38,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 38, 1, 1],"float16"), list[2,38,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 33 / 38 (86.8%)
Greatest absolute difference: 0.21875 at index (0, 21, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.2415771484375 at index (0, 25, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 38, 1, 1]), dtype=torch.float16)
tensor([[[[ 6.1328]],

         [[-3.4297]],

         [[ 2.0859]],

         [[ 2.0605]],

         [[-1.9648]],

         [[-1.0635]],

         [[ 1.0195]],

         [[ 2.7051]],

         [[ 3.0762]],

         [[-4.5664]],

         [[ 0.4478]],

         [[-5.2578]],

         [[-4.3125]],

         [[-0.8823]],

         [[ 0.4392]],

         [[-1.5020]],

         [[ 3.0059]],

         [[-3.6758]],

         [[ 3.7734]],

         [[ 3.4336]],

         [[ 1.2656]],

         [[10.2656]],

         [[ 2.0742]],

         [[ 2.2773]],

         [[-5.2148]],

         [[-0.0962]],

         [[ 4.8125]],

         [[-0.7314]],

         [[ 5.2734]],

         [[-2.6367]],

         [[ 1.9541]],

         [[-0.2388]],

         [[-6.7227]],

         [[-7.7578]],

         [[-6.3477]],

         [[ 3.2109]],

         [[ 1.2695]],

         [[-2.2129]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 38, 1, 1]), dtype=torch.float16)
tensor([[[[ 6.2148]],

         [[-3.4883]],

         [[ 2.1367]],

         [[ 2.1484]],

         [[-2.0117]],

         [[-1.1230]],

         [[ 1.0430]],

         [[ 2.8008]],

         [[ 3.0977]],

         [[-4.6836]],

         [[ 0.5078]],

         [[-5.4102]],

         [[-4.4727]],

         [[-0.9121]],

         [[ 0.4324]],

         [[-1.5508]],

         [[ 3.0586]],

         [[-3.7578]],

         [[ 3.8047]],

         [[ 3.5020]],

         [[ 1.3447]],

         [[10.4844]],

         [[ 2.1445]],

         [[ 2.3340]],

         [[-5.3477]],

         [[-0.1268]],

         [[ 4.8516]],

         [[-0.7246]],

         [[ 5.3516]],

         [[-2.7754]],

         [[ 2.0176]],

         [[-0.2812]],

         [[-6.8789]],

         [[-7.9258]],

         [[-6.5078]],

         [[ 3.2715]],

         [[ 1.3145]],

         [[-2.3711]]]], dtype=torch.float16)

2025-06-09 23:16:07.390967 GPU 7 128180 test begin: paddle.Tensor.expand(Tensor([1, 39, 1, 1],"float16"), list[2,39,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 39, 1, 1],"float16"), list[2,39,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 24 / 39 (61.5%)
Greatest absolute difference: 0.140625 at index (0, 6, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 5.62109375 at index (0, 4, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 39, 1, 1]), dtype=torch.float16)
tensor([[[[ 7.3398]],

         [[ 2.4648]],

         [[-1.2891]],

         [[-1.3027]],

         [[-0.0757]],

         [[ 2.9688]],

         [[ 6.5938]],

         [[-0.1030]],

         [[-2.1387]],

         [[ 1.1709]],

         [[ 2.3867]],

         [[-1.5371]],

         [[-2.4316]],

         [[ 2.1680]],

         [[-1.3652]],

         [[-4.2891]],

         [[ 1.1592]],

         [[-4.9961]],

         [[-5.5859]],

         [[-1.3184]],

         [[ 0.7568]],

         [[ 1.2168]],

         [[ 6.5664]],

         [[ 0.7065]],

         [[ 2.3301]],

         [[ 0.3115]],

         [[ 1.3789]],

         [[-0.8047]],

         [[-1.0195]],

         [[ 4.6016]],

         [[ 0.3323]],

         [[ 2.0312]],

         [[-4.6562]],

         [[-3.9219]],

         [[-1.9355]],

         [[-1.1445]],

         [[-1.2344]],

         [[-1.3574]],

         [[-2.3672]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 39, 1, 1]), dtype=torch.float16)
tensor([[[[ 7.4531]],

         [[ 2.4688]],

         [[-1.3457]],

         [[-1.3799]],

         [[-0.0114]],

         [[ 2.9980]],

         [[ 6.7344]],

         [[-0.0924]],

         [[-2.1660]],

         [[ 1.1504]],

         [[ 2.3926]],

         [[-1.5703]],

         [[-2.4766]],

         [[ 2.2305]],

         [[-1.3828]],

         [[-4.3203]],

         [[ 1.2051]],

         [[-5.1016]],

         [[-5.7227]],

         [[-1.3662]],

         [[ 0.7993]],

         [[ 1.2520]],

         [[ 6.6211]],

         [[ 0.7700]],

         [[ 2.4609]],

         [[ 0.3442]],

         [[ 1.3789]],

         [[-0.8882]],

         [[-1.0850]],

         [[ 4.6875]],

         [[ 0.3088]],

         [[ 1.9980]],

         [[-4.6875]],

         [[-3.9707]],

         [[-1.9463]],

         [[-1.1650]],

         [[-1.2490]],

         [[-1.4053]],

         [[-2.4473]]]], dtype=torch.float16)

2025-06-09 23:16:07.394144 GPU 6 128202 test begin: paddle.Tensor.expand(Tensor([1, 45, 1, 1],"float16"), list[2,45,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 45, 1, 1],"float16"), list[2,45,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 30 / 45 (66.7%)
Greatest absolute difference: 0.1796875 at index (0, 30, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.2393798828125 at index (0, 40, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 45, 1, 1]), dtype=torch.float16)
tensor([[[[-1.8057]],

         [[ 1.2334]],

         [[-2.5059]],

         [[-2.9258]],

         [[-4.4648]],

         [[ 1.3066]],

         [[ 0.3201]],

         [[ 1.5908]],

         [[ 2.0098]],

         [[ 2.1699]],

         [[ 0.4705]],

         [[-2.6445]],

         [[ 0.7734]],

         [[-3.1992]],

         [[ 2.5977]],

         [[-3.8926]],

         [[ 2.4102]],

         [[ 3.3516]],

         [[ 1.8789]],

         [[ 2.5449]],

         [[-1.0479]],

         [[-3.4199]],

         [[-1.0381]],

         [[-2.6035]],

         [[-0.4163]],

         [[-0.2903]],

         [[-3.4863]],

         [[ 2.4961]],

         [[-1.6348]],

         [[ 2.1309]],

         [[ 3.6230]],

         [[-5.4023]],

         [[ 6.4766]],

         [[ 1.8066]],

         [[-7.5078]],

         [[ 2.8047]],

         [[ 2.6797]],

         [[-3.0059]],

         [[ 2.0957]],

         [[-3.8496]],

         [[-0.1283]],

         [[-2.1191]],

         [[-0.8682]],

         [[ 2.2402]],

         [[ 4.6523]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 45, 1, 1]), dtype=torch.float16)
tensor([[[[-1.7930]],

         [[ 1.2881]],

         [[-2.4844]],

         [[-3.0059]],

         [[-4.5156]],

         [[ 1.3750]],

         [[ 0.3674]],

         [[ 1.5361]],

         [[ 2.1152]],

         [[ 2.2402]],

         [[ 0.5259]],

         [[-2.6484]],

         [[ 0.7754]],

         [[-3.1211]],

         [[ 2.5918]],

         [[-3.9902]],

         [[ 2.4570]],

         [[ 3.3672]],

         [[ 1.9287]],

         [[ 2.5488]],

         [[-1.0459]],

         [[-3.4219]],

         [[-1.1094]],

         [[-2.6641]],

         [[-0.4207]],

         [[-0.3052]],

         [[-3.5996]],

         [[ 2.5508]],

         [[-1.6387]],

         [[ 2.0684]],

         [[ 3.8027]],

         [[-5.4961]],

         [[ 6.5664]],

         [[ 1.8398]],

         [[-7.6523]],

         [[ 2.8242]],

         [[ 2.7617]],

         [[-3.0547]],

         [[ 2.1914]],

         [[-3.8926]],

         [[-0.1035]],

         [[-2.2090]],

         [[-0.8599]],

         [[ 2.3320]],

         [[ 4.7617]]]], dtype=torch.float16)

2025-06-09 23:16:07.410891 GPU 7 128188 test begin: paddle.Tensor.expand(Tensor([1, 50, 1, 1],"float16"), list[2,50,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 50, 1, 1],"float16"), list[2,50,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 32 / 50 (64.0%)
Greatest absolute difference: 0.197265625 at index (0, 35, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.4013671875 at index (0, 15, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 50, 1, 1]), dtype=torch.float16)
tensor([[[[-1.3613]],

         [[ 0.5005]],

         [[ 0.9971]],

         [[ 2.2285]],

         [[ 2.1289]],

         [[-1.6172]],

         [[ 4.6211]],

         [[-5.1250]],

         [[-0.9307]],

         [[-1.9639]],

         [[-3.8945]],

         [[ 6.9141]],

         [[ 3.2656]],

         [[-2.0742]],

         [[-1.4854]],

         [[-0.0737]],

         [[-1.8711]],

         [[-3.7383]],

         [[ 6.8906]],

         [[ 3.5781]],

         [[ 0.3010]],

         [[-0.9453]],

         [[ 4.8477]],

         [[ 0.1260]],

         [[ 5.8594]],

         [[ 1.6943]],

         [[-3.3340]],

         [[ 1.5908]],

         [[ 0.6460]],

         [[ 0.5938]],

         [[ 2.6816]],

         [[ 2.8516]],

         [[ 1.2061]],

         [[ 2.3027]],

         [[ 3.4980]],

         [[-3.4551]],

         [[ 0.7905]],

         [[ 0.7363]],

         [[ 0.8008]],

         [[-4.3633]],

         [[-0.3252]],

         [[-0.6748]],

         [[ 3.3281]],

         [[-0.8584]],

         [[-0.4729]],

         [[-0.8022]],

         [[ 4.0820]],

         [[ 2.3867]],

         [[ 0.2161]],

         [[ 2.9199]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 50, 1, 1]), dtype=torch.float16)
tensor([[[[-1.3447]],

         [[ 0.5122]],

         [[ 1.0312]],

         [[ 2.2734]],

         [[ 2.2031]],

         [[-1.6455]],

         [[ 4.6680]],

         [[-5.2930]],

         [[-0.8472]],

         [[-1.9785]],

         [[-4.0039]],

         [[ 7.0352]],

         [[ 3.3438]],

         [[-2.1016]],

         [[-1.5264]],

         [[-0.0526]],

         [[-1.8633]],

         [[-3.8105]],

         [[ 7.0273]],

         [[ 3.6562]],

         [[ 0.3079]],

         [[-0.8750]],

         [[ 4.9180]],

         [[ 0.1580]],

         [[ 6.0195]],

         [[ 1.7783]],

         [[-3.4199]],

         [[ 1.5850]],

         [[ 0.6221]],

         [[ 0.6353]],

         [[ 2.7168]],

         [[ 2.8750]],

         [[ 1.2285]],

         [[ 2.3320]],

         [[ 3.5801]],

         [[-3.6523]],

         [[ 0.8066]],

         [[ 0.7915]],

         [[ 0.8867]],

         [[-4.3945]],

         [[-0.2896]],

         [[-0.6538]],

         [[ 3.4023]],

         [[-0.8647]],

         [[-0.4629]],

         [[-0.7856]],

         [[ 4.1250]],

         [[ 2.4492]],

         [[ 0.1783]],

         [[ 2.9102]]]], dtype=torch.float16)

2025-06-09 23:16:07.417281 GPU 5 128190 test begin: paddle.Tensor.expand(Tensor([1, 51, 1, 1],"float16"), list[2,51,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 51, 1, 1],"float16"), list[2,51,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 35 / 51 (68.6%)
Greatest absolute difference: 0.17578125 at index (0, 16, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.1920166015625 at index (0, 25, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 51, 1, 1]), dtype=torch.float16)
tensor([[[[ 1.5615]],

         [[-2.1758]],

         [[-4.0742]],

         [[ 2.2441]],

         [[-4.5625]],

         [[-3.3633]],

         [[ 2.3633]],

         [[ 0.4912]],

         [[ 0.4185]],

         [[-1.4902]],

         [[-1.3525]],

         [[-0.4717]],

         [[ 0.5928]],

         [[ 2.8613]],

         [[ 2.2383]],

         [[ 6.6445]],

         [[ 7.9805]],

         [[ 4.2070]],

         [[ 7.0820]],

         [[-2.4609]],

         [[ 8.9141]],

         [[ 5.1992]],

         [[-4.5742]],

         [[-1.0127]],

         [[ 2.1777]],

         [[ 0.1630]],

         [[ 2.0547]],

         [[-2.4355]],

         [[ 0.5020]],

         [[-1.9561]],

         [[-7.2500]],

         [[ 5.9453]],

         [[-3.0195]],

         [[ 1.3477]],

         [[-2.8340]],

         [[ 1.4893]],

         [[ 0.3164]],

         [[ 0.8813]],

         [[-0.4050]],

         [[ 2.1699]],

         [[ 0.6743]],

         [[-0.5835]],

         [[-5.4180]],

         [[-4.2656]],

         [[ 0.6133]],

         [[ 5.1094]],

         [[-3.8340]],

         [[ 0.8623]],

         [[ 2.7461]],

         [[ 2.8457]],

         [[-1.6680]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 51, 1, 1]), dtype=torch.float16)
tensor([[[[ 1.5430]],

         [[-2.2148]],

         [[-4.1562]],

         [[ 2.2773]],

         [[-4.6055]],

         [[-3.4824]],

         [[ 2.4297]],

         [[ 0.4573]],

         [[ 0.4563]],

         [[-1.5254]],

         [[-1.3457]],

         [[-0.4714]],

         [[ 0.6172]],

         [[ 2.9082]],

         [[ 2.2910]],

         [[ 6.7695]],

         [[ 8.1562]],

         [[ 4.3594]],

         [[ 7.2109]],

         [[-2.4629]],

         [[ 9.0703]],

         [[ 5.3516]],

         [[-4.6406]],

         [[-1.0127]],

         [[ 2.1797]],

         [[ 0.1367]],

         [[ 2.0645]],

         [[-2.5137]],

         [[ 0.4932]],

         [[-2.0508]],

         [[-7.3555]],

         [[ 6.0664]],

         [[-3.0703]],

         [[ 1.3730]],

         [[-2.8711]],

         [[ 1.4629]],

         [[ 0.2781]],

         [[ 0.8804]],

         [[-0.4424]],

         [[ 2.1875]],

         [[ 0.7256]],

         [[-0.5791]],

         [[-5.5664]],

         [[-4.3281]],

         [[ 0.5815]],

         [[ 5.2070]],

         [[-3.8711]],

         [[ 0.8779]],

         [[ 2.8105]],

         [[ 2.8770]],

         [[-1.6396]]]], dtype=torch.float16)

2025-06-09 23:16:07.426765 GPU 4 128203 test begin: paddle.Tensor.expand(Tensor([1, 52, 1, 1],"float16"), list[2,52,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 52, 1, 1],"float16"), list[2,52,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 43 / 52 (82.7%)
Greatest absolute difference: 0.19921875 at index (0, 41, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.701171875 at index (0, 33, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 52, 1, 1]), dtype=torch.float16)
tensor([[[[ 3.4551]],

         [[ 2.4219]],

         [[ 5.3594]],

         [[-3.8633]],

         [[ 5.0586]],

         [[ 6.3906]],

         [[ 3.3652]],

         [[-2.5840]],

         [[-1.3320]],

         [[ 1.4072]],

         [[ 4.5234]],

         [[-3.7129]],

         [[-3.2852]],

         [[-4.2305]],

         [[ 0.1550]],

         [[ 7.1914]],

         [[-5.7344]],

         [[-4.0117]],

         [[-2.5996]],

         [[ 0.5767]],

         [[ 0.7749]],

         [[-4.1484]],

         [[-0.7363]],

         [[-6.0586]],

         [[ 3.2754]],

         [[ 2.2441]],

         [[-0.6733]],

         [[ 5.4531]],

         [[-3.0449]],

         [[ 1.8359]],

         [[-1.3838]],

         [[-1.4658]],

         [[-1.7686]],

         [[ 0.0088]],

         [[-3.8633]],

         [[ 1.0586]],

         [[-2.2734]],

         [[ 2.3359]],

         [[ 0.8613]],

         [[-0.5254]],

         [[-2.5371]],

         [[ 5.0352]],

         [[ 0.1660]],

         [[ 2.1387]],

         [[-4.0000]],

         [[-0.4661]],

         [[-3.4746]],

         [[ 1.2354]],

         [[ 1.2861]],

         [[-6.1289]],

         [[-1.9209]],

         [[ 2.6543]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 52, 1, 1]), dtype=torch.float16)
tensor([[[[ 3.5508]],

         [[ 2.4766]],

         [[ 5.4844]],

         [[-3.9297]],

         [[ 5.1992]],

         [[ 6.5391]],

         [[ 3.4043]],

         [[-2.6816]],

         [[-1.4414]],

         [[ 1.4990]],

         [[ 4.6250]],

         [[-3.8770]],

         [[-3.4141]],

         [[-4.3359]],

         [[ 0.1696]],

         [[ 7.2969]],

         [[-5.8398]],

         [[-4.0898]],

         [[-2.6777]],

         [[ 0.6235]],

         [[ 0.7959]],

         [[-4.1836]],

         [[-0.7480]],

         [[-6.2188]],

         [[ 3.3730]],

         [[ 2.2285]],

         [[-0.6680]],

         [[ 5.5273]],

         [[-3.0938]],

         [[ 1.8369]],

         [[-1.3506]],

         [[-1.5176]],

         [[-1.7949]],

         [[ 0.0294]],

         [[-3.9160]],

         [[ 1.1299]],

         [[-2.3301]],

         [[ 2.4570]],

         [[ 0.8804]],

         [[-0.5493]],

         [[-2.5957]],

         [[ 5.2344]],

         [[ 0.1492]],

         [[ 2.1582]],

         [[-4.1445]],

         [[-0.4680]],

         [[-3.5234]],

         [[ 1.2842]],

         [[ 1.2549]],

         [[-6.2383]],

         [[-1.9971]],

         [[ 2.7344]]]], dtype=torch.float16)

2025-06-09 23:16:07.433559 GPU 5 128184 test begin: paddle.Tensor.expand(Tensor([1, 57, 1, 1],"float16"), list[2,57,1,64,], )
[accuracy error] backward  paddle.Tensor.expand(Tensor([1, 57, 1, 1],"float16"), list[2,57,1,64,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 43 / 57 (75.4%)
Greatest absolute difference: 0.296875 at index (0, 13, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.4404296875 at index (0, 15, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 57, 1, 1]), dtype=torch.float16)
tensor([[[[-3.3535]],

         [[-2.7891]],

         [[ 1.3232]],

         [[ 4.3398]],

         [[ 4.9688]],

         [[-4.2578]],

         [[-1.1064]],

         [[ 2.6836]],

         [[-0.8174]],

         [[-3.2148]],

         [[-3.8027]],

         [[ 3.6250]],

         [[ 0.4829]],

         [[ 9.1094]],

         [[ 1.8613]],

         [[-0.0739]],

         [[-2.1719]],

         [[ 4.1367]],

         [[ 3.1973]],

         [[-0.5498]],

         [[-2.9141]],

         [[ 0.9932]],

         [[ 4.3359]],

         [[ 0.5889]],

         [[ 1.2266]],

         [[ 4.5117]],

         [[ 0.5552]],

         [[ 2.1309]],

         [[-4.0039]],

         [[-1.7676]],

         [[ 2.0273]],

         [[-3.5723]],

         [[ 7.3359]],

         [[ 4.1445]],

         [[ 3.8281]],

         [[-1.3535]],

         [[-3.6387]],

         [[-0.3826]],

         [[ 1.6504]],

         [[-5.1094]],

         [[-3.1055]],

         [[ 3.6270]],

         [[-0.4697]],

         [[-0.9448]],

         [[-0.9121]],

         [[ 2.6113]],

         [[ 5.5234]],

         [[-2.1309]],

         [[-4.3125]],

         [[ 2.2109]],

         [[-2.7344]],

         [[-0.9951]],

         [[ 1.4766]],

         [[ 2.4395]],

         [[ 4.0312]],

         [[-0.4841]],

         [[ 0.5132]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 57, 1, 1]), dtype=torch.float16)
tensor([[[[-3.3809]],

         [[-2.8457]],

         [[ 1.3291]],

         [[ 4.4258]],

         [[ 5.0430]],

         [[-4.3828]],

         [[-1.0850]],

         [[ 2.7324]],

         [[-0.8433]],

         [[-3.2363]],

         [[-3.8809]],

         [[ 3.6680]],

         [[ 0.5420]],

         [[ 9.4062]],

         [[ 1.9395]],

         [[-0.1321]],

         [[-2.2344]],

         [[ 4.2148]],

         [[ 3.3145]],

         [[-0.5811]],

         [[-2.9531]],

         [[ 0.9956]],

         [[ 4.4336]],

         [[ 0.5835]],

         [[ 1.2539]],

         [[ 4.6641]],

         [[ 0.6401]],

         [[ 2.0957]],

         [[-4.1211]],

         [[-1.8379]],

         [[ 2.0430]],

         [[-3.6465]],

         [[ 7.4727]],

         [[ 4.2461]],

         [[ 3.9219]],

         [[-1.3672]],

         [[-3.7012]],

         [[-0.3848]],

         [[ 1.6348]],

         [[-5.1875]],

         [[-3.1367]],

         [[ 3.7539]],

         [[-0.4902]],

         [[-0.9673]],

         [[-0.9336]],

         [[ 2.7090]],

         [[ 5.5742]],

         [[-2.1797]],

         [[-4.3984]],

         [[ 2.2773]],

         [[-2.8340]],

         [[-1.0244]],

         [[ 1.4902]],

         [[ 2.5156]],

         [[ 4.1523]],

         [[-0.5068]],

         [[ 0.4915]]]], dtype=torch.float16)

2025-06-09 23:16:41.878404 GPU 5 128184 test begin: paddle.add_n(list[Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),], )
[accuracy error] paddle.add_n(list[Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 13 / 4096 (0.3%)
Greatest absolute difference: 0.0263671875 at index (0, 148) (up to 0.01 allowed)
Greatest relative difference: 1.802734375 at index (9, 81) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([16, 256]), dtype=torch.float16)
tensor([[ 3.9219,  4.8125, -0.0764,  ...,  2.1660, -1.0586,  0.6768],
        [-2.8809,  0.8237, -1.7852,  ..., -0.7500,  1.9170, -0.0757],
        [-1.7461, -0.9946,  1.2793,  ...,  0.7881,  1.0400,  1.4268],
        ...,
        [ 1.5049,  1.3213,  1.0664,  ...,  0.0408,  1.9922, -2.3223],
        [ 2.0020,  0.3865, -0.9121,  ...,  0.7583, -0.0581, -0.8877],
        [ 2.6387,  2.3496,  1.1357,  ..., -1.2578,  1.9756,  0.3789]], dtype=torch.float16)
DESIRED: (shape=torch.Size([16, 256]), dtype=torch.float16)
tensor([[ 3.9414,  4.8320, -0.0774,  ...,  2.1816, -1.0664,  0.6943],
        [-2.8984,  0.8364, -1.7930,  ..., -0.7578,  1.9248, -0.0721],
        [-1.7549, -1.0039,  1.2852,  ...,  0.7910,  1.0518,  1.4287],
        ...,
        [ 1.5088,  1.3301,  1.0752,  ...,  0.0498,  1.9990, -2.3379],
        [ 2.0078,  0.3899, -0.9165,  ...,  0.7651, -0.0597, -0.8931],
        [ 2.6484,  2.3672,  1.1357,  ..., -1.2627,  1.9756,  0.3811]], dtype=torch.float16)

2025-06-09 23:16:41.883688 GPU 4 128186 test begin: paddle.add_n(list[Tensor([16, 256],"float32"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),], )
[paddle error] paddle.add_n(list[Tensor([16, 256],"float32"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),Tensor([16, 256],"float16"),], ) 
 (InvalidArgument) The type of data we are trying to retrieve (float32) does not match the type of data (float16) currently contained in the container.
  [Hint: Expected dtype() == phi::CppTypeToDataType<T>::Type(), but received dtype():15 != phi::CppTypeToDataType<T>::Type():10.] (at ../paddle/phi/core/dense_tensor.cc:153)


2025-06-09 23:16:41.884758 GPU 4 128193 test begin: paddle.broadcast_to(Tensor([1],"float16"), list[300,40,], )
[accuracy error] backward  paddle.broadcast_to(Tensor([1],"float16"), list[300,40,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 3.25 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 0.1251220703125 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1]), dtype=torch.float16)
tensor([-29.2188], dtype=torch.float16)
DESIRED: (shape=torch.Size([1]), dtype=torch.float16)
tensor([-25.9688], dtype=torch.float16)

2025-06-09 23:16:41.886352 GPU 4 128195 test begin: paddle.broadcast_to(Tensor([1],"float16"), list[6,8,9,18,], )
[accuracy error] backward  paddle.broadcast_to(Tensor([1],"float16"), list[6,8,9,18,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 24.953125 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 0.69677734375 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1]), dtype=torch.float16)
tensor([10.8594], dtype=torch.float16)
DESIRED: (shape=torch.Size([1]), dtype=torch.float16)
tensor([35.8125], dtype=torch.float16)

2025-06-09 23:16:41.890466 GPU 4 128203 test begin: paddle.broadcast_to(Tensor([300, 1],"float16"), list[300,40,], )
[accuracy error] backward  paddle.broadcast_to(Tensor([300, 1],"float16"), list[300,40,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 300 (1.0%)
Greatest absolute difference: 0.02105712890625 at index (189, 0) (up to 0.01 allowed)
Greatest relative difference: 0.248046875 at index (203, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([300, 1]), dtype=torch.float16)
tensor([[ 1.0215],
        [-0.2727],
        [ 0.0853],
        ...,
        [ 0.1956],
        [ 1.2031],
        [ 2.4414]], dtype=torch.float16)
DESIRED: (shape=torch.Size([300, 1]), dtype=torch.float16)
tensor([[ 1.0361],
        [-0.2715],
        [ 0.0797],
        ...,
        [ 0.1942],
        [ 1.2139],
        [ 2.4609]], dtype=torch.float16)

2025-06-09 23:16:41.901440 GPU 6 128199 test begin: paddle.broadcast_to(Tensor([],"float16"), list[11008,], )
[accuracy error] backward  paddle.broadcast_to(Tensor([],"float16"), list[11008,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected 4.8671875 but got -10.3828125.
Absolute difference: 15.25 (up to 0.01 allowed)
Relative difference: 3.13322632423756 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
-10.3828125
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
4.8671875

2025-06-09 23:16:41.902568 GPU 5 128198 test begin: paddle.broadcast_to(Tensor([],"float16"), list[168,], )
[accuracy error] backward  paddle.broadcast_to(Tensor([],"float16"), list[168,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected -2.30078125 but got -2.234375.
Absolute difference: 0.06640625 (up to 0.01 allowed)
Relative difference: 0.028862478777589132 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
-2.234375
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
-2.30078125

2025-06-09 23:16:41.905760 GPU 4 128182 test begin: paddle.broadcast_to(Tensor([],"float16"), list[300,40,], )
[accuracy error] backward  paddle.broadcast_to(Tensor([],"float16"), list[300,40,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected -20.25 but got -21.4375.
Absolute difference: 1.1875 (up to 0.01 allowed)
Relative difference: 0.05864197530864197 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
-21.4375
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
-20.25

2025-06-09 23:16:41.908369 GPU 7 128188 test begin: paddle.cast(Tensor([20, 500, 2],"int32"), dtype=Dtype(float16), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.cast(Tensor([20, 500, 2],"int32"), dtype=Dtype(float16), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 5 / 20000 (0.0%)
Greatest absolute difference: inf at index (0, 488, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 488, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([20, 500, 2]), dtype=torch.float16)
tensor([[[-38048., -38304.],
         [-23664.,  17072.],
         [ 39488.,  39360.],
         ...,
         [-28864.,   2414.],
         [ -1910., -36352.],
         [ 19776.,  54208.]],

        [[-65440., -36832.],
         [ 27216.,  48608.],
         [-61664., -41568.],
         ...,
         [-25024., -25792.],
         [-21008.,   8272.],
         [ -4836., -58432.]],

        [[ 17264.,  18544.],
         [ 28784.,  62304.],
         [  9864.,  44992.],
         ...,
         [  -228., -55008.],
         [-57920.,  54752.],
         [-35072.,  13904.]],

        ...,

        [[ 51648., -16464.],
         [ 52480.,  -2990.],
         [-26672.,  17376.],
         ...,
         [ -4892.,  -1989.],
         [-34848., -43040.],
         [ 44992.,   8792.]],

        [[  3222., -20544.],
         [ -6276.,  42272.],
         [-22240., -25728.],
         ...,
         [ -6876.,  -2366.],
         [ 53600.,    899.],
         [ 29440.,  17536.]],

        [[  4128., -11832.],
         [-19568.,  48096.],
         [ -6452.,  52192.],
         ...,
         [-15304.,  41792.],
         [ -4552.,   5648.],
         [-51296., -40928.]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([20, 500, 2]), dtype=torch.float16)
tensor([[[-38048., -38304.],
         [-23664.,  17072.],
         [ 39488.,  39392.],
         ...,
         [-28864.,   2416.],
         [ -1910., -36352.],
         [ 19776.,  54240.]],

        [[-65472., -36864.],
         [ 27216.,  48640.],
         [-61664., -41600.],
         ...,
         [-25024., -25792.],
         [-21008.,   8280.],
         [ -4836., -58432.]],

        [[ 17280.,  18544.],
         [ 28800.,  62336.],
         [  9864.,  45024.],
         ...,
         [  -228., -55040.],
         [-57920.,  54784.],
         [-35072.,  13912.]],

        ...,

        [[ 51648., -16464.],
         [ 52512.,  -2992.],
         [-26672.,  17376.],
         ...,
         [ -4892.,  -1989.],
         [-34880., -43072.],
         [ 44992.,   8792.]],

        [[  3222., -20560.],
         [ -6280.,  42272.],
         [-22240., -25728.],
         ...,
         [ -6876.,  -2368.],
         [ 53632.,    899.],
         [ 29440.,  17552.]],

        [[  4128., -11832.],
         [-19568.,  48096.],
         [ -6456.,  52192.],
         ...,
         [-15312.,  41824.],
         [ -4552.,   5648.],
         [-51328., -40960.]]], dtype=torch.float16)

2025-06-09 23:16:41.909846 GPU 4 128204 test begin: paddle.cast(Tensor([20, 500, 4],"int32"), dtype=Dtype(float16), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.cast(Tensor([20, 500, 4],"int32"), dtype=Dtype(float16), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 9 / 40000 (0.0%)
Greatest absolute difference: inf at index (1, 138, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 138, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([20, 500, 4]), dtype=torch.float16)
tensor([[[-25664.,  64064., -46720.,  56832.],
         [ 64256.,  29136., -55264.,  35456.],
         [ 54496.,   6348., -36576.,   3174.],
         ...,
         [ 49344.,  32832.,  54112., -28240.],
         [-18816., -36704.,  52448., -16328.],
         [ 26288.,  14496., -27664., -44736.]],

        [[-20048.,  15688., -55104.,  54720.],
         [ 37984., -46432.,   8976.,  33504.],
         [  4436., -24736.,  14112., -33664.],
         ...,
         [ 48192.,  -4840., -50144., -22368.],
         [ 24080.,  18288., -15632.,  20336.],
         [-61664.,  43328., -10464.,  65280.]],

        [[-29440., -48224., -61024., -21888.],
         [-54464.,  28752., -43968., -42336.],
         [ 57472., -22608., -50208.,   9248.],
         ...,
         [ 25344.,  27520.,  27072.,  13888.],
         [  7732., -41984.,   7448.,  37760.],
         [ 20592.,  57856.,  61440.,   5656.]],

        ...,

        [[ 29056.,  28128.,  57312., -63808.],
         [ 62592.,  58048., -14088.,  41280.],
         [-22320., -58336., -48608., -22592.],
         ...,
         [ 59424.,  50624., -21040.,  56896.],
         [ 55072.,  32720., -32176., -31024.],
         [ 39360.,   1341.,  37632., -11136.]],

        [[ 27936., -28816.,   7040., -11760.],
         [ -1965.,  48512.,  10776.,  23280.],
         [ 17056., -42496.,  39712.,    -inf],
         ...,
         [ -3800.,  -2900., -34720.,   2360.],
         [-16384., -18624.,  19072., -46528.],
         [ 49184., -34784.,  10984.,  27248.]],

        [[ 57312., -39392., -35200.,  32768.],
         [ 10712., -63872.,  52896., -36640.],
         [-57632., -60992.,  -2204.,  27296.],
         ...,
         [ 11432.,  50944.,  -9736.,  28992.],
         [ 64960.,  63296.,  56160.,  25744.],
         [-53440., -54176.,  25904., -15760.]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([20, 500, 4]), dtype=torch.float16)
tensor([[[-25664.,  64096., -46720.,  56832.],
         [ 64288.,  29136., -55296.,  35456.],
         [ 54528.,   6348., -36576.,   3174.],
         ...,
         [ 49344.,  32864.,  54144., -28256.],
         [-18832., -36704.,  52480., -16336.],
         [ 26288.,  14504., -27664., -44736.]],

        [[-20048.,  15688., -55104.,  54752.],
         [ 37984., -46464.,   8976.,  33536.],
         [  4436., -24752.,  14120., -33664.],
         ...,
         [ 48224.,  -4840., -50176., -22368.],
         [ 24080.,  18304., -15632.,  20336.],
         [-61664.,  43360., -10472.,  65312.]],

        [[-29440., -48256., -61056., -21904.],
         [-54464.,  28752., -44000., -42368.],
         [ 57504., -22624., -50208.,   9256.],
         ...,
         [ 25344.,  27520.,  27072.,  13896.],
         [  7732., -42016.,   7448.,  37760.],
         [ 20608.,  57856.,  61440.,   5656.]],

        ...,

        [[ 29056.,  28128.,  57312., -63808.],
         [ 62592.,  58048., -14088.,  41312.],
         [-22320., -58336., -48608., -22608.],
         ...,
         [ 59456.,  50624., -21056.,  56896.],
         [ 55072.,  32720., -32192., -31024.],
         [ 39360.,   1341.,  37664., -11144.]],

        [[ 27936., -28816.,   7040., -11760.],
         [ -1965.,  48512.,  10784.,  23280.],
         [ 17056., -42496.,  39744.,    -inf],
         ...,
         [ -3800.,  -2900., -34752.,   2360.],
         [-16384., -18624.,  19072., -46560.],
         [ 49184., -34784.,  10984.,  27248.]],

        [[ 57312., -39392., -35232.,  32800.],
         [ 10712., -63904.,  52928., -36672.],
         [-57632., -60992.,  -2204.,  27296.],
         ...,
         [ 11432.,  50944.,  -9744.,  28992.],
         [ 64992.,  63328.,  56160.,  25744.],
         [-53440., -54176.,  25904., -15760.]]], dtype=torch.float16)

2025-06-09 23:16:41.911246 GPU 5 128190 test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=None, axis=-1, )
Warning: The core code of paddle.cumulative_trapezoid is too complex.
[accuracy error] backward  paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 6 (50.0%)
Greatest absolute difference: 0.15579813718795776 at index (1, 2) (up to 0.01 allowed)
Greatest relative difference: 6.8823323249816895 at index (1, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[0.1543, 0.3327, 0.1784],
        [0.1543, 0.3327, 0.1784]])
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[0.1543, 0.3327, 0.1784],
        [0.2590, 0.2817, 0.0226]])

2025-06-09 23:16:41.951932 GPU 6 128183 test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, )
Warning: The core code of paddle.cumulative_trapezoid is too complex.
[accuracy error] backward  paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 6 (50.0%)
Greatest absolute difference: 0.13130873441696167 at index (1, 1) (up to 0.01 allowed)
Greatest relative difference: 1.1236340999603271 at index (1, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[ 0.1236,  0.1005, -0.0231],
        [ 0.1236,  0.1005, -0.0231]])
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[ 0.1236,  0.1005, -0.0231],
        [ 0.2427,  0.2319, -0.0109]])

2025-06-09 23:16:41.991768 GPU 5 128179 test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=None, dx=None, axis=-1, )
Warning: The core code of paddle.cumulative_trapezoid is too complex.
W0609 23:16:42.107234 128179 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] backward  paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=None, dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 6 (50.0%)
Greatest absolute difference: 0.6443680770136986 at index (1, 1) (up to 0.01 allowed)
Greatest relative difference: 3.081234737122416 at index (1, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[-0.2367, -0.3300, -0.0933],
        [-0.2367, -0.3300, -0.0933]], dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[-0.2367, -0.3300, -0.0933],
        [ 0.2695,  0.3143,  0.0448]], dtype=torch.float64)

2025-06-09 23:16:41.999470 GPU 7 128180 test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
Warning: The core code of paddle.cumulative_trapezoid is too complex.
[accuracy error] backward  paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 6 (50.0%)
Greatest absolute difference: 0.0880245683923466 at index (1, 2) (up to 0.01 allowed)
Greatest relative difference: 3.5526075368205214 at index (1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[ 0.0464,  0.0325, -0.0139],
        [ 0.0464,  0.0325, -0.0139]], dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[ 0.0464,  0.0325, -0.0139],
        [-0.0182,  0.0560,  0.0741]], dtype=torch.float64)

2025-06-09 23:16:42.105468 GPU 4 128186 test begin: paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
Warning: The core code of paddle.cumulative_trapezoid is too complex.
[accuracy error] backward  paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 21 / 36 (58.3%)
Greatest absolute difference: 0.1856607347726822 at index (1, 1, 3) (up to 0.01 allowed)
Greatest relative difference: 94.80085754394531 at index (2, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3, 4]), dtype=torch.float32)
tensor([[[-0.0083, -0.0034,  0.0131, -0.0134],
         [-0.0877, -0.0372,  0.0880, -0.0601],
         [-0.0793, -0.0338,  0.0749, -0.0467]],

        [[-0.0083, -0.0034,  0.0131, -0.0134],
         [-0.0877, -0.0372,  0.0880, -0.0601],
         [-0.0793, -0.0338,  0.0749, -0.0467]],

        [[-0.0083, -0.0034,  0.0131, -0.0134],
         [-0.0877, -0.0372,  0.0880, -0.0601],
         [-0.0793, -0.0338,  0.0749, -0.0467]]])
DESIRED: (shape=torch.Size([3, 3, 4]), dtype=torch.float32)
tensor([[[-0.0083, -0.0034,  0.0131, -0.0134],
         [-0.0877, -0.0372,  0.0880, -0.0601],
         [-0.0793, -0.0338,  0.0749, -0.0467]],

        [[-0.0142, -0.0218, -0.0052,  0.0321],
         [-0.0460, -0.0643, -0.0961,  0.1255],
         [-0.0317, -0.0425, -0.0909,  0.0934]],

        [[-0.0230,  0.0006,  0.0001,  0.0049],
         [-0.0675,  0.0323, -0.0750,  0.0337],
         [-0.0445,  0.0317, -0.0752,  0.0287]]])

2025-06-09 23:16:42.124340 GPU 7 128196 test begin: paddle.expand(Tensor([3, 2],"float16"), shape=list[512,3,2,], )
[accuracy error] backward  paddle.expand(Tensor([3, 2],"float16"), shape=list[512,3,2,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: 1.125 at index (2, 0) (up to 0.01 allowed)
Greatest relative difference: 0.13330078125 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 2]), dtype=torch.float16)
tensor([[  5.2305,  -1.3359],
        [ -6.1367,  -7.9102],
        [-14.5625,   8.3125]], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 2]), dtype=torch.float16)
tensor([[  6.0352,  -1.3779],
        [ -6.6953,  -8.4844],
        [-15.6875,   8.5234]], dtype=torch.float16)

2025-06-10 11:50:10.313768 GPU 3 67422 test begin: paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "add", "max", None, None, )
One of the differentiated Tensors does not require grad

2025-06-10 11:50:12.035305 GPU 3 67428 test begin: paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "add", "min", None, None, )
One of the differentiated Tensors does not require grad
malloc(): smallbin double linked list corrupted

2025-06-10 11:50:24.720028 GPU 3 67425 test begin: paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "add", "sum", None, None, )
One of the differentiated Tensors does not require grad
corrupted size vs. prev_size

2025-06-10 11:50:25.826041 GPU 3 67427 test begin: paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "mul", "mean", None, None, )
One of the differentiated Tensors does not require grad

2025-06-10 11:50:26.332787 GPU 3 67426 test begin: paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "mul", "min", None, None, )
One of the differentiated Tensors does not require grad
corrupted size vs. prev_size

2025-06-10 00:11:12.234237 GPU 6 156006 test begin: paddle.geometric.send_ue_recv(Tensor([10, 20],"float64"), Tensor([150, 1],"float64"), Tensor([150],"int64"), Tensor([150],"int64"), "mul", "sum", None, None, )
One of the differentiated Tensors does not require grad

2025-06-10 11:50:26.338039 GPU 3 67423 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "add", "mean", None, None, )
One of the differentiated Tensors does not require grad
free(): invalid next size (normal)

2025-06-10 11:50:31.834015 GPU 3 67885 test begin: paddle.geometric.send_ue_recv(Tensor([10, 8, 5],"float64"), Tensor([15, 8, 1],"float64"), Tensor([15],"int64"), Tensor([15],"int64"), "mul", "min", None, None, )
One of the differentiated Tensors does not require grad


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_send_ue_recv(_object*, _object*, _object*)
1   send_ue_recv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, std::string, std::string, paddle::experimental::IntArrayBase<paddle::Tensor>)
2   paddle::experimental::send_ue_recv_intermediate(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, std::string const&, std::string const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&)
3   void phi::GraphSendUERecvOpKernelLaunchHelper<phi::CPUContext, double, long>(phi::CPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::string const&, std::string const&, long, phi::DenseTensor*, phi::DenseTensor*)
4   GOMP_parallel

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749527446 (unix time) try "date -d @1749527446" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 67885 (TID 0x7f360f436740) from PID 0 ***]


2025-06-10 12:00:39.058224 GPU 3 78430 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([16, 256],"float32"), residual_alpha=0.69204696, )
[accuracy error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([16, 256],"float32"), residual_alpha=0.69204696, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: 2.189056396484375 at index (10,) (up to 0.01 allowed)
Greatest relative difference: 12.27008056640625 at index (10,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([16]), dtype=torch.float32)
tensor([2.1316, 2.1618, 2.0742, 2.1571, 2.0900, 2.1160, 2.1988, 2.1812, 2.1951, 2.2344, 2.3675, 2.2542, 2.1532, 2.1980,
        2.2312, 2.0873])
DESIRED: (shape=torch.Size([16]), dtype=torch.float32)
tensor([0.2201, 0.2140, 0.2324, 0.2149, 0.2289, 0.2233, 0.2068, 0.2102, 0.2075, 0.2003, 0.1784, 0.1968, 0.2157, 0.2070,
        0.2009, 0.2295])

2025-06-10 00:11:12.920402 GPU 7 156015 test begin: paddle.kron(Tensor([12, 8],"float16"), Tensor([16, 8],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([12, 8],"float16"), Tensor([16, 8],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 38 / 96 (39.6%)
Greatest absolute difference: 0.04296875 at index (2, 3) (up to 0.01 allowed)
Greatest relative difference: 1.2685546875 at index (7, 6) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([12, 8]), dtype=torch.float16)
tensor([[-0.0276,  0.2125, -1.0283, -1.3105, -0.0133, -1.2900,  0.3198, -0.0983],
        [-0.5347, -0.1968, -0.4861,  0.6089, -0.9395,  0.9224,  0.1805, -0.3774],
        [ 0.3586,  0.9873, -0.3818, -2.0039, -0.4434,  1.0039,  0.0107, -1.0371],
        [ 0.4692,  0.6948,  0.6162, -0.9829, -0.4988,  0.1801, -0.4585,  0.3508],
        [-0.2939,  0.4092,  1.1719,  0.3386, -1.2461,  0.1981,  0.1387, -1.7568],
        [ 0.7437,  1.2676,  0.0995,  0.6714, -0.4690, -1.2119, -0.1122, -0.3018],
        [-0.1501,  0.4226, -0.4634,  0.3718, -1.2559, -0.3669, -1.4072,  0.3452],
        [ 0.2192,  0.3142, -0.3005,  1.5498, -0.3752, -0.5518,  0.0273, -0.3110],
        [-1.3242,  0.8555,  0.1940, -0.0599, -0.1113,  0.5581, -0.7056, -0.0493],
        [-0.3831,  0.5898, -1.2793,  0.1301,  1.0078, -0.2593,  0.2742,  1.0791],
        [ 0.7231, -0.1375, -0.8721,  0.8262,  0.9438, -0.3013, -0.4255,  1.5840],
        [ 0.1582, -0.8101,  0.3120, -2.4805, -0.4126,  0.8584,  0.1077,  1.0137]], dtype=torch.float16)
DESIRED: (shape=torch.Size([12, 8]), dtype=torch.float16)
tensor([[-0.0159,  0.2195, -1.0557, -1.3398, -0.0273, -1.3311,  0.3521, -0.0964],
        [-0.5278, -0.2047, -0.4844,  0.6152, -0.9521,  0.9434,  0.1718, -0.3870],
        [ 0.3569,  0.9966, -0.3901, -2.0469, -0.4604,  1.0234,  0.0142, -1.0537],
        [ 0.4690,  0.7124,  0.6187, -1.0000, -0.4937,  0.1936, -0.4504,  0.3560],
        [-0.3076,  0.4399,  1.2061,  0.3418, -1.2871,  0.2068,  0.1429, -1.7783],
        [ 0.7700,  1.2920,  0.0959,  0.6997, -0.4878, -1.2461, -0.0948, -0.3127],
        [-0.1495,  0.4048, -0.4822,  0.3828, -1.2686, -0.3691, -1.4326,  0.3491],
        [ 0.2051,  0.3037, -0.3228,  1.5771, -0.3738, -0.5522,  0.0120, -0.3147],
        [-1.3379,  0.8740,  0.2181, -0.0388, -0.1145,  0.5562, -0.7178, -0.0495],
        [-0.3716,  0.6143, -1.3066,  0.1388,  1.0342, -0.2571,  0.2637,  1.0957],
        [ 0.7290, -0.1312, -0.8984,  0.8447,  0.9692, -0.2986, -0.4097,  1.5996],
        [ 0.1647, -0.8379,  0.3105, -2.5137, -0.4263,  0.8486,  0.0986,  1.0244]], dtype=torch.float16)

2025-06-10 00:11:12.920709 GPU 7 155998 test begin: paddle.kron(Tensor([16, 16],"float16"), Tensor([32, 20],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([16, 16],"float16"), Tensor([32, 20],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 240 / 256 (93.8%)
Greatest absolute difference: 0.59765625 at index (8, 8) (up to 0.01 allowed)
Greatest relative difference: 44.59375 at index (13, 14) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([16, 16]), dtype=torch.float16)
tensor([[-0.8511, -1.4580, -2.3809,  ...,  0.8970,  3.5332, -1.3682],
        [-0.3650,  1.0156,  3.7695,  ..., -2.3105,  0.8481, -1.4307],
        [-1.0264, -0.2764, -0.3550,  ..., -3.5664, -1.4619,  1.6445],
        ...,
        [ 1.8994,  3.9961, -2.3184,  ...,  0.3855, -0.1057, -0.6055],
        [ 0.6001,  1.2363,  1.2988,  ..., -0.0150, -1.3838, -0.6187],
        [ 1.1523,  0.8223,  1.0732,  ...,  0.9585,  0.8516, -3.8184]], dtype=torch.float16)
DESIRED: (shape=torch.Size([16, 16]), dtype=torch.float16)
tensor([[-8.7646e-01, -1.5820e+00, -2.5957e+00,  ...,  8.5107e-01,  3.8691e+00, -1.4814e+00],
        [-4.4946e-01,  1.0693e+00,  4.1797e+00,  ..., -2.6250e+00,  1.0732e+00, -1.6318e+00],
        [-1.0518e+00, -3.3960e-01, -3.6426e-01,  ..., -3.9766e+00, -1.5156e+00,  1.9434e+00],
        ...,
        [ 2.1738e+00,  4.2031e+00, -2.7148e+00,  ...,  3.5352e-01, -2.3174e-03, -6.4111e-01],
        [ 7.5098e-01,  1.5293e+00,  1.5410e+00,  ...,  6.4880e-02, -1.6064e+00, -7.7393e-01],
        [ 1.2402e+00,  8.3545e-01,  1.0967e+00,  ...,  7.0020e-01,  8.3008e-01, -4.1289e+00]], dtype=torch.float16)

2025-06-10 00:11:12.925863 GPU 6 156010 test begin: paddle.kron(Tensor([16, 16],"float16"), Tensor([32, 32],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([16, 16],"float16"), Tensor([32, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 249 / 256 (97.3%)
Greatest absolute difference: 1.5390625 at index (3, 14) (up to 0.01 allowed)
Greatest relative difference: 28.1875 at index (15, 7) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([16, 16]), dtype=torch.float16)
tensor([[-1.8945,  0.4307, -0.1077,  ..., -6.5938,  3.2793, -0.8315],
        [-0.7656, -0.5078,  2.1289,  ..., -0.9819,  1.0293, -0.1735],
        [-0.5210, -1.1953, -0.1891,  ..., -2.2324,  1.1426, -3.4590],
        ...,
        [-1.9600, -1.1611,  4.7930,  ...,  0.6348, -1.2930, -1.6455],
        [-3.5762, -1.4141,  0.1389,  ..., -1.9863, -0.2576,  0.9448],
        [-0.1368,  0.6758,  0.6470,  ...,  0.1196,  0.3884,  2.3848]], dtype=torch.float16)
DESIRED: (shape=torch.Size([16, 16]), dtype=torch.float16)
tensor([[-2.1211,  0.1128,  0.0667,  ..., -7.0898,  3.6602, -0.7979],
        [-1.1543, -0.9458,  2.5273,  ..., -0.8477,  1.7617, -0.1398],
        [-0.2759, -1.6289, -0.1201,  ..., -2.8203,  1.0342, -3.7031],
        ...,
        [-2.7871, -1.6553,  5.4609,  ...,  0.8760, -1.3750, -1.9180],
        [-4.1562, -1.6875,  0.4841,  ..., -2.0371, -0.3101,  0.9272],
        [-0.1584,  1.0225,  0.5156,  ...,  0.2822,  0.3276,  2.2637]], dtype=torch.float16)

2025-06-10 00:11:12.930737 GPU 6 156013 test begin: paddle.kron(Tensor([16, 8],"float16"), Tensor([16, 8],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([16, 8],"float16"), Tensor([16, 8],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 48 / 128 (37.5%)
Greatest absolute difference: 0.0517578125 at index (4, 2) (up to 0.01 allowed)
Greatest relative difference: 0.64990234375 at index (4, 7) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([16, 8]), dtype=torch.float16)
tensor([[-0.7822,  0.9648, -0.3992,  ...,  0.2595,  1.5762, -1.4082],
        [ 0.1464,  1.9463,  0.6055,  ..., -1.1094,  0.1841,  0.4573],
        [ 1.6680, -0.6890, -1.5547,  ...,  0.3237, -0.4573,  0.4431],
        ...,
        [ 0.9209,  0.8975,  0.3303,  ...,  0.3779,  0.4617,  0.4270],
        [-2.3594,  1.2344, -0.6328,  ...,  1.3936, -0.7930,  0.2424],
        [ 0.3313, -0.5415, -0.8135,  ..., -1.5088, -0.5737,  1.0127]], dtype=torch.float16)
DESIRED: (shape=torch.Size([16, 8]), dtype=torch.float16)
tensor([[-0.7993,  1.0010, -0.3948,  ...,  0.2491,  1.5967, -1.4277],
        [ 0.1456,  1.9912,  0.6147,  ..., -1.1553,  0.1656,  0.4583],
        [ 1.6924, -0.6948, -1.6045,  ...,  0.3315, -0.4680,  0.4663],
        ...,
        [ 0.9238,  0.9097,  0.3406,  ...,  0.3892,  0.4678,  0.4417],
        [-2.4043,  1.2627, -0.6401,  ...,  1.4199, -0.8013,  0.2515],
        [ 0.3357, -0.5625, -0.8462,  ..., -1.5557, -0.5874,  1.0264]], dtype=torch.float16)

2025-06-10 00:11:12.932367 GPU 4 156022 test begin: paddle.kron(Tensor([20, 16],"float16"), Tensor([32, 32],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([20, 16],"float16"), Tensor([32, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 307 / 320 (95.9%)
Greatest absolute difference: 1.3984375 at index (7, 6) (up to 0.01 allowed)
Greatest relative difference: 17.578125 at index (17, 8) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([20, 16]), dtype=torch.float16)
tensor([[-0.8955,  0.2213, -2.1699,  ..., -3.4922, -0.7134, -3.3398],
        [ 0.5820, -1.7695,  4.5625,  ...,  1.0596, -3.4844, -4.3828],
        [ 3.0879, -1.2754,  0.7974,  ...,  5.1484, -0.1316,  1.0693],
        ...,
        [ 2.6816,  0.9263,  1.2930,  ..., -1.3916, -2.9395,  0.0153],
        [ 0.5020, -2.4648,  0.1003,  ...,  0.7393, -4.4531, -2.3535],
        [ 2.8750,  5.8320, -2.3750,  ..., -3.3789,  2.3574,  2.1816]], dtype=torch.float16)
DESIRED: (shape=torch.Size([20, 16]), dtype=torch.float16)
tensor([[-1.4238,  0.1475, -2.5332,  ..., -3.5918, -0.7930, -3.8203],
        [ 1.0635, -1.3223,  5.2773,  ...,  0.8662, -3.6738, -5.5078],
        [ 3.7344, -1.6953,  0.6245,  ...,  5.9336, -0.0608,  1.0850],
        ...,
        [ 2.8301,  1.1279,  1.3086,  ..., -1.9688, -3.6465,  0.0596],
        [ 0.9697, -2.9395,  0.1146,  ...,  0.9385, -5.4375, -2.4766],
        [ 2.9492,  6.9766, -2.9492,  ..., -3.9043,  3.0684,  2.7227]], dtype=torch.float16)

2025-06-10 00:11:12.940640 GPU 7 156023 test begin: paddle.kron(Tensor([24, 24],"float16"), Tensor([32, 32],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([24, 24],"float16"), Tensor([32, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 556 / 576 (96.5%)
Greatest absolute difference: 1.3359375 at index (0, 23) (up to 0.01 allowed)
Greatest relative difference: 47.8125 at index (12, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([24, 24]), dtype=torch.float16)
tensor([[ 3.4805, -0.8369, -1.9883,  ...,  3.8047, -1.3555,  5.4336],
        [ 1.7158,  0.2812,  0.4558,  ..., -0.0930, -4.4141, -2.0840],
        [-6.0312, -1.3828, -1.0918,  ..., -2.3320, -3.0859,  5.1367],
        ...,
        [-3.5449,  0.7427, -1.0635,  ...,  0.1960,  0.5640,  0.5239],
        [-0.2905, -2.2969, -0.3730,  ...,  5.4922,  2.8809, -1.1807],
        [ 0.0551, -2.4512, -2.5430,  ..., -0.2646,  1.0352, -1.2930]], dtype=torch.float16)
DESIRED: (shape=torch.Size([24, 24]), dtype=torch.float16)
tensor([[ 4.1875, -1.1377, -2.1973,  ...,  3.9883, -1.8955,  6.7695],
        [ 1.8799,  0.0737,  0.3306,  ...,  0.1420, -4.8672, -2.2656],
        [-6.9258, -1.7607, -1.1797,  ..., -3.0938, -3.5254,  5.9648],
        ...,
        [-4.3164,  0.8677, -1.0693,  ...,  0.2271,  0.3977,  0.5537],
        [-0.2008, -2.4082, -0.9043,  ...,  6.0195,  3.4941, -1.6299],
        [ 0.4775, -2.6641, -3.1055,  ..., -0.2856,  1.3857, -1.5361]], dtype=torch.float16)

2025-06-10 00:11:12.941246 GPU 4 156011 test begin: paddle.kron(Tensor([24, 86],"float16"), Tensor([32, 128],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([24, 86],"float16"), Tensor([32, 128],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2054 / 2064 (99.5%)
Greatest absolute difference: 11.078125 at index (6, 55) (up to 0.01 allowed)
Greatest relative difference: 393.0 at index (12, 56) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([24, 86]), dtype=torch.float16)
tensor([[ 0.5962,  1.0820, -1.1094,  ..., -4.1602,  0.8794,  0.5640],
        [-0.1504,  0.8008,  2.1387,  ...,  1.6826, -3.2812,  2.3652],
        [-2.0859, -0.8774,  2.4336,  ...,  1.3643, -6.4102, -0.5000],
        ...,
        [-2.5801, -1.5527, -5.0938,  ...,  4.6836,  2.6016, -1.3203],
        [-0.8115,  2.9590, -3.8066,  ...,  0.8599,  4.5039,  0.0181],
        [-5.0664, -1.1055,  1.3828,  ..., -0.1420, -3.0020,  2.1270]], dtype=torch.float16)
DESIRED: (shape=torch.Size([24, 86]), dtype=torch.float16)
tensor([[  0.9277,   0.9536,  -0.6680,  ...,  -9.0625,   5.0625,   1.3018],
        [ -1.0479,   6.5039,   3.1094,  ...,   3.8555,  -3.8359,   7.9453],
        [ -2.3984,  -2.4941,   3.0586,  ...,   3.3398, -10.6250,   1.4648],
        ...,
        [ -2.8125,  -3.1523,  -4.6602,  ...,   9.3438,   1.7549,  -5.4023],
        [ -1.5303,   2.2656,  -6.0938,  ...,   2.4492,  10.8984,  -1.7139],
        [ -9.0625,  -0.2622,   3.6055,  ...,   1.0742,  -5.5781,   3.4473]], dtype=torch.float16)

2025-06-10 00:11:12.945993 GPU 5 156021 test begin: paddle.kron(Tensor([32, 16],"float16"), Tensor([32, 32],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([32, 16],"float16"), Tensor([32, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 486 / 512 (94.9%)
Greatest absolute difference: 1.375 at index (5, 1) (up to 0.01 allowed)
Greatest relative difference: 119.6875 at index (11, 14) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([32, 16]), dtype=torch.float16)
tensor([[ 2.2168,  1.0371, -3.8320,  ...,  1.1055, -0.3811,  3.9805],
        [-1.5234,  2.2344, -1.8379,  ..., -0.6689,  1.7949,  1.6689],
        [ 2.5645,  2.8594, -1.1836,  ..., -2.1973,  2.0430,  4.4922],
        ...,
        [ 2.6035,  0.0919, -1.6104,  ...,  3.0234,  2.1738, -2.7031],
        [ 0.9766, -0.2654,  0.2365,  ..., -3.5332, -4.2031, -4.6953],
        [-0.0858,  1.1260, -1.6904,  ...,  0.0825, -1.3008,  2.4199]], dtype=torch.float16)
DESIRED: (shape=torch.Size([32, 16]), dtype=torch.float16)
tensor([[ 2.2109,  1.6855, -4.0391,  ...,  1.6387, -0.7222,  4.4570],
        [-1.4111,  2.4941, -2.2949,  ..., -0.8813,  1.8447,  2.3691],
        [ 2.9844,  3.4746, -1.7939,  ..., -2.6055,  2.3652,  5.8555],
        ...,
        [ 2.6641,  0.5386, -2.0977,  ...,  3.6738,  2.5391, -3.1895],
        [ 0.9702, -0.1398, -0.1233,  ..., -4.1094, -4.7617, -5.4648],
        [-0.1818,  1.4736, -2.0098,  ...,  0.3223, -1.8652,  2.7793]], dtype=torch.float16)

2025-06-10 00:11:12.953803 GPU 7 156019 test begin: paddle.kron(Tensor([8, 16],"float16"), Tensor([8, 16],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([8, 16],"float16"), Tensor([8, 16],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 60 / 128 (46.9%)
Greatest absolute difference: 0.060546875 at index (6, 5) (up to 0.01 allowed)
Greatest relative difference: 0.6767578125 at index (7, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8, 16]), dtype=torch.float16)
tensor([[ 0.1761,  0.2078,  0.6851,  ..., -0.9780,  0.3748, -0.4753],
        [-0.6978,  1.4590, -0.1823,  ...,  1.1445,  0.0529, -0.9209],
        [ 0.1523,  0.2078, -0.8701,  ...,  0.5498, -0.1841,  0.6064],
        ...,
        [-0.3027, -0.6401, -1.9043,  ..., -0.4116, -0.4890,  0.8306],
        [-0.6226, -0.0695, -0.9766,  ..., -0.7842,  0.2651,  0.3779],
        [-1.9434, -1.6270, -0.0089,  ...,  0.4771, -0.0290, -0.6079]], dtype=torch.float16)
DESIRED: (shape=torch.Size([8, 16]), dtype=torch.float16)
tensor([[ 0.1578,  0.2208,  0.6938,  ..., -1.0137,  0.3914, -0.4958],
        [-0.7100,  1.4932, -0.1812,  ...,  1.1445,  0.0574, -0.9663],
        [ 0.1669,  0.2236, -0.9106,  ...,  0.5596, -0.1917,  0.6270],
        ...,
        [-0.3125, -0.6465, -1.9414,  ..., -0.4224, -0.5029,  0.8403],
        [-0.6294, -0.0939, -0.9878,  ..., -0.7915,  0.2803,  0.3923],
        [-1.9883, -1.6484, -0.0276,  ...,  0.4993, -0.0383, -0.6318]], dtype=torch.float16)

2025-06-10 00:11:12.956452 GPU 6 156017 test begin: paddle.kron(Tensor([8, 4],"float16"), Tensor([8, 8],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([8, 4],"float16"), Tensor([8, 8],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1 / 32 (3.1%)
Greatest absolute difference: 0.01904296875 at index (3, 0) (up to 0.01 allowed)
Greatest relative difference: 0.021453857421875 at index (3, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8, 4]), dtype=torch.float16)
tensor([[-0.5850, -0.3147,  0.5874,  0.9492],
        [ 0.7563, -0.3887,  0.7476, -0.7061],
        [-0.3777, -0.7422, -1.0117, -0.0185],
        [-0.8687, -0.2057, -0.4812,  0.1205],
        [-0.7393, -0.2788, -0.6094,  0.6377],
        [ 0.3547, -0.9087,  0.1278, -0.6479],
        [ 0.8794,  0.6499, -1.4668, -0.1035],
        [ 0.2269,  0.4258, -0.3943, -0.9985]], dtype=torch.float16)
DESIRED: (shape=torch.Size([8, 4]), dtype=torch.float16)
tensor([[-0.5977, -0.3203,  0.5938,  0.9600],
        [ 0.7607, -0.3914,  0.7563, -0.7095],
        [-0.3809, -0.7432, -1.0205, -0.0151],
        [-0.8877, -0.2062, -0.4854,  0.1228],
        [-0.7524, -0.2766, -0.6182,  0.6455],
        [ 0.3542, -0.9165,  0.1296, -0.6587],
        [ 0.8818,  0.6567, -1.4795, -0.1069],
        [ 0.2305,  0.4307, -0.4006, -1.0059]], dtype=torch.float16)

2025-06-10 00:11:12.965802 GPU 4 156000 test begin: paddle.kron(Tensor([8, 8],"float16"), Tensor([8, 8],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([8, 8],"float16"), Tensor([8, 8],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1 / 64 (1.6%)
Greatest absolute difference: 0.0205078125 at index (7, 2) (up to 0.01 allowed)
Greatest relative difference: 0.030364990234375 at index (7, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8, 8]), dtype=torch.float16)
tensor([[ 0.1370,  0.7397, -0.0139, -0.3147, -0.6021, -0.4561, -0.1646,  0.5688],
        [-0.8081,  0.2561,  0.1537,  0.0895,  0.4036, -0.4399,  0.9570,  0.3367],
        [ 0.6299, -0.6108,  0.3262, -0.1228, -1.0127,  0.9004,  0.1143,  0.7690],
        [ 0.3892,  0.6777,  0.1543,  0.8140, -0.7173,  0.1941, -0.8530, -0.1414],
        [-0.2732, -0.9746, -0.1917,  0.7998,  0.3164,  0.9395, -0.0312, -0.5239],
        [ 1.2051,  0.2778,  0.3931, -0.5625, -0.3726, -0.2155, -0.6108,  0.7402],
        [ 0.3369, -0.0291,  0.2966,  0.4473,  0.0643,  0.1936,  0.4744,  0.2322],
        [ 0.7227,  0.2815, -0.6548,  0.3130, -0.2524, -0.2260, -0.9985, -0.6953]], dtype=torch.float16)
DESIRED: (shape=torch.Size([8, 8]), dtype=torch.float16)
tensor([[ 0.1362,  0.7456, -0.0188, -0.3167, -0.6055, -0.4617, -0.1619,  0.5771],
        [-0.8193,  0.2607,  0.1597,  0.0914,  0.4026, -0.4441,  0.9688,  0.3384],
        [ 0.6309, -0.6191,  0.3247, -0.1208, -1.0264,  0.9146,  0.1159,  0.7749],
        [ 0.3977,  0.6821,  0.1562,  0.8169, -0.7241,  0.1959, -0.8633, -0.1421],
        [-0.2732, -0.9819, -0.1959,  0.8091,  0.3167,  0.9517, -0.0362, -0.5288],
        [ 1.2188,  0.2854,  0.3997, -0.5737, -0.3813, -0.2194, -0.6240,  0.7437],
        [ 0.3420, -0.0251,  0.3042,  0.4531,  0.0676,  0.1935,  0.4775,  0.2380],
        [ 0.7324,  0.2883, -0.6753,  0.3127, -0.2568, -0.2289, -1.0127, -0.7065]], dtype=torch.float16)

2025-06-10 00:11:12.972813 GPU 6 156020 test begin: paddle.kron(Tensor([86, 24],"float16"), Tensor([128, 32],"float16"), )
[accuracy error] backward  paddle.kron(Tensor([86, 24],"float16"), Tensor([128, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2046 / 2064 (99.1%)
Greatest absolute difference: 9.609375 at index (77, 3) (up to 0.01 allowed)
Greatest relative difference: 223.875 at index (63, 21) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([86, 24]), dtype=torch.float16)
tensor([[-5.7578,  2.7109, -2.4277,  ...,  3.8398, -2.9492,  1.8555],
        [-0.9912, -2.2363,  2.2383,  ...,  0.1332,  0.2169, -2.9355],
        [-1.2598, -1.6182,  2.1289,  ...,  1.6113,  2.9336,  1.2822],
        ...,
        [-5.6328, -3.1074, -3.2598,  ..., -3.0449,  0.1000, -0.9175],
        [-7.5664,  1.2217,  0.1439,  ..., -4.6328,  4.4023,  4.1016],
        [ 2.9746, -4.6406,  1.0791,  ..., -4.9766,  2.8359, -1.2803]], dtype=torch.float16)
DESIRED: (shape=torch.Size([86, 24]), dtype=torch.float16)
tensor([[ -7.2578,   1.8125,  -2.5371,  ...,   5.3633,  -0.3889,   4.0781],
        [ -0.7729,  -1.2129,   5.5078,  ...,  -0.9336,  -2.6094,  -2.9258],
        [ -5.2734,  -2.4160,   0.1013,  ...,   3.5195,   3.7734,   3.6191],
        ...,
        [-10.2500,  -5.5664,  -6.9180,  ...,  -9.9688,  -0.6914,  -1.3311],
        [-11.7188,   0.7314,  -1.0283,  ...,  -8.6953,   6.0430,   8.5156],
        [  6.2031,  -8.2734,   2.3301,  ...,  -8.0781,   2.7480,  -0.7837]], dtype=torch.float16)

2025-06-10 00:11:28.865893 GPU 5 156012 test begin: paddle.linalg.cond(Tensor([3, 5, 4, 1],"float32"), -2, )
[accuracy error] backward  paddle.linalg.cond(Tensor([3, 5, 4, 1],"float32"), -2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 49 / 60 (81.7%)
Greatest absolute difference: 4.1161551906590244e+26 at index (0, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 5, 4, 1]), dtype=torch.float32)
tensor([[[[-4.1162e+26],
          [-8.0376e+24],
          [-2.0786e+26],
          [ 7.2423e+25]],

         [[ 0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00]],

         [[ 1.5062e-01],
          [ 2.4564e-01],
          [-1.0624e-01],
          [ 9.6238e-02]],

         [[-8.2775e-03],
          [ 1.5562e-02],
          [-5.6867e-02],
          [ 6.5708e-02]],

         [[ 2.0423e+14],
          [-2.3941e+14],
          [-1.4807e+14],
          [ 1.4159e+14]]],


        [[[-8.4350e-02],
          [ 7.8477e-02],
          [ 6.8012e-02],
          [-6.5632e-02]],

         [[ 5.0714e-02],
          [-8.2749e-02],
          [-1.9208e-01],
          [ 1.2514e-01]],

         [[ 2.8868e-03],
          [ 4.1882e-03],
          [-2.9405e-04],
          [-1.8382e-03]],

         [[-2.2635e+14],
          [ 2.3085e+14],
          [ 1.7880e+14],
          [-6.7100e+13]],

         [[-1.0433e-01],
          [-1.2526e-01],
          [ 1.2454e-01],
          [ 1.1526e-01]]],


        [[[ 8.3545e-03],
          [ 1.4572e-01],
          [-8.0229e-03],
          [-1.1133e-01]],

         [[-2.0576e-01],
          [ 2.4374e-01],
          [ 1.9760e-01],
          [ 1.3666e-01]],

         [[ 1.9202e+14],
          [-1.5377e+13],
          [-1.0374e+14],
          [-3.0517e+14]],

         [[ 8.4466e-02],
          [-2.9558e-02],
          [ 2.8333e-02],
          [-1.0865e-01]],

         [[-2.7160e-01],
          [-1.2101e-01],
          [-1.3452e-02],
          [ 3.7201e-01]]]])
DESIRED: (shape=torch.Size([3, 5, 4, 1]), dtype=torch.float32)
tensor([[[[ 0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00],
          [-0.0000e+00]],

         [[-0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00]],

         [[ 0.0000e+00],
          [ 0.0000e+00],
          [-0.0000e+00],
          [ 0.0000e+00]],

         [[ 0.0000e+00],
          [-0.0000e+00],
          [ 0.0000e+00],
          [-0.0000e+00]],

         [[ 0.0000e+00],
          [-0.0000e+00],
          [-0.0000e+00],
          [ 0.0000e+00]]],


        [[[-0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00],
          [-0.0000e+00]],

         [[ 0.0000e+00],
          [-0.0000e+00],
          [-0.0000e+00],
          [ 0.0000e+00]],

         [[ 0.0000e+00],
          [ 0.0000e+00],
          [-0.0000e+00],
          [-0.0000e+00]],

         [[-8.9825e-09],
          [ 9.1610e-09],
          [ 7.0955e-09],
          [-2.6628e-09]],

         [[ 1.3213e-08],
          [ 1.5865e-08],
          [-1.5773e-08],
          [-1.4598e-08]]],


        [[[-0.0000e+00],
          [-0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00]],

         [[-0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00],
          [ 0.0000e+00]],

         [[ 0.0000e+00],
          [-0.0000e+00],
          [-0.0000e+00],
          [-0.0000e+00]],

         [[ 0.0000e+00],
          [-0.0000e+00],
          [ 0.0000e+00],
          [-0.0000e+00]],

         [[-0.0000e+00],
          [-0.0000e+00],
          [-0.0000e+00],
          [ 0.0000e+00]]]])

2025-06-10 00:11:30.156060 GPU 7 156014 test begin: paddle.linalg.eigh(Tensor([2, 2],"complex128"), "L", )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([2, 2],"complex128"), "L", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 1.4987085258492399 at index (0, 1) (up to 0.01 allowed)
Greatest relative difference: 2.0000000000000004 at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 2]), dtype=torch.complex128)
tensor([[-0.6622+0.0000j, -0.7494+0.0000j],
        [ 0.6717+0.3322j, -0.5936-0.2935j]], dtype=torch.complex128)
DESIRED: (shape=torch.Size([2, 2]), dtype=torch.complex128)
tensor([[ 0.6622+0.0000j,  0.7494+0.0000j],
        [-0.6717-0.3322j,  0.5936+0.2935j]], dtype=torch.complex128)

2025-06-10 00:11:30.239952 GPU 6 156013 test begin: paddle.linalg.eigh(Tensor([2, 2],"complex128"), "U", )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([2, 2],"complex128"), "U", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.5630481589685126 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 2.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 2]), dtype=torch.complex128)
tensor([[ 0.7802-0.0462j,  0.6228-0.0368j],
        [-0.6239+0.0000j,  0.7815+0.0000j]], dtype=torch.complex128)
DESIRED: (shape=torch.Size([2, 2]), dtype=torch.complex128)
tensor([[-0.7802+0.0462j,  0.6228-0.0368j],
        [ 0.6239+0.0000j,  0.7815+0.0000j]], dtype=torch.complex128)

2025-06-10 00:11:30.398267 GPU 6 156010 test begin: paddle.linalg.eigh(Tensor([2, 2],"complex64"), "L", )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([2, 2],"complex64"), "L", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.62847900390625 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.9999998807907104 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 2]), dtype=torch.complex64)
tensor([[-0.8142+0.0000j, -0.5805+0.0000j],
        [ 0.5799+0.0278j, -0.8133-0.0389j]])
DESIRED: (shape=torch.Size([2, 2]), dtype=torch.complex64)
tensor([[ 0.8142+0.0000j, -0.5805+0.0000j],
        [-0.5799-0.0278j, -0.8133-0.0389j]])

2025-06-10 00:11:30.413976 GPU 7 156019 test begin: paddle.linalg.eigh(Tensor([2, 5, 5],"complex64"), )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([2, 5, 5],"complex64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 50 / 50 (100.0%)
Greatest absolute difference: 1.6621440649032593 at index (1, 3, 2) (up to 0.01 allowed)
Greatest relative difference: 2.0 at index (0, 3, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 5, 5]), dtype=torch.complex64)
tensor([[[-0.4623+0.0000j,  0.4767+0.0000j,  0.5435+0.0000j, -0.1505+0.0000j, -0.4909+0.0000j],
         [ 0.6162-0.2286j,  0.0219-0.1919j,  0.0522+0.2510j, -0.2120+0.4483j, -0.4363+0.1694j],
         [ 0.1565+0.3755j, -0.1548+0.4747j,  0.0560-0.0625j,  0.6227+0.0909j, -0.4267+0.0102j],
         [-0.1229-0.0593j, -0.1918-0.6257j, -0.1859+0.2696j,  0.3407-0.4104j, -0.3809-0.1274j],
         [-0.2587-0.3212j, -0.0814+0.2264j, -0.6054-0.3975j, -0.2241+0.0264j, -0.4370+0.0741j]],

        [[ 0.1929+0.0000j,  0.4356+0.0000j, -0.1701+0.0000j, -0.7474+0.0000j, -0.4308+0.0000j],
         [-0.0139+0.3166j,  0.4585-0.1228j,  0.1586-0.3408j,  0.5175+0.1057j, -0.5030-0.0312j],
         [-0.6444-0.4289j, -0.3069-0.0952j, -0.0296-0.1456j, -0.0492-0.1447j, -0.5017+0.0202j],
         [ 0.1705+0.1710j, -0.2188-0.0897j,  0.5815+0.6041j, -0.0088-0.2061j, -0.3594+0.1047j],
         [ 0.4344-0.1268j, -0.3579+0.5456j, -0.3234+0.0042j,  0.2075+0.2314j, -0.3997+0.0918j]]])
DESIRED: (shape=torch.Size([2, 5, 5]), dtype=torch.complex64)
tensor([[[-0.1414-4.4014e-01j, -0.4488-1.6056e-01j,  0.0418-5.4193e-01j,  0.1047-1.0820e-01j,  0.4909+2.4382e-04j],
         [ 0.4061+5.1682e-01j, -0.0852+1.7328e-01j,  0.2543-3.2715e-02j, -0.1748-4.6407e-01j,  0.4364-1.6918e-01j],
         [-0.3097+2.6384e-01j,  0.3056-3.9479e-01j, -0.0580-6.0602e-02j, -0.4983+3.8433e-01j,  0.4267-9.9527e-03j],
         [ 0.0188-1.3517e-01j, -0.0301+6.5377e-01j,  0.2545+2.0609e-01j,  0.0581+5.3022e-01j,  0.3808+1.2761e-01j],
         [ 0.2267-3.4457e-01j,  0.1529-1.8577e-01j, -0.4429+5.7309e-01j,  0.1369-1.7940e-01j,  0.4371-7.3931e-02j]],

        [[ 0.0845-1.7334e-01j, -0.0208+4.3509e-01j,  0.1641+4.4833e-02j, -0.1298+7.3600e-01j,  0.4265-6.0304e-02j],
         [ 0.2785+1.5132e-01j,  0.1007+4.6386e-01j, -0.2428+2.8694e-01j,  0.1940-4.9124e-01j,  0.5024-3.9473e-02j],
         [-0.6680+3.9123e-01j,  0.1098-3.0198e-01j, -0.0098+1.4820e-01j, -0.1511+2.3359e-02j,  0.4939-9.0256e-02j],
         [ 0.2284-7.8284e-02j,  0.1001-2.1425e-01j, -0.4017-7.3601e-01j, -0.2045-2.7164e-02j,  0.3412-1.5400e-01j],
         [ 0.0764-4.4606e-01j, -0.5278-3.8362e-01j,  0.3131+8.1151e-02j,  0.2639-1.6418e-01j,  0.3829-1.4688e-01j]]])

2025-06-10 00:11:30.592265 GPU 4 156022 test begin: paddle.linalg.eigh(Tensor([32, 32],"float32"), "L", )
[accuracy error] paddle.linalg.eigh(Tensor([32, 32],"float32"), "L", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 439 / 1024 (42.9%)
Greatest absolute difference: 0.889765739440918 at index (15, 16) (up to 0.01 allowed)
Greatest relative difference: 2.007838487625122 at index (28, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([32, 32]), dtype=torch.float32)
tensor([[ 0.0888,  0.0525,  0.0998,  ...,  0.4287, -0.0437,  0.1671],
        [-0.1378, -0.1701, -0.1101,  ...,  0.0628,  0.0126,  0.1605],
        [-0.1681,  0.0803, -0.2133,  ..., -0.2676,  0.1163,  0.1575],
        ...,
        [-0.1273, -0.0280, -0.0184,  ...,  0.0792,  0.0553,  0.1829],
        [ 0.0096, -0.0919, -0.2106,  ...,  0.0978, -0.3688,  0.1583],
        [ 0.3101,  0.0509,  0.1638,  ..., -0.1018,  0.3071,  0.1869]])
DESIRED: (shape=torch.Size([32, 32]), dtype=torch.float32)
tensor([[-0.0887,  0.0524,  0.0997,  ..., -0.4287,  0.0437,  0.1671],
        [ 0.1378, -0.1701, -0.1100,  ..., -0.0628, -0.0126,  0.1605],
        [ 0.1682,  0.0804, -0.2134,  ...,  0.2676, -0.1163,  0.1575],
        ...,
        [ 0.1273, -0.0280, -0.0184,  ..., -0.0792, -0.0553,  0.1829],
        [-0.0096, -0.0919, -0.2107,  ..., -0.0978,  0.3688,  0.1583],
        [-0.3101,  0.0508,  0.1638,  ...,  0.1018, -0.3071,  0.1869]])

2025-06-10 00:11:30.655199 GPU 5 156018 test begin: paddle.linalg.eigh(Tensor([4, 4],"complex128"), "L", )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([4, 4],"complex128"), "L", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 16 (50.0%)
Greatest absolute difference: 1.5960849009943574 at index (2, 0) (up to 0.01 allowed)
Greatest relative difference: 2.0000000000000013 at index (2, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.complex128)
tensor([[-0.3952+0.0000j,  0.5203+0.0000j, -0.5729+0.0000j, -0.4948+0.0000j],
        [-0.0377-0.3142j,  0.2391-0.4765j,  0.6214-0.1920j, -0.4380-0.0278j],
        [ 0.7503+0.2720j, -0.1446-0.0276j, -0.2036-0.1811j, -0.5156-0.0366j],
        [-0.3231-0.0489j, -0.5985+0.2551j,  0.1299+0.3971j, -0.5216-0.1524j]], dtype=torch.complex128)
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.complex128)
tensor([[ 0.3952+0.0000j,  0.5203+0.0000j, -0.5729+0.0000j,  0.4948+0.0000j],
        [ 0.0377+0.3142j,  0.2391-0.4765j,  0.6214-0.1920j,  0.4380+0.0278j],
        [-0.7503-0.2720j, -0.1446-0.0276j, -0.2036-0.1811j,  0.5156+0.0366j],
        [ 0.3231+0.0489j, -0.5985+0.2551j,  0.1299+0.3971j,  0.5216+0.1524j]], dtype=torch.complex128)

2025-06-10 00:11:30.902785 GPU 7 155998 test begin: paddle.linalg.eigh(Tensor([4, 4],"complex64"), "L", )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([4, 4],"complex64"), "L", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: 1.6908886432647705 at index (2, 0) (up to 0.01 allowed)
Greatest relative difference: 2.0000009536743164 at index (1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.complex64)
tensor([[-0.2692+0.0000j, -0.6967+0.0000j,  0.3556+0.0000j, -0.5618+0.0000j],
        [-0.0202-0.0429j,  0.6820+0.0322j,  0.5104+0.0824j, -0.5131+0.0327j],
        [ 0.8454-0.0125j, -0.1048-0.0501j, -0.2669-0.0395j, -0.4439+0.0431j],
        [-0.4449+0.1124j,  0.1702-0.0768j, -0.7161+0.1438j, -0.4512+0.1324j]])
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.complex64)
tensor([[ 0.2692+0.0000j,  0.6967+0.0000j, -0.3556+0.0000j,  0.5618+0.0000j],
        [ 0.0202+0.0429j, -0.6820-0.0322j, -0.5104-0.0824j,  0.5131-0.0327j],
        [-0.8454+0.0125j,  0.1048+0.0501j,  0.2669+0.0395j,  0.4439-0.0431j],
        [ 0.4449-0.1124j, -0.1702+0.0768j,  0.7161-0.1438j,  0.4512-0.1324j]])

2025-06-10 00:11:30.915828 GPU 4 156000 test begin: paddle.linalg.eigh(Tensor([4, 4],"complex64"), "U", )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([4, 4],"complex64"), "U", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 16 (75.0%)
Greatest absolute difference: 1.4795883893966675 at index (0, 2) (up to 0.01 allowed)
Greatest relative difference: 2.0000009536743164 at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.complex64)
tensor([[-0.2062-0.3399j,  0.2709+0.1970j, -0.5577-0.4860j,  0.4044+0.1376j],
        [ 0.6097+0.2466j, -0.2640-0.3751j, -0.1528-0.0755j,  0.5727+0.0104j],
        [ 0.1845-0.1219j,  0.6627+0.1702j,  0.4800+0.2125j,  0.4317-0.1451j],
        [-0.6005+0.0000j, -0.4576+0.0000j,  0.3848+0.0000j,  0.5310+0.0000j]])
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.complex64)
tensor([[ 0.2062+0.3399j, -0.2709-0.1970j,  0.5577+0.4860j,  0.4044+0.1376j],
        [-0.6097-0.2466j,  0.2640+0.3751j,  0.1528+0.0755j,  0.5727+0.0104j],
        [-0.1845+0.1219j, -0.6627-0.1702j, -0.4800-0.2125j,  0.4317-0.1451j],
        [ 0.6005+0.0000j,  0.4576+0.0000j, -0.3848+0.0000j,  0.5310+0.0000j]])

2025-06-10 00:11:30.996578 GPU 6 156017 test begin: paddle.linalg.eigh(Tensor([4, 4],"float32"), "L", )
[accuracy error] paddle.linalg.eigh(Tensor([4, 4],"float32"), "L", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 16 (50.0%)
Greatest absolute difference: 1.3486518859863281 at index (0, 3) (up to 0.01 allowed)
Greatest relative difference: 2.0000011920928955 at index (1, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.float32)
tensor([[ 0.4173, -0.3927, -0.4657, -0.6743],
        [ 0.6192,  0.3702,  0.6367, -0.2722],
        [-0.4596, -0.5364,  0.5952, -0.3831],
        [-0.4808,  0.6488, -0.1531, -0.5696]])
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.float32)
tensor([[-0.4173, -0.3927, -0.4657,  0.6743],
        [-0.6192,  0.3702,  0.6367,  0.2722],
        [ 0.4596, -0.5364,  0.5952,  0.3831],
        [ 0.4808,  0.6488, -0.1531,  0.5696]])

2025-06-10 00:11:31.001940 GPU 7 156023 test begin: paddle.linalg.eigh(Tensor([4, 4],"float32"), "U", )
[accuracy error] paddle.linalg.eigh(Tensor([4, 4],"float32"), "U", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 16 (75.0%)
Greatest absolute difference: 1.6748875379562378 at index (1, 0) (up to 0.01 allowed)
Greatest relative difference: 2.000004529953003 at index (0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.float32)
tensor([[ 0.4234, -0.7020, -0.1473,  0.5534],
        [-0.8374, -0.0801, -0.2736,  0.4663],
        [-0.0089,  0.2222,  0.8310,  0.5099],
        [ 0.3455,  0.6718, -0.4614,  0.4652]])
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.float32)
tensor([[-0.4234,  0.7020,  0.1472,  0.5534],
        [ 0.8374,  0.0801,  0.2736,  0.4663],
        [ 0.0089, -0.2222, -0.8310,  0.5099],
        [-0.3455, -0.6718,  0.4614,  0.4652]])

2025-06-10 00:11:32.026408 GPU 6 156020 test begin: paddle.linalg.eigh(Tensor([4, 4],"float64"), "L", )
[accuracy error] paddle.linalg.eigh(Tensor([4, 4],"float64"), "L", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 16 (50.0%)
Greatest absolute difference: 1.3912102452216155 at index (1, 2) (up to 0.01 allowed)
Greatest relative difference: 2.000000000000006 at index (2, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.float64)
tensor([[ 0.2329,  0.8714, -0.2426, -0.3573],
        [ 0.3106, -0.1479,  0.6956, -0.6307],
        [-0.8119, -0.0560, -0.1567, -0.5595],
        [ 0.4360, -0.4645, -0.6578, -0.4019]], dtype=torch.float64)
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.float64)
tensor([[ 0.2329,  0.8714,  0.2426,  0.3573],
        [ 0.3106, -0.1479, -0.6956,  0.6307],
        [-0.8119, -0.0560,  0.1567,  0.5595],
        [ 0.4360, -0.4645,  0.6578,  0.4019]], dtype=torch.float64)

2025-06-10 00:11:32.106276 GPU 4 156011 test begin: paddle.linalg.eigh(Tensor([4, 4],"float64"), "U", )
[accuracy error] paddle.linalg.eigh(Tensor([4, 4],"float64"), "U", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 16 (25.0%)
Greatest absolute difference: 1.5797232586421535 at index (1, 0) (up to 0.01 allowed)
Greatest relative difference: 2.000000000000022 at index (2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.float64)
tensor([[ 0.1677,  0.4227,  0.5934,  0.6641],
        [-0.7899,  0.2333, -0.3967,  0.4054],
        [ 0.0656, -0.8277, -0.0501,  0.5550],
        [ 0.5863,  0.2860, -0.6986,  0.2942]], dtype=torch.float64)
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.float64)
tensor([[-0.1677,  0.4227,  0.5934,  0.6641],
        [ 0.7899,  0.2333, -0.3967,  0.4054],
        [-0.0656, -0.8277, -0.0501,  0.5550],
        [-0.5863,  0.2860, -0.6986,  0.2942]], dtype=torch.float64)

2025-06-10 00:11:33.020532 GPU 6 156956 test begin: paddle.linalg.eigh(Tensor([5, 5],"complex64"), )
linalg_eigh_backward: The eigenvectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this quantity, so it is ill-defined.
[accuracy error] paddle.linalg.eigh(Tensor([5, 5],"complex64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 20 / 25 (80.0%)
Greatest absolute difference: 1.322566032409668 at index (4, 3) (up to 0.01 allowed)
Greatest relative difference: 2.0000011920928955 at index (3, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5]), dtype=torch.complex64)
tensor([[ 0.1266+0.0000j,  0.5444+0.0000j, -0.4887+0.0000j,  0.4363-0.0000j, -0.5084+0.0000j],
        [-0.2362+0.5735j, -0.4453-0.2823j, -0.0276-0.2630j,  0.2221-0.2996j, -0.3186-0.1637j],
        [-0.5287+0.1847j,  0.2503+0.3604j,  0.2593+0.2852j, -0.3758-0.0799j, -0.4354+0.0893j],
        [ 0.2697-0.4333j,  0.0522-0.1770j,  0.4380-0.4567j, -0.1961-0.2173j, -0.4662-0.0449j],
        [ 0.1076-0.1164j, -0.4379-0.0851j,  0.1420+0.3495j,  0.1694+0.6392j, -0.4333+0.0925j]])
DESIRED: (shape=torch.Size([5, 5]), dtype=torch.complex64)
tensor([[-0.1266+0.0000j, -0.5444+0.0000j, -0.4887+0.0000j, -0.4363+0.0000j,  0.5084+0.0000j],
        [ 0.2362-0.5735j,  0.4453+0.2823j, -0.0276-0.2630j, -0.2221+0.2996j,  0.3186+0.1637j],
        [ 0.5287-0.1847j, -0.2503-0.3604j,  0.2593+0.2852j,  0.3758+0.0799j,  0.4354-0.0893j],
        [-0.2697+0.4333j, -0.0522+0.1770j,  0.4380-0.4567j,  0.1961+0.2173j,  0.4662+0.0449j],
        [-0.1076+0.1164j,  0.4379+0.0851j,  0.1420+0.3495j, -0.1694-0.6392j,  0.4333-0.0925j]])

2025-06-10 00:11:33.221255 GPU 7 156955 test begin: paddle.linalg.eigh(Tensor([5, 5],"float32"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[accuracy error] paddle.linalg.eigh(Tensor([5, 5],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 10 / 25 (40.0%)
Greatest absolute difference: 1.3059571981430054 at index (2, 3) (up to 0.01 allowed)
Greatest relative difference: 2.0000035762786865 at index (1, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5]), dtype=torch.float32)
tensor([[-0.4084,  0.5797, -0.3573,  0.4076,  0.4510],
        [-0.5234, -0.6262, -0.2321, -0.3110,  0.4282],
        [ 0.4802,  0.3095, -0.2467, -0.6530,  0.4317],
        [-0.3138,  0.2585,  0.8375, -0.2463,  0.2697],
        [ 0.4798, -0.3304,  0.2372,  0.5001,  0.5951]])
DESIRED: (shape=torch.Size([5, 5]), dtype=torch.float32)
tensor([[ 0.4084,  0.5797, -0.3573, -0.4076,  0.4510],
        [ 0.5234, -0.6262, -0.2321,  0.3110,  0.4282],
        [-0.4802,  0.3095, -0.2467,  0.6530,  0.4317],
        [ 0.3138,  0.2585,  0.8375,  0.2463,  0.2697],
        [-0.4798, -0.3304,  0.2372, -0.5001,  0.5951]])

2025-06-10 00:11:33.424362 GPU 4 156002 test begin: paddle.linalg.lstsq(Tensor([2, 3, 10],"float32"), Tensor([2, 3, 4],"float32"), rcond=1e-15, driver="gelss", )
[accuracy error] paddle.linalg.lstsq(Tensor([2, 3, 10],"float32"), Tensor([2, 3, 4],"float32"), rcond=1e-15, driver="gelss", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([2]) != torch.Size([0]).
ACTUAL: (shape=torch.Size([2]), dtype=torch.int32)
tensor([3, 3], dtype=torch.int32)
DESIRED: (shape=torch.Size([0]), dtype=torch.int64)
tensor([], dtype=torch.int64)

2025-06-10 00:11:33.606241 GPU 4 156016 test begin: paddle.linalg.lstsq(Tensor([200, 100],"float64"), Tensor([200, 50],"float64"), rcond=1e-15, driver="gelsd", )
[accuracy error] paddle.linalg.lstsq(Tensor([200, 100],"float64"), Tensor([200, 50],"float64"), rcond=1e-15, driver="gelsd", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([]) != torch.Size([0]).
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
100
DESIRED: (shape=torch.Size([0]), dtype=torch.int64)
tensor([], dtype=torch.int64)

2025-06-10 00:11:33.607253 GPU 5 156001 test begin: paddle.linalg.lstsq(Tensor([3, 2],"float64"), Tensor([3, 3],"float64"), rcond=1e-07, driver="gelsd", )
[accuracy error] paddle.linalg.lstsq(Tensor([3, 2],"float64"), Tensor([3, 3],"float64"), rcond=1e-07, driver="gelsd", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([]) != torch.Size([0]).
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
2
DESIRED: (shape=torch.Size([0]), dtype=torch.int64)
tensor([], dtype=torch.int64)

2025-06-10 00:11:33.621534 GPU 5 155999 test begin: paddle.linalg.lstsq(Tensor([5, 4],"float64"), Tensor([5, 3],"float64"), rcond=1e-15, driver="gelsd", )
[accuracy error] paddle.linalg.lstsq(Tensor([5, 4],"float64"), Tensor([5, 3],"float64"), rcond=1e-15, driver="gelsd", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([]) != torch.Size([0]).
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
4
DESIRED: (shape=torch.Size([0]), dtype=torch.int64)
tensor([], dtype=torch.int64)

2025-06-10 00:11:33.860530 GPU 5 156012 test begin: paddle.linalg.lstsq(Tensor([5, 5],"float64"), Tensor([5, 1],"float64"), rcond=None, driver="gelss", )
[accuracy error] paddle.linalg.lstsq(Tensor([5, 5],"float64"), Tensor([5, 1],"float64"), rcond=None, driver="gelss", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([]) != torch.Size([0]).
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
5
DESIRED: (shape=torch.Size([0]), dtype=torch.int64)
tensor([], dtype=torch.int64)

2025-06-10 00:11:33.968065 GPU 7 156015 test begin: paddle.linalg.lstsq(Tensor([50, 600],"float64"), Tensor([50, 300],"float64"), rcond=1e-15, driver="gelss", )
[accuracy error] paddle.linalg.lstsq(Tensor([50, 600],"float64"), Tensor([50, 300],"float64"), rcond=1e-15, driver="gelss", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([]) != torch.Size([0]).
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
50
DESIRED: (shape=torch.Size([0]), dtype=torch.int64)
tensor([], dtype=torch.int64)

2025-06-10 00:11:34.052978 GPU 5 156012 test begin: paddle.linalg.lstsq(Tensor([8, 2],"float32"), Tensor([8, 10],"float32"), rcond=1e-15, driver="gelsy", )
[accuracy error] paddle.linalg.lstsq(Tensor([8, 2],"float32"), Tensor([8, 10],"float32"), rcond=1e-15, driver="gelsy", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'shape' do not match: torch.Size([]) != torch.Size([0]).
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
2
DESIRED: (shape=torch.Size([0]), dtype=torch.int64)
tensor([], dtype=torch.int64)

2025-06-10 00:11:34.285454 GPU 5 156012 test begin: paddle.linalg.matrix_rank(Tensor([1, 10],"float32"), None, False, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([1, 10],"float32"), None, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
1
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
1

2025-06-10 00:11:34.372182 GPU 7 156015 test begin: paddle.linalg.matrix_rank(Tensor([1, 10],"float32"), None, False, Tensor([],"float32"), Tensor([],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([1, 10],"float32"), None, False, Tensor([],"float32"), Tensor([],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
1
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
1

2025-06-10 00:11:34.531589 GPU 6 156010 test begin: paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
10
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
10

2025-06-10 00:11:34.557164 GPU 5 156012 test begin: paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
10
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
10

2025-06-10 00:11:34.565941 GPU 4 156002 test begin: paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, atol=0.015, rtol=None, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, atol=0.015, rtol=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
10
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
10

2025-06-10 00:11:34.586062 GPU 6 156013 test begin: paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, atol=0.2, rtol=0.05, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, atol=0.2, rtol=0.05, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
8
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
8

2025-06-10 00:11:34.623273 GPU 7 156014 test begin: paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, atol=None, rtol=1.1, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), hermitian=True, atol=None, rtol=1.1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
0
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-10 00:11:34.627326 GPU 7 156015 test begin: paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), tol=0.1, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), tol=0.1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
9
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
9

2025-06-10 00:11:34.658215 GPU 5 156001 test begin: paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), tol=Tensor([2],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.matrix_rank(Tensor([10, 10],"float32"), tol=Tensor([2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([2]), dtype=torch.int32)
tensor([10, 10], dtype=torch.int32)
DESIRED: (shape=torch.Size([2]), dtype=torch.int64)
tensor([10, 10])

2025-06-10 00:11:34.723923 GPU 5 156018 test begin: paddle.linalg.matrix_rank(Tensor([200, 200],"float64"), None, True, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([200, 200],"float64"), None, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
200
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
200

2025-06-10 00:11:34.774305 GPU 4 156016 test begin: paddle.linalg.matrix_rank(Tensor([200, 200],"float64"), None, True, Tensor([200, 200],"float64"), Tensor([200, 200],"float64"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [200, 200]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.matrix_rank(Tensor([200, 200],"float64"), None, True, Tensor([200, 200],"float64"), Tensor([200, 200],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([200, 200]), dtype=torch.int32)
tensor([[185, 192, 200,  ..., 195, 187, 187],
        [186,  80, 101,  ..., 195, 169, 200],
        [200, 186, 198,  ...,  94, 200,  98],
        ...,
        [190, 109, 131,  ...,  84, 192, 143],
        [120, 200, 192,  ..., 200, 148, 184],
        [143, 163,  97,  ..., 179, 195, 200]], dtype=torch.int32)
DESIRED: (shape=torch.Size([200, 200]), dtype=torch.int64)
tensor([[185, 192, 200,  ..., 195, 187, 187],
        [186,  80, 101,  ..., 195, 169, 200],
        [200, 186, 198,  ...,  94, 200,  98],
        ...,
        [190, 109, 131,  ...,  84, 192, 143],
        [120, 200, 192,  ..., 200, 148, 184],
        [143, 163,  97,  ..., 179, 195, 200]])

2025-06-10 00:11:34.790078 GPU 5 156012 test begin: paddle.linalg.matrix_rank(Tensor([200, 200],"float64"), Tensor([200, 200],"float64"), True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [200, 200]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.matrix_rank(Tensor([200, 200],"float64"), Tensor([200, 200],"float64"), True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([200, 200]), dtype=torch.int32)
tensor([[191, 196, 200,  ..., 199, 190, 197],
        [200, 186, 200,  ..., 186, 197, 200],
        [186, 200, 196,  ..., 196, 196, 191],
        ...,
        [191, 200, 191,  ..., 196, 187, 187],
        [191, 194, 186,  ..., 200, 189, 200],
        [200, 200, 200,  ..., 200, 200, 186]], dtype=torch.int32)
DESIRED: (shape=torch.Size([200, 200]), dtype=torch.int64)
tensor([[191, 196, 200,  ..., 199, 190, 197],
        [200, 186, 200,  ..., 186, 197, 200],
        [186, 200, 196,  ..., 196, 196, 191],
        ...,
        [191, 200, 191,  ..., 196, 187, 187],
        [191, 194, 186,  ..., 200, 189, 200],
        [200, 200, 200,  ..., 200, 200, 186]])

2025-06-10 00:11:34.798741 GPU 6 156013 test begin: paddle.linalg.matrix_rank(Tensor([3, 3],"float32"), 0.1, True, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 3],"float32"), 0.1, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
3
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
3

2025-06-10 00:11:34.806450 GPU 4 156022 test begin: paddle.linalg.matrix_rank(Tensor([3, 3],"float32"), None, True, Tensor([],"float32"), Tensor([],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 3],"float32"), None, True, Tensor([],"float32"), Tensor([],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
2
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
2

2025-06-10 00:11:34.809471 GPU 6 156010 test begin: paddle.linalg.matrix_rank(Tensor([3, 3],"float64"), None, False, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 3],"float64"), None, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
3
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
3

2025-06-10 00:11:34.822685 GPU 4 156002 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 5],"float64"), hermitian=False, atol=Tensor([3, 4],"float64"), rtol=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[4, 3, 5, 5],
        [5, 5, 5, 4],
        [5, 5, 5, 3]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[4, 3, 5, 5],
        [5, 5, 5, 4],
        [5, 5, 5, 3]])

2025-06-10 00:11:34.829238 GPU 5 155999 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 5],"float64"), hermitian=True, atol=0.5, rtol=None, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 5],"float64"), hermitian=True, atol=0.5, rtol=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[4, 4, 2, 2],
        [3, 3, 3, 2],
        [3, 4, 2, 3]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[4, 4, 2, 2],
        [3, 3, 3, 2],
        [3, 4, 2, 3]])

2025-06-10 00:11:34.859189 GPU 7 156015 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 6],"float32"), None, False, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 6],"float32"), None, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[5, 5, 5, 5],
        [5, 5, 5, 5],
        [5, 5, 5, 5]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[5, 5, 5, 5],
        [5, 5, 5, 5],
        [5, 5, 5, 5]])

2025-06-10 00:11:34.877796 GPU 5 156001 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 6],"float32"), None, False, Tensor([3, 4],"float32"), Tensor([3, 4],"float32"), )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 6],"float32"), None, False, Tensor([3, 4],"float32"), Tensor([3, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[3, 4, 5, 5],
        [5, 4, 4, 5],
        [4, 5, 4, 5]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[3, 4, 5, 5],
        [5, 4, 4, 5],
        [4, 5, 4, 5]])

2025-06-10 00:11:35.064386 GPU 5 156021 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[5, 5, 5, 5],
        [3, 5, 4, 2],
        [4, 3, 5, 5]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[5, 5, 5, 5],
        [3, 5, 4, 2],
        [4, 3, 5, 5]])

2025-06-10 00:11:35.065330 GPU 4 156000 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 5],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3]), dtype=torch.int32)
tensor([4, 4, 4], dtype=torch.int32)
DESIRED: (shape=torch.Size([3]), dtype=torch.int64)
tensor([4, 4, 4])

2025-06-10 00:11:35.066871 GPU 7 155998 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 5],"float32"), tol=0.1, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 5],"float32"), tol=0.1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3]), dtype=torch.int32)
tensor([4, 4, 4], dtype=torch.int32)
DESIRED: (shape=torch.Size([3]), dtype=torch.int64)
tensor([4, 4, 4])

2025-06-10 00:11:35.161057 GPU 6 156013 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), 0.1, hermitian=False, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), 0.1, hermitian=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[7, 7, 6, 7],
        [6, 7, 7, 7],
        [7, 7, 7, 7]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[7, 7, 6, 7],
        [6, 7, 7, 7],
        [7, 7, 7, 7]])

2025-06-10 00:11:35.172336 GPU 7 156014 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), Tensor([3, 4],"float32"), hermitian=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[6, 7, 7, 5],
        [6, 4, 7, 6],
        [7, 7, 7, 6]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[6, 7, 7, 5],
        [6, 4, 7, 6],
        [7, 7, 7, 6]])

2025-06-10 00:11:35.192876 GPU 5 156018 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=0.01, rtol=Tensor([3, 4],"float32"), )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=0.01, rtol=Tensor([3, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[7, 4, 6, 5],
        [5, 7, 7, 7],
        [7, 7, 7, 7]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[7, 4, 6, 5],
        [5, 7, 7, 7],
        [7, 7, 7, 7]])

2025-06-10 00:11:35.204568 GPU 7 156023 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 1],"float32"), rtol=Tensor([3, 1],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[7, 6, 6, 7],
        [6, 5, 5, 6],
        [7, 7, 7, 7]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[7, 6, 6, 7],
        [6, 5, 5, 6],
        [7, 7, 7, 7]])

2025-06-10 00:11:35.204999 GPU 4 156022 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=0.01, )
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=0.01, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[6, 6, 7, 7],
        [5, 7, 7, 7],
        [5, 7, 6, 7]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[6, 6, 7, 7],
        [5, 7, 7, 7],
        [5, 7, 6, 7]])

2025-06-10 00:11:35.255607 GPU 6 156017 test begin: paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(Tensor([3, 4, 7, 8],"float64"), hermitian=False, atol=Tensor([3, 4],"float32"), rtol=Tensor([3, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([3, 4]), dtype=torch.int32)
tensor([[7, 5, 4, 5],
        [5, 5, 5, 7],
        [7, 6, 7, 7]], dtype=torch.int32)
DESIRED: (shape=torch.Size([3, 4]), dtype=torch.int64)
tensor([[7, 5, 4, 5],
        [5, 5, 5, 7],
        [7, 6, 7, 7]])

2025-06-10 00:11:35.261711 GPU 5 156012 test begin: paddle.linalg.matrix_rank(Tensor([5, 1],"float64"), None, False, Tensor([1, 4],"float64"), Tensor([1, 4],"float64"), )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [1, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.matrix_rank(Tensor([5, 1],"float64"), None, False, Tensor([1, 4],"float64"), Tensor([1, 4],"float64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.int32)
tensor([[1, 1, 1, 1]], dtype=torch.int32)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.int64)
tensor([[1, 1, 1, 1]])

2025-06-10 00:11:35.268686 GPU 6 156010 test begin: paddle.linalg.matrix_rank(Tensor([5, 1],"float64"), Tensor([1, 4],"float64"), False, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [1, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.matrix_rank(Tensor([5, 1],"float64"), Tensor([1, 4],"float64"), False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([1, 4]), dtype=torch.int32)
tensor([[1, 1, 1, 1]], dtype=torch.int32)
DESIRED: (shape=torch.Size([1, 4]), dtype=torch.int64)
tensor([[1, 1, 1, 1]])

2025-06-10 00:11:35.279191 GPU 4 156002 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 2, 4, 4],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([2, 2, 4, 4],"float64"), tol=Tensor([1, 1],"float64"), hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([2, 2]), dtype=torch.int32)
tensor([[3, 2],
        [3, 2]], dtype=torch.int32)
DESIRED: (shape=torch.Size([2, 2]), dtype=torch.int64)
tensor([[3, 2],
        [3, 2]])

2025-06-10 00:11:35.302917 GPU 7 156019 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
Warning: The core code of paddle.linalg.matrix_rank is too complex.
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.int32)
tensor([[3, 3, 2],
        [3, 2, 3]], dtype=torch.int32)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.int64)
tensor([[3, 3, 2],
        [3, 2, 3]])

2025-06-10 00:11:35.380160 GPU 4 156016 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([2, 3, 4, 4],"float64"), tol=Tensor([2, 3],"float64"), hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.int32)
tensor([[4, 3, 4],
        [4, 4, 3]], dtype=torch.int32)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.int64)
tensor([[4, 3, 4],
        [4, 4, 3]])

2025-06-10 00:11:35.487232 GPU 5 155999 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 4],"float64"), tol=None, hermitian=True, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 4],"float64"), tol=None, hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([2, 4]), dtype=torch.int32)
tensor([[4, 4, 4, 4],
        [4, 4, 4, 4]], dtype=torch.int32)
DESIRED: (shape=torch.Size([2, 4]), dtype=torch.int64)
tensor([[4, 4, 4, 4],
        [4, 4, 4, 4]])

2025-06-10 00:11:35.524106 GPU 7 156015 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 4],"float64"), tol=Tensor([2, 1],"float64"), hermitian=True, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 4],"float64"), tol=Tensor([2, 1],"float64"), hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([2, 4]), dtype=torch.int32)
tensor([[2, 3, 2, 3],
        [3, 3, 3, 3]], dtype=torch.int32)
DESIRED: (shape=torch.Size([2, 4]), dtype=torch.int64)
tensor([[2, 3, 2, 3],
        [3, 3, 3, 3]])

2025-06-10 00:11:35.538895 GPU 5 156001 test begin: paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([2, 4, 4, 5],"float64"), tol=Tensor([2, 1],"float64"), hermitian=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([2, 4]), dtype=torch.int32)
tensor([[4, 4, 3, 4],
        [4, 4, 4, 4]], dtype=torch.int32)
DESIRED: (shape=torch.Size([2, 4]), dtype=torch.int64)
tensor([[4, 4, 3, 4],
        [4, 4, 4, 4]])

2025-06-10 00:11:35.541077 GPU 5 156021 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 4],"float64"), tol=4.4, hermitian=True, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([4, 4],"float64"), tol=4.4, hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
0
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-10 00:11:35.555706 GPU 6 156013 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, )
/root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/utils/_device.py:104: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [1]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)
  return func(*args, **kwargs)
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([4, 4],"float64"), tol=Tensor([1],"float64"), hermitian=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([1]), dtype=torch.int32)
tensor([4], dtype=torch.int32)
DESIRED: (shape=torch.Size([1]), dtype=torch.int64)
tensor([4])

2025-06-10 00:11:35.561498 GPU 5 156018 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 5],"float32"), tol=None, hermitian=False, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([4, 5],"float32"), tol=None, hermitian=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
4
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
4

2025-06-10 00:11:35.567954 GPU 5 156012 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 5],"float64"), tol=4.4, hermitian=False, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([4, 5],"float64"), tol=4.4, hermitian=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
0
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
0

2025-06-10 00:11:35.677986 GPU 4 156000 test begin: paddle.linalg.matrix_rank(x=Tensor([4, 5],"float64"), tol=None, hermitian=False, )
[accuracy error] paddle.linalg.matrix_rank(x=Tensor([4, 5],"float64"), tol=None, hermitian=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
The values for attribute 'dtype' do not match: torch.int32 != torch.int64.
ACTUAL: (shape=torch.Size([]), dtype=torch.int32)
4
DESIRED: (shape=torch.Size([]), dtype=torch.int64)
4

2025-06-10 00:11:35.821551 GPU 4 156022 test begin: paddle.max(Tensor([1, 32, 8],"float32"), axis=list[0,], )
[accuracy error] backward  paddle.max(Tensor([1, 32, 8],"float32"), axis=list[0,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 252 / 256 (98.4%)
Greatest absolute difference: 2.4318071766594347e+28 at index (0, 14, 4) (up to 0.01 allowed)
Greatest relative difference: 2.6193028065694715e+30 at index (0, 23, 6) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 32, 8]), dtype=torch.float32)
tensor([[[ 1.1210e-44,  4.4842e-44,  3.3631e-44,  ...,  4.5609e-41,  1.4013e-45,  1.6589e+00],
         [ 1.2597e+06, -1.5975e+00,  1.1210e-44,  ...,  2.1019e-44,  1.5891e-42,  1.5149e+00],
         [-2.4217e+28,  0.0000e+00,  1.0089e-43,  ...,  0.0000e+00,  1.5863e-42, -1.6817e+00],
         ...,
         [ 1.5568e-42,  1.6416e+00,  0.0000e+00,  ..., -1.6554e+00, -2.4219e+28,  0.0000e+00],
         [ 1.5456e-42,  1.5101e+00,  0.0000e+00,  ..., -1.6264e+00, -2.4219e+28,  0.0000e+00],
         [ 1.5498e-42, -1.6378e+00,  0.0000e+00,  ..., -1.6380e+00, -2.4219e+28,  0.0000e+00]]])
DESIRED: (shape=torch.Size([1, 32, 8]), dtype=torch.float32)
tensor([[[ 0.3705, -0.0114,  0.3783,  ..., -0.4667,  0.0506, -0.3436],
         [-0.2246, -0.4395, -0.1393,  ...,  0.3614,  0.4204,  0.1031],
         [-0.2511,  0.0861, -0.2133,  ..., -0.2750, -0.3496, -0.3045],
         ...,
         [-0.2029, -0.1565,  0.1984,  ...,  0.2929,  0.3746,  0.2673],
         [ 0.3735,  0.1042,  0.2622,  ..., -0.3243, -0.2836, -0.0336],
         [ 0.1629,  0.1315, -0.2522,  ...,  0.2140, -0.3076,  0.2921]]])

2025-06-10 00:13:04.390286 GPU 6 156017 test begin: paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", )
[accuracy error] backward  paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 247 / 4096 (6.0%)
Greatest absolute difference: 1.223402738571167 at index (2, 0, 8, 1) (up to 0.01 allowed)
Greatest relative difference: 70.42343139648438 at index (2, 0, 15, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 16, 16, 4]), dtype=torch.float32)
tensor([[[[-2.3926e-01, -5.5855e-02,  1.1197e-01,  6.1549e-01],
          [-5.6777e-01, -6.3011e-01, -1.0823e-01,  4.3031e-02],
          [-5.2763e-01, -3.2453e-01, -7.2129e-02,  3.7447e-01],
          ...,
          [ 2.1129e-01,  7.8485e-01, -4.3005e-01, -1.0039e-01],
          [ 6.5213e-01,  6.4756e-01,  4.6228e-02,  2.4248e-01],
          [ 1.3381e-01, -6.3451e-03,  9.4754e-02,  4.0429e-01]],

         [[-1.5588e-01,  2.0030e-01, -1.2931e-03,  3.0746e-01],
          [-7.3578e-01, -8.3911e-01, -1.4364e-01,  3.6761e-01],
          [-6.2002e-01, -3.8330e-01, -7.7343e-04, -1.2073e-01],
          ...,
          [ 2.4110e-01,  1.1067e+00, -4.9490e-01, -2.6027e-01],
          [ 5.9808e-01,  4.3429e-01,  1.4240e-01,  5.9469e-01],
          [ 1.2323e-01,  6.2938e-02,  1.3954e-01,  3.2989e-01]],

         [[ 6.7337e-01,  3.7866e-01,  4.2522e-01, -7.2930e-02],
          [-5.3818e-01,  1.6759e-01, -5.9166e-01, -1.9169e-01],
          [ 9.2447e-02, -3.7581e-01, -6.7794e-01,  1.8217e-01],
          ...,
          [ 3.8764e-01, -3.5092e-01,  3.0320e-02, -4.2906e-01],
          [ 1.1581e-01,  3.2043e-01,  2.4593e-01,  5.6786e-01],
          [ 1.1817e-01,  1.4175e-02,  1.5874e-01, -6.4076e-01]],

         ...,

         [[-1.6010e-01,  8.8713e-02, -2.9926e-01,  7.3260e-01],
          [-8.6138e-02, -3.8819e-01, -5.0409e-01, -5.6525e-01],
          [ 8.6562e-03, -4.7744e-01,  8.1010e-02,  5.0586e-01],
          ...,
          [ 6.2544e-01,  4.1199e-01, -7.1494e-02,  3.5054e-01],
          [ 3.9921e-01, -1.9848e-01,  2.5230e-01, -9.4165e-01],
          [-4.4354e-01, -5.5357e-01, -2.6523e-01,  5.5724e-01]],

         [[ 2.0698e-01,  3.5788e-01,  2.7777e-02,  2.8672e-02],
          [ 3.7042e-01, -4.6041e-01, -1.8170e-01, -6.8377e-02],
          [ 1.5954e-01, -2.3294e-01, -1.7012e-01,  5.7982e-01],
          ...,
          [ 2.4077e-02,  8.8339e-02, -1.4730e-01,  8.8024e-01],
          [-1.8617e-01, -3.0522e-01, -3.1175e-01, -5.0042e-02],
          [-4.5071e-02, -6.0833e-02,  6.3071e-02, -1.4303e-01]],

         [[ 3.2275e-01,  3.5767e-01,  1.4580e-01, -1.2070e-01],
          [ 1.8110e-01, -8.2791e-03, -3.2358e-01,  2.2629e-01],
          [-2.6517e-01,  2.4941e-01,  5.4451e-01,  1.4377e-01],
          ...,
          [-1.0030e-01,  3.4512e-01,  3.2943e-01,  1.7597e-01],
          [-3.0578e-02,  3.7325e-01, -1.9052e-01,  1.1710e-01],
          [-4.7748e-01, -8.8928e-01,  1.3909e-01, -1.7201e-02]]],


        [[[-1.1433e-01,  2.6920e-01, -1.2628e-01, -2.1064e-01],
          [ 2.9734e-01,  1.2816e-01,  3.4653e-01, -2.1820e-01],
          [-3.2158e-02, -3.0639e-01,  6.9728e-01,  4.6284e-01],
          ...,
          [ 2.7996e-01,  3.8178e-01, -6.6793e-01,  3.1577e-01],
          [ 7.7599e-01,  6.0226e-01,  2.1192e-02, -2.3749e-01],
          [ 6.0729e-01,  2.3925e-01,  2.0011e-01,  1.2386e-02]],

         [[-2.9833e-01,  3.9364e-01,  1.3529e-02,  6.9753e-02],
          [ 6.5482e-02, -6.5252e-01,  3.1658e-01, -6.1259e-01],
          [ 1.6643e-01,  1.3365e-01,  6.0560e-01,  7.5624e-01],
          ...,
          [ 1.0277e-01,  4.4233e-01, -6.8260e-01,  8.0204e-02],
          [ 6.7468e-01,  5.8448e-01, -1.3882e-01, -2.9062e-01],
          [ 4.9774e-01,  2.6064e-01,  2.3541e-01,  3.4651e-01]],

         [[-4.4858e-01,  1.9564e-01, -1.4707e-01, -6.3587e-01],
          [ 3.5818e-02, -1.5352e-01,  4.4151e-01, -3.6633e-01],
          [ 3.1745e-02,  2.3718e-01,  6.7563e-01,  5.6560e-01],
          ...,
          [-2.0262e-01,  2.6175e-01, -2.8395e-01, -4.2805e-01],
          [ 5.7666e-01,  1.0053e+00,  6.7317e-01,  7.6143e-01],
          [ 3.9019e-01, -3.7838e-01, -1.8812e-01, -4.3521e-02]],

         ...,

         [[ 7.0157e-02,  6.8909e-01, -2.6031e-01, -2.0297e-01],
          [ 7.5166e-01, -3.0170e-01,  4.9154e-01, -1.3591e-01],
          [ 1.4545e-02, -7.1870e-01, -4.2758e-01,  1.8689e-01],
          ...,
          [ 9.7857e-02,  3.7855e-01,  1.4591e-01, -9.6841e-02],
          [-1.1064e-02, -2.0543e-01, -1.2882e-01,  1.0466e+00],
          [-2.1434e-01, -7.1309e-03, -5.4383e-01, -4.1700e-01]],

         [[-1.0398e-01, -4.0365e-01,  6.6828e-01,  1.4218e-01],
          [-3.9747e-01,  1.5662e-01,  3.4488e-01,  1.9269e-03],
          [-1.1327e-01,  7.1301e-01,  2.2794e-01,  3.0535e-01],
          ...,
          [ 5.5399e-02,  4.0149e-01, -1.6026e-01, -2.9141e-01],
          [-9.9323e-02, -3.4825e-02,  4.5242e-02,  1.2114e-01],
          [-6.1540e-02, -2.8435e-01,  2.7886e-01, -2.7115e-01]],

         [[-1.3339e-01, -2.4870e-01,  1.5639e-01,  7.5473e-02],
          [-2.6541e-01, -5.4328e-01,  2.6403e-01,  5.2961e-01],
          [-4.7025e-01,  2.3457e-01,  1.9355e-01, -4.2877e-01],
          ...,
          [ 1.4617e-01,  3.1048e-01,  2.3010e-01, -2.0969e-01],
          [ 1.2842e-01, -3.0666e-01,  1.8047e-01, -4.5091e-01],
          [-2.9041e-01, -4.5063e-01,  1.2787e-01,  4.3684e-01]]],


        [[[ 8.3723e-02, -1.4682e-02, -1.0466e-02,  2.0079e-01],
          [ 4.2029e-01,  5.1914e-01, -5.8155e-02,  5.3104e-01],
          [ 3.4987e-01, -2.8810e-02, -6.1476e-01, -8.1623e-02],
          ...,
          [-4.6848e-02,  2.8382e-01,  9.2542e-02, -4.6929e-02],
          [ 5.1452e-01,  6.2101e-01,  4.6534e-01,  5.8003e-02],
          [ 5.9263e-01,  1.5187e-01, -3.4842e-01, -3.5307e-02]],

         [[ 2.4820e-01,  3.9599e-02, -9.8151e-02,  3.6684e-01],
          [ 5.2868e-01,  8.8096e-01, -9.5100e-02,  1.5046e-01],
          [ 3.9609e-01,  5.6087e-02, -4.4975e-01, -1.6981e-01],
          ...,
          [-2.3758e-01,  1.9796e-01,  8.8358e-02,  4.4476e-02],
          [ 3.9088e-01,  4.6534e-01,  4.5813e-01,  3.4209e-01],
          [ 6.4071e-01,  1.7903e-01, -4.4121e-01, -1.3775e-01]],

         [[-1.0110e-02, -4.7765e-02,  3.8717e-01, -3.8095e-01],
          [ 6.1492e-01, -5.0295e-02,  1.7143e-01, -1.4815e-01],
          [-2.3472e-01,  3.9916e-01, -3.8426e-01,  1.9989e-01],
          ...,
          [ 9.9110e-01,  4.2689e-01,  1.1391e-01, -6.5738e-01],
          [ 3.3974e-01,  4.0580e-01,  7.4989e-01,  8.3661e-01],
          [ 2.4796e-01,  1.6818e-01, -1.8894e-01, -2.6828e-01]],

         ...,

         [[ 2.7897e-01,  2.4975e-01, -1.5593e-01, -1.5442e-01],
          [ 2.1971e-01, -2.4133e-01,  3.5693e-02,  1.6951e-01],
          [-4.9526e-01,  6.4457e-02,  1.1073e-02, -2.6860e-02],
          ...,
          [-1.9014e-02, -4.0622e-01, -6.9352e-02,  1.1173e-01],
          [-7.8494e-01, -1.3660e-01, -4.6211e-01,  1.2586e-01],
          [-7.2756e-01, -9.8911e-02, -1.3289e-01, -1.9748e-01]],

         [[ 5.3529e-01,  1.7893e-01, -3.4354e-01,  4.3737e-01],
          [ 4.7035e-01,  3.3534e-01, -7.2811e-01, -7.5867e-03],
          [-1.0443e-01, -2.3446e-01,  1.3202e-01,  1.8263e-01],
          ...,
          [-9.1845e-01, -1.2431e-01,  4.3265e-01,  4.0175e-01],
          [ 3.9929e-01,  2.5766e-01, -1.1195e-01, -1.6429e-02],
          [-4.3904e-01, -3.5800e-01, -1.0585e-01,  3.7930e-01]],

         [[-1.6522e-01, -4.4975e-01, -5.3357e-01, -1.9521e-01],
          [-5.6112e-02, -4.2132e-02, -2.3484e-01, -5.5256e-01],
          [-5.2129e-01,  2.6513e-01,  4.5232e-01,  2.3801e-01],
          ...,
          [-4.9452e-02, -2.4143e-01,  2.5477e-01,  3.8056e-01],
          [-2.9964e-01, -1.1477e-01,  8.9048e-02,  2.3631e-01],
          [ 7.6943e-03,  9.8435e-02, -2.2599e-01, -1.1746e-01]]],


        [[[ 3.7557e-01,  8.9485e-02, -7.0231e-01, -2.2147e-01],
          [ 9.4114e-02,  2.1384e-01,  3.6678e-01,  1.2622e-01],
          [ 4.1444e-01,  2.2439e-01,  2.9802e-01,  1.6246e-01],
          ...,
          [-1.0464e-01,  3.1397e-01,  8.0355e-01,  9.3312e-02],
          [-9.2136e-02,  1.0988e-01, -1.4832e-01, -4.3109e-01],
          [ 2.7273e-01, -3.2167e-01,  7.2704e-02,  2.8271e-01]],

         [[ 2.3455e-01,  1.8368e-01, -6.6277e-01, -3.0688e-01],
          [ 2.0468e-01,  2.0016e-01,  3.4475e-01,  1.7212e-01],
          [ 4.1529e-01, -8.2115e-02,  2.9594e-01,  3.3197e-01],
          ...,
          [ 1.7711e-01,  5.3465e-01,  7.6625e-01, -9.8705e-03],
          [ 1.0764e-01,  5.0269e-01, -1.8650e-01, -5.9734e-01],
          [ 2.7510e-01, -2.7984e-01,  1.7275e-01,  4.4678e-01]],

         [[-2.8045e-01,  2.2175e-01,  2.9540e-01,  3.3914e-01],
          [ 1.2513e-01, -3.0577e-01, -1.7301e-01,  4.4461e-01],
          [-4.6787e-01,  2.0755e-01,  7.2794e-01, -4.0720e-01],
          ...,
          [-7.7905e-02,  2.0687e-01,  1.4575e-01,  3.8608e-01],
          [-4.7435e-01,  9.2301e-02, -5.1287e-02, -1.0429e+00],
          [ 7.8287e-02, -7.0287e-02,  3.2801e-01, -1.6338e-01]],

         ...,

         [[ 4.5119e-01,  1.0409e-01,  2.7836e-01, -2.1992e-01],
          [-5.5999e-01, -2.8063e-01,  3.7546e-01,  7.0551e-02],
          [ 1.5413e-01,  4.9300e-02, -8.3715e-02,  1.9648e-01],
          ...,
          [-2.6784e-01, -1.0640e-01, -2.2049e-01, -1.3943e-01],
          [-2.5521e-01,  1.4406e-01,  8.2021e-01,  3.4094e-02],
          [-2.8396e-01, -1.3480e-01, -1.4182e-01,  2.3456e-01]],

         [[ 3.4092e-01,  5.5880e-02, -4.6844e-01, -4.8961e-04],
          [ 3.6266e-02, -2.2348e-01,  2.4050e-01,  3.3377e-01],
          [-5.6870e-01, -2.7321e-01,  1.1539e-01,  1.1243e-01],
          ...,
          [ 3.8343e-01,  2.7960e-01, -2.1769e-01, -3.2183e-01],
          [-4.5280e-02,  2.2970e-02,  5.6902e-01, -2.4880e-01],
          [-2.0451e-02, -5.8563e-01, -3.2587e-02, -1.1422e-01]],

         [[ 2.3556e-01, -2.1337e-01, -4.5207e-01, -3.1051e-01],
          [ 1.3370e-01,  5.3984e-01,  2.4018e-01, -2.1837e-01],
          [-2.3743e-02, -1.0946e-01,  4.1661e-01,  2.9228e-01],
          ...,
          [-4.0579e-01, -1.4802e-01, -4.3793e-02, -2.5565e-01],
          [-3.9645e-01, -4.6470e-01,  4.9459e-01,  5.2322e-01],
          [-3.6619e-01,  9.7820e-02, -7.0014e-02, -4.8797e-01]]]])
DESIRED: (shape=torch.Size([4, 16, 16, 4]), dtype=torch.float32)
tensor([[[[-2.0063e-01, -1.7970e-01,  7.2391e-02,  2.0642e-01],
          [-2.8231e-01,  3.1114e-01,  4.3771e-01, -5.3144e-03],
          [-1.5982e-01, -2.2666e-01,  3.6410e-01,  1.3027e-01],
          ...,
          [ 3.8890e-01, -3.8584e-01, -6.9650e-02,  5.2425e-01],
          [ 2.8274e-01,  8.0283e-01, -3.2902e-01, -8.0456e-01],
          [ 9.8772e-01,  8.2812e-01, -1.3777e-01, -1.6181e-01]],

         [[-1.5588e-01,  2.0030e-01, -1.2931e-03,  3.0746e-01],
          [-7.3578e-01, -8.3911e-01, -1.4364e-01,  3.6761e-01],
          [-6.2002e-01, -3.8330e-01, -7.7343e-04, -1.2073e-01],
          ...,
          [ 2.4110e-01,  1.1067e+00, -4.9490e-01, -2.6027e-01],
          [ 5.9808e-01,  4.3429e-01,  1.4240e-01,  5.9469e-01],
          [ 1.2323e-01,  6.2938e-02,  1.3954e-01,  3.2989e-01]],

         [[ 6.7337e-01,  3.7866e-01,  4.2522e-01, -7.2930e-02],
          [-5.3818e-01,  1.6759e-01, -5.9166e-01, -1.9169e-01],
          [ 9.2447e-02, -3.7581e-01, -6.7794e-01,  1.8217e-01],
          ...,
          [ 3.8764e-01, -3.5092e-01,  3.0320e-02, -4.2906e-01],
          [ 1.1581e-01,  3.2043e-01,  2.4593e-01,  5.6786e-01],
          [ 1.1817e-01,  1.4175e-02,  1.5874e-01, -6.4076e-01]],

         ...,

         [[-1.6010e-01,  8.8713e-02, -2.9926e-01,  7.3260e-01],
          [-8.6138e-02, -3.8819e-01, -5.0409e-01, -5.6525e-01],
          [ 8.6562e-03, -4.7744e-01,  8.1010e-02,  5.0586e-01],
          ...,
          [ 6.2544e-01,  4.1199e-01, -7.1494e-02,  3.5054e-01],
          [ 3.9921e-01, -1.9848e-01,  2.5230e-01, -9.4165e-01],
          [-4.4354e-01, -5.5357e-01, -2.6523e-01,  5.5724e-01]],

         [[ 2.0698e-01,  3.5788e-01,  2.7777e-02,  2.8672e-02],
          [ 3.7042e-01, -4.6041e-01, -1.8170e-01, -6.8377e-02],
          [ 1.5954e-01, -2.3294e-01, -1.7012e-01,  5.7982e-01],
          ...,
          [ 2.4077e-02,  8.8339e-02, -1.4730e-01,  8.8024e-01],
          [-1.8617e-01, -3.0522e-01, -3.1175e-01, -5.0042e-02],
          [-4.5071e-02, -6.0833e-02,  6.3071e-02, -1.4303e-01]],

         [[ 3.2275e-01,  3.5767e-01,  1.4580e-01, -1.2070e-01],
          [ 1.8110e-01, -8.2791e-03, -3.2358e-01,  2.2629e-01],
          [-2.6517e-01,  2.4941e-01,  5.4451e-01,  1.4377e-01],
          ...,
          [-1.0030e-01,  3.4512e-01,  3.2943e-01,  1.7597e-01],
          [-3.0578e-02,  3.7325e-01, -1.9052e-01,  1.1710e-01],
          [-4.7748e-01, -8.8928e-01,  1.3909e-01, -1.7201e-02]]],


        [[[-5.6750e-01, -1.2612e-01,  1.9199e-01,  3.2069e-01],
          [ 1.8747e-01,  3.9067e-01, -3.3349e-01,  6.1904e-01],
          [-2.8844e-02, -3.5036e-01, -2.1852e-01, -1.6683e-01],
          ...,
          [ 3.0497e-01,  3.1286e-02,  1.5703e-01,  4.7771e-01],
          [-3.3616e-01, -3.3254e-01, -8.1452e-01, -6.4897e-01],
          [ 1.9488e-01,  2.8688e-02,  2.5727e-01,  3.5489e-01]],

         [[-2.9833e-01,  3.9364e-01,  1.3529e-02,  6.9753e-02],
          [ 6.5482e-02, -6.5252e-01,  3.1658e-01, -6.1259e-01],
          [ 1.6643e-01,  1.3365e-01,  6.0560e-01,  7.5624e-01],
          ...,
          [ 1.0277e-01,  4.4233e-01, -6.8260e-01,  8.0204e-02],
          [ 6.7468e-01,  5.8448e-01, -1.3882e-01, -2.9062e-01],
          [ 4.9774e-01,  2.6064e-01,  2.3541e-01,  3.4651e-01]],

         [[-4.4858e-01,  1.9564e-01, -1.4707e-01, -6.3587e-01],
          [ 3.5818e-02, -1.5352e-01,  4.4151e-01, -3.6633e-01],
          [ 3.1745e-02,  2.3718e-01,  6.7563e-01,  5.6560e-01],
          ...,
          [-2.0262e-01,  2.6175e-01, -2.8395e-01, -4.2805e-01],
          [ 5.7666e-01,  1.0053e+00,  6.7317e-01,  7.6143e-01],
          [ 3.9019e-01, -3.7838e-01, -1.8812e-01, -4.3521e-02]],

         ...,

         [[ 7.0157e-02,  6.8909e-01, -2.6031e-01, -2.0297e-01],
          [ 7.5166e-01, -3.0170e-01,  4.9154e-01, -1.3591e-01],
          [ 1.4545e-02, -7.1870e-01, -4.2758e-01,  1.8689e-01],
          ...,
          [ 9.7857e-02,  3.7855e-01,  1.4591e-01, -9.6841e-02],
          [-1.1064e-02, -2.0543e-01, -1.2882e-01,  1.0466e+00],
          [-2.1434e-01, -7.1309e-03, -5.4383e-01, -4.1700e-01]],

         [[-1.0398e-01, -4.0365e-01,  6.6828e-01,  1.4218e-01],
          [-3.9747e-01,  1.5662e-01,  3.4488e-01,  1.9269e-03],
          [-1.1327e-01,  7.1301e-01,  2.2794e-01,  3.0535e-01],
          ...,
          [ 5.5399e-02,  4.0149e-01, -1.6026e-01, -2.9141e-01],
          [-9.9323e-02, -3.4825e-02,  4.5242e-02,  1.2114e-01],
          [-6.1540e-02, -2.8435e-01,  2.7886e-01, -2.7115e-01]],

         [[-1.3339e-01, -2.4870e-01,  1.5639e-01,  7.5473e-02],
          [-2.6541e-01, -5.4328e-01,  2.6403e-01,  5.2961e-01],
          [-4.7025e-01,  2.3457e-01,  1.9355e-01, -4.2877e-01],
          ...,
          [ 1.4617e-01,  3.1048e-01,  2.3010e-01, -2.0969e-01],
          [ 1.2842e-01, -3.0666e-01,  1.8047e-01, -4.5091e-01],
          [-2.9041e-01, -4.5063e-01,  1.2787e-01,  4.3684e-01]]],


        [[[ 3.3464e-01,  4.6759e-01,  5.9672e-01,  1.2014e-01],
          [ 4.0895e-01,  1.0036e-01,  2.1252e-01,  1.9910e-02],
          [-5.3141e-02, -1.7703e-01, -3.2369e-01,  6.4152e-02],
          ...,
          [ 2.6099e-01,  2.8982e-01,  4.4007e-02,  5.4081e-02],
          [ 1.7500e-02,  1.0361e-01,  3.6294e-01, -4.1635e-02],
          [ 1.9762e-01, -1.1533e-01, -4.8782e-03,  1.2370e-01]],

         [[ 2.4820e-01,  3.9599e-02, -9.8151e-02,  3.6684e-01],
          [ 5.2868e-01,  8.8096e-01, -9.5100e-02,  1.5046e-01],
          [ 3.9609e-01,  5.6087e-02, -4.4975e-01, -1.6981e-01],
          ...,
          [-2.3758e-01,  1.9796e-01,  8.8358e-02,  4.4476e-02],
          [ 3.9088e-01,  4.6534e-01,  4.5813e-01,  3.4209e-01],
          [ 6.4071e-01,  1.7903e-01, -4.4121e-01, -1.3775e-01]],

         [[-1.0110e-02, -4.7765e-02,  3.8717e-01, -3.8095e-01],
          [ 6.1492e-01, -5.0295e-02,  1.7143e-01, -1.4815e-01],
          [-2.3472e-01,  3.9916e-01, -3.8426e-01,  1.9989e-01],
          ...,
          [ 9.9110e-01,  4.2689e-01,  1.1391e-01, -6.5738e-01],
          [ 3.3974e-01,  4.0580e-01,  7.4989e-01,  8.3661e-01],
          [ 2.4796e-01,  1.6818e-01, -1.8894e-01, -2.6828e-01]],

         ...,

         [[ 2.7897e-01,  2.4975e-01, -1.5593e-01, -1.5442e-01],
          [ 2.1971e-01, -2.4133e-01,  3.5693e-02,  1.6951e-01],
          [-4.9526e-01,  6.4457e-02,  1.1073e-02, -2.6860e-02],
          ...,
          [-1.9014e-02, -4.0622e-01, -6.9352e-02,  1.1173e-01],
          [-7.8494e-01, -1.3660e-01, -4.6211e-01,  1.2586e-01],
          [-7.2756e-01, -9.8911e-02, -1.3289e-01, -1.9748e-01]],

         [[ 5.3529e-01,  1.7893e-01, -3.4354e-01,  4.3737e-01],
          [ 4.7035e-01,  3.3534e-01, -7.2811e-01, -7.5867e-03],
          [-1.0443e-01, -2.3446e-01,  1.3202e-01,  1.8263e-01],
          ...,
          [-9.1845e-01, -1.2431e-01,  4.3265e-01,  4.0175e-01],
          [ 3.9929e-01,  2.5766e-01, -1.1195e-01, -1.6429e-02],
          [-4.3904e-01, -3.5800e-01, -1.0585e-01,  3.7930e-01]],

         [[-1.6522e-01, -4.4975e-01, -5.3357e-01, -1.9521e-01],
          [-5.6112e-02, -4.2132e-02, -2.3484e-01, -5.5256e-01],
          [-5.2129e-01,  2.6513e-01,  4.5232e-01,  2.3801e-01],
          ...,
          [-4.9452e-02, -2.4143e-01,  2.5477e-01,  3.8056e-01],
          [-2.9964e-01, -1.1477e-01,  8.9048e-02,  2.3631e-01],
          [ 7.6943e-03,  9.8435e-02, -2.2599e-01, -1.1746e-01]]],


        [[[-1.9158e-01, -1.1994e-01, -4.6702e-01, -1.8764e-01],
          [ 1.4008e-01,  7.4387e-02, -1.6295e-01,  1.1871e-01],
          [-1.1904e-01,  3.9132e-01,  7.5292e-01, -2.8206e-01],
          ...,
          [ 4.4601e-01,  6.4730e-02,  6.4472e-01, -4.7113e-02],
          [ 4.3274e-01, -1.3238e-01,  5.4712e-01,  5.3844e-01],
          [-1.8415e-01,  9.0243e-03,  4.4267e-02, -5.5834e-01]],

         [[ 2.3455e-01,  1.8368e-01, -6.6277e-01, -3.0688e-01],
          [ 2.0468e-01,  2.0016e-01,  3.4475e-01,  1.7212e-01],
          [ 4.1529e-01, -8.2115e-02,  2.9594e-01,  3.3197e-01],
          ...,
          [ 1.7711e-01,  5.3465e-01,  7.6625e-01, -9.8705e-03],
          [ 1.0764e-01,  5.0269e-01, -1.8650e-01, -5.9734e-01],
          [ 2.7510e-01, -2.7984e-01,  1.7275e-01,  4.4678e-01]],

         [[-2.8045e-01,  2.2175e-01,  2.9540e-01,  3.3914e-01],
          [ 1.2513e-01, -3.0577e-01, -1.7301e-01,  4.4461e-01],
          [-4.6787e-01,  2.0755e-01,  7.2794e-01, -4.0720e-01],
          ...,
          [-7.7905e-02,  2.0687e-01,  1.4575e-01,  3.8608e-01],
          [-4.7435e-01,  9.2301e-02, -5.1287e-02, -1.0429e+00],
          [ 7.8287e-02, -7.0287e-02,  3.2801e-01, -1.6338e-01]],

         ...,

         [[ 4.5119e-01,  1.0409e-01,  2.7836e-01, -2.1992e-01],
          [-5.5999e-01, -2.8063e-01,  3.7546e-01,  7.0551e-02],
          [ 1.5413e-01,  4.9300e-02, -8.3715e-02,  1.9648e-01],
          ...,
          [-2.6784e-01, -1.0640e-01, -2.2049e-01, -1.3943e-01],
          [-2.5521e-01,  1.4406e-01,  8.2021e-01,  3.4094e-02],
          [-2.8396e-01, -1.3480e-01, -1.4182e-01,  2.3456e-01]],

         [[ 3.4092e-01,  5.5880e-02, -4.6844e-01, -4.8961e-04],
          [ 3.6266e-02, -2.2348e-01,  2.4050e-01,  3.3377e-01],
          [-5.6870e-01, -2.7321e-01,  1.1539e-01,  1.1243e-01],
          ...,
          [ 3.8343e-01,  2.7960e-01, -2.1769e-01, -3.2183e-01],
          [-4.5280e-02,  2.2970e-02,  5.6902e-01, -2.4880e-01],
          [-2.0451e-02, -5.8563e-01, -3.2587e-02, -1.1422e-01]],

         [[ 2.3556e-01, -2.1337e-01, -4.5207e-01, -3.1051e-01],
          [ 1.3370e-01,  5.3984e-01,  2.4018e-01, -2.1837e-01],
          [-2.3743e-02, -1.0946e-01,  4.1661e-01,  2.9228e-01],
          ...,
          [-4.0579e-01, -1.4802e-01, -4.3793e-02, -2.5565e-01],
          [-3.9645e-01, -4.6470e-01,  4.9459e-01,  5.2322e-01],
          [-3.6619e-01,  9.7820e-02, -7.0014e-02, -4.8797e-01]]]])

2025-06-10 00:13:29.009754 GPU 6 156017 test begin: paddle.nn.functional.conv2d_transpose(Tensor([64, 64, 43, 19],"float32"), Tensor([64, 32, 5, 5],"float32"), bias=Tensor([32],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[accuracy error] backward  paddle.nn.functional.conv2d_transpose(Tensor([64, 64, 43, 19],"float32"), Tensor([64, 32, 5, 5],"float32"), bias=Tensor([32],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 5044 / 51200 (9.9%)
Greatest absolute difference: 0.8406982421875 at index (46, 17, 4, 4) (up to 0.01 allowed)
Greatest relative difference: 43.04513931274414 at index (26, 27, 4, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([64, 32, 5, 5]), dtype=torch.float32)
tensor([[[[-43.7446, -17.1307,  23.6590,   0.8194,  -3.6680],
          [ 15.5339, -34.6710,  -4.9517,  -2.7534,  -6.6630],
          [ 22.4001,  12.7963,  20.0600,  -0.5387,  10.4512],
          [-33.5924,  19.0703,  18.6435,  -2.6133,   8.5202],
          [-21.6183,   6.9402, -14.6530, -36.0007, -28.8500]],

         [[  5.6082, -16.6610,   2.1220, -13.5209,  28.2728],
          [-20.2519,  10.2405,   7.5116, -21.7518,  14.3503],
          [ 29.3911,  13.4667,  -7.3197,   3.1258,  -4.4072],
          [ -0.3210,  -6.7146,   4.2428,   1.1250,  14.3464],
          [-17.2106,   1.8505,  -4.0754,   5.4063,  -2.9418]],

         [[  3.2712, -16.8948,  19.0459,  -2.7974,  -1.6312],
          [ -1.9087,   9.3711,  -7.0981,  -2.5645,   3.8099],
          [  0.4102,  -3.9983, -17.0490, -41.7209,  27.3968],
          [ 29.7757,  -9.0556,  21.0050,  -5.8259,   3.0897],
          [-19.7985, -11.0764, -36.7082, -23.1159,  10.8752]],

         ...,

         [[  1.8388, -23.7965,   2.0322,  23.9697,  38.2466],
          [  9.3084,  12.9093,   6.6570,  -6.9685,  27.7514],
          [ -9.0918,  -6.4191, -35.8309,  16.8342,   9.8792],
          [ -0.2540,   5.1569,   9.2906, -20.3751, -18.2245],
          [-22.2065,  -9.8681,  20.0191,  32.7348,  -3.4606]],

         [[ -8.0784,  18.9651, -30.0448,  11.9855,  11.2280],
          [ -1.6181,  -3.3573, -11.3602, -19.8797,   5.5940],
          [-28.4449, -27.3803,  20.1840,   9.0849,  14.6329],
          [-18.8043,   4.5285,  -8.8533, -22.2981,  -8.6295],
          [ 11.5806, -29.5688, -18.4867,  -2.1860,   7.4238]],

         [[  7.3229,  -9.1227,  -0.9600,  -2.5814,   8.8544],
          [-20.7575,  17.4284, -19.4947, -19.2680,   9.4421],
          [  8.7646,  14.2371,   0.7137, -11.5803,  -0.9410],
          [ 14.7148,  33.5540,  20.8479,  -0.4729, -12.3992],
          [  1.4115,   7.5653, -13.8383,  -3.3691,  17.2168]]],


        [[[ -1.7366,   8.4587,  13.5332,   0.6361, -15.3229],
          [  4.0859, -27.4153,   5.0122,   1.8794,   2.1733],
          [-15.2741,  13.2844,   9.2357,   5.8223,  14.0187],
          [ 24.0759, -10.5638, -31.0601,  17.9085,  -1.2433],
          [ 20.8095, -34.5154, -31.1653,   3.4520,  -2.9265]],

         [[ 20.1828,   9.8135,  23.2347,  -1.8844,   0.5357],
          [ 19.5631, -31.2297,  19.1282,  24.6230, -17.9886],
          [ 10.0915,  -4.9851,   7.3778,  -4.7484,  31.9389],
          [-47.4694,  -7.9664,  -2.4984,  -5.2921,  -1.3723],
          [ 35.1620, -16.0437,  29.3202,  14.3002,   6.5116]],

         [[ 20.3881,  -5.2785,   0.1178, -22.5904,  24.1469],
          [ 15.0043,  38.8551,  -3.2099, -26.5432,   0.7180],
          [ 15.7624, -45.8779,  19.4732, -39.9123,   9.5383],
          [ -0.3713,  -1.6236,  14.2497,  -5.9200,  29.6005],
          [  1.5075,  38.7456,  28.4205,  -4.5184, -14.0982]],

         ...,

         [[ 17.5740,   8.0389,  16.4873,  -1.4439,  24.9862],
          [ -1.1142, -13.4320,   2.8884,  28.7294,  28.8491],
          [ -0.4586,  18.5664,  -9.3338,  12.0271, -10.5832],
          [ -7.9976, -25.1321,  -0.9342,  -1.9248, -11.4157],
          [ -3.8084, -10.0013, -13.9414,  32.7549,  12.3263]],

         [[-31.4885,  -2.0717,  17.5545,  29.5351,  14.2553],
          [-22.1666, -13.1164, -20.2297,  20.5118,   2.2008],
          [-17.9508,  -2.3383,  -9.2198,   7.5594,  21.4558],
          [ 33.8218,   5.4934,  -0.7857,   3.0400, -12.7322],
          [ 10.2022, -30.3794,  13.4883,  13.2662,   9.4298]],

         [[ 28.2600,  12.3872,  -0.7696, -13.4195,   8.3999],
          [-11.8996,  -5.4845,  -3.0157, -20.0110, -41.2021],
          [  5.9958,  -8.8890, -26.2554, -13.0039, -50.2699],
          [-22.8912,   8.4378, -25.6836,  17.4209, -29.0426],
          [ -1.6703, -29.6479,  -6.6077,  18.9964,   9.6847]]],


        [[[ -9.0757,  11.7840, -13.5064,   7.8362,  -1.5678],
          [ -6.3914, -18.1966, -13.2372,  -8.9102, -10.9486],
          [  4.3037,   3.3210,  -2.6929,  14.0459,  26.0451],
          [ 12.9261,  -1.0979,  -6.8126,  21.1628, -17.1544],
          [ -2.9674,  12.2090,   3.6930, -16.3683, -31.5845]],

         [[ 20.6589,   9.9887, -45.4463,   7.5110, -20.9487],
          [  4.6566,  37.1888,  29.5874, -21.6658,  -0.0694],
          [ -9.3748, -27.1694, -13.9611, -28.7938,   4.7359],
          [  7.2193,  -3.3986, -20.7928,  -2.2504,  38.4285],
          [ -8.5870,   5.4336, -26.6726,  18.6014,   0.4264]],

         [[ -8.1114,  -5.0493,  16.5208, -16.6010,  -8.0854],
          [  4.3411, -16.3775,  -7.8982,  23.8399,   7.5096],
          [  1.1685,   5.9916,  -2.2080,   7.8185, -17.0424],
          [ -1.1904, -27.2016, -15.3151, -26.9865,  -0.9932],
          [  9.6419,  -9.5282,  -3.1741, -11.0180, -15.3198]],

         ...,

         [[ -0.3051,  21.2254,   9.2012,   5.7030,  -4.0566],
          [  4.0155,  -1.5245,   9.6222,   5.0172,  14.2612],
          [ -2.7069, -27.1182,  19.2625,  -2.0732,  39.1901],
          [ 14.7862,  14.8830, -15.3531,   0.7565,   2.1379],
          [-14.1041,  19.8962,   9.6205,  37.3233, -17.1850]],

         [[ -8.4347,   4.7580,   3.5859, -20.1213,   9.6710],
          [ 11.6529,  26.6733, -22.5230, -26.8852,  31.9564],
          [ 28.0863,  -3.0237, -26.3516, -15.2072,  12.7797],
          [ 19.3892,  -1.6946,  -1.9289,  -9.7964,   1.4976],
          [ 14.2041,  35.4999,  -8.7869,  -3.2035,  -9.9996]],

         [[-13.8956,  -1.0580,  16.6994, -37.0973,  10.1901],
          [ -4.8238,   0.4494, -12.7179,   9.1692,   4.0691],
          [ -2.5056,  -1.8033,  40.2430,  -6.8085, -11.8258],
          [  8.7304,  17.3263,  21.0899,  23.9779, -15.2143],
          [-25.7072,  18.3336,   1.7414, -31.1068,  17.8873]]],


        ...,


        [[[ 36.7397,  -1.2231,  12.5953, -14.9146,  -5.8905],
          [  0.6762,  -5.4948,  -0.8758, -23.1752,   4.4948],
          [ 13.5907,   9.4363, -13.0167,  -1.4605,   3.9022],
          [ -4.0801,   3.7814, -48.8959, -35.1264, -10.0767],
          [ 15.5882,   7.8834, -17.8241, -22.1677, -13.2384]],

         [[ 32.1797, -45.1707, -32.0996,  22.9766,  14.5513],
          [  3.8955,  21.5738,  -3.4840,  12.6511,  35.9534],
          [  1.6460,  19.9709,   9.4766, -13.2459,  18.9727],
          [  5.0571, -16.7125,   9.4681, -41.1717,   5.7789],
          [ -5.8519,  -7.9813,  -0.3942,   4.2023,  -7.2805]],

         [[ 20.2435,  26.9356,  14.7535,  -3.8149, -31.5770],
          [ 22.0421, -11.1209,  -4.6350, -14.7601,  49.6942],
          [ -5.6897,   4.7019,  -1.0194, -31.1413, -14.6233],
          [-22.6417,  31.8014,  -0.6371,  -4.7577,  24.1700],
          [ -6.8809,  -9.4995,  -7.1463,  -6.7840,   3.8862]],

         ...,

         [[-13.4290,  17.0721, -13.5616, -14.1157, -20.3650],
          [ -0.6895, -20.3975,  -8.2773,  22.6509,  12.6159],
          [ -2.7897,  -8.5398, -30.1972,  -0.3449,  22.6382],
          [ 26.7651, -27.6496, -13.5425,  -1.3880,  26.2989],
          [  5.9767,  -6.4924, -14.9828, -12.2041, -10.1280]],

         [[ -5.0247, -15.9079,  10.8754,  -0.8131,  19.1581],
          [  4.3167,  30.5344,  16.9922,  25.9103, -10.1564],
          [ 36.0279, -25.7650, -16.8958,   7.7564, -14.0927],
          [ -1.4171, -41.2973,   3.1658,  -2.5153,   1.4971],
          [ -2.0435,  18.7455,  -6.9049,  42.0779,  40.5171]],

         [[-14.3954,   5.9996,   8.8892,  15.6706,   1.1227],
          [ -3.0290,  -9.6134,   0.7748,   4.7610,  18.9477],
          [  3.3605, -30.4005,  18.6487,  -7.2948,  18.8750],
          [ 14.4491,  18.8228,  14.9067, -24.6420, -10.9739],
          [-22.5095,   5.4913,  20.7508,  -2.9628,  26.6230]]],


        [[[-37.8438, -12.5619,  22.8481,   7.1358,   4.2093],
          [ 20.0507,  -0.7664,   5.8641, -39.9688,  -0.7513],
          [  6.0183,   5.8898,  -0.9329,  26.1654,   4.3801],
          [-35.4107,  18.9599, -31.5032, -11.8523,   7.3677],
          [  6.3016,   7.8110,   4.0839,   7.2388, -17.9435]],

         [[ 16.9852,  11.1629,  -0.6949,   9.1976,  38.7121],
          [ -7.0278,  -2.9338, -24.6729,  10.2643,  11.4311],
          [  1.1735,   7.2511,  -9.7582,  18.7349, -15.6096],
          [ 25.7566,   7.4602,  19.9966, -22.7925,  20.0638],
          [  4.7172,  28.0131,   1.5347,  35.3185,  27.0548]],

         [[  0.8271,  -8.7255,   5.5151,  35.2468, -21.2811],
          [  6.3399, -13.9609,   2.5655,   5.3083,  11.9057],
          [ 33.9725,  -5.3648,   4.8503,  19.1244,   2.5710],
          [ 21.3511,  14.7794,  -6.4268,   9.3330,   6.3377],
          [  2.6238,  17.4177,  32.7135, -26.7331, -11.0698]],

         ...,

         [[ 20.1187,   6.1363,  14.4541, -15.8593,  19.7191],
          [ 16.9685,  -9.6608, -28.4588,  14.2180,  -5.9282],
          [  0.5960,   8.6152, -22.4684,  16.6834,  -4.7279],
          [  7.1866, -16.5282, -29.4657,   8.8968,  38.5720],
          [-30.7734,  11.4007,  14.4744, -15.5643,  13.4636]],

         [[ 30.7941,  14.5826,   4.2904,  19.6492,   2.6921],
          [ 40.0666,  12.4805,  25.9716,  12.7944, -13.0022],
          [  4.9426,  38.4751, -43.0020, -37.8245,   4.1182],
          [  0.7665,  33.9877, -10.4981, -28.3230,  29.4689],
          [-31.3197,   3.2229, -18.2263, -11.1589,   3.9811]],

         [[ 19.1849,  -3.8462,   5.0611, -40.1178, -18.9401],
          [ -3.8493,   7.2470,  16.7368,   6.9630, -20.1746],
          [ -7.3231, -13.6737,  -0.7112,  15.6188, -18.6690],
          [ 28.9719,  22.8327, -16.1341, -33.0990,   0.9931],
          [  1.0695,   7.1946,   5.2606, -31.4139, -31.7782]]],


        [[[ -3.7254,   6.7371,  32.5399,  32.3948, -12.2531],
          [-14.4684,  -9.6656,   9.2429,  28.2353,   1.9758],
          [-11.8215,  15.9693,   4.1095,  27.2257,  12.7298],
          [  6.0725,  10.5683, -29.1462,   7.6862,   3.7598],
          [ 33.4514,  37.4538,  18.7971,  -6.1630,   3.0145]],

         [[ -6.9670,  22.0890,  17.6762, -22.2825,   2.7070],
          [-28.3949, -29.0563,   9.1431,  -3.1324, -20.3062],
          [ -8.9316,   6.0465,  33.8763, -17.1560,  -0.3651],
          [ 17.1885, -16.8132, -12.1854,  13.0426,   3.9115],
          [  2.9299,  15.8226, -17.8220,   8.9196,   7.7572]],

         [[-12.2807,  -6.5472,  16.9019,  -2.1074,   3.9160],
          [-23.4730, -21.7072,   6.0341, -29.4728,   5.1391],
          [ -6.5311,   7.2641,  -5.7087, -11.5525, -26.0675],
          [-14.4078,  21.4661,   3.0275,  12.9593,   8.6055],
          [-11.9820,  -4.1519, -10.7201, -54.3572,   3.2330]],

         ...,

         [[-25.0097,  35.8248,  14.8300,   7.4665,  26.3431],
          [ 35.9735,   9.9326, -14.6631,   3.8056,   8.6904],
          [-14.5735,   7.8065,   2.3971,  -9.1679, -24.6217],
          [  4.0892,  -0.2361, -23.3539, -16.5487, -14.7438],
          [-21.0442, -15.1294,  30.7480,  22.7784,  -5.4401]],

         [[ 10.1806,  -9.7599, -13.0879, -11.2862,   8.7011],
          [ 16.9221, -22.5619,  -9.1881,   7.2206, -14.2488],
          [  7.2253, -20.9041,  37.5530,  -2.5788,  -5.6223],
          [ -8.2343,  12.4944, -12.7566,   2.6582,  20.6420],
          [ 29.4380,   8.9442,   7.4303,   3.7857,   1.9862]],

         [[-15.6053,  42.0223, -43.0718,  16.9400,  11.3386],
          [  2.3042, -27.9817,   9.1433,  29.1376,   7.6629],
          [-20.5137,   5.2436, -15.3141,  -6.1896,  31.4788],
          [ -2.2009, -26.3716,   2.7668,  24.5455,   6.2913],
          [-17.2962,   4.3340,  -7.5388,  38.4184, -10.4836]]]])
DESIRED: (shape=torch.Size([64, 32, 5, 5]), dtype=torch.float32)
tensor([[[[-4.3840e+01, -1.7138e+01,  2.3669e+01,  8.3084e-01, -3.6211e+00],
          [ 1.5481e+01, -3.4671e+01, -4.9521e+00, -2.7620e+00, -6.6689e+00],
          [ 2.2356e+01,  1.2791e+01,  2.0057e+01, -5.4688e-01,  1.0457e+01],
          [-3.3595e+01,  1.9065e+01,  1.8654e+01, -2.6118e+00,  8.5164e+00],
          [-2.1667e+01,  6.9535e+00, -1.4680e+01, -3.5996e+01, -2.8886e+01]],

         [[ 5.6100e+00, -1.6650e+01,  2.1153e+00, -1.3520e+01,  2.8238e+01],
          [-2.0252e+01,  1.0230e+01,  7.5181e+00, -2.1763e+01,  1.4381e+01],
          [ 2.9367e+01,  1.3483e+01, -7.3329e+00,  3.1492e+00, -4.4375e+00],
          [-2.6385e-01, -6.7474e+00,  4.2725e+00,  1.0955e+00,  1.4373e+01],
          [-1.7410e+01,  1.9261e+00, -4.1270e+00,  5.4626e+00, -2.9872e+00]],

         [[ 3.3231e+00, -1.6904e+01,  1.9108e+01, -2.8248e+00, -1.4730e+00],
          [-1.8852e+00,  9.3849e+00, -7.1140e+00, -2.5300e+00,  3.7294e+00],
          [ 4.0399e-01, -4.0083e+00, -1.7033e+01, -4.1761e+01,  2.7472e+01],
          [ 2.9822e+01, -9.0406e+00,  2.1003e+01, -5.7751e+00,  2.9702e+00],
          [-1.9886e+01, -1.1110e+01, -3.6699e+01, -2.3241e+01,  1.1076e+01]],

         ...,

         [[ 1.8269e+00, -2.3796e+01,  2.0370e+00,  2.3956e+01,  3.8248e+01],
          [ 9.2995e+00,  1.2901e+01,  6.6683e+00, -6.9939e+00,  2.7783e+01],
          [-9.0937e+00, -6.4128e+00, -3.5836e+01,  1.6849e+01,  9.8624e+00],
          [-2.4859e-01,  5.1452e+00,  9.3071e+00, -2.0412e+01, -1.8186e+01],
          [-2.2210e+01, -9.8446e+00,  1.9997e+01,  3.2806e+01, -3.5494e+00]],

         [[-8.0494e+00,  1.8954e+01, -3.0052e+01,  1.1985e+01,  1.1229e+01],
          [-1.6434e+00, -3.3558e+00, -1.1366e+01, -1.9870e+01,  5.5679e+00],
          [-2.8415e+01, -2.7371e+01,  2.0180e+01,  9.0916e+00,  1.4621e+01],
          [-1.8788e+01,  4.5058e+00, -8.8306e+00, -2.2334e+01, -8.5858e+00],
          [ 1.1620e+01, -2.9529e+01, -1.8523e+01, -2.1270e+00,  7.3343e+00]],

         [[ 7.3441e+00, -9.1284e+00, -9.4730e-01, -2.6127e+00,  8.8901e+00],
          [-2.0767e+01,  1.7443e+01, -1.9505e+01, -1.9243e+01,  9.4191e+00],
          [ 8.7783e+00,  1.4239e+01,  7.2574e-01, -1.1602e+01, -9.0149e-01],
          [ 1.4707e+01,  3.3555e+01,  2.0838e+01, -4.4702e-01, -1.2459e+01],
          [ 1.4555e+00,  7.5675e+00, -1.3789e+01, -3.4401e+00,  1.7375e+01]]],


        [[[-1.7576e+00,  8.4965e+00,  1.3499e+01,  6.7949e-01, -1.5441e+01],
          [ 4.0708e+00, -2.7404e+01,  5.0134e+00,  1.8755e+00,  2.2104e+00],
          [-1.5219e+01,  1.3288e+01,  9.2366e+00,  5.8369e+00,  1.3970e+01],
          [ 2.3993e+01, -1.0572e+01, -3.1053e+01,  1.7862e+01, -1.1172e+00],
          [ 2.1085e+01, -3.4472e+01, -3.1190e+01,  3.5927e+00, -3.2664e+00]],

         [[ 2.0169e+01,  9.8237e+00,  2.3266e+01, -1.9043e+00,  6.0461e-01],
          [ 1.9568e+01, -3.1235e+01,  1.9122e+01,  2.4641e+01, -1.8007e+01],
          [ 1.0092e+01, -4.9721e+00,  7.3832e+00, -4.7541e+00,  3.1956e+01],
          [-4.7473e+01, -7.9875e+00, -2.4958e+00, -5.2867e+00, -1.3691e+00],
          [ 3.5212e+01, -1.6007e+01,  2.9332e+01,  1.4290e+01,  6.5361e+00]],

         [[ 2.0367e+01, -5.2769e+00,  1.3696e-01, -2.2613e+01,  2.4227e+01],
          [ 1.5012e+01,  3.8842e+01, -3.2110e+00, -2.6548e+01,  7.0007e-01],
          [ 1.5762e+01, -4.5881e+01,  1.9489e+01, -3.9936e+01,  9.5977e+00],
          [-3.5725e-01, -1.6436e+00,  1.4252e+01, -5.9358e+00,  2.9591e+01],
          [ 1.4893e+00,  3.8770e+01,  2.8441e+01, -4.5441e+00, -1.3990e+01]],

         ...,

         [[ 1.7636e+01,  8.1223e+00,  1.6476e+01, -1.4121e+00,  2.4906e+01],
          [-1.1331e+00, -1.3464e+01,  2.8860e+00,  2.8717e+01,  2.8843e+01],
          [-4.6945e-01,  1.8584e+01, -9.3450e+00,  1.2038e+01, -1.0626e+01],
          [-7.9704e+00, -2.5155e+01, -9.1428e-01, -1.9496e+00, -1.1371e+01],
          [-3.8704e+00, -9.9690e+00, -1.3985e+01,  3.2775e+01,  1.2215e+01]],

         [[-3.1474e+01, -2.0762e+00,  1.7555e+01,  2.9539e+01,  1.4252e+01],
          [-2.2186e+01, -1.3117e+01, -2.0223e+01,  2.0489e+01,  2.2283e+00],
          [-1.7967e+01, -2.3372e+00, -9.2318e+00,  7.5803e+00,  2.1414e+01],
          [ 3.3854e+01,  5.4869e+00, -7.5926e-01,  2.9894e+00, -1.2653e+01],
          [ 1.0136e+01, -3.0402e+01,  1.3468e+01,  1.3296e+01,  9.3710e+00]],

         [[ 2.8450e+01,  1.2384e+01, -7.6523e-01, -1.3421e+01,  8.3670e+00],
          [-1.1914e+01, -5.4661e+00, -3.0169e+00, -1.9995e+01, -4.1205e+01],
          [ 6.0024e+00, -8.8880e+00, -2.6262e+01, -1.3005e+01, -5.0301e+01],
          [-2.2923e+01,  8.4618e+00, -2.5686e+01,  1.7437e+01, -2.9011e+01],
          [-1.6839e+00, -2.9660e+01, -6.6125e+00,  1.8949e+01,  9.6560e+00]]],


        [[[-8.9500e+00,  1.1774e+01, -1.3492e+01,  7.8279e+00, -1.6199e+00],
          [-6.3873e+00, -1.8191e+01, -1.3234e+01, -8.9279e+00, -1.0886e+01],
          [ 4.3062e+00,  3.3182e+00, -2.6811e+00,  1.4051e+01,  2.6020e+01],
          [ 1.2938e+01, -1.0891e+00, -6.8476e+00,  2.1183e+01, -1.7166e+01],
          [-2.9853e+00,  1.2178e+01,  3.7854e+00, -1.6475e+01, -3.1421e+01]],

         [[ 2.0711e+01,  9.9870e+00, -4.5460e+01,  7.5364e+00, -2.1026e+01],
          [ 4.6574e+00,  3.7185e+01,  2.9593e+01, -2.1678e+01, -4.0649e-02],
          [-9.3547e+00, -2.7183e+01, -1.3941e+01, -2.8837e+01,  4.8127e+00],
          [ 7.2245e+00, -3.3732e+00, -2.0826e+01, -2.1780e+00,  3.8325e+01],
          [-8.5471e+00,  5.3599e+00, -2.6576e+01,  1.8382e+01,  8.3258e-01]],

         [[-8.0743e+00, -5.0646e+00,  1.6524e+01, -1.6580e+01, -8.1660e+00],
          [ 4.3545e+00, -1.6366e+01, -7.8858e+00,  2.3844e+01,  7.5521e+00],
          [ 1.1713e+00,  5.9862e+00, -2.2161e+00,  7.8323e+00, -1.7110e+01],
          [-1.1579e+00, -2.7190e+01, -1.5301e+01, -2.7001e+01, -9.1595e-01],
          [ 9.5776e+00, -9.5276e+00, -3.1913e+00, -1.0988e+01, -1.5461e+01]],

         ...,

         [[-2.9867e-01,  2.1232e+01,  9.1824e+00,  5.7247e+00, -4.1267e+00],
          [ 4.0239e+00, -1.5323e+00,  9.6265e+00,  5.0143e+00,  1.4243e+01],
          [-2.7332e+00, -2.7116e+01,  1.9253e+01, -2.0624e+00,  3.9177e+01],
          [ 1.4849e+01,  1.4874e+01, -1.5339e+01,  7.3846e-01,  2.1320e+00],
          [-1.4248e+01,  1.9901e+01,  9.5870e+00,  3.7352e+01, -1.7201e+01]],

         [[-8.4667e+00,  4.7650e+00,  3.6026e+00, -2.0147e+01,  9.7278e+00],
          [ 1.1646e+01,  2.6676e+01, -2.2522e+01, -2.6898e+01,  3.1964e+01],
          [ 2.8094e+01, -3.0260e+00, -2.6361e+01, -1.5183e+01,  1.2756e+01],
          [ 1.9379e+01, -1.6973e+00, -1.9059e+00, -9.8605e+00,  1.5626e+00],
          [ 1.4203e+01,  3.5495e+01, -8.8468e+00, -3.0644e+00, -1.0148e+01]],

         [[-1.3835e+01, -1.0936e+00,  1.6723e+01, -3.7147e+01,  1.0255e+01],
          [-4.8349e+00,  4.5267e-01, -1.2729e+01,  9.1891e+00,  4.0166e+00],
          [-2.4615e+00, -1.8170e+00,  4.0258e+01, -6.8268e+00, -1.1798e+01],
          [ 8.7121e+00,  1.7322e+01,  2.1068e+01,  2.3994e+01, -1.5281e+01],
          [-2.5531e+01,  1.8320e+01,  1.7800e+00, -3.1118e+01,  1.7930e+01]]],


        ...,


        [[[ 3.6770e+01, -1.2181e+00,  1.2632e+01, -1.4968e+01, -5.7903e+00],
          [ 6.6270e-01, -5.4862e+00, -8.8379e-01, -2.3152e+01,  4.4717e+00],
          [ 1.3610e+01,  9.4427e+00, -1.3016e+01, -1.4646e+00,  3.8935e+00],
          [-4.1014e+00,  3.7771e+00, -4.8875e+01, -3.5148e+01, -9.9706e+00],
          [ 1.5609e+01,  7.9095e+00, -1.7863e+01, -2.2120e+01, -1.3440e+01]],

         [[ 3.2149e+01, -4.5104e+01, -3.2134e+01,  2.3056e+01,  1.4445e+01],
          [ 3.8925e+00,  2.1581e+01, -3.5041e+00,  1.2673e+01,  3.5894e+01],
          [ 1.6369e+00,  1.9995e+01,  9.4606e+00, -1.3211e+01,  1.8923e+01],
          [ 5.0475e+00, -1.6720e+01,  9.4477e+00, -4.1162e+01,  5.7384e+00],
          [-5.8163e+00, -7.9502e+00, -3.9023e-01,  4.2526e+00, -7.3142e+00]],

         [[ 2.0200e+01,  2.6939e+01,  1.4761e+01, -3.8060e+00, -3.1517e+01],
          [ 2.2012e+01, -1.1102e+01, -4.6349e+00, -1.4762e+01,  4.9719e+01],
          [-5.6250e+00,  4.6689e+00, -1.0038e+00, -3.1155e+01, -1.4613e+01],
          [-2.2735e+01,  3.1847e+01, -6.5240e-01, -4.7430e+00,  2.4207e+01],
          [-6.6907e+00, -9.6165e+00, -7.0898e+00, -6.8651e+00,  3.9285e+00]],

         ...,

         [[-1.3459e+01,  1.7073e+01, -1.3567e+01, -1.4134e+01, -2.0367e+01],
          [-6.8019e-01, -2.0408e+01, -8.2681e+00,  2.2635e+01,  1.2640e+01],
          [-2.7971e+00, -8.5282e+00, -3.0206e+01, -3.3319e-01,  2.2620e+01],
          [ 2.6774e+01, -2.7671e+01, -1.3527e+01, -1.4141e+00,  2.6346e+01],
          [ 5.9641e+00, -6.4410e+00, -1.5031e+01, -1.2121e+01, -1.0307e+01]],

         [[-4.9477e+00, -1.5931e+01,  1.0913e+01, -8.5175e-01,  1.9237e+01],
          [ 4.3124e+00,  3.0540e+01,  1.6992e+01,  2.5915e+01, -1.0158e+01],
          [ 3.6021e+01, -2.5773e+01, -1.6888e+01,  7.7500e+00, -1.4080e+01],
          [-1.4270e+00, -4.1294e+01,  3.1564e+00, -2.5144e+00,  1.4678e+00],
          [-2.0810e+00,  1.8724e+01, -6.8947e+00,  4.2080e+01,  4.0544e+01]],

         [[-1.4408e+01,  5.9979e+00,  8.9075e+00,  1.5646e+01,  1.1926e+00],
          [-3.0381e+00, -9.6277e+00,  7.8137e-01,  4.7516e+00,  1.8940e+01],
          [ 3.3951e+00, -3.0387e+01,  1.8655e+01, -7.2961e+00,  1.8896e+01],
          [ 1.4389e+01,  1.8796e+01,  1.4898e+01, -2.4652e+01, -1.0987e+01],
          [-2.2315e+01,  5.5291e+00,  2.0785e+01, -2.9842e+00,  2.6702e+01]]],


        [[[-3.7924e+01, -1.2607e+01,  2.2885e+01,  7.0842e+00,  4.3037e+00],
          [ 2.0062e+01, -7.5669e-01,  5.8590e+00, -3.9936e+01, -7.9684e-01],
          [ 6.0235e+00,  5.8908e+00, -9.2401e-01,  2.6151e+01,  4.4038e+00],
          [-3.5428e+01,  1.8958e+01, -3.1522e+01, -1.1802e+01,  7.2925e+00],
          [ 6.3757e+00,  7.8255e+00,  4.1241e+00,  7.1720e+00, -1.7821e+01]],

         [[ 1.6949e+01,  1.1184e+01, -6.9409e-01,  9.1833e+00,  3.8773e+01],
          [-7.0432e+00, -2.9557e+00, -2.4670e+01,  1.0246e+01,  1.1442e+01],
          [ 1.2036e+00,  7.2668e+00, -9.7569e+00,  1.8747e+01, -1.5609e+01],
          [ 2.5685e+01,  7.4321e+00,  1.9995e+01, -2.2822e+01,  2.0080e+01],
          [ 4.8647e+00,  2.8070e+01,  1.5396e+00,  3.5373e+01,  2.7042e+01]],

         [[ 7.7911e-01, -8.7426e+00,  5.5354e+00,  3.5101e+01, -2.1109e+01],
          [ 6.3286e+00, -1.3939e+01,  2.5490e+00,  5.3669e+00,  1.1830e+01],
          [ 3.3962e+01, -5.3944e+00,  4.8613e+00,  1.9083e+01,  2.6270e+00],
          [ 2.1361e+01,  1.4800e+01, -6.4269e+00,  9.3327e+00,  6.3255e+00],
          [ 2.5667e+00,  1.7389e+01,  3.2712e+01, -2.6747e+01, -1.1008e+01]],

         ...,

         [[ 2.0161e+01,  6.1288e+00,  1.4496e+01, -1.5891e+01,  1.9842e+01],
          [ 1.6965e+01, -9.6594e+00, -2.8462e+01,  1.4219e+01, -5.9507e+00],
          [ 5.9668e-01,  8.6129e+00, -2.2469e+01,  1.6687e+01, -4.7305e+00],
          [ 7.2319e+00, -1.6504e+01, -2.9463e+01,  8.9181e+00,  3.8539e+01],
          [-3.0834e+01,  1.1359e+01,  1.4476e+01, -1.5606e+01,  1.3478e+01]],

         [[ 3.0797e+01,  1.4564e+01,  4.3005e+00,  1.9606e+01,  2.7543e+00],
          [ 4.0099e+01,  1.2475e+01,  2.5978e+01,  1.2798e+01, -1.3004e+01],
          [ 4.9319e+00,  3.8479e+01, -4.3001e+01, -3.7824e+01,  4.1139e+00],
          [ 7.8159e-01,  3.3972e+01, -1.0497e+01, -2.8322e+01,  2.9475e+01],
          [-3.1291e+01,  3.2221e+00, -1.8196e+01, -1.1180e+01,  4.0446e+00]],

         [[ 1.9157e+01, -3.8580e+00,  5.0841e+00, -4.0177e+01, -1.8797e+01],
          [-3.8465e+00,  7.2520e+00,  1.6739e+01,  6.9709e+00, -2.0185e+01],
          [-7.3354e+00, -1.3674e+01, -7.1179e-01,  1.5617e+01, -1.8665e+01],
          [ 2.8992e+01,  2.2839e+01, -1.6129e+01, -3.3094e+01,  9.9924e-01],
          [ 1.0950e+00,  7.1961e+00,  5.2463e+00, -3.1382e+01, -3.1851e+01]]],


        [[[-3.7152e+00,  6.7525e+00,  3.2515e+01,  3.2439e+01, -1.2242e+01],
          [-1.4457e+01, -9.6650e+00,  9.2460e+00,  2.8220e+01,  2.0060e+00],
          [-1.1824e+01,  1.5971e+01,  4.1033e+00,  2.7239e+01,  1.2727e+01],
          [ 6.0641e+00,  1.0580e+01, -2.9138e+01,  7.6818e+00,  3.7897e+00],
          [ 3.3464e+01,  3.7437e+01,  1.8758e+01, -6.1414e+00,  2.8590e+00]],

         [[-7.0030e+00,  2.2066e+01,  1.7641e+01, -2.2229e+01,  2.5649e+00],
          [-2.8364e+01, -2.9059e+01,  9.1448e+00, -3.1244e+00, -2.0298e+01],
          [-8.9437e+00,  6.0359e+00,  3.3873e+01, -1.7171e+01, -3.8461e-01],
          [ 1.7200e+01, -1.6804e+01, -1.2190e+01,  1.3080e+01,  3.9031e+00],
          [ 2.9148e+00,  1.5776e+01, -1.7809e+01,  8.8368e+00,  7.7669e+00]],

         [[-1.2220e+01, -6.5478e+00,  1.6923e+01, -2.1360e+00,  3.9503e+00],
          [-2.3464e+01, -2.1719e+01,  6.0399e+00, -2.9471e+01,  5.1408e+00],
          [-6.5409e+00,  7.2819e+00, -5.7218e+00, -1.1533e+01, -2.6112e+01],
          [-1.4408e+01,  2.1453e+01,  3.0402e+00,  1.2963e+01,  8.5903e+00],
          [-1.1959e+01, -4.1038e+00, -1.0757e+01, -5.4308e+01,  3.1422e+00]],

         ...,

         [[-2.4996e+01,  3.5855e+01,  1.4793e+01,  7.5678e+00,  2.6093e+01],
          [ 3.6009e+01,  9.9265e+00, -1.4645e+01,  3.7701e+00,  8.7659e+00],
          [-1.4618e+01,  7.8183e+00,  2.3841e+00, -9.1534e+00, -2.4667e+01],
          [ 4.1686e+00, -2.5687e-01, -2.3323e+01, -1.6585e+01, -1.4654e+01],
          [-2.1225e+01, -1.5080e+01,  3.0700e+01,  2.2805e+01, -5.5237e+00]],

         [[ 1.0161e+01, -9.7658e+00, -1.3054e+01, -1.1357e+01,  8.9031e+00],
          [ 1.6892e+01, -2.2557e+01, -9.2053e+00,  7.2509e+00, -1.4327e+01],
          [ 7.2385e+00, -2.0897e+01,  3.7561e+01, -2.5876e+00, -5.5867e+00],
          [-8.2718e+00,  1.2483e+01, -1.2766e+01,  2.6738e+00,  2.0599e+01],
          [ 2.9520e+01,  8.9808e+00,  7.4323e+00,  3.7935e+00,  2.0170e+00]],

         [[-1.5635e+01,  4.2062e+01, -4.3120e+01,  1.7002e+01,  1.1314e+01],
          [ 2.3601e+00, -2.7989e+01,  9.1508e+00,  2.9133e+01,  7.6349e+00],
          [-2.0532e+01,  5.2537e+00, -1.5319e+01, -6.1874e+00,  3.1517e+01],
          [-2.1642e+00, -2.6381e+01,  2.7676e+00,  2.4548e+01,  6.2358e+00],
          [-1.7334e+01,  4.3395e+00, -7.5237e+00,  3.8373e+01, -1.0349e+01]]]])

2025-06-10 00:13:31.302099 GPU 6 156013 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 298, 364, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 298, 364, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 433888 (0.0%)
Greatest absolute difference: 0.6191434860229492 at index (0, 2, 36, 79) (up to 0.01 allowed)
Greatest relative difference: 1.7157717943191528 at index (0, 2, 41, 32) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 298, 364]), dtype=torch.float32)
tensor([[[[ 0.2081, -0.4827, -0.3027,  ...,  0.0904,  0.0124, -0.2162],
          [-0.3597,  0.4869,  0.0700,  ...,  0.2447, -0.1975, -0.0505],
          [-0.2631,  0.1497,  0.2568,  ..., -0.3137, -0.3268, -0.2212],
          ...,
          [-0.3308,  0.4273,  0.3127,  ...,  0.0518, -0.4002, -0.4321],
          [ 0.1724, -0.1233,  0.1884,  ..., -0.1525, -0.1212, -0.1773],
          [ 0.3401,  0.1846,  0.3775,  ..., -0.1258, -0.0280,  0.1100]],

         [[-0.4132,  0.0476,  0.4442,  ..., -0.1790,  0.3332,  0.2837],
          [ 0.0354, -0.1040,  0.4391,  ..., -0.1803,  0.0698, -0.1826],
          [ 0.3442, -0.3615, -0.4294,  ...,  0.3626,  0.0107,  0.3020],
          ...,
          [-0.0622, -0.2386, -0.0951,  ...,  0.3321, -0.0724,  0.2607],
          [-0.1585, -0.2183, -0.0816,  ...,  0.2357, -0.4026, -0.1463],
          [-0.2372, -0.0022, -0.4949,  ..., -0.1784,  0.3341, -0.4050]],

         [[-0.1335, -0.1455,  0.3951,  ..., -0.4733, -0.1026, -0.4759],
          [-0.0402,  0.4230,  0.0508,  ..., -0.1162, -0.1327, -0.3702],
          [ 0.0732,  0.0633, -0.1731,  ..., -0.1412,  0.4880, -0.0616],
          ...,
          [-0.4584, -0.0661,  0.2546,  ..., -0.1154, -0.1551,  0.2206],
          [-0.0687,  0.4414, -0.1525,  ...,  0.4499, -0.2726, -0.1883],
          [ 0.4591, -0.0727, -0.2261,  ..., -0.4811, -0.3006,  0.3983]],

         [[ 0.4465,  0.3412, -0.0800,  ...,  0.4329,  0.4746, -0.3209],
          [ 0.4641, -0.4444,  0.4790,  ...,  0.1908, -0.1347,  0.0411],
          [-0.1040, -0.4451,  0.1352,  ...,  0.4846,  0.1724,  0.2174],
          ...,
          [ 0.4616, -0.2574, -0.3835,  ..., -0.0019,  0.2970,  0.2620],
          [-0.4569,  0.3172, -0.1026,  ...,  0.2283,  0.4861, -0.3434],
          [ 0.4505, -0.2990,  0.3682,  ..., -0.1874, -0.2740,  0.2075]]]])
DESIRED: (shape=torch.Size([1, 4, 298, 364]), dtype=torch.float32)
tensor([[[[ 0.2081, -0.4827, -0.3027,  ...,  0.0904,  0.0124, -0.2162],
          [-0.3597,  0.4869,  0.0700,  ...,  0.2447, -0.1975, -0.0505],
          [-0.2631,  0.1497,  0.2568,  ..., -0.3137, -0.3268, -0.2212],
          ...,
          [-0.3308,  0.4273,  0.3127,  ...,  0.0518, -0.4002, -0.4321],
          [ 0.1724, -0.1233,  0.1884,  ..., -0.1525, -0.1212, -0.1773],
          [ 0.3401,  0.1846,  0.3775,  ..., -0.1258, -0.0280,  0.1100]],

         [[-0.4132,  0.0476,  0.4442,  ..., -0.1790,  0.3332,  0.2837],
          [ 0.0354, -0.1040,  0.4391,  ..., -0.1803,  0.0698, -0.1826],
          [ 0.3442, -0.3615, -0.4294,  ...,  0.3626,  0.0107,  0.3020],
          ...,
          [-0.0622, -0.2386, -0.0951,  ...,  0.3321, -0.0724,  0.2607],
          [-0.1585, -0.2183, -0.0816,  ...,  0.2357, -0.4026, -0.1463],
          [-0.2372, -0.0022, -0.4949,  ..., -0.1784,  0.3341, -0.4050]],

         [[-0.1335, -0.1455,  0.3951,  ..., -0.4733, -0.1026, -0.4759],
          [-0.0402,  0.4230,  0.0508,  ..., -0.1162, -0.1327, -0.3702],
          [ 0.0732,  0.0633, -0.1731,  ..., -0.1412,  0.4880, -0.0616],
          ...,
          [-0.4584, -0.0661,  0.2546,  ..., -0.1154, -0.1551,  0.2206],
          [-0.0687,  0.4414, -0.1525,  ...,  0.4499, -0.2726, -0.1883],
          [ 0.4591, -0.0727, -0.2261,  ..., -0.4811, -0.3006,  0.3983]],

         [[ 0.4465,  0.3412, -0.0800,  ...,  0.4329,  0.4746, -0.3209],
          [ 0.4641, -0.4444,  0.4790,  ...,  0.1908, -0.1347,  0.0411],
          [-0.1040, -0.4451,  0.1352,  ...,  0.4846,  0.1724,  0.2174],
          ...,
          [ 0.4616, -0.2574, -0.3835,  ..., -0.0019,  0.2970,  0.2620],
          [-0.4569,  0.3172, -0.1026,  ...,  0.2283,  0.4861, -0.3434],
          [ 0.4505, -0.2990,  0.3682,  ..., -0.1874, -0.2740,  0.2075]]]])

2025-06-10 00:13:31.499634 GPU 5 156012 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 368, 416, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 350],"float32"), Tensor([1, 368, 416, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 612352 (0.0%)
Greatest absolute difference: 0.8103618621826172 at index (0, 0, 341, 409) (up to 0.01 allowed)
Greatest relative difference: 3.343942165374756 at index (0, 3, 347, 80) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 368, 416]), dtype=torch.float32)
tensor([[[[ 1.2676e-01, -1.8823e-01, -1.8921e-01,  ...,  2.1428e-01,  2.0447e-02, -1.6723e-01],
          [ 2.3028e-01,  2.5616e-01,  1.2643e-01,  ..., -4.9247e-01, -2.5767e-01,  7.2555e-02],
          [ 2.9824e-01,  4.9854e-04,  1.2475e-01,  ...,  3.8373e-01,  4.5973e-01,  7.8724e-02],
          ...,
          [-4.0841e-01,  4.9499e-02,  4.2190e-01,  ..., -2.5874e-01,  2.5595e-01,  4.2719e-01],
          [-3.5078e-01, -3.7976e-01,  3.3434e-01,  ..., -2.1713e-01, -3.0796e-01, -4.2793e-01],
          [-1.0792e-01,  3.6253e-01, -3.8774e-01,  ...,  1.3042e-01,  1.1026e-02, -4.0678e-01]],

         [[ 4.3447e-01, -1.8692e-01,  3.3946e-01,  ...,  1.1645e-01, -1.4425e-01,  2.5100e-01],
          [-4.4399e-01,  3.5200e-01, -3.1358e-01,  ...,  2.8244e-01, -3.0872e-01, -4.8980e-01],
          [ 2.4163e-01,  3.1569e-01,  1.6261e-02,  ...,  1.4794e-01, -3.9548e-01, -2.6787e-01],
          ...,
          [ 6.4648e-02,  1.5275e-01, -2.5636e-01,  ...,  1.6165e-01, -1.5824e-01,  2.6517e-01],
          [ 1.2856e-01,  1.9209e-01,  4.6215e-01,  ..., -4.8776e-01,  3.5991e-01,  2.9045e-02],
          [-1.5341e-01,  1.7324e-01, -3.2280e-01,  ..., -4.1288e-01,  4.7077e-01, -2.6923e-01]],

         [[-3.2951e-01,  1.8900e-01, -1.7385e-01,  ...,  1.4672e-01, -1.8023e-01,  2.9530e-01],
          [-4.8174e-01, -3.4875e-01, -3.9189e-01,  ...,  1.1195e-02,  6.0314e-02,  1.7098e-02],
          [-4.6335e-02, -2.9107e-01, -3.8315e-01,  ..., -3.9585e-01, -1.2496e-01, -2.4218e-01],
          ...,
          [ 2.5667e-01, -9.5516e-02, -4.8214e-01,  ..., -4.4862e-01, -4.8743e-01, -4.7654e-02],
          [ 3.5385e-01, -2.9934e-01, -2.5256e-01,  ...,  4.8637e-01, -4.5046e-01,  3.0475e-01],
          [ 3.0618e-01,  4.9461e-01,  3.9478e-01,  ..., -4.8856e-03,  1.0853e-01,  3.4729e-01]],

         [[ 3.9526e-01, -1.4053e-01,  2.6717e-01,  ..., -6.0627e-02,  3.7994e-01,  1.5116e-04],
          [ 3.6127e-01,  4.1945e-01, -3.7524e-01,  ...,  1.9584e-01, -3.3006e-01,  4.8002e-01],
          [ 4.2634e-01,  7.1303e-02, -5.3210e-02,  ..., -4.7999e-01,  2.9872e-01,  5.2144e-02],
          ...,
          [-4.6001e-01,  9.6416e-02, -4.8854e-02,  ...,  2.9148e-02, -4.6997e-01,  4.3890e-02],
          [-3.2599e-01, -1.9882e-01,  2.8099e-01,  ...,  5.5793e-02,  4.8811e-01,  4.9667e-01],
          [-4.8781e-01, -3.8670e-01, -4.6174e-01,  ..., -3.7871e-01,  8.3586e-02,  1.2286e-02]]]])
DESIRED: (shape=torch.Size([1, 4, 368, 416]), dtype=torch.float32)
tensor([[[[ 1.2676e-01, -1.8823e-01, -1.8921e-01,  ...,  2.1428e-01,  2.0447e-02, -1.6723e-01],
          [ 2.3028e-01,  2.5616e-01,  1.2643e-01,  ..., -4.9247e-01, -2.5767e-01,  7.2555e-02],
          [ 2.9824e-01,  4.9854e-04,  1.2475e-01,  ...,  3.8373e-01,  4.5973e-01,  7.8724e-02],
          ...,
          [-4.0841e-01,  4.9499e-02,  4.2190e-01,  ..., -2.5874e-01,  2.5595e-01,  4.2719e-01],
          [-3.5078e-01, -3.7976e-01,  3.3434e-01,  ..., -2.1713e-01, -3.0796e-01, -4.2793e-01],
          [-1.0792e-01,  3.6253e-01, -3.8774e-01,  ...,  1.3042e-01,  1.1026e-02, -4.0678e-01]],

         [[ 4.3447e-01, -1.8692e-01,  3.3946e-01,  ...,  1.1645e-01, -1.4425e-01,  2.5100e-01],
          [-4.4399e-01,  3.5200e-01, -3.1358e-01,  ...,  2.8244e-01, -3.0872e-01, -4.8980e-01],
          [ 2.4163e-01,  3.1569e-01,  1.6261e-02,  ...,  1.4794e-01, -3.9548e-01, -2.6787e-01],
          ...,
          [ 6.4648e-02,  1.5275e-01, -2.5636e-01,  ...,  1.6165e-01, -1.5824e-01,  2.6517e-01],
          [ 1.2856e-01,  1.9209e-01,  4.6215e-01,  ..., -4.8776e-01,  3.5991e-01,  2.9045e-02],
          [-1.5341e-01,  1.7324e-01, -3.2280e-01,  ..., -4.1288e-01,  4.7077e-01, -2.6923e-01]],

         [[-3.2951e-01,  1.8900e-01, -1.7385e-01,  ...,  1.4672e-01, -1.8023e-01,  2.9530e-01],
          [-4.8174e-01, -3.4875e-01, -3.9189e-01,  ...,  1.1195e-02,  6.0314e-02,  1.7098e-02],
          [-4.6335e-02, -2.9107e-01, -3.8315e-01,  ..., -3.9585e-01, -1.2496e-01, -2.4218e-01],
          ...,
          [ 2.5667e-01, -9.5516e-02, -4.8214e-01,  ..., -4.4862e-01, -4.8743e-01, -4.7654e-02],
          [ 3.5385e-01, -2.9934e-01, -2.5256e-01,  ...,  4.8637e-01, -4.5046e-01,  3.0475e-01],
          [ 3.0618e-01,  4.9461e-01,  3.9478e-01,  ..., -4.8856e-03,  1.0853e-01,  3.4729e-01]],

         [[ 3.9526e-01, -1.4053e-01,  2.6717e-01,  ..., -6.0627e-02,  3.7994e-01,  1.5116e-04],
          [ 3.6127e-01,  4.1945e-01, -3.7524e-01,  ...,  1.9584e-01, -3.3006e-01,  4.8002e-01],
          [ 4.2634e-01,  7.1303e-02, -5.3210e-02,  ..., -4.7999e-01,  2.9872e-01,  5.2144e-02],
          ...,
          [-4.6001e-01,  9.6416e-02, -4.8854e-02,  ...,  2.9148e-02, -4.6997e-01,  4.3890e-02],
          [-3.2599e-01, -1.9882e-01,  2.8099e-01,  ...,  5.5793e-02,  4.8811e-01,  4.9667e-01],
          [-4.8781e-01, -3.8670e-01, -4.6174e-01,  ..., -3.7871e-01,  8.3586e-02,  1.2286e-02]]]])

2025-06-10 00:13:31.517789 GPU 6 156013 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 298, 364],"float32"), Tensor([1, 352, 407, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 298, 364],"float32"), Tensor([1, 352, 407, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 24 / 573056 (0.0%)
Greatest absolute difference: 0.7940096855163574 at index (0, 1, 54, 281) (up to 0.01 allowed)
Greatest relative difference: 30.14227294921875 at index (0, 3, 54, 281) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 352, 407]), dtype=torch.float32)
tensor([[[[ 3.2462e-01, -3.6380e-01, -3.6848e-02,  ...,  6.3186e-02, -4.0543e-01,  1.5318e-01],
          [-1.7587e-01, -4.0583e-01, -2.4911e-01,  ..., -3.0388e-01,  4.4524e-01,  4.6016e-01],
          [-3.8947e-01, -4.1217e-02,  2.3227e-01,  ..., -2.9993e-01,  2.9936e-02,  2.2307e-01],
          ...,
          [-2.1020e-01, -6.1097e-02, -2.4870e-03,  ...,  3.5999e-01, -2.1434e-01,  2.3114e-01],
          [ 1.8941e-01, -1.9318e-01, -2.6040e-01,  ..., -2.8082e-01, -3.1549e-02,  2.7888e-01],
          [-4.2817e-01, -4.2552e-01,  2.9344e-01,  ..., -3.5236e-01, -3.7458e-01,  3.3316e-01]],

         [[-2.1569e-01, -2.9476e-01,  6.0393e-02,  ...,  2.1384e-01,  4.4529e-01,  6.3976e-02],
          [-2.0014e-01, -2.7552e-01, -7.5190e-02,  ...,  2.4938e-02, -4.9756e-01, -4.0678e-01],
          [ 3.5314e-01, -2.5684e-01, -3.8631e-01,  ..., -1.5991e-01, -1.6912e-01, -1.4982e-01],
          ...,
          [-1.7340e-01, -4.1307e-01, -2.7847e-01,  ..., -1.5830e-01, -4.4731e-01,  3.6823e-01],
          [-2.7979e-01, -2.7151e-01, -1.0061e-01,  ...,  4.8993e-01, -3.2299e-01, -7.4533e-02],
          [-2.7051e-01,  3.4453e-01,  3.4767e-01,  ..., -3.1814e-01, -3.1129e-02,  4.3068e-01]],

         [[ 1.9887e-01,  1.8879e-02,  3.3497e-01,  ..., -2.7990e-01,  4.1335e-01, -1.4647e-01],
          [-4.2610e-01,  3.3914e-01, -3.1654e-01,  ...,  4.8006e-01, -3.6912e-01, -2.3604e-01],
          [-2.6172e-01,  5.8839e-02, -3.0456e-01,  ...,  2.3608e-01, -3.6963e-01,  1.8240e-01],
          ...,
          [-3.9902e-01,  4.9048e-01,  9.4465e-02,  ..., -4.2318e-01, -3.2561e-01, -1.2298e-01],
          [-1.7207e-01, -4.5986e-01,  1.1180e-01,  ..., -5.0736e-02, -4.0266e-01,  1.8005e-02],
          [-2.9259e-01, -3.0897e-01,  1.4575e-01,  ..., -2.1220e-01,  2.8494e-01, -2.0406e-01]],

         [[ 2.4009e-01, -2.7842e-03,  1.5571e-01,  ..., -2.6466e-01, -3.7977e-01, -4.9689e-01],
          [ 4.9958e-01, -6.5036e-02,  2.9660e-02,  ..., -6.0208e-02,  1.4233e-01, -4.2971e-01],
          [ 3.5009e-02,  2.5389e-01,  4.4944e-01,  ..., -3.9510e-02, -2.7981e-01, -9.6061e-02],
          ...,
          [ 1.4983e-01, -4.3377e-01, -4.8779e-01,  ...,  2.2361e-04,  3.3784e-01,  2.9541e-01],
          [ 2.0299e-01,  8.6453e-02,  4.0580e-01,  ...,  1.8772e-01, -1.9894e-01, -9.5180e-02],
          [-3.5683e-01,  4.7303e-01,  8.3771e-02,  ..., -4.9882e-01,  2.4116e-01, -2.7714e-01]]]])
DESIRED: (shape=torch.Size([1, 4, 352, 407]), dtype=torch.float32)
tensor([[[[ 3.2462e-01, -3.6380e-01, -3.6848e-02,  ...,  6.3186e-02, -4.0543e-01,  1.5318e-01],
          [-1.7587e-01, -4.0583e-01, -2.4911e-01,  ..., -3.0388e-01,  4.4524e-01,  4.6016e-01],
          [-3.8947e-01, -4.1217e-02,  2.3227e-01,  ..., -2.9993e-01,  2.9936e-02,  2.2307e-01],
          ...,
          [-2.1020e-01, -6.1097e-02, -2.4870e-03,  ...,  3.5999e-01, -2.1434e-01,  2.3114e-01],
          [ 1.8941e-01, -1.9318e-01, -2.6040e-01,  ..., -2.8082e-01, -3.1549e-02,  2.7888e-01],
          [-4.2817e-01, -4.2552e-01,  2.9344e-01,  ..., -3.5236e-01, -3.7458e-01,  3.3316e-01]],

         [[-2.1569e-01, -2.9476e-01,  6.0393e-02,  ...,  2.1384e-01,  4.4529e-01,  6.3976e-02],
          [-2.0014e-01, -2.7552e-01, -7.5190e-02,  ...,  2.4938e-02, -4.9756e-01, -4.0678e-01],
          [ 3.5314e-01, -2.5684e-01, -3.8631e-01,  ..., -1.5991e-01, -1.6912e-01, -1.4982e-01],
          ...,
          [-1.7340e-01, -4.1307e-01, -2.7847e-01,  ..., -1.5830e-01, -4.4731e-01,  3.6823e-01],
          [-2.7979e-01, -2.7151e-01, -1.0061e-01,  ...,  4.8993e-01, -3.2299e-01, -7.4533e-02],
          [-2.7051e-01,  3.4453e-01,  3.4767e-01,  ..., -3.1814e-01, -3.1129e-02,  4.3068e-01]],

         [[ 1.9887e-01,  1.8879e-02,  3.3497e-01,  ..., -2.7990e-01,  4.1335e-01, -1.4647e-01],
          [-4.2610e-01,  3.3914e-01, -3.1654e-01,  ...,  4.8006e-01, -3.6912e-01, -2.3604e-01],
          [-2.6172e-01,  5.8839e-02, -3.0456e-01,  ...,  2.3608e-01, -3.6963e-01,  1.8240e-01],
          ...,
          [-3.9902e-01,  4.9048e-01,  9.4465e-02,  ..., -4.2318e-01, -3.2561e-01, -1.2298e-01],
          [-1.7207e-01, -4.5986e-01,  1.1180e-01,  ..., -5.0736e-02, -4.0266e-01,  1.8005e-02],
          [-2.9259e-01, -3.0897e-01,  1.4575e-01,  ..., -2.1220e-01,  2.8494e-01, -2.0406e-01]],

         [[ 2.4009e-01, -2.7842e-03,  1.5571e-01,  ..., -2.6466e-01, -3.7977e-01, -4.9689e-01],
          [ 4.9958e-01, -6.5036e-02,  2.9660e-02,  ..., -6.0208e-02,  1.4233e-01, -4.2971e-01],
          [ 3.5009e-02,  2.5389e-01,  4.4944e-01,  ..., -3.9510e-02, -2.7981e-01, -9.6061e-02],
          ...,
          [ 1.4983e-01, -4.3377e-01, -4.8779e-01,  ...,  2.2361e-04,  3.3784e-01,  2.9541e-01],
          [ 2.0299e-01,  8.6453e-02,  4.0580e-01,  ...,  1.8772e-01, -1.9894e-01, -9.5180e-02],
          [-3.5683e-01,  4.7303e-01,  8.3771e-02,  ..., -4.9882e-01,  2.4116e-01, -2.7714e-01]]]])

2025-06-10 00:13:31.715262 GPU 5 156012 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 368, 416],"float32"), Tensor([1, 391, 436, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 368, 416],"float32"), Tensor([1, 391, 436, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 7 / 681904 (0.0%)
Greatest absolute difference: 0.6537615060806274 at index (0, 3, 168, 15) (up to 0.01 allowed)
Greatest relative difference: 72.41787719726562 at index (0, 3, 177, 272) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 391, 436]), dtype=torch.float32)
tensor([[[[-0.1377,  0.1596,  0.0483,  ..., -0.3015, -0.2337, -0.1324],
          [-0.2107,  0.0782,  0.4627,  ..., -0.0490,  0.3115, -0.3960],
          [ 0.1457,  0.4698,  0.2393,  ...,  0.4779,  0.3550,  0.3911],
          ...,
          [-0.0110,  0.1772,  0.4567,  ..., -0.0966, -0.1352,  0.0550],
          [-0.1984, -0.4105, -0.0322,  ...,  0.2346, -0.4569, -0.3723],
          [ 0.2186, -0.4236,  0.1953,  ..., -0.2510,  0.4169,  0.1827]],

         [[ 0.0571, -0.0464,  0.2640,  ...,  0.2866,  0.0510,  0.3882],
          [-0.4797,  0.4615, -0.3633,  ..., -0.4369,  0.3665,  0.0049],
          [-0.4004, -0.3815,  0.0480,  ..., -0.0358, -0.0105,  0.1764],
          ...,
          [-0.4206, -0.4351, -0.4594,  ..., -0.1212, -0.3134, -0.0536],
          [ 0.1980,  0.4654,  0.4751,  ...,  0.0119,  0.1962, -0.0063],
          [-0.2178,  0.1125,  0.0823,  ...,  0.3301,  0.0818, -0.1789]],

         [[-0.3552, -0.4500,  0.3888,  ..., -0.2668, -0.0759, -0.4163],
          [ 0.0750, -0.2115, -0.2736,  ...,  0.3676,  0.1104, -0.3061],
          [ 0.4642, -0.2453, -0.1712,  ..., -0.3498, -0.1965,  0.1992],
          ...,
          [-0.4196,  0.1812, -0.1014,  ..., -0.2962,  0.3993, -0.3727],
          [ 0.2178,  0.2101,  0.2815,  ...,  0.2822,  0.4793,  0.0044],
          [ 0.4765,  0.1126,  0.4001,  ...,  0.3950,  0.3108, -0.0656]],

         [[-0.4713, -0.3259, -0.0964,  ..., -0.2827, -0.1083, -0.0621],
          [ 0.1607, -0.3331,  0.0732,  ...,  0.3496, -0.0429,  0.2006],
          [ 0.4052, -0.0522, -0.4068,  ..., -0.2772,  0.3773, -0.1876],
          ...,
          [-0.1669, -0.1962,  0.2887,  ..., -0.0627,  0.4904,  0.3560],
          [ 0.4312, -0.1699, -0.4443,  ...,  0.3881,  0.1833,  0.2984],
          [-0.0174, -0.3542,  0.4522,  ..., -0.3154,  0.2388, -0.4869]]]])
DESIRED: (shape=torch.Size([1, 4, 391, 436]), dtype=torch.float32)
tensor([[[[-0.1377,  0.1596,  0.0483,  ..., -0.3015, -0.2337, -0.1324],
          [-0.2107,  0.0782,  0.4627,  ..., -0.0490,  0.3115, -0.3960],
          [ 0.1457,  0.4698,  0.2393,  ...,  0.4779,  0.3550,  0.3911],
          ...,
          [-0.0110,  0.1772,  0.4567,  ..., -0.0966, -0.1352,  0.0550],
          [-0.1984, -0.4105, -0.0322,  ...,  0.2346, -0.4569, -0.3723],
          [ 0.2186, -0.4236,  0.1953,  ..., -0.2510,  0.4169,  0.1827]],

         [[ 0.0571, -0.0464,  0.2640,  ...,  0.2866,  0.0510,  0.3882],
          [-0.4797,  0.4615, -0.3633,  ..., -0.4369,  0.3665,  0.0049],
          [-0.4004, -0.3815,  0.0480,  ..., -0.0358, -0.0105,  0.1764],
          ...,
          [-0.4206, -0.4351, -0.4594,  ..., -0.1212, -0.3134, -0.0536],
          [ 0.1980,  0.4654,  0.4751,  ...,  0.0119,  0.1962, -0.0063],
          [-0.2178,  0.1125,  0.0823,  ...,  0.3301,  0.0818, -0.1789]],

         [[-0.3552, -0.4500,  0.3888,  ..., -0.2668, -0.0759, -0.4163],
          [ 0.0750, -0.2115, -0.2736,  ...,  0.3676,  0.1104, -0.3061],
          [ 0.4642, -0.2453, -0.1712,  ..., -0.3498, -0.1965,  0.1992],
          ...,
          [-0.4196,  0.1812, -0.1014,  ..., -0.2962,  0.3993, -0.3727],
          [ 0.2178,  0.2101,  0.2815,  ...,  0.2822,  0.4793,  0.0044],
          [ 0.4765,  0.1126,  0.4001,  ...,  0.3950,  0.3108, -0.0656]],

         [[-0.4713, -0.3259, -0.0964,  ..., -0.2827, -0.1083, -0.0621],
          [ 0.1607, -0.3331,  0.0732,  ...,  0.3496, -0.0429,  0.2006],
          [ 0.4052, -0.0522, -0.4068,  ..., -0.2772,  0.3773, -0.1876],
          ...,
          [-0.1669, -0.1962,  0.2887,  ..., -0.0627,  0.4904,  0.3560],
          [ 0.4312, -0.1699, -0.4443,  ...,  0.3881,  0.1833,  0.2984],
          [-0.0174, -0.3542,  0.4522,  ..., -0.3154,  0.2388, -0.4869]]]])

2025-06-10 00:13:31.730325 GPU 6 156013 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 400, 300],"float32"), Tensor([1, 400, 300, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 400, 300],"float32"), Tensor([1, 400, 300, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 480000 (0.0%)
Greatest absolute difference: 0.7602975368499756 at index (0, 1, 379, 122) (up to 0.01 allowed)
Greatest relative difference: 2.5253348350524902 at index (0, 0, 140, 180) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 400, 300]), dtype=torch.float32)
tensor([[[[-0.2622, -0.1084,  0.4704,  ...,  0.2658,  0.2027,  0.3757],
          [ 0.2840, -0.4934,  0.0450,  ...,  0.2777,  0.1098, -0.3440],
          [-0.2053, -0.1028,  0.4224,  ...,  0.0568, -0.1068, -0.1330],
          ...,
          [-0.2884, -0.4869, -0.0122,  ...,  0.1757, -0.0017, -0.1814],
          [ 0.3013,  0.0994,  0.1995,  ..., -0.0115,  0.3199, -0.1304],
          [-0.4741,  0.1084, -0.3009,  ...,  0.3092, -0.1995, -0.0394]],

         [[ 0.3530,  0.1343, -0.0897,  ...,  0.0782,  0.1969, -0.2129],
          [ 0.4112,  0.4977, -0.4428,  ...,  0.1333, -0.1903,  0.0986],
          [-0.4662,  0.1209, -0.2661,  ..., -0.3025,  0.0553, -0.0607],
          ...,
          [-0.3638,  0.0967,  0.4916,  ..., -0.3666, -0.2093,  0.1501],
          [-0.0228,  0.2368, -0.1068,  ...,  0.3491, -0.0276,  0.4236],
          [ 0.1501, -0.1373,  0.0355,  ..., -0.1582,  0.0524, -0.2421]],

         [[-0.3527,  0.4573,  0.3076,  ..., -0.1708,  0.1009,  0.3311],
          [ 0.3327,  0.3007,  0.3669,  ...,  0.4196,  0.0944,  0.1132],
          [-0.2679,  0.4774,  0.4840,  ..., -0.3189, -0.1592,  0.4589],
          ...,
          [-0.0783,  0.1037,  0.4494,  ..., -0.4894, -0.2073,  0.3673],
          [-0.4325,  0.3581, -0.0170,  ...,  0.0403,  0.3290, -0.3498],
          [ 0.3979, -0.3506,  0.1574,  ...,  0.3497,  0.3717,  0.2621]],

         [[ 0.1859,  0.3834, -0.1392,  ..., -0.0123, -0.4727, -0.1143],
          [-0.1449,  0.4622,  0.2659,  ..., -0.1101,  0.3250,  0.3571],
          [-0.0277,  0.3088, -0.1803,  ...,  0.0127,  0.1429, -0.4848],
          ...,
          [ 0.2546,  0.2353, -0.1010,  ..., -0.1335, -0.0457, -0.4416],
          [ 0.1987, -0.1469, -0.0744,  ...,  0.3578, -0.4662,  0.3839],
          [-0.1524,  0.1322,  0.0941,  ...,  0.0968, -0.1878,  0.1445]]]])
DESIRED: (shape=torch.Size([1, 4, 400, 300]), dtype=torch.float32)
tensor([[[[-0.2622, -0.1084,  0.4704,  ...,  0.2658,  0.2027,  0.3757],
          [ 0.2840, -0.4934,  0.0450,  ...,  0.2777,  0.1098, -0.3440],
          [-0.2053, -0.1028,  0.4224,  ...,  0.0568, -0.1068, -0.1330],
          ...,
          [-0.2884, -0.4869, -0.0122,  ...,  0.1757, -0.0017, -0.1814],
          [ 0.3013,  0.0994,  0.1995,  ..., -0.0115,  0.3199, -0.1304],
          [-0.4741,  0.1084, -0.3009,  ...,  0.3092, -0.1995, -0.0394]],

         [[ 0.3530,  0.1343, -0.0897,  ...,  0.0782,  0.1969, -0.2129],
          [ 0.4112,  0.4977, -0.4428,  ...,  0.1333, -0.1903,  0.0986],
          [-0.4662,  0.1209, -0.2661,  ..., -0.3025,  0.0553, -0.0607],
          ...,
          [-0.3638,  0.0967,  0.4916,  ..., -0.3666, -0.2093,  0.1501],
          [-0.0228,  0.2368, -0.1068,  ...,  0.3491, -0.0276,  0.4236],
          [ 0.1501, -0.1373,  0.0355,  ..., -0.1582,  0.0524, -0.2421]],

         [[-0.3527,  0.4573,  0.3076,  ..., -0.1708,  0.1009,  0.3311],
          [ 0.3327,  0.3007,  0.3669,  ...,  0.4196,  0.0944,  0.1132],
          [-0.2679,  0.4774,  0.4840,  ..., -0.3189, -0.1592,  0.4589],
          ...,
          [-0.0783,  0.1037,  0.4494,  ..., -0.4894, -0.2073,  0.3673],
          [-0.4325,  0.3581, -0.0170,  ...,  0.0403,  0.3290, -0.3498],
          [ 0.3979, -0.3506,  0.1574,  ...,  0.3497,  0.3717,  0.2621]],

         [[ 0.1859,  0.3834, -0.1392,  ..., -0.0123, -0.4727, -0.1143],
          [-0.1449,  0.4622,  0.2659,  ..., -0.1101,  0.3250,  0.3571],
          [-0.0277,  0.3088, -0.1803,  ...,  0.0127,  0.1429, -0.4848],
          ...,
          [ 0.2546,  0.2353, -0.1010,  ..., -0.1335, -0.0457, -0.4416],
          [ 0.1987, -0.1469, -0.0744,  ...,  0.3578, -0.4662,  0.3839],
          [-0.1524,  0.1322,  0.0941,  ...,  0.0968, -0.1878,  0.1445]]]])

2025-06-10 00:13:31.930251 GPU 5 156012 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 400, 300],"float32"), Tensor([1, 430, 340, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 400, 300],"float32"), Tensor([1, 430, 340, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 584800 (0.0%)
Greatest absolute difference: 0.8628708720207214 at index (0, 2, 251, 93) (up to 0.01 allowed)
Greatest relative difference: 3.6202001571655273 at index (0, 2, 401, 156) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 430, 340]), dtype=torch.float32)
tensor([[[[ 0.3970,  0.1679,  0.3706,  ...,  0.0952, -0.3126, -0.1207],
          [ 0.4577,  0.0748,  0.3492,  ..., -0.4193,  0.2998,  0.0012],
          [ 0.1281,  0.0500,  0.1296,  ..., -0.0859, -0.1004, -0.0201],
          ...,
          [ 0.4316,  0.3016, -0.2343,  ...,  0.3303, -0.3730,  0.4921],
          [ 0.2523, -0.0796, -0.2356,  ..., -0.4782, -0.2056,  0.1432],
          [-0.4761, -0.1479, -0.2120,  ..., -0.2370,  0.2873, -0.3273]],

         [[ 0.3253, -0.0554,  0.3001,  ..., -0.2312, -0.0741,  0.2182],
          [ 0.1072, -0.0545, -0.0358,  ..., -0.2371, -0.1667,  0.2535],
          [ 0.2736,  0.4469, -0.0846,  ...,  0.0025, -0.4790, -0.2150],
          ...,
          [-0.3360, -0.1161, -0.2601,  ...,  0.4045,  0.1471, -0.4606],
          [ 0.4001, -0.3312,  0.2159,  ..., -0.4964, -0.2287,  0.4632],
          [-0.4737, -0.3013,  0.0929,  ...,  0.0229,  0.0331,  0.3119]],

         [[ 0.2823,  0.0117, -0.4960,  ..., -0.0792, -0.1957,  0.4204],
          [ 0.4741,  0.1334, -0.0492,  ...,  0.2357, -0.3008,  0.3256],
          [ 0.0631,  0.1337, -0.4613,  ...,  0.3074, -0.4812, -0.3641],
          ...,
          [ 0.1026,  0.0742, -0.2310,  ..., -0.1400, -0.2183, -0.2762],
          [-0.4136, -0.4001,  0.0165,  ..., -0.0257,  0.4249, -0.4744],
          [-0.3383,  0.3237, -0.1418,  ..., -0.1049,  0.1796, -0.4489]],

         [[-0.3289, -0.4119,  0.4996,  ..., -0.2032,  0.3428, -0.2518],
          [ 0.1504, -0.0698,  0.4716,  ..., -0.1609, -0.0562,  0.1167],
          [-0.0767, -0.4006, -0.1882,  ..., -0.0130,  0.0833,  0.2192],
          ...,
          [-0.3269, -0.2385,  0.3490,  ...,  0.2950,  0.3063, -0.4856],
          [-0.2774,  0.0788,  0.0324,  ..., -0.4462, -0.2298,  0.0912],
          [-0.3363, -0.1152, -0.4999,  ..., -0.0195, -0.3219,  0.3633]]]])
DESIRED: (shape=torch.Size([1, 4, 430, 340]), dtype=torch.float32)
tensor([[[[ 0.3970,  0.1679,  0.3706,  ...,  0.0952, -0.3126, -0.1207],
          [ 0.4577,  0.0748,  0.3492,  ..., -0.4193,  0.2998,  0.0012],
          [ 0.1281,  0.0500,  0.1296,  ..., -0.0859, -0.1004, -0.0201],
          ...,
          [ 0.4316,  0.3016, -0.2343,  ...,  0.3303, -0.3730,  0.4921],
          [ 0.2523, -0.0796, -0.2356,  ..., -0.4782, -0.2056,  0.1432],
          [-0.4761, -0.1479, -0.2120,  ..., -0.2370,  0.2873, -0.3273]],

         [[ 0.3253, -0.0554,  0.3001,  ..., -0.2312, -0.0741,  0.2182],
          [ 0.1072, -0.0545, -0.0358,  ..., -0.2371, -0.1667,  0.2535],
          [ 0.2736,  0.4469, -0.0846,  ...,  0.0025, -0.4790, -0.2150],
          ...,
          [-0.3360, -0.1161, -0.2601,  ...,  0.4045,  0.1471, -0.4606],
          [ 0.4001, -0.3312,  0.2159,  ..., -0.4964, -0.2287,  0.4632],
          [-0.4737, -0.3013,  0.0929,  ...,  0.0229,  0.0331,  0.3119]],

         [[ 0.2823,  0.0117, -0.4960,  ..., -0.0792, -0.1957,  0.4204],
          [ 0.4741,  0.1334, -0.0492,  ...,  0.2357, -0.3008,  0.3256],
          [ 0.0631,  0.1337, -0.4613,  ...,  0.3074, -0.4812, -0.3641],
          ...,
          [ 0.1026,  0.0742, -0.2310,  ..., -0.1400, -0.2183, -0.2762],
          [-0.4136, -0.4001,  0.0165,  ..., -0.0257,  0.4249, -0.4744],
          [-0.3383,  0.3237, -0.1418,  ..., -0.1049,  0.1796, -0.4489]],

         [[-0.3289, -0.4119,  0.4996,  ..., -0.2032,  0.3428, -0.2518],
          [ 0.1504, -0.0698,  0.4716,  ..., -0.1609, -0.0562,  0.1167],
          [-0.0767, -0.4006, -0.1882,  ..., -0.0130,  0.0833,  0.2192],
          ...,
          [-0.3269, -0.2385,  0.3490,  ...,  0.2950,  0.3063, -0.4856],
          [-0.2774,  0.0788,  0.0324,  ..., -0.4462, -0.2298,  0.0912],
          [-0.3363, -0.1152, -0.4999,  ..., -0.0195, -0.3219,  0.3633]]]])

2025-06-10 00:13:31.941678 GPU 6 156013 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 400, 300],"float32"), Tensor([1, 434, 346, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 400, 300],"float32"), Tensor([1, 434, 346, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 8 / 600656 (0.0%)
Greatest absolute difference: 0.558783233165741 at index (0, 2, 44, 38) (up to 0.01 allowed)
Greatest relative difference: 4.536255836486816 at index (0, 2, 44, 38) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 434, 346]), dtype=torch.float32)
tensor([[[[-0.3278,  0.2990, -0.4051,  ..., -0.1381,  0.0242, -0.0401],
          [-0.2028, -0.0322,  0.0671,  ...,  0.2293,  0.4761,  0.2928],
          [-0.0024, -0.0168, -0.4726,  ..., -0.2892, -0.2942,  0.3358],
          ...,
          [-0.0367,  0.4690,  0.1633,  ..., -0.2769,  0.3756,  0.2945],
          [-0.4228,  0.2770, -0.2347,  ..., -0.4950, -0.0730, -0.1213],
          [ 0.0502,  0.0245, -0.2312,  ..., -0.3951, -0.1088, -0.4189]],

         [[ 0.1779, -0.4997,  0.4935,  ..., -0.2428,  0.4428, -0.4503],
          [-0.1204,  0.0072,  0.3435,  ..., -0.1876, -0.3251,  0.3253],
          [ 0.1561, -0.3853, -0.0915,  ..., -0.3088,  0.3120,  0.1129],
          ...,
          [-0.0791, -0.2336,  0.1018,  ...,  0.0862, -0.1384,  0.4056],
          [ 0.0622,  0.0521,  0.2247,  ...,  0.3412,  0.3825, -0.2488],
          [ 0.0067,  0.0235, -0.2192,  ..., -0.0632,  0.4243,  0.0880]],

         [[-0.2804, -0.1813, -0.2342,  ...,  0.2291, -0.3968, -0.2263],
          [-0.2555,  0.0972, -0.3654,  ..., -0.1012, -0.3683,  0.1900],
          [ 0.1652, -0.2627, -0.1670,  ..., -0.3821, -0.4484, -0.4257],
          ...,
          [ 0.4792,  0.2318,  0.0940,  ...,  0.3593,  0.1468,  0.1662],
          [-0.4361, -0.0615,  0.3253,  ..., -0.2104, -0.2193,  0.3822],
          [ 0.0373,  0.2506,  0.2974,  ...,  0.2450, -0.1579,  0.3383]],

         [[-0.0782, -0.2188,  0.0500,  ...,  0.3163,  0.2074, -0.3369],
          [-0.1819, -0.4023,  0.3475,  ...,  0.0230,  0.3767,  0.0431],
          [ 0.3507,  0.1226, -0.0087,  ..., -0.2494, -0.1914, -0.1285],
          ...,
          [ 0.0982, -0.2601,  0.1138,  ..., -0.1117,  0.1919, -0.3574],
          [-0.1309, -0.3741,  0.0692,  ..., -0.3062, -0.4834,  0.3039],
          [-0.0398, -0.4491,  0.1498,  ...,  0.3353, -0.0814, -0.0572]]]])
DESIRED: (shape=torch.Size([1, 4, 434, 346]), dtype=torch.float32)
tensor([[[[-0.3278,  0.2990, -0.4051,  ..., -0.1381,  0.0242, -0.0401],
          [-0.2028, -0.0322,  0.0671,  ...,  0.2293,  0.4761,  0.2928],
          [-0.0024, -0.0168, -0.4726,  ..., -0.2892, -0.2942,  0.3358],
          ...,
          [-0.0367,  0.4690,  0.1633,  ..., -0.2769,  0.3756,  0.2945],
          [-0.4228,  0.2770, -0.2347,  ..., -0.4950, -0.0730, -0.1213],
          [ 0.0502,  0.0245, -0.2312,  ..., -0.3951, -0.1088, -0.4189]],

         [[ 0.1779, -0.4997,  0.4935,  ..., -0.2428,  0.4428, -0.4503],
          [-0.1204,  0.0072,  0.3435,  ..., -0.1876, -0.3251,  0.3253],
          [ 0.1561, -0.3853, -0.0915,  ..., -0.3088,  0.3120,  0.1129],
          ...,
          [-0.0791, -0.2336,  0.1018,  ...,  0.0862, -0.1384,  0.4056],
          [ 0.0622,  0.0521,  0.2247,  ...,  0.3412,  0.3825, -0.2488],
          [ 0.0067,  0.0235, -0.2192,  ..., -0.0632,  0.4243,  0.0880]],

         [[-0.2804, -0.1813, -0.2342,  ...,  0.2291, -0.3968, -0.2263],
          [-0.2555,  0.0972, -0.3654,  ..., -0.1012, -0.3683,  0.1900],
          [ 0.1652, -0.2627, -0.1670,  ..., -0.3821, -0.4484, -0.4257],
          ...,
          [ 0.4792,  0.2318,  0.0940,  ...,  0.3593,  0.1468,  0.1662],
          [-0.4361, -0.0615,  0.3253,  ..., -0.2104, -0.2193,  0.3822],
          [ 0.0373,  0.2506,  0.2974,  ...,  0.2450, -0.1579,  0.3383]],

         [[-0.0782, -0.2188,  0.0500,  ...,  0.3163,  0.2074, -0.3369],
          [-0.1819, -0.4023,  0.3475,  ...,  0.0230,  0.3767,  0.0431],
          [ 0.3507,  0.1226, -0.0087,  ..., -0.2494, -0.1914, -0.1285],
          ...,
          [ 0.0982, -0.2601,  0.1138,  ..., -0.1117,  0.1919, -0.3574],
          [-0.1309, -0.3741,  0.0692,  ..., -0.3062, -0.4834,  0.3039],
          [-0.0398, -0.4491,  0.1498,  ...,  0.3353, -0.0814, -0.0572]]]])

2025-06-10 00:13:32.142297 GPU 6 156013 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 430, 340],"float32"), Tensor([1, 477, 401, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 430, 340],"float32"), Tensor([1, 477, 401, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 4 / 765108 (0.0%)
Greatest absolute difference: 0.5753676891326904 at index (0, 1, 391, 258) (up to 0.01 allowed)
Greatest relative difference: 4.880588054656982 at index (0, 1, 391, 258) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 477, 401]), dtype=torch.float32)
tensor([[[[-0.1892, -0.2679, -0.3918,  ..., -0.3103, -0.3588,  0.2019],
          [-0.4728,  0.4743, -0.1537,  ..., -0.2452,  0.3015, -0.1785],
          [ 0.2579, -0.1203, -0.2377,  ..., -0.1857,  0.0024,  0.0265],
          ...,
          [ 0.3231,  0.0782, -0.0727,  ...,  0.1085,  0.4543, -0.0347],
          [-0.0993,  0.0042,  0.2631,  ...,  0.3361, -0.2729,  0.0880],
          [-0.3471, -0.0062,  0.2912,  ...,  0.4762, -0.3481,  0.2354]],

         [[-0.3392,  0.4368,  0.2204,  ...,  0.3746,  0.3757, -0.4979],
          [ 0.2537, -0.1171,  0.2663,  ..., -0.2503,  0.4467, -0.2295],
          [ 0.3536, -0.3568, -0.0754,  ...,  0.4610,  0.1847, -0.3614],
          ...,
          [-0.1820,  0.4974, -0.2421,  ..., -0.2166,  0.4381, -0.3173],
          [ 0.4255,  0.1385,  0.0743,  ...,  0.1247,  0.3514, -0.2593],
          [ 0.4758,  0.3066, -0.1671,  ..., -0.0961,  0.0248,  0.4263]],

         [[ 0.3254, -0.1195, -0.3759,  ...,  0.0189,  0.2634,  0.1814],
          [-0.0058, -0.3829, -0.2519,  ..., -0.4606, -0.3752,  0.1253],
          [-0.0823,  0.0166,  0.0666,  ..., -0.2969,  0.2500, -0.0178],
          ...,
          [ 0.2577, -0.1852,  0.2300,  ...,  0.0665,  0.2763,  0.3443],
          [-0.2085, -0.1999, -0.1769,  ..., -0.3455,  0.3698,  0.4972],
          [-0.4994, -0.4432,  0.2012,  ..., -0.4432,  0.2335, -0.1567]],

         [[ 0.2718, -0.0817,  0.4217,  ...,  0.4608, -0.2103,  0.3080],
          [ 0.0655, -0.0459,  0.0770,  ..., -0.1838,  0.3136, -0.2996],
          [-0.4390, -0.1953,  0.4575,  ...,  0.1561,  0.3679,  0.1282],
          ...,
          [ 0.2230, -0.2800, -0.0831,  ..., -0.1366,  0.1278,  0.2822],
          [ 0.4195,  0.1675,  0.3507,  ...,  0.2421,  0.3621,  0.1896],
          [-0.2454, -0.3826,  0.1805,  ...,  0.3276,  0.4913, -0.3807]]]])
DESIRED: (shape=torch.Size([1, 4, 477, 401]), dtype=torch.float32)
tensor([[[[-0.1892, -0.2679, -0.3918,  ..., -0.3103, -0.3588,  0.2019],
          [-0.4728,  0.4743, -0.1537,  ..., -0.2452,  0.3015, -0.1785],
          [ 0.2579, -0.1203, -0.2377,  ..., -0.1857,  0.0024,  0.0265],
          ...,
          [ 0.3231,  0.0782, -0.0727,  ...,  0.1085,  0.4543, -0.0347],
          [-0.0993,  0.0042,  0.2631,  ...,  0.3361, -0.2729,  0.0880],
          [-0.3471, -0.0062,  0.2912,  ...,  0.4762, -0.3481,  0.2354]],

         [[-0.3392,  0.4368,  0.2204,  ...,  0.3746,  0.3757, -0.4979],
          [ 0.2537, -0.1171,  0.2663,  ..., -0.2503,  0.4467, -0.2295],
          [ 0.3536, -0.3568, -0.0754,  ...,  0.4610,  0.1847, -0.3614],
          ...,
          [-0.1820,  0.4974, -0.2421,  ..., -0.2166,  0.4381, -0.3173],
          [ 0.4255,  0.1385,  0.0743,  ...,  0.1247,  0.3514, -0.2593],
          [ 0.4758,  0.3066, -0.1671,  ..., -0.0961,  0.0248,  0.4263]],

         [[ 0.3254, -0.1195, -0.3759,  ...,  0.0189,  0.2634,  0.1814],
          [-0.0058, -0.3829, -0.2519,  ..., -0.4606, -0.3752,  0.1253],
          [-0.0823,  0.0166,  0.0666,  ..., -0.2969,  0.2500, -0.0178],
          ...,
          [ 0.2577, -0.1852,  0.2300,  ...,  0.0665,  0.2763,  0.3443],
          [-0.2085, -0.1999, -0.1769,  ..., -0.3455,  0.3698,  0.4972],
          [-0.4994, -0.4432,  0.2012,  ..., -0.4432,  0.2335, -0.1567]],

         [[ 0.2718, -0.0817,  0.4217,  ...,  0.4608, -0.2103,  0.3080],
          [ 0.0655, -0.0459,  0.0770,  ..., -0.1838,  0.3136, -0.2996],
          [-0.4390, -0.1953,  0.4575,  ...,  0.1561,  0.3679,  0.1282],
          ...,
          [ 0.2230, -0.2800, -0.0831,  ..., -0.1366,  0.1278,  0.2822],
          [ 0.4195,  0.1675,  0.3507,  ...,  0.2421,  0.3621,  0.1896],
          [-0.2454, -0.3826,  0.1805,  ...,  0.3276,  0.4913, -0.3807]]]])

2025-06-10 00:13:32.146462 GPU 5 156018 test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 434, 346],"float32"), Tensor([1, 466, 386, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
[accuracy error] paddle.nn.functional.grid_sample(Tensor([1, 4, 434, 346],"float32"), Tensor([1, 466, 386, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 19 / 719504 (0.0%)
Greatest absolute difference: 0.7434985637664795 at index (0, 0, 438, 265) (up to 0.01 allowed)
Greatest relative difference: 48.360477447509766 at index (0, 3, 201, 42) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 4, 466, 386]), dtype=torch.float32)
tensor([[[[ 0.0123,  0.0328, -0.4175,  ...,  0.2980, -0.4180,  0.0351],
          [-0.0738, -0.2266, -0.2440,  ..., -0.1081, -0.0755,  0.1339],
          [-0.2797, -0.2225,  0.1832,  ..., -0.4274,  0.1112, -0.3040],
          ...,
          [-0.3943,  0.4544,  0.0668,  ...,  0.1516, -0.1099, -0.0788],
          [-0.2938, -0.3747, -0.1711,  ...,  0.1384, -0.0786, -0.0290],
          [ 0.0817,  0.0862, -0.3268,  ...,  0.3582,  0.0220, -0.0461]],

         [[ 0.1482,  0.1617,  0.4831,  ..., -0.4824, -0.0808,  0.3496],
          [-0.0058,  0.1101, -0.1236,  ...,  0.1076, -0.2518, -0.0342],
          [-0.3190,  0.3698,  0.4713,  ..., -0.4055,  0.0133,  0.2697],
          ...,
          [-0.2294, -0.1684,  0.1340,  ..., -0.4408, -0.0282, -0.4219],
          [ 0.1423, -0.0990,  0.0382,  ...,  0.2889,  0.0041,  0.2046],
          [ 0.4715,  0.1147,  0.1095,  ...,  0.4098, -0.2866,  0.2346]],

         [[ 0.4309, -0.2429, -0.1368,  ..., -0.4611, -0.2261,  0.0878],
          [ 0.0614, -0.1221,  0.0854,  ..., -0.3140,  0.3263, -0.1626],
          [ 0.0815,  0.3344,  0.1358,  ...,  0.2249, -0.3255, -0.2161],
          ...,
          [-0.0497,  0.0581,  0.2849,  ...,  0.4765,  0.1478,  0.1540],
          [-0.4655,  0.1915,  0.2021,  ...,  0.2408, -0.2403,  0.2102],
          [-0.4576, -0.3080,  0.3642,  ...,  0.4584, -0.1519, -0.0182]],

         [[-0.4115, -0.3510, -0.4015,  ..., -0.1379, -0.3876,  0.0292],
          [ 0.3695,  0.4451,  0.3967,  ..., -0.1776,  0.1361, -0.4811],
          [ 0.1178,  0.2575, -0.2250,  ...,  0.0011,  0.1591, -0.4452],
          ...,
          [ 0.2612, -0.2282,  0.3192,  ...,  0.3556,  0.0144,  0.1518],
          [ 0.3049, -0.0250, -0.0217,  ..., -0.2743, -0.3110,  0.2269],
          [-0.1439,  0.1963, -0.3766,  ..., -0.1515, -0.2863, -0.3781]]]])
DESIRED: (shape=torch.Size([1, 4, 466, 386]), dtype=torch.float32)
tensor([[[[ 0.0123,  0.0328, -0.4175,  ...,  0.2980, -0.4180,  0.0351],
          [-0.0738, -0.2266, -0.2440,  ..., -0.1081, -0.0755,  0.1339],
          [-0.2797, -0.2225,  0.1832,  ..., -0.4274,  0.1112, -0.3040],
          ...,
          [-0.3943,  0.4544,  0.0668,  ...,  0.1516, -0.1099, -0.0788],
          [-0.2938, -0.3747, -0.1711,  ...,  0.1384, -0.0786, -0.0290],
          [ 0.0817,  0.0862, -0.3268,  ...,  0.3582,  0.0220, -0.0461]],

         [[ 0.1482,  0.1617,  0.4831,  ..., -0.4824, -0.0808,  0.3496],
          [-0.0058,  0.1101, -0.1236,  ...,  0.1076, -0.2518, -0.0342],
          [-0.3190,  0.3698,  0.4713,  ..., -0.4055,  0.0133,  0.2697],
          ...,
          [-0.2294, -0.1684,  0.1340,  ..., -0.4408, -0.0282, -0.4219],
          [ 0.1423, -0.0990,  0.0382,  ...,  0.2889,  0.0041,  0.2046],
          [ 0.4715,  0.1147,  0.1095,  ...,  0.4098, -0.2866,  0.2346]],

         [[ 0.4309, -0.2429, -0.1368,  ..., -0.4611, -0.2261,  0.0878],
          [ 0.0614, -0.1221,  0.0854,  ..., -0.3140,  0.3263, -0.1626],
          [ 0.0815,  0.3344,  0.1358,  ...,  0.2249, -0.3255, -0.2161],
          ...,
          [-0.0497,  0.0581,  0.2849,  ...,  0.4765,  0.1478,  0.1540],
          [-0.4655,  0.1915,  0.2021,  ...,  0.2408, -0.2403,  0.2102],
          [-0.4576, -0.3080,  0.3642,  ...,  0.4584, -0.1519, -0.0182]],

         [[-0.4115, -0.3510, -0.4015,  ..., -0.1379, -0.3876,  0.0292],
          [ 0.3695,  0.4451,  0.3967,  ..., -0.1776,  0.1361, -0.4811],
          [ 0.1178,  0.2575, -0.2250,  ...,  0.0011,  0.1591, -0.4452],
          ...,
          [ 0.2612, -0.2282,  0.3192,  ...,  0.3556,  0.0144,  0.1518],
          [ 0.3049, -0.0250, -0.0217,  ..., -0.2743, -0.3110,  0.2269],
          [-0.1439,  0.1963, -0.3766,  ..., -0.1515, -0.2863, -0.3781]]]])

2025-06-10 00:13:32.198012 GPU 4 157147 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 128, 128],"float16"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([1, 2, 128, 128],"float16"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 84 / 32768 (0.3%)
Greatest absolute difference: 0.04296875 at index (0, 1, 105, 47) (up to 0.01 allowed)
Greatest relative difference: 0.225830078125 at index (0, 1, 23, 115) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2, 128, 128]), dtype=torch.float16)
tensor([[[[-0.3154, -1.3145, -0.4922,  ...,  0.2139,  0.4055,  0.4492],
          [ 0.2954, -1.7627,  0.2649,  ..., -0.2563,  0.5039,  0.6079],
          [ 0.8423, -0.3440,  1.2109,  ..., -0.3430, -0.9678, -0.0536],
          ...,
          [-0.1376,  0.6670, -1.0156,  ...,  0.0703, -0.5459, -0.0829],
          [-0.2394,  0.3123, -0.3181,  ...,  1.6562,  0.7305,  0.0812],
          [-0.1169,  0.1880,  0.4678,  ...,  1.7383,  0.9111,  0.3369]],

         [[-0.8677, -0.3296, -1.6904,  ..., -0.6733, -0.0425,  1.0879],
          [-0.2571, -0.5229,  0.0709,  ..., -0.0477,  0.8115, -0.4570],
          [ 1.3145,  1.6260,  0.4438,  ..., -0.9644, -0.1476,  0.1196],
          ...,
          [ 0.7080,  0.0524,  0.9722,  ...,  0.2742, -1.0273,  0.3225],
          [-0.2998, -0.2698,  0.6528,  ...,  0.6528,  0.0316,  0.1272],
          [-0.6089, -0.5000,  1.0615,  ...,  0.1080, -0.1127, -0.4507]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 2, 128, 128]), dtype=torch.float16)
tensor([[[[-0.3186, -1.3301, -0.5005,  ...,  0.2137,  0.4070,  0.4478],
          [ 0.2974, -1.7832,  0.2646,  ..., -0.2593,  0.5098,  0.6196],
          [ 0.8462, -0.3501,  1.2295,  ..., -0.3464, -0.9746, -0.0572],
          ...,
          [-0.1393,  0.6787, -1.0273,  ...,  0.0714, -0.5508, -0.0809],
          [-0.2388,  0.3145, -0.3235,  ...,  1.6689,  0.7373,  0.0786],
          [-0.1169,  0.1942,  0.4805,  ...,  1.7578,  0.9175,  0.3428]],

         [[-0.8706, -0.3306, -1.7070,  ..., -0.6851, -0.0426,  1.1006],
          [-0.2629, -0.5376,  0.0681,  ..., -0.0455,  0.8188, -0.4614],
          [ 1.3223,  1.6465,  0.4558,  ..., -0.9834, -0.1476,  0.1238],
          ...,
          [ 0.7134,  0.0528,  0.9795,  ...,  0.2764, -1.0420,  0.3269],
          [-0.3025, -0.2715,  0.6621,  ...,  0.6572,  0.0332,  0.1283],
          [-0.6069, -0.5049,  1.0693,  ...,  0.1155, -0.1128, -0.4502]]]], dtype=torch.float16)

2025-06-10 00:13:32.237356 GPU 6 156010 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 128, 128],"float16"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([2, 2, 128, 128],"float16"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 170 / 65536 (0.3%)
Greatest absolute difference: 0.046875 at index (1, 0, 36, 80) (up to 0.01 allowed)
Greatest relative difference: 1.8154296875 at index (1, 1, 127, 18) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 2, 128, 128]), dtype=torch.float16)
tensor([[[[ 0.5815, -1.1514,  0.3506,  ...,  1.3467,  1.6211, -0.8579],
          [-0.5713, -0.1740, -0.9321,  ...,  0.4504, -0.0764, -0.2559],
          [-0.6133,  0.6982, -0.2461,  ...,  0.8135,  0.6611,  1.2227],
          ...,
          [ 0.6812, -0.0317,  0.1990,  ...,  0.4558, -1.7314, -0.6885],
          [ 0.6606, -0.7334, -0.2144,  ...,  0.0337, -0.4470,  0.9375],
          [ 0.0536, -0.4036, -1.4482,  ..., -1.4697,  0.1628,  1.1035]],

         [[-0.4141,  0.7671,  0.4221,  ..., -0.4016, -0.6099,  0.1473],
          [ 1.1631,  0.1235,  0.1383,  ...,  0.4026, -0.2969, -0.2610],
          [-1.1230, -0.4553,  0.1804,  ..., -0.0880, -0.5151,  0.2239],
          ...,
          [ 0.2832,  0.4937,  0.7554,  ..., -0.4512, -0.7744,  0.5439],
          [ 0.3335,  0.0560, -0.0077,  ...,  0.9531, -0.4290,  1.0498],
          [-0.7324, -0.5190,  0.3215,  ...,  0.3225, -0.7314,  1.8613]]],


        [[[ 0.1127, -0.3135, -0.3701,  ..., -0.0763,  0.7817,  0.2456],
          [ 0.1639, -0.0493, -0.5557,  ..., -0.0637, -0.6558, -0.3838],
          [-0.2832,  0.4412, -1.2031,  ...,  0.0765, -0.8140, -1.3125],
          ...,
          [ 0.5112,  0.1943, -1.2754,  ..., -0.9375, -0.3025,  0.1139],
          [-0.1564, -1.3350, -0.3611,  ..., -1.1162,  0.6787,  1.5469],
          [-0.5596, -0.7139, -1.3496,  ..., -1.0820,  0.8350,  1.4668]],

         [[-0.2396,  0.7725, -0.8154,  ..., -0.4658,  1.8447,  0.1050],
          [ 0.1748, -0.2393, -0.5293,  ...,  0.9053,  0.1769,  0.9307],
          [-1.0176,  0.4832,  0.4668,  ...,  0.5093,  0.2189,  0.3667],
          ...,
          [-0.2023,  0.2727,  0.3093,  ...,  0.0675, -1.1699,  0.2678],
          [ 0.7124, -0.2991,  0.4043,  ..., -0.0550, -0.7715, -0.9502],
          [ 0.3196, -1.8711,  0.2881,  ...,  0.9263,  0.5474, -0.0206]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 2, 128, 128]), dtype=torch.float16)
tensor([[[[ 0.5894, -1.1641,  0.3550,  ...,  1.3682,  1.6387, -0.8638],
          [-0.5757, -0.1761, -0.9424,  ...,  0.4536, -0.0740, -0.2627],
          [-0.6177,  0.7026, -0.2471,  ...,  0.8252,  0.6680,  1.2373],
          ...,
          [ 0.6870, -0.0312,  0.2002,  ...,  0.4570, -1.7461, -0.6968],
          [ 0.6641, -0.7417, -0.2162,  ...,  0.0387, -0.4575,  0.9424],
          [ 0.0578, -0.4045, -1.4619,  ..., -1.4805,  0.1721,  1.1094]],

         [[-0.4180,  0.7778,  0.4250,  ..., -0.4053, -0.6177,  0.1519],
          [ 1.1748,  0.1276,  0.1395,  ...,  0.4062, -0.2993, -0.2686],
          [-1.1357, -0.4590,  0.1792,  ..., -0.0928, -0.5186,  0.2284],
          ...,
          [ 0.2847,  0.4978,  0.7632,  ..., -0.4590, -0.7817,  0.5542],
          [ 0.3381,  0.0586, -0.0068,  ...,  0.9653, -0.4321,  1.0576],
          [-0.7432, -0.5264,  0.3208,  ...,  0.3254, -0.7354,  1.8789]]],


        [[[ 0.1133, -0.3149, -0.3728,  ..., -0.0806,  0.7939,  0.2466],
          [ 0.1663, -0.0526, -0.5625,  ..., -0.0619, -0.6641, -0.3877],
          [-0.2878,  0.4453, -1.2168,  ...,  0.0787, -0.8203, -1.3271],
          ...,
          [ 0.5151,  0.2009, -1.2881,  ..., -0.9438, -0.3074,  0.1113],
          [-0.1567, -1.3486, -0.3635,  ..., -1.1338,  0.6855,  1.5645],
          [-0.5679, -0.7192, -1.3584,  ..., -1.0889,  0.8477,  1.4795]],

         [[-0.2427,  0.7847, -0.8174,  ..., -0.4678,  1.8711,  0.1078],
          [ 0.1782, -0.2408, -0.5425,  ...,  0.9087,  0.1748,  0.9419],
          [-1.0312,  0.4854,  0.4722,  ...,  0.5234,  0.2240,  0.3726],
          ...,
          [-0.2002,  0.2749,  0.3098,  ...,  0.0701, -1.1777,  0.2708],
          [ 0.7153, -0.2993,  0.4126,  ..., -0.0561, -0.7842, -0.9585],
          [ 0.3257, -1.8906,  0.2874,  ...,  0.9321,  0.5503, -0.0177]]]], dtype=torch.float16)

2025-06-10 00:13:32.269036 GPU 7 155998 test begin: paddle.nn.functional.interpolate(Tensor([4, 128, 32, 32],"float16"), list[128,128,], mode="bilinear", align_corners=False, )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 128, 32, 32],"float16"), list[128,128,], mode="bilinear", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1490 / 524288 (0.3%)
Greatest absolute difference: 0.048828125 at index (0, 108, 15, 5) (up to 0.01 allowed)
Greatest relative difference: 5.48046875 at index (0, 92, 6, 21) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 128, 32, 32]), dtype=torch.float16)
tensor([[[[ 2.8345e-01, -2.9343e-02,  7.4561e-01,  ..., -1.4443e+00, -1.1445e+00,  6.1768e-01],
          [ 1.2441e+00, -4.0942e-01,  5.7422e-01,  ..., -6.1133e-01, -1.1318e+00,  4.2090e-01],
          [ 4.9072e-01,  1.8494e-01, -9.5764e-02,  ..., -1.5645e+00,  4.2603e-01,  9.7949e-01],
          ...,
          [ 1.3057e+00,  3.0811e-01,  1.7114e-01,  ..., -1.2080e+00,  5.5878e-02, -2.7832e-01],
          [ 7.2852e-01,  8.8501e-02,  7.4609e-01,  ..., -3.4302e-01, -3.6401e-01, -9.6924e-01],
          [ 4.0186e-01, -1.2520e+00, -1.4221e-01,  ..., -1.8726e-01, -5.3101e-02, -6.5723e-01]],

         [[ 7.6172e-02,  4.3286e-01,  6.6357e-01,  ..., -1.0176e+00, -1.8232e+00,  4.1382e-01],
          [ 1.5186e-01, -1.4062e+00,  1.0527e+00,  ..., -8.8281e-01, -3.1885e-01,  1.1094e+00],
          [ 2.1133e+00,  1.2360e-01,  4.0063e-01,  ..., -2.3413e-01,  4.2328e-02,  1.1853e-01],
          ...,
          [-2.4353e-01, -5.9082e-01,  2.4097e-01,  ..., -1.0732e+00, -2.0422e-01,  1.9348e-01],
          [-6.7920e-01, -7.9199e-01, -1.0590e-01,  ..., -6.6064e-01,  1.7432e-01, -1.5840e+00],
          [-5.2295e-01, -2.2693e-01,  1.2695e+00,  ..., -9.7705e-01, -4.1565e-02, -1.8320e+00]],

         [[ 5.7861e-01,  5.4810e-02,  9.0039e-01,  ...,  5.9131e-01, -7.0361e-01, -4.9927e-01],
          [ 6.4795e-01,  6.1621e-01,  6.4648e-01,  ..., -8.1787e-02, -3.4393e-02, -6.1523e-01],
          [ 6.1865e-01,  1.2705e+00,  9.3750e-01,  ...,  3.6914e-01, -7.0312e-01, -1.5498e+00],
          ...,
          [ 5.2490e-01,  1.4362e-03, -1.1407e-01,  ...,  2.9492e-01, -7.3486e-01, -1.0742e+00],
          [ 5.5078e-01,  4.7754e-01,  6.7920e-01,  ..., -5.3076e-01,  3.2861e-01, -1.3223e+00],
          [ 8.8281e-01,  9.4971e-01, -6.0742e-01,  ..., -1.9666e-01, -1.2817e-01, -2.4561e-01]],

         ...,

         [[ 1.1084e-01, -2.6880e-01, -8.6279e-01,  ...,  6.8994e-01,  1.5322e+00,  9.5068e-01],
          [ 4.8584e-01, -1.3220e-01, -2.7759e-01,  ..., -1.0957e+00, -4.3091e-01, -1.7847e-01],
          [ 2.8305e-02, -1.1787e+00, -1.0137e+00,  ..., -7.8174e-01, -5.7080e-01,  6.5283e-01],
          ...,
          [ 3.3105e-01, -5.7275e-01,  2.3547e-01,  ...,  8.5791e-01,  4.3732e-02, -9.2468e-02],
          [-9.0881e-02, -1.0049e+00, -9.6924e-01,  ...,  5.6006e-01,  1.5088e+00,  5.2002e-01],
          [-6.3281e-01, -1.1992e+00, -1.0732e+00,  ...,  9.0625e-01,  5.8350e-01,  1.2432e+00]],

         [[-1.1562e+00, -1.0186e+00, -1.7549e+00,  ...,  6.0272e-02,  6.0693e-01, -4.2114e-01],
          [ 3.4088e-02, -1.2832e+00, -8.3313e-02,  ..., -4.6729e-01, -5.9863e-01, -4.2407e-01],
          [ 1.8652e-01, -7.0264e-01, -4.2188e-01,  ...,  1.3623e-01, -8.8086e-01,  1.1250e+00],
          ...,
          [ 4.5068e-01, -5.8350e-01, -2.8662e-01,  ..., -9.1260e-01,  1.2201e-01, -1.2627e+00],
          [ 1.4434e+00, -7.8906e-01,  1.8516e+00,  ...,  3.3447e-01,  6.2109e-01,  3.2422e-01],
          [ 1.7957e-01,  7.2461e-01, -3.8599e-01,  ...,  5.5762e-01,  7.0251e-02,  7.0947e-01]],

         [[-8.3643e-01,  8.3447e-01,  2.0105e-01,  ...,  8.3105e-01,  2.5659e-01, -3.6597e-01],
          [-4.6875e-01,  3.3008e-01, -2.1713e-02,  ..., -1.4365e+00,  1.5778e-02,  5.3271e-01],
          [ 4.4702e-01, -3.4692e-01, -2.1399e-01,  ..., -6.6748e-01, -2.5684e+00, -1.3203e+00],
          ...,
          [ 3.9502e-01, -1.0234e+00,  1.1387e+00,  ..., -8.0322e-01, -1.0742e+00,  4.8438e-01],
          [-3.5156e-01, -3.1958e-01,  4.6216e-01,  ...,  4.2212e-01, -3.6401e-01,  1.2666e+00],
          [ 1.3916e+00,  3.4521e-01,  7.4158e-02,  ...,  4.4922e-01, -5.8545e-01,  5.0146e-01]]],


        [[[ 7.6709e-01, -1.3525e-01, -7.2607e-01,  ...,  5.2539e-01,  7.8906e-01,  1.9609e+00],
          [ 6.7578e-01,  5.8740e-01, -2.6074e-01,  ...,  1.0068e+00,  4.4458e-01,  6.8665e-03],
          [ 3.4253e-01,  4.4019e-01, -1.2476e-01,  ..., -3.8422e-02, -1.3633e+00, -1.1340e-01],
          ...,
          [-2.7368e-01, -1.0977e+00, -1.6296e-01,  ..., -1.0557e+00,  5.4248e-01,  8.5449e-02],
          [ 4.4995e-01, -2.1753e-01,  1.9519e-01,  ...,  4.3018e-01,  7.8076e-01,  6.8408e-01],
          [ 5.4626e-02,  6.7627e-01, -5.6885e-01,  ...,  2.2285e+00,  1.9756e+00,  8.2861e-01]],

         [[ 1.7939e+00,  1.8242e+00,  9.5898e-01,  ...,  1.5173e-01,  3.0737e-01,  3.7622e-01],
          [ 9.6045e-01, -3.4644e-01,  9.8389e-01,  ...,  4.9133e-02,  2.0422e-01,  8.1177e-02],
          [-1.9910e-01, -3.9453e-01,  8.0127e-01,  ...,  8.2666e-01,  2.8638e-01, -6.9092e-01],
          ...,
          [ 5.3613e-01, -6.9287e-01, -3.1323e-01,  ..., -7.3425e-02,  1.9165e-02,  2.6074e-01],
          [-1.3318e-01, -6.6309e-01, -2.1716e-01,  ..., -4.1528e-01, -9.0637e-02,  1.7773e+00],
          [ 5.9082e-02,  1.0068e+00,  1.7603e-01,  ...,  1.7566e-01,  2.4805e-01,  1.6172e+00]],

         [[-2.2864e-01,  5.1605e-02,  1.0293e+00,  ..., -1.2695e-02,  6.0791e-01,  7.9980e-01],
          [ 7.0020e-01,  2.3596e-01,  1.1123e+00,  ..., -1.1240e+00,  1.4343e-01,  7.3303e-02],
          [-3.3130e-01, -1.1243e-01, -6.0791e-01,  ...,  4.1699e-01,  9.4434e-01,  2.2876e-01],
          ...,
          [ 2.1460e-01, -8.2373e-01, -8.0859e-01,  ...,  3.1470e-01,  1.1377e+00, -2.3010e-01],
          [-5.2338e-02,  9.0967e-01,  1.6973e+00,  ..., -3.0811e-01,  6.4795e-01,  4.9707e-01],
          [ 7.3535e-01,  3.2886e-01,  1.2129e+00,  ...,  7.2949e-01,  4.9072e-01, -5.4688e-01]],

         ...,

         [[ 1.6064e+00,  8.5815e-02, -1.0215e+00,  ...,  1.2988e+00,  4.6411e-01, -2.4988e-01],
          [ 1.7441e-02,  7.8674e-02,  1.2134e-01,  ..., -5.2881e-01, -1.7242e-02, -3.0737e-01],
          [ 1.0527e+00, -4.1187e-01,  7.4805e-01,  ...,  1.0016e-01,  4.7681e-01,  6.6846e-01],
          ...,
          [ 1.9199e+00,  6.6797e-01, -1.6387e+00,  ...,  1.3789e+00,  1.2803e+00,  5.0439e-01],
          [ 5.9131e-01,  5.0293e-01, -4.5190e-01,  ...,  2.5312e+00,  1.0664e+00, -1.8701e-01],
          [ 1.9360e-01, -1.7676e-01,  1.0889e+00,  ...,  7.8223e-01, -4.5923e-01, -2.7939e-02]],

         [[-1.3105e+00, -7.2510e-01,  4.6704e-01,  ..., -1.5049e+00, -7.9248e-01, -1.7656e+00],
          [-5.5469e-01,  4.6069e-01, -1.5393e-01,  ...,  6.4600e-01,  6.6309e-01, -1.9080e-01],
          [ 1.8242e+00,  3.4570e-01,  3.6353e-01,  ..., -5.9863e-01,  6.6992e-01, -7.3853e-02],
          ...,
          [-1.6052e-02, -7.4512e-01,  6.2354e-01,  ..., -5.1270e-01, -1.3725e-02,  1.7212e-01],
          [ 9.5020e-01,  2.4902e-01,  1.3660e-01,  ..., -4.1089e-01,  3.0786e-01,  1.3857e+00],
          [-3.6450e-01, -7.4072e-01, -8.8525e-01,  ...,  3.2251e-01,  3.4717e-01,  7.5000e-01]],

         [[-4.4800e-01, -3.5596e-01, -5.1123e-01,  ...,  1.1029e-01,  9.2468e-02,  3.8477e-01],
          [ 9.3262e-01, -7.1094e-01,  6.4990e-01,  ..., -5.7471e-01,  2.6636e-01, -5.8716e-02],
          [ 1.4709e-02, -2.0862e-01,  2.7856e-01,  ...,  3.9062e-01,  1.1035e+00, -4.9902e-01],
          ...,
          [-8.4619e-01, -1.7944e-01,  1.0703e+00,  ...,  1.0168e-01,  6.3916e-01,  6.2256e-01],
          [ 3.0054e-01,  7.7197e-01,  8.3008e-01,  ..., -5.9229e-01, -1.3926e+00, -4.9390e-01],
          [ 2.2402e+00,  1.1982e+00,  1.4717e+00,  ..., -7.4268e-01, -2.2668e-01,  7.0459e-01]]],


        [[[ 7.2461e-01, -8.3801e-02, -1.2334e+00,  ...,  1.1133e+00,  1.7957e-01,  7.1826e-01],
          [-1.3464e-01,  2.3483e-02,  3.0957e-01,  ..., -5.2277e-02,  3.6926e-02,  7.2510e-01],
          [ 2.0039e+00,  1.0020e+00, -4.6478e-02,  ...,  4.7803e-01,  1.7041e-01,  7.9688e-01],
          ...,
          [ 7.0850e-01, -1.6565e-01,  3.1152e-01,  ...,  1.6516e-01,  2.6099e-01, -2.3267e-01],
          [-2.8882e-01,  6.6406e-01, -6.0254e-01,  ...,  9.4775e-01, -2.4304e-01,  2.4426e-01],
          [ 1.4434e+00,  1.3320e+00,  1.4951e+00,  ...,  9.9219e-01, -2.3242e-01, -1.2329e-02]],

         [[ 1.6104e+00,  2.2266e-01,  9.9658e-01,  ..., -1.4941e+00, -1.4346e+00,  7.4005e-04],
          [ 1.5635e+00, -5.2100e-01,  2.4878e-01,  ...,  1.2030e-01, -1.2324e+00, -3.2935e-01],
          [-1.6998e-02,  2.6099e-01,  5.6396e-01,  ..., -9.1309e-01,  1.6455e-01,  7.6855e-01],
          ...,
          [ 1.2927e-01,  7.7393e-01, -3.9233e-01,  ...,  3.7744e-01,  3.3594e-01, -9.0674e-01],
          [ 3.0914e-02,  2.2766e-01, -1.9580e+00,  ...,  1.7615e-01,  9.5947e-01,  3.7842e-01],
          [-4.7144e-01,  4.7180e-02, -1.4844e+00,  ..., -1.5547e+00, -1.1597e-01,  6.4893e-01]],

         [[ 4.6631e-01,  3.6963e-01,  2.0981e-04,  ..., -1.5498e+00, -2.0654e-01, -1.0381e+00],
          [ 1.5420e+00, -2.6440e-01, -9.0771e-01,  ..., -7.1631e-01,  2.2522e-01,  4.0869e-01],
          [ 8.4229e-01,  4.1162e-01, -3.4863e-01,  ..., -1.2512e-01, -2.8906e-01,  1.2539e+00],
          ...,
          [ 1.9409e-01,  1.2854e-01, -2.9883e-01,  ...,  1.7764e+00, -2.5586e-01, -4.8004e-02],
          [ 6.7139e-01,  1.0684e+00,  5.5371e-01,  ..., -1.0126e-01, -4.7803e-01, -7.2510e-01],
          [ 3.4839e-01,  1.1650e+00, -5.6641e-01,  ..., -8.5266e-02, -1.0869e+00, -5.2637e-01]],

         ...,

         [[ 1.6973e+00, -2.0935e-01,  3.2837e-01,  ..., -1.6123e+00,  1.1924e+00,  7.0703e-01],
          [ 3.6890e-01, -8.3350e-01, -1.0455e-01,  ..., -1.0852e-01, -9.2773e-02, -2.9224e-01],
          [ 1.2559e+00, -5.9570e-01,  3.2495e-01,  ...,  4.8950e-01,  2.1289e-01,  2.2534e-01],
          ...,
          [ 3.5059e-01,  4.0527e-01,  4.3915e-02,  ...,  5.0195e-01,  9.9182e-03,  1.0137e+00],
          [-8.9111e-01, -3.2275e-01,  1.0938e+00,  ..., -3.8037e-01,  7.9199e-01,  7.1191e-01],
          [ 1.5146e+00, -8.0994e-02,  5.9424e-01,  ..., -5.1562e-01, -1.5811e+00, -2.0081e-01]],

         [[-1.3965e-01,  7.0117e-01, -9.9414e-01,  ..., -8.6182e-01, -3.5449e-01,  4.7314e-01],
          [-1.2607e+00,  9.7107e-02, -4.5581e-01,  ...,  1.0034e-01,  8.2617e-01, -1.1090e-01],
          [ 6.6553e-01, -2.0654e-01, -1.8677e-01,  ..., -4.0503e-01,  6.0156e-01, -3.4790e-01],
          ...,
          [ 6.3086e-01,  5.6836e-01,  5.8545e-01,  ..., -1.0088e+00, -1.1729e+00, -6.2598e-01],
          [-1.1328e-01, -6.6699e-01, -2.2229e-01,  ..., -1.4297e+00, -7.6318e-01, -2.4277e-02],
          [-4.2065e-01, -6.9727e-01, -1.1475e+00,  ...,  4.1064e-01, -6.8018e-01, -1.7109e+00]],

         [[ 2.3547e-01, -2.8595e-02,  1.0967e+00,  ..., -7.1924e-01, -9.6094e-01,  6.1719e-01],
          [ 4.2114e-01,  1.3084e-02,  5.8301e-01,  ...,  2.2925e-01,  5.9052e-03, -6.5332e-01],
          [-1.5303e+00, -2.6074e-01, -5.5322e-01,  ...,  6.1963e-01,  3.0380e-02,  8.0127e-01],
          ...,
          [-9.2627e-01, -4.6509e-01, -1.6484e+00,  ..., -6.5527e-01, -2.4011e-01, -9.6533e-01],
          [-1.8481e-01, -5.7617e-01, -1.9812e-01,  ..., -5.7812e-01, -3.8599e-01, -9.9854e-01],
          [-1.6992e-01,  1.3447e+00,  6.0938e-01,  ..., -7.1533e-01,  5.0928e-01,  6.4746e-01]]],


        [[[ 1.4932e+00, -1.1250e+00, -2.2253e-01,  ...,  7.4805e-01, -1.4814e+00,  6.1371e-02],
          [ 2.2539e+00, -1.3489e-02, -4.8926e-01,  ..., -4.7095e-01, -8.7842e-01,  6.8359e-01],
          [-3.3813e-01, -2.5854e-01, -4.9829e-01,  ..., -5.0934e-02, -3.0029e-01, -8.0811e-02],
          ...,
          [ 6.7578e-01,  9.0332e-03, -1.6436e+00,  ...,  3.5596e-01, -1.0820e+00,  1.3892e-01],
          [-6.0693e-01, -9.7803e-01, -7.6416e-01,  ..., -2.0422e-01, -4.2969e-01,  1.7725e-01],
          [-8.8672e-01, -6.3623e-01, -1.0742e+00,  ...,  5.6006e-01,  3.3618e-01, -3.0215e+00]],

         [[ 3.9209e-01,  1.3145e+00, -6.8408e-01,  ..., -8.5596e-01, -3.3105e-01, -7.2021e-01],
          [-1.3416e-01, -1.4922e+00,  6.0889e-01,  ...,  1.2656e+00,  1.8389e+00,  1.6083e-02],
          [ 7.3584e-01, -1.1523e+00, -8.8770e-01,  ..., -3.9453e-01, -2.6050e-01, -1.2812e+00],
          ...,
          [ 4.9194e-01,  5.2734e-01, -2.5366e-01,  ...,  9.5801e-01,  3.5571e-01,  6.0303e-01],
          [-2.4139e-02,  1.1045e+00,  3.2935e-01,  ..., -5.8496e-01, -2.9077e-01,  8.6670e-02],
          [-7.2205e-02,  1.5410e+00,  1.3662e+00,  ..., -3.5376e-01, -1.5027e-01, -5.5469e-01]],

         [[ 1.1859e-01, -2.9712e-01, -8.5010e-01,  ...,  1.7295e+00, -6.1084e-01,  1.0820e+00],
          [-5.2930e-01,  3.5181e-01,  2.2644e-01,  ..., -9.2920e-01, -1.4246e-01,  6.7041e-01],
          [-2.1460e-01, -6.1816e-01, -8.2617e-01,  ..., -1.3154e+00,  5.4199e-02,  4.3970e-01],
          ...,
          [-5.8350e-02, -3.3887e-01, -5.8838e-01,  ..., -5.4199e-01,  2.1680e-01,  1.4941e-01],
          [ 1.1494e+00, -5.3516e-01, -1.1719e+00,  ..., -1.7285e+00, -4.4336e-01, -6.7969e-01],
          [ 4.3921e-01,  2.9272e-01, -1.6772e-01,  ...,  3.8428e-01,  4.9658e-01, -7.6221e-01]],

         ...,

         [[ 1.2656e+00, -6.3623e-01, -1.2354e+00,  ...,  6.3184e-01, -3.4204e-01, -4.6240e-01],
          [ 2.6782e-01, -1.0186e+00, -1.9551e+00,  ...,  3.9209e-01,  3.7158e-01,  7.7686e-01],
          [-6.3086e-01,  3.0688e-01, -6.7822e-01,  ...,  4.6143e-01, -1.1943e+00,  1.1016e+00],
          ...,
          [ 1.3799e+00,  8.5400e-01,  6.0205e-01,  ..., -3.4576e-02, -6.4087e-02,  2.9321e-01],
          [ 6.4551e-01, -3.0249e-01, -1.2568e+00,  ...,  5.2588e-01, -1.3733e-01,  4.0698e-01],
          [-6.1328e-01, -6.6357e-01,  5.2441e-01,  ...,  6.8066e-01,  1.2390e-01,  7.3730e-01]],

         [[-1.7883e-01, -1.9739e-01, -6.1328e-01,  ..., -5.8447e-01, -1.3994e+00,  5.6543e-01],
          [ 5.6836e-01,  4.3018e-01, -6.8799e-01,  ..., -4.9286e-02, -2.1997e-01,  9.4189e-01],
          [ 1.0723e+00, -8.3679e-02, -3.5571e-01,  ..., -5.5957e-01,  1.3789e+00,  3.3350e-01],
          ...,
          [ 1.8604e+00, -8.9844e-02,  5.5811e-01,  ..., -3.4912e-01, -1.6443e-01,  5.0586e-01],
          [ 6.5527e-01, -1.0332e+00,  1.6143e+00,  ..., -4.7632e-01,  3.7402e-01,  8.6426e-01],
          [-9.7656e-01, -5.4785e-01,  8.4424e-01,  ..., -1.8408e-01, -1.7842e+00, -9.8193e-01]],

         [[-3.6987e-01,  3.2910e-01, -8.8806e-02,  ...,  9.5605e-01, -1.9629e-01,  8.2764e-01],
          [-6.6309e-01, -8.5693e-01,  1.8481e-01,  ...,  1.7163e-01, -3.0078e-01, -6.4941e-02],
          [ 1.5693e+00,  1.3105e+00,  7.9297e-01,  ..., -3.3521e-01,  4.9316e-01,  1.3555e+00],
          ...,
          [ 2.9053e-01,  1.0674e+00,  5.1331e-02,  ...,  9.0869e-01,  4.3872e-01, -2.9346e-01],
          [ 2.7441e-01,  2.0723e+00,  6.4111e-01,  ..., -6.2305e-01,  1.4395e+00, -2.0234e+00],
          [-1.4082e+00,  8.2825e-02,  1.4075e-01,  ...,  7.4097e-02,  1.6875e+00, -3.9185e-01]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 128, 32, 32]), dtype=torch.float16)
tensor([[[[ 2.8491e-01, -2.7588e-02,  7.5195e-01,  ..., -1.4629e+00, -1.1592e+00,  6.2109e-01],
          [ 1.2529e+00, -4.1138e-01,  5.8105e-01,  ..., -6.1523e-01, -1.1455e+00,  4.2432e-01],
          [ 4.9756e-01,  1.8738e-01, -9.6191e-02,  ..., -1.5850e+00,  4.2700e-01,  9.8926e-01],
          ...,
          [ 1.3184e+00,  3.1079e-01,  1.6821e-01,  ..., -1.2207e+00,  5.5511e-02, -2.8052e-01],
          [ 7.3486e-01,  9.0088e-02,  7.5684e-01,  ..., -3.4912e-01, -3.6572e-01, -9.7461e-01],
          [ 4.0698e-01, -1.2617e+00, -1.4355e-01,  ..., -1.8481e-01, -5.7556e-02, -6.7529e-01]],

         [[ 7.8125e-02,  4.4141e-01,  6.7529e-01,  ..., -1.0303e+00, -1.8408e+00,  4.2163e-01],
          [ 1.5088e-01, -1.4209e+00,  1.0625e+00,  ..., -8.9258e-01, -3.2495e-01,  1.1152e+00],
          [ 2.1309e+00,  1.2061e-01,  4.0649e-01,  ..., -2.3779e-01,  4.3518e-02,  1.2476e-01],
          ...,
          [-2.4426e-01, -5.9570e-01,  2.4731e-01,  ..., -1.0801e+00, -2.0850e-01,  1.9885e-01],
          [-6.8604e-01, -8.0127e-01, -1.1084e-01,  ..., -6.6846e-01,  1.7725e-01, -1.5947e+00],
          [-5.2490e-01, -2.2852e-01,  1.2861e+00,  ..., -9.8730e-01, -4.3823e-02, -1.8506e+00]],

         [[ 5.8545e-01,  5.2490e-02,  9.0674e-01,  ...,  6.0059e-01, -7.1289e-01, -5.0244e-01],
          [ 6.5088e-01,  6.2305e-01,  6.5625e-01,  ..., -8.4106e-02, -3.7109e-02, -6.2354e-01],
          [ 6.2793e-01,  1.2891e+00,  9.5361e-01,  ...,  3.7305e-01, -7.0850e-01, -1.5635e+00],
          ...,
          [ 5.2686e-01, -3.2959e-03, -1.1438e-01,  ...,  2.9492e-01, -7.4170e-01, -1.0820e+00],
          [ 5.5518e-01,  4.8340e-01,  6.8359e-01,  ..., -5.3516e-01,  3.3032e-01, -1.3418e+00],
          [ 8.8770e-01,  9.5898e-01, -6.1133e-01,  ..., -2.0068e-01, -1.3281e-01, -2.4622e-01]],

         ...,

         [[ 1.1127e-01, -2.7295e-01, -8.7451e-01,  ...,  7.0020e-01,  1.5410e+00,  9.6484e-01],
          [ 4.8950e-01, -1.3208e-01, -2.7856e-01,  ..., -1.1045e+00, -4.3213e-01, -1.8384e-01],
          [ 3.0029e-02, -1.1914e+00, -1.0283e+00,  ..., -7.9639e-01, -5.8398e-01,  6.6553e-01],
          ...,
          [ 3.3252e-01, -5.7617e-01,  2.3743e-01,  ...,  8.6572e-01,  3.7231e-02, -9.7839e-02],
          [-9.0454e-02, -1.0146e+00, -9.7607e-01,  ...,  5.6494e-01,  1.5283e+00,  5.2832e-01],
          [-6.4111e-01, -1.2070e+00, -1.0850e+00,  ...,  9.1943e-01,  5.9180e-01,  1.2461e+00]],

         [[-1.1660e+00, -1.0234e+00, -1.7734e+00,  ...,  6.5186e-02,  6.1572e-01, -4.2090e-01],
          [ 3.3325e-02, -1.3027e+00, -8.5938e-02,  ..., -4.7241e-01, -6.0400e-01, -4.3677e-01],
          [ 1.8774e-01, -7.0996e-01, -4.2578e-01,  ...,  1.3794e-01, -8.8867e-01,  1.1426e+00],
          ...,
          [ 4.5239e-01, -5.9180e-01, -2.9224e-01,  ..., -9.1992e-01,  1.2024e-01, -1.2803e+00],
          [ 1.4609e+00, -7.9688e-01,  1.8643e+00,  ...,  3.3545e-01,  6.2549e-01,  3.2642e-01],
          [ 1.8884e-01,  7.2852e-01, -3.8721e-01,  ...,  5.6787e-01,  7.9102e-02,  7.1680e-01]],

         [[-8.4473e-01,  8.4668e-01,  2.0288e-01,  ...,  8.4375e-01,  2.5513e-01, -3.7109e-01],
          [-4.7363e-01,  3.3228e-01, -2.0569e-02,  ..., -1.4482e+00,  2.2583e-02,  5.4443e-01],
          [ 4.4897e-01, -3.4644e-01, -2.1704e-01,  ..., -6.7432e-01, -2.6016e+00, -1.3398e+00],
          ...,
          [ 3.9746e-01, -1.0381e+00,  1.1514e+00,  ..., -8.1396e-01, -1.0889e+00,  4.9268e-01],
          [-3.5400e-01, -3.2422e-01,  4.6997e-01,  ...,  4.2529e-01, -3.7061e-01,  1.2783e+00],
          [ 1.3994e+00,  3.4521e-01,  7.4341e-02,  ...,  4.5166e-01, -5.8984e-01,  5.1367e-01]]],


        [[[ 7.7148e-01, -1.3770e-01, -7.3145e-01,  ...,  5.3223e-01,  7.9736e-01,  1.9873e+00],
          [ 6.8066e-01,  5.9082e-01, -2.6465e-01,  ...,  1.0166e+00,  4.4922e-01,  8.4229e-03],
          [ 3.4692e-01,  4.4629e-01, -1.2158e-01,  ..., -3.5278e-02, -1.3799e+00, -1.1493e-01],
          ...,
          [-2.7661e-01, -1.1094e+00, -1.6797e-01,  ..., -1.0732e+00,  5.4883e-01,  8.4106e-02],
          [ 4.5044e-01, -2.2278e-01,  1.9946e-01,  ...,  4.2920e-01,  7.8613e-01,  6.9141e-01],
          [ 5.5847e-02,  6.8164e-01, -5.7520e-01,  ...,  2.2578e+00,  1.9893e+00,  8.3496e-01]],

         [[ 1.8086e+00,  1.8545e+00,  9.6582e-01,  ...,  1.5454e-01,  3.1006e-01,  3.8037e-01],
          [ 9.6631e-01, -3.5205e-01,  9.9219e-01,  ...,  4.8706e-02,  2.0752e-01,  8.4229e-02],
          [-1.9983e-01, -3.9624e-01,  8.1055e-01,  ...,  8.3594e-01,  2.8857e-01, -6.9922e-01],
          ...,
          [ 5.4150e-01, -6.9727e-01, -3.1787e-01,  ..., -7.0068e-02,  1.8387e-02,  2.6099e-01],
          [-1.3330e-01, -6.7432e-01, -2.1997e-01,  ..., -4.2236e-01, -9.0576e-02,  1.7959e+00],
          [ 5.7800e-02,  1.0176e+00,  1.7712e-01,  ...,  1.7969e-01,  2.4854e-01,  1.6318e+00]],

         [[-2.3010e-01,  5.4443e-02,  1.0410e+00,  ..., -1.1902e-02,  6.1426e-01,  8.0322e-01],
          [ 7.0508e-01,  2.3730e-01,  1.1240e+00,  ..., -1.1416e+00,  1.4502e-01,  7.6355e-02],
          [-3.3301e-01, -1.1249e-01, -6.1084e-01,  ...,  4.2285e-01,  9.5654e-01,  2.2876e-01],
          ...,
          [ 2.1802e-01, -8.3594e-01, -8.2275e-01,  ...,  3.1763e-01,  1.1504e+00, -2.3169e-01],
          [-5.2460e-02,  9.1650e-01,  1.7129e+00,  ..., -3.1128e-01,  6.5869e-01,  4.9927e-01],
          [ 7.3682e-01,  3.2935e-01,  1.2285e+00,  ...,  7.3193e-01,  4.9219e-01, -5.4785e-01]],

         ...,

         [[ 1.6211e+00,  8.7463e-02, -1.0352e+00,  ...,  1.3154e+00,  4.6533e-01, -2.5195e-01],
          [ 1.7914e-02,  7.8918e-02,  1.2097e-01,  ..., -5.3516e-01, -1.5930e-02, -3.1104e-01],
          [ 1.0586e+00, -4.1406e-01,  7.5732e-01,  ...,  9.7717e-02,  4.8291e-01,  6.7090e-01],
          ...,
          [ 1.9395e+00,  6.7188e-01, -1.6572e+00,  ...,  1.3906e+00,  1.2998e+00,  5.1367e-01],
          [ 5.9619e-01,  5.1025e-01, -4.5679e-01,  ...,  2.5645e+00,  1.0771e+00, -1.9153e-01],
          [ 1.9666e-01, -1.7590e-01,  1.0957e+00,  ...,  7.9346e-01, -4.5703e-01, -2.4750e-02]],

         [[-1.3193e+00, -7.3291e-01,  4.7021e-01,  ..., -1.5186e+00, -8.0127e-01, -1.7803e+00],
          [-5.6445e-01,  4.6045e-01, -1.5393e-01,  ...,  6.4941e-01,  6.6357e-01, -1.9434e-01],
          [ 1.8398e+00,  3.5107e-01,  3.6572e-01,  ..., -6.0498e-01,  6.7969e-01, -7.6599e-02],
          ...,
          [-1.8265e-02, -7.5098e-01,  6.3232e-01,  ..., -5.1807e-01, -1.8372e-02,  1.7139e-01],
          [ 9.6143e-01,  2.5293e-01,  1.4160e-01,  ..., -4.1699e-01,  3.1226e-01,  1.4072e+00],
          [-3.6621e-01, -7.4219e-01, -8.9746e-01,  ...,  3.2471e-01,  3.5303e-01,  7.5488e-01]],

         [[-4.5093e-01, -3.5815e-01, -5.1807e-01,  ...,  1.1304e-01,  9.3384e-02,  3.8477e-01],
          [ 9.3750e-01, -7.2363e-01,  6.5918e-01,  ..., -5.8057e-01,  2.6611e-01, -5.6671e-02],
          [ 1.7960e-02, -2.0752e-01,  2.8271e-01,  ...,  3.9136e-01,  1.1191e+00, -5.0488e-01],
          ...,
          [-8.5352e-01, -1.7822e-01,  1.0850e+00,  ...,  1.0248e-01,  6.4990e-01,  6.2939e-01],
          [ 3.0225e-01,  7.7490e-01,  8.3545e-01,  ..., -5.9668e-01, -1.4053e+00, -5.0000e-01],
          [ 2.2520e+00,  1.2148e+00,  1.4814e+00,  ..., -7.5195e-01, -2.2864e-01,  7.1289e-01]]],


        [[[ 7.3242e-01, -8.4839e-02, -1.2480e+00,  ...,  1.1230e+00,  1.7993e-01,  7.2510e-01],
          [-1.3672e-01,  2.1744e-02,  3.0981e-01,  ..., -4.5624e-02,  3.9459e-02,  7.3145e-01],
          [ 2.0195e+00,  1.0166e+00, -4.3457e-02,  ...,  4.7998e-01,  1.7041e-01,  8.0371e-01],
          ...,
          [ 7.1533e-01, -1.6785e-01,  3.1299e-01,  ...,  1.6675e-01,  2.6318e-01, -2.3450e-01],
          [-2.9346e-01,  6.7236e-01, -6.0645e-01,  ...,  9.5703e-01, -2.4500e-01,  2.4438e-01],
          [ 1.4512e+00,  1.3408e+00,  1.4990e+00,  ...,  9.9902e-01, -2.3584e-01, -7.3204e-03]],

         [[ 1.6250e+00,  2.2693e-01,  1.0078e+00,  ..., -1.5078e+00, -1.4492e+00,  5.4932e-04],
          [ 1.5771e+00, -5.3271e-01,  2.5049e-01,  ...,  1.2036e-01, -1.2520e+00, -3.3252e-01],
          [-1.6068e-02,  2.6367e-01,  5.6934e-01,  ..., -9.2432e-01,  1.6418e-01,  7.7344e-01],
          ...,
          [ 1.2939e-01,  7.8564e-01, -3.9673e-01,  ...,  3.7842e-01,  3.3716e-01, -9.1992e-01],
          [ 3.1311e-02,  2.3157e-01, -1.9785e+00,  ...,  1.7822e-01,  9.6973e-01,  3.8257e-01],
          [-4.7949e-01,  4.7363e-02, -1.4980e+00,  ..., -1.5654e+00, -1.1761e-01,  6.5332e-01]],

         [[ 4.6973e-01,  3.7646e-01,  7.3242e-04,  ..., -1.5586e+00, -2.1265e-01, -1.0557e+00],
          [ 1.5537e+00, -2.6880e-01, -9.1211e-01,  ..., -7.2461e-01,  2.3242e-01,  4.1333e-01],
          [ 8.4717e-01,  4.1455e-01, -3.6206e-01,  ..., -1.2915e-01, -2.9419e-01,  1.2695e+00],
          ...,
          [ 1.9800e-01,  1.3171e-01, -3.0151e-01,  ...,  1.7969e+00, -2.5903e-01, -4.9286e-02],
          [ 6.7676e-01,  1.0791e+00,  5.6445e-01,  ..., -9.9121e-02, -4.8096e-01, -7.3145e-01],
          [ 3.5059e-01,  1.1797e+00, -5.6982e-01,  ..., -9.0332e-02, -1.1035e+00, -5.3027e-01]],

         ...,

         [[ 1.7119e+00, -2.1130e-01,  3.2910e-01,  ..., -1.6309e+00,  1.2041e+00,  7.1191e-01],
          [ 3.7329e-01, -8.3789e-01, -1.0229e-01,  ..., -1.1456e-01, -9.6680e-02, -2.9443e-01],
          [ 1.2646e+00, -6.0498e-01,  3.2495e-01,  ...,  4.9438e-01,  2.1558e-01,  2.2571e-01],
          ...,
          [ 3.5327e-01,  4.0894e-01,  4.4067e-02,  ...,  5.0732e-01,  3.9902e-03,  1.0205e+00],
          [-9.0088e-01, -3.2520e-01,  1.1016e+00,  ..., -3.7988e-01,  8.0518e-01,  7.2510e-01],
          [ 1.5234e+00, -7.8979e-02,  6.0791e-01,  ..., -5.2686e-01, -1.5869e+00, -2.0117e-01]],

         [[-1.4160e-01,  7.0654e-01, -1.0068e+00,  ..., -8.6865e-01, -3.5791e-01,  4.7974e-01],
          [-1.2715e+00,  1.0028e-01, -4.5923e-01,  ...,  9.9121e-02,  8.3398e-01, -1.0791e-01],
          [ 6.7139e-01, -2.0837e-01, -1.9080e-01,  ..., -4.0747e-01,  6.0449e-01, -3.5718e-01],
          ...,
          [ 6.3623e-01,  5.7275e-01,  5.8936e-01,  ..., -1.0156e+00, -1.1846e+00, -6.3672e-01],
          [-1.1224e-01, -6.7188e-01, -2.2314e-01,  ..., -1.4424e+00, -7.7051e-01, -2.4094e-02],
          [-4.2383e-01, -7.0312e-01, -1.1543e+00,  ...,  4.0430e-01, -6.9287e-01, -1.7236e+00]],

         [[ 2.3914e-01, -2.8442e-02,  1.1084e+00,  ..., -7.2461e-01, -9.7559e-01,  6.2207e-01],
          [ 4.2578e-01,  1.3779e-02,  5.9521e-01,  ...,  2.2925e-01,  7.4158e-03, -6.6113e-01],
          [-1.5410e+00, -2.6514e-01, -5.6152e-01,  ...,  6.2793e-01,  3.0762e-02,  8.0957e-01],
          ...,
          [-9.3164e-01, -4.6680e-01, -1.6611e+00,  ..., -6.6064e-01, -2.3804e-01, -9.7559e-01],
          [-1.8787e-01, -5.8496e-01, -2.0203e-01,  ..., -5.8740e-01, -3.8989e-01, -1.0176e+00],
          [-1.7139e-01,  1.3545e+00,  6.1719e-01,  ..., -7.2266e-01,  5.1074e-01,  6.5186e-01]]],


        [[[ 1.5059e+00, -1.1406e+00, -2.2571e-01,  ...,  7.6416e-01, -1.5010e+00,  5.6061e-02],
          [ 2.2793e+00, -1.5350e-02, -4.9463e-01,  ..., -4.7681e-01, -8.8721e-01,  6.9434e-01],
          [-3.3813e-01, -2.5806e-01, -5.0244e-01,  ..., -5.1147e-02, -3.0493e-01, -8.2764e-02],
          ...,
          [ 6.8115e-01,  1.1719e-02, -1.6582e+00,  ...,  3.5938e-01, -1.0957e+00,  1.4282e-01],
          [-6.0938e-01, -9.9219e-01, -7.7441e-01,  ..., -2.0483e-01, -4.3701e-01,  1.7810e-01],
          [-8.9355e-01, -6.4258e-01, -1.0820e+00,  ...,  5.5957e-01,  3.3691e-01, -3.0508e+00]],

         [[ 3.9429e-01,  1.3330e+00, -6.9141e-01,  ..., -8.6719e-01, -3.3618e-01, -7.2754e-01],
          [-1.3550e-01, -1.5059e+00,  6.1377e-01,  ...,  1.2832e+00,  1.8545e+00,  1.3153e-02],
          [ 7.4121e-01, -1.1709e+00, -8.9258e-01,  ..., -3.9258e-01, -2.5708e-01, -1.2891e+00],
          ...,
          [ 4.9463e-01,  5.3076e-01, -2.5684e-01,  ...,  9.7461e-01,  3.6768e-01,  6.1523e-01],
          [-2.3117e-02,  1.1143e+00,  3.3350e-01,  ..., -5.8984e-01, -2.9639e-01,  8.8989e-02],
          [-7.0374e-02,  1.5586e+00,  1.3789e+00,  ..., -3.6108e-01, -1.5112e-01, -5.6250e-01]],

         [[ 1.2146e-01, -3.0103e-01, -8.5547e-01,  ...,  1.7432e+00, -6.2061e-01,  1.0947e+00],
          [-5.3516e-01,  3.5425e-01,  2.2974e-01,  ..., -9.3115e-01, -1.4539e-01,  6.7871e-01],
          [-2.1509e-01, -6.2500e-01, -8.3350e-01,  ..., -1.3359e+00,  5.4138e-02,  4.4604e-01],
          ...,
          [-5.8899e-02, -3.3911e-01, -5.9473e-01,  ..., -5.4297e-01,  2.1924e-01,  1.5796e-01],
          [ 1.1602e+00, -5.3906e-01, -1.1836e+00,  ..., -1.7480e+00, -4.4604e-01, -6.8750e-01],
          [ 4.4727e-01,  2.9199e-01, -1.7126e-01,  ...,  3.8623e-01,  4.9951e-01, -7.6807e-01]],

         ...,

         [[ 1.2803e+00, -6.4160e-01, -1.2422e+00,  ...,  6.4062e-01, -3.4839e-01, -4.6558e-01],
          [ 2.7148e-01, -1.0332e+00, -1.9746e+00,  ...,  3.9551e-01,  3.7817e-01,  7.8027e-01],
          [-6.3525e-01,  3.0835e-01, -6.8652e-01,  ...,  4.6680e-01, -1.2090e+00,  1.1182e+00],
          ...,
          [ 1.3916e+00,  8.6670e-01,  6.1230e-01,  ..., -3.6652e-02, -6.5247e-02,  2.9028e-01],
          [ 6.4941e-01, -3.0640e-01, -1.2764e+00,  ...,  5.3369e-01, -1.3867e-01,  4.1309e-01],
          [-6.1328e-01, -6.6699e-01,  5.2979e-01,  ...,  6.8555e-01,  1.2256e-01,  7.4365e-01]],

         [[-1.7993e-01, -1.9971e-01, -6.2305e-01,  ..., -5.9375e-01, -1.4170e+00,  5.7373e-01],
          [ 5.7471e-01,  4.3555e-01, -6.9434e-01,  ..., -4.7668e-02, -2.2632e-01,  9.5215e-01],
          [ 1.0840e+00, -8.4717e-02, -3.5986e-01,  ..., -5.6934e-01,  1.3965e+00,  3.3569e-01],
          ...,
          [ 1.8760e+00, -8.6792e-02,  5.6250e-01,  ..., -3.5059e-01, -1.6711e-01,  5.1270e-01],
          [ 6.6260e-01, -1.0449e+00,  1.6309e+00,  ..., -4.8291e-01,  3.7817e-01,  8.7500e-01],
          [-9.8584e-01, -5.5176e-01,  8.5107e-01,  ..., -1.8689e-01, -1.7910e+00, -9.9170e-01]],

         [[-3.7012e-01,  3.3203e-01, -9.5337e-02,  ...,  9.6582e-01, -1.9885e-01,  8.3496e-01],
          [-6.7188e-01, -8.6914e-01,  1.8530e-01,  ...,  1.7810e-01, -3.0371e-01, -6.7139e-02],
          [ 1.5762e+00,  1.3242e+00,  7.9883e-01,  ..., -3.3911e-01,  4.9780e-01,  1.3691e+00],
          ...,
          [ 2.9175e-01,  1.0703e+00,  5.3925e-02,  ...,  9.2090e-01,  4.4165e-01, -2.9248e-01],
          [ 2.8101e-01,  2.0996e+00,  6.4600e-01,  ..., -6.2842e-01,  1.4551e+00, -2.0527e+00],
          [-1.4131e+00,  9.4849e-02,  1.4490e-01,  ...,  7.1655e-02,  1.7041e+00, -3.9551e-01]]]], dtype=torch.float16)

2025-06-10 00:13:32.340953 GPU 7 156019 test begin: paddle.nn.functional.interpolate(Tensor([4, 128, 4, 4],"float16"), list[16,32,], mode="bilinear", align_corners=False, )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 128, 4, 4],"float16"), list[16,32,], mode="bilinear", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3468 / 8192 (42.3%)
Greatest absolute difference: 0.11328125 at index (0, 7, 0, 2) (up to 0.01 allowed)
Greatest relative difference: 49.9375 at index (2, 75, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 128, 4, 4]), dtype=torch.float16)
tensor([[[[ 0.3647,  0.6382,  1.7598, -0.0372],
          [ 0.7393,  0.2252,  0.2245,  0.4473],
          [-1.1953, -1.5127, -0.1975, -0.3889],
          [ 0.5703,  0.1763,  0.6738,  1.1582]],

         [[ 2.0742,  0.8120, -0.9248,  0.7681],
          [-0.8809, -0.9272, -0.8853, -1.1660],
          [-0.7007,  0.2394,  0.2336,  0.8442],
          [-1.0859,  1.6406,  0.1130,  0.4292]],

         [[-0.6465, -1.2988, -0.4417, -1.8789],
          [-0.8481, -1.4385,  0.1797,  0.5430],
          [-0.9058,  0.2306, -0.0485, -0.1304],
          [ 0.0681,  1.0713,  0.5815, -2.8340]],

         ...,

         [[ 3.3438,  0.8730, -1.3301, -1.3789],
          [-0.7178, -0.8462, -0.4170, -1.6895],
          [ 1.7598,  0.6309,  0.1737,  1.6777],
          [ 1.6777,  2.5977,  0.5024, -0.1840]],

         [[ 1.7305,  0.8955,  0.7544,  0.2896],
          [ 1.9160,  1.5713,  1.7354,  0.3958],
          [ 1.0254,  1.8750,  3.2656,  1.5732],
          [ 1.4814,  2.9570,  1.8379,  0.2761]],

         [[ 1.5010,  1.8848,  1.3633,  0.1594],
          [-1.2061,  0.5342, -0.3582,  0.0360],
          [-1.7764, -1.6670,  0.7632, -0.1326],
          [-2.5840, -1.4688, -0.3962, -0.4976]]],


        [[[-0.4939,  0.4470,  1.2656,  1.1436],
          [ 1.0898,  0.0825, -1.5469, -0.0368],
          [-1.9453,  0.0322,  0.1098,  0.7290],
          [ 1.0332,  1.2998,  0.4563,  0.6206]],

         [[-1.6484, -0.5669, -0.6289,  0.1990],
          [ 0.9194,  0.4065,  1.0293,  0.3203],
          [-0.7788, -0.0622,  0.8765, -0.8813],
          [-0.7900,  0.1215,  1.7783, -0.1509]],

         [[ 0.3235, -1.4717, -1.7852, -2.0820],
          [-0.4814, -0.3320, -1.1328, -1.6943],
          [ 0.1775,  2.0977,  0.8955,  0.0782],
          [ 1.8545, -0.3577, -0.3228, -0.1282]],

         ...,

         [[-0.5513,  2.6875,  1.6787,  2.3496],
          [-0.9429,  1.2471,  0.8340, -0.2590],
          [-1.0352, -0.6597,  1.6162,  0.0579],
          [-0.3184, -0.1660,  0.2988,  0.2111]],

         [[ 0.0952,  0.6040,  0.8940,  0.3345],
          [ 0.0906,  0.0144, -2.3223, -1.8389],
          [ 0.5312,  0.2095, -2.4883, -0.3906],
          [-0.9517,  1.3369,  1.3799, -0.6191]],

         [[-1.4531,  0.4817,  0.7949,  0.3340],
          [ 1.4375,  1.6982, -0.9463,  0.3599],
          [-0.9531,  0.6006, -0.5645, -0.7915],
          [-0.5762,  0.3892,  1.7627,  0.5791]]],


        [[[ 1.2441, -0.2949,  0.2344,  0.4033],
          [-0.1760,  0.8374,  0.3208, -0.7856],
          [-3.1152, -1.7070,  0.3608, -2.6094],
          [-1.2910, -0.1893, -0.9673, -2.2031]],

         [[-0.4363,  1.9541, -0.2194,  0.8975],
          [ 1.4365, -0.2678, -1.7480, -2.3262],
          [ 0.5669,  0.8872, -0.1091, -1.3477],
          [ 3.3770,  2.6953,  2.6250,  0.5796]],

         [[-2.9824, -0.1818,  0.7842, -0.7144],
          [-2.0605, -0.5972,  0.6250,  1.1367],
          [ 0.5054, -0.0688, -0.9014,  0.3936],
          [ 0.3567,  0.6567, -1.1387, -0.9536]],

         ...,

         [[-2.3691, -1.3584, -1.3564,  0.8799],
          [ 2.1484,  1.2676, -0.7827,  1.1768],
          [ 2.9082,  1.0098, -0.4329, -0.5669],
          [ 1.8125,  1.5400,  0.3015, -0.6133]],

         [[-0.3555, -0.1373, -1.7080, -0.4175],
          [ 1.0635,  0.8599,  0.0442,  0.9077],
          [ 2.2930,  1.0293,  0.0554,  0.9346],
          [ 0.4556,  0.4080, -2.1777,  0.0461]],

         [[-0.1567,  0.9023, -0.4631, -0.8091],
          [-0.7485, -1.2061,  1.2529, -0.7446],
          [-0.5151, -0.7974,  0.1132, -1.6699],
          [ 0.1169,  0.0654,  0.4114, -0.9136]]],


        [[[-0.0924, -1.7412,  0.2354,  0.4287],
          [-0.1541,  1.3486,  1.3291,  1.1455],
          [ 0.6523,  0.9609, -0.6011, -1.8789],
          [-0.6602, -3.3105, -2.4551,  1.1270]],

         [[ 0.9155, -0.3972,  0.0366, -0.9067],
          [ 0.3647,  0.4373, -0.8257, -0.0565],
          [ 1.1953,  0.6309,  0.4011, -0.3516],
          [ 1.4033,  0.3718, -0.6895,  1.6494]],

         [[ 0.9653, -1.3027,  1.7998,  0.1322],
          [-0.6416, -0.5015, -0.0455, -0.8550],
          [-1.0459,  0.1646,  0.2377,  2.3496],
          [-1.8320,  0.4727, -0.9995,  0.1655]],

         ...,

         [[-0.4116, -1.8936, -1.4404,  0.7949],
          [ 0.0316,  1.5820, -0.0889,  0.6938],
          [-0.9829,  0.0693, -2.0527, -0.2107],
          [-2.4551, -1.2168, -0.6616, -0.3171]],

         [[ 0.8789, -1.4639, -2.2695,  0.0828],
          [ 0.2068, -1.1777,  0.3306,  1.7471],
          [-0.9185, -0.2976, -0.2690, -1.3086],
          [-1.8018,  0.2167,  0.6235,  0.1901]],

         [[ 3.0234,  0.5415,  1.3525,  0.4404],
          [-0.1008,  0.7114,  0.0557, -0.3264],
          [ 0.5430, -0.7817, -0.4658,  0.8042],
          [ 1.9092,  0.7202, -0.4736, -0.6719]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 128, 4, 4]), dtype=torch.float16)
tensor([[[[ 0.3730,  0.6475,  1.7969, -0.0424],
          [ 0.7559,  0.2366,  0.2430,  0.4563],
          [-1.2188, -1.5449, -0.2100, -0.4011],
          [ 0.5767,  0.1769,  0.6875,  1.1787]],

         [[ 2.1367,  0.8291, -0.9355,  0.7734],
          [-0.8970, -0.9409, -0.9141, -1.1797],
          [-0.7056,  0.2346,  0.2396,  0.8516],
          [-1.1084,  1.6807,  0.1158,  0.4414]],

         [[-0.6626, -1.3301, -0.4507, -1.9160],
          [-0.8496, -1.4688,  0.1786,  0.5493],
          [-0.9282,  0.2316, -0.0459, -0.1246],
          [ 0.0695,  1.0830,  0.5830, -2.8965]],

         ...,

         [[ 3.4004,  0.8857, -1.3652, -1.4092],
          [-0.7231, -0.8447, -0.4106, -1.7256],
          [ 1.7764,  0.6284,  0.1676,  1.6953],
          [ 1.7090,  2.6699,  0.5327, -0.1755]],

         [[ 1.7549,  0.9111,  0.7676,  0.2900],
          [ 1.9443,  1.5977,  1.7676,  0.4121],
          [ 1.0449,  1.9102,  3.3477,  1.5977],
          [ 1.5020,  2.9980,  1.8818,  0.2852]],

         [[ 1.5215,  1.9199,  1.4033,  0.1564],
          [-1.2207,  0.5459, -0.3728,  0.0436],
          [-1.8086, -1.6865,  0.7817, -0.1415],
          [-2.6191, -1.4971, -0.3931, -0.5127]]],


        [[[-0.5039,  0.4592,  1.2959,  1.1816],
          [ 1.1094,  0.0881, -1.5703, -0.0447],
          [-1.9697,  0.0286,  0.1055,  0.7524],
          [ 1.0303,  1.3096,  0.4573,  0.6245]],

         [[-1.6777, -0.5674, -0.6489,  0.1960],
          [ 0.9233,  0.3999,  1.0615,  0.3347],
          [-0.7788, -0.0570,  0.8853, -0.8965],
          [-0.8164,  0.1145,  1.8193, -0.1711]],

         [[ 0.3315, -1.4824, -1.8086, -2.1484],
          [-0.4878, -0.3433, -1.1621, -1.7227],
          [ 0.1730,  2.1543,  0.9072,  0.0719],
          [ 1.8799, -0.3508, -0.3345, -0.1244]],

         ...,

         [[-0.5732,  2.7402,  1.7246,  2.4102],
          [-0.9478,  1.2891,  0.8604, -0.2593],
          [-1.0557, -0.6724,  1.6396,  0.0546],
          [-0.3201, -0.1754,  0.3198,  0.2208]],

         [[ 0.0937,  0.5938,  0.9102,  0.3550],
          [ 0.0952,  0.0338, -2.3652, -1.8955],
          [ 0.5366,  0.2014, -2.5625, -0.3975],
          [-0.9580,  1.3633,  1.3984, -0.6289]],

         [[-1.4863,  0.4805,  0.8276,  0.3386],
          [ 1.4668,  1.7471, -0.9688,  0.3635],
          [-0.9692,  0.6064, -0.5815, -0.8057],
          [-0.5947,  0.3999,  1.8047,  0.5938]]],


        [[[ 1.2568, -0.3032,  0.2412,  0.4158],
          [-0.1669,  0.8633,  0.3225, -0.7915],
          [-3.1777, -1.7354,  0.3794, -2.6680],
          [-1.3213, -0.2103, -0.9751, -2.2734]],

         [[-0.4485,  2.0176, -0.2114,  0.9199],
          [ 1.4756, -0.2690, -1.7871, -2.3730],
          [ 0.5645,  0.8989, -0.1157, -1.3789],
          [ 3.4180,  2.7285,  2.6680,  0.6025]],

         [[-3.0312, -0.1782,  0.7974, -0.7280],
          [-2.1094, -0.6128,  0.6406,  1.1553],
          [ 0.5059, -0.0656, -0.9141,  0.4131],
          [ 0.3770,  0.6670, -1.1475, -0.9834]],

         ...,

         [[-2.4160, -1.3984, -1.3809,  0.8843],
          [ 2.1680,  1.2871, -0.8018,  1.2041],
          [ 2.9668,  1.0283, -0.4377, -0.5732],
          [ 1.8545,  1.5820,  0.2939, -0.6211]],

         [[-0.3555, -0.1394, -1.7354, -0.4263],
          [ 1.0693,  0.8838,  0.0352,  0.9150],
          [ 2.3477,  1.0566,  0.0668,  0.9609],
          [ 0.4565,  0.4050, -2.2285,  0.0440]],

         [[-0.1628,  0.9297, -0.4878, -0.8179],
          [-0.7563, -1.2344,  1.2803, -0.7544],
          [-0.5327, -0.8149,  0.1230, -1.6992],
          [ 0.1295,  0.0677,  0.4182, -0.9458]]],


        [[[-0.0853, -1.7969,  0.2334,  0.4141],
          [-0.1588,  1.3691,  1.3574,  1.1914],
          [ 0.6675,  0.9980, -0.6016, -1.9111],
          [-0.6738, -3.3535, -2.5195,  1.1182]],

         [[ 0.9346, -0.4038,  0.0526, -0.9062],
          [ 0.3618,  0.4414, -0.8516, -0.0673],
          [ 1.2256,  0.6504,  0.4104, -0.3604],
          [ 1.4258,  0.3787, -0.6992,  1.6865]],

         [[ 0.9780, -1.3242,  1.8516,  0.1587],
          [-0.6509, -0.5239, -0.0429, -0.8940],
          [-1.0557,  0.1704,  0.2412,  2.4121],
          [-1.8711,  0.4751, -1.0225,  0.1722]],

         ...,

         [[-0.4194, -1.9414, -1.4766,  0.7949],
          [ 0.0361,  1.6045, -0.0896,  0.7207],
          [-0.9922,  0.0932, -2.0977, -0.2163],
          [-2.4941, -1.2490, -0.6880, -0.3230]],

         [[ 0.8882, -1.5215, -2.3242,  0.0822],
          [ 0.2168, -1.2012,  0.3269,  1.7783],
          [-0.9268, -0.3076, -0.2629, -1.3340],
          [-1.8311,  0.2061,  0.6255,  0.1804]],

         [[ 3.0840,  0.5508,  1.3711,  0.4490],
          [-0.0991,  0.7212,  0.0654, -0.3374],
          [ 0.5513, -0.7925, -0.4739,  0.8179],
          [ 1.9287,  0.7363, -0.4795, -0.6787]]]], dtype=torch.float16)

2025-06-10 00:13:32.460334 GPU 7 156955 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 128, 256],"float16"), list[512,1024,], mode="bilinear", align_corners=False, data_format="NCHW", )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 19, 128, 256],"float16"), list[512,1024,], mode="bilinear", align_corners=False, data_format="NCHW", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6494 / 2490368 (0.3%)
Greatest absolute difference: 0.05078125 at index (2, 17, 21, 152) (up to 0.01 allowed)
Greatest relative difference: 10.5625 at index (3, 3, 76, 169) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 19, 128, 256]), dtype=torch.float16)
tensor([[[[-2.0605e-01,  5.7861e-02,  2.4668e+00,  ...,  2.0239e-01,  3.9282e-01,  1.4043e+00],
          [ 3.7231e-01,  3.5474e-01, -2.0679e-01,  ...,  4.2725e-01, -1.2480e+00,  3.9380e-01],
          [ 5.7373e-01,  9.1992e-01, -1.4160e-01,  ..., -1.4197e-01, -3.2080e-01, -7.3682e-01],
          ...,
          [-9.7900e-02, -4.9146e-01,  6.7676e-01,  ..., -7.0850e-01, -2.8784e-01, -1.2607e+00],
          [ 6.2451e-01, -5.6494e-01, -3.1396e-01,  ...,  9.0283e-01, -1.1455e+00, -7.9688e-01],
          [-8.0078e-01, -1.0527e+00,  7.5134e-02,  ...,  5.3613e-01, -1.9238e-01,  5.9717e-01]],

         [[ 5.3925e-02,  3.1323e-01,  4.2212e-01,  ...,  8.8721e-01, -5.4834e-01, -8.3789e-01],
          [ 2.0309e-02,  7.1436e-01,  1.2666e+00,  ..., -5.0201e-02,  2.8296e-01, -6.5283e-01],
          [ 6.9482e-01,  2.6685e-01, -1.3367e-01,  ..., -1.9119e-02,  2.9980e-01, -4.6631e-01],
          ...,
          [-6.2207e-01, -6.4307e-01,  4.4067e-01,  ..., -6.3330e-01,  9.9902e-01,  1.7227e+00],
          [-1.1074e+00, -7.7734e-01, -3.5718e-01,  ..., -7.6807e-01, -6.7920e-01,  1.3718e-02],
          [-1.0127e+00, -3.1885e-01, -2.6123e-01,  ...,  6.6846e-01,  1.4639e+00,  1.5938e+00]],

         [[ 9.0771e-01,  8.2324e-01, -1.0107e+00,  ...,  5.5518e-01, -1.1494e+00, -6.5869e-01],
          [-4.0259e-01,  1.5747e-01,  1.0381e+00,  ..., -6.7773e-01, -1.2979e+00, -3.7231e-01],
          [-2.2290e-01, -1.0901e-01,  1.2891e+00,  ...,  1.7334e-01,  1.9946e-01,  3.1104e-01],
          ...,
          [ 2.2324e+00, -4.6582e-01,  6.1768e-01,  ..., -2.5366e-01,  5.8203e-01, -5.6543e-01],
          [ 2.5537e-01, -1.2051e+00, -3.1738e-02,  ...,  8.3496e-02, -9.2920e-01,  4.5093e-01],
          [-1.1787e+00, -1.7395e-01, -2.9810e-01,  ..., -1.0303e+00, -9.3567e-02, -8.5327e-02]],

         ...,

         [[ 4.9896e-03, -9.9707e-01, -3.0502e-02,  ..., -1.2500e+00,  3.1812e-01, -1.0195e+00],
          [ 1.1289e+00, -4.0869e-01, -4.7461e-01,  ...,  1.0840e+00,  6.6895e-01,  1.0315e-01],
          [-1.0742e-01, -1.2725e+00, -5.4785e-01,  ...,  1.0596e+00,  1.6589e-01, -6.8457e-01],
          ...,
          [-1.8076e+00, -1.7383e-01,  1.1963e+00,  ..., -2.1936e-01,  1.2891e+00,  9.8975e-01],
          [-1.4854e+00, -2.0508e-02, -3.4766e-01,  ...,  4.0747e-01,  1.0605e+00, -3.2471e-01],
          [-2.4463e-01, -1.8408e-01,  9.4336e-01,  ..., -3.0908e-01,  1.1455e+00,  1.6904e+00]],

         [[ 2.2400e-01, -2.3450e-01, -4.8633e-01,  ...,  6.6345e-02,  1.1053e-01,  1.1514e+00],
          [ 6.4307e-01,  1.4365e+00,  1.7944e-01,  ...,  9.0430e-01,  4.6167e-01,  4.7314e-01],
          [-1.3945e+00,  6.8262e-01, -8.0371e-01,  ...,  2.0195e+00,  4.0161e-01,  2.8784e-01],
          ...,
          [ 7.5928e-02,  3.7500e-01, -7.2949e-01,  ...,  9.8340e-01, -7.7576e-02, -3.2690e-01],
          [-1.3550e-01,  1.6025e+00, -5.3125e-01,  ...,  7.6953e-01,  9.5410e-01,  2.9712e-01],
          [ 5.8350e-01,  1.5391e+00,  2.7954e-01,  ..., -1.6101e-01, -2.1167e-01,  1.3799e+00]],

         [[ 5.1904e-01,  1.5615e+00,  2.9053e-01,  ..., -7.0117e-01, -1.0332e+00,  1.8579e-01],
          [ 2.4268e-01, -6.0205e-01,  1.1787e+00,  ...,  1.4050e-01,  7.3547e-02,  1.3779e+00],
          [ 1.5417e-01, -1.3281e-01,  3.6963e-01,  ...,  1.3994e+00,  2.5732e-01,  1.7324e+00],
          ...,
          [ 1.7310e-01, -4.6143e-01, -4.0186e-01,  ..., -8.5303e-01, -8.7305e-01,  4.1211e-01],
          [-1.3623e+00, -1.6855e+00,  1.3306e-02,  ..., -8.1104e-01,  5.5756e-02,  1.8030e-01],
          [ 7.1289e-01,  4.3262e-01, -9.8694e-02,  ...,  1.1865e-01,  1.2805e-01,  2.2205e-01]]],


        [[[ 1.6736e-01,  8.9258e-01,  9.4141e-01,  ...,  4.5190e-01, -6.9092e-02, -1.3701e+00],
          [-8.5754e-02, -9.5752e-01, -1.2854e-01,  ..., -2.4512e-01,  1.1016e+00, -1.3757e-01],
          [-1.3367e-01, -5.0000e-01, -5.2783e-01,  ...,  5.1318e-01,  7.6599e-02,  8.1982e-01],
          ...,
          [-5.1544e-02,  7.8613e-02, -9.3848e-01,  ..., -5.2539e-01,  2.4744e-01,  3.4009e-01],
          [ 6.6113e-01,  2.1167e-01, -2.0020e-01,  ...,  6.5002e-02, -5.6299e-01,  1.3379e+00],
          [-2.6050e-01,  4.5142e-01,  5.4004e-01,  ..., -1.5271e-01, -1.8982e-01, -3.4570e-01]],

         [[-1.1504e+00, -7.7100e-01, -8.1543e-01,  ..., -4.5435e-01, -4.2212e-01,  1.5332e+00],
          [ 3.0981e-01,  9.1504e-01, -5.1367e-01,  ..., -2.3816e-01,  8.2910e-01,  4.5013e-03],
          [-9.8633e-01, -1.0654e+00, -1.0635e+00,  ...,  3.2288e-02, -9.0576e-02, -8.9502e-01],
          ...,
          [-1.6101e-01, -1.2900e+00,  1.7554e-01,  ...,  1.1981e-01,  7.8735e-02,  1.0907e-01],
          [-6.8066e-01,  1.1853e-01,  2.9565e-01,  ...,  6.9727e-01,  3.9331e-01, -1.7603e-01],
          [ 1.1289e+00,  5.7764e-01,  2.8345e-01,  ..., -2.8687e-01, -3.5742e-01, -5.5078e-01]],

         [[-5.0049e-01,  8.8135e-01, -2.9419e-01,  ..., -8.7695e-01, -9.7900e-02,  7.7246e-01],
          [-2.3975e-01, -1.4414e+00, -8.4424e-01,  ...,  5.8203e-01,  1.2793e+00, -1.7810e-01],
          [ 7.2510e-01, -6.0498e-01, -6.3818e-01,  ..., -4.4995e-01, -2.2266e-01,  4.7437e-01],
          ...,
          [-7.3486e-01, -6.6943e-01,  3.2153e-01,  ...,  3.6938e-01, -3.4717e-01,  1.9629e-01],
          [-8.9551e-01,  1.1543e+00,  1.0430e+00,  ..., -2.0547e+00, -9.8926e-01,  1.1133e+00],
          [-8.2227e-01, -1.1191e+00, -4.1089e-01,  ..., -1.9707e+00, -1.7371e-01, -1.2683e-01]],

         ...,

         [[-2.3267e-01, -6.3843e-02,  6.4258e-01,  ..., -7.2479e-03, -7.2754e-01,  2.7734e-01],
          [-1.2188e+00, -3.3960e-01,  3.2275e-01,  ...,  1.5186e-01, -4.6362e-01, -1.6523e+00],
          [-9.2529e-01, -1.8420e-01,  2.6343e-01,  ..., -1.0410e+00, -5.4053e-01, -9.5557e-01],
          ...,
          [-2.7954e-01,  6.1279e-01, -1.5674e-01,  ...,  4.9023e-01, -4.6045e-01, -2.3125e+00],
          [ 1.9570e+00, -2.9810e-01,  2.8540e-01,  ...,  3.0933e-01, -8.4766e-01, -1.2695e+00],
          [ 1.0527e+00, -1.4883e+00,  7.7539e-01,  ..., -1.2539e+00, -5.0293e-01, -5.0732e-01]],

         [[-3.4473e-01,  8.6572e-01,  2.0288e-01,  ..., -2.1313e-01,  3.2007e-01, -7.6111e-02],
          [-1.6760e-01,  5.3516e-01,  1.4844e+00,  ...,  8.7354e-01,  8.8379e-01,  9.7314e-01],
          [ 4.3604e-01,  7.5537e-01,  6.6992e-01,  ...,  2.1069e-01,  3.6938e-01, -7.9688e-01],
          ...,
          [-8.6731e-02,  3.9819e-01, -5.8823e-03,  ..., -8.8867e-02, -6.9824e-01, -1.3574e+00],
          [ 4.4653e-01, -2.7222e-01, -7.6611e-01,  ...,  3.2422e-01,  2.3804e-01, -3.1934e-01],
          [-6.7627e-01, -5.8398e-01, -1.1230e+00,  ..., -3.8770e-01, -4.2529e-01,  4.5093e-01]],

         [[-7.4365e-01,  9.4824e-01,  2.1094e-01,  ..., -1.6367e+00, -6.5039e-01,  1.3740e+00],
          [-1.0752e+00,  2.5131e-02,  5.9082e-01,  ..., -5.1660e-01,  1.1914e-01,  2.2217e-01],
          [ 2.5049e-01,  5.7495e-02,  8.2178e-01,  ...,  9.4775e-01, -3.8867e-01,  6.7688e-02],
          ...,
          [ 1.3496e+00,  3.5962e-01, -6.6357e-01,  ..., -7.4341e-02,  4.7705e-01, -8.3447e-01],
          [ 8.7207e-01,  8.7354e-01,  2.3816e-01,  ...,  8.4082e-01,  1.1709e+00, -5.1514e-01],
          [-9.3872e-02,  5.9131e-01, -1.1260e+00,  ...,  2.0056e-01, -4.0088e-01,  2.2339e-01]]],


        [[[-5.7800e-02, -1.3770e+00, -1.4575e-01,  ..., -8.3984e-01,  8.4167e-02,  7.5732e-01],
          [-1.0449e-01, -1.4758e-01,  1.0925e-01,  ..., -8.0615e-01,  7.6709e-01,  8.5303e-01],
          [-6.6064e-01, -5.0635e-01,  3.6240e-03,  ..., -1.9275e-01, -4.3213e-01, -8.0225e-01],
          ...,
          [-8.1885e-01,  1.2480e+00, -3.2715e-02,  ...,  3.1274e-01, -1.0223e-01, -5.1709e-01],
          [-6.7383e-01,  2.4072e-01, -9.0820e-01,  ..., -2.9419e-01,  1.7664e-01,  3.4912e-01],
          [-1.2041e+00, -1.3245e-01, -8.5840e-01,  ..., -1.3721e-01,  5.6201e-01,  1.4990e-01]],

         [[-1.1953e+00, -1.4883e+00, -2.6465e+00,  ..., -1.4258e-01, -2.1797e+00, -1.4775e+00],
          [ 1.4990e-01,  8.3301e-01,  4.4037e-02,  ..., -1.5635e+00,  3.1555e-02,  1.7731e-02],
          [-7.8516e-01,  3.9160e-01,  1.3096e+00,  ..., -3.2080e-01,  1.3564e+00,  9.7217e-01],
          ...,
          [-1.0137e+00, -1.6321e-01, -1.7749e-01,  ..., -4.2871e-01, -5.5029e-01,  5.7526e-02],
          [-5.4443e-01, -3.8013e-01, -1.0957e+00,  ...,  1.8916e+00,  5.0781e-01,  1.3232e-01],
          [-2.3657e-01, -3.3887e-01,  1.8604e-01,  ..., -1.7432e+00, -4.6631e-01, -1.0376e-01]],

         [[-6.6602e-01, -7.1655e-02, -8.9600e-01,  ...,  6.4160e-01,  5.3223e-01,  6.1279e-01],
          [ 7.7539e-01, -9.6008e-02,  1.9946e-01,  ..., -1.8188e-01,  4.2212e-01, -7.8857e-02],
          [-1.5527e-01, -4.2896e-01,  1.1664e-01,  ...,  3.8574e-01, -9.5459e-02, -1.1299e+00],
          ...,
          [-3.2616e-03, -1.3369e+00, -1.9543e-01,  ..., -1.3066e+00,  6.7676e-01, -2.7679e-02],
          [ 5.7324e-01, -1.1396e+00,  6.0974e-02,  ..., -1.0859e+00, -2.8809e-01, -1.3750e+00],
          [-8.6304e-02, -6.6406e-01, -1.5906e-01,  ..., -7.5635e-01, -9.2529e-02,  6.4160e-01]],

         ...,

         [[-1.1328e+00,  1.3196e-01, -1.3293e-01,  ..., -4.3701e-01, -1.6870e-01,  1.4141e+00],
          [ 4.9414e-01,  2.2778e-01,  6.0010e-01,  ..., -4.5044e-01,  2.0703e-01,  2.9373e-02],
          [ 2.5513e-01,  1.1299e+00,  2.2715e+00,  ...,  6.3171e-02,  1.5198e-01,  1.1646e-01],
          ...,
          [ 1.9082e+00,  2.2827e-02,  1.0029e+00,  ..., -2.5464e-01,  5.9296e-02,  5.2979e-01],
          [ 1.5176e+00,  5.6934e-01,  1.2158e-01,  ...,  1.4463e+00, -7.3682e-01, -2.0905e-03],
          [ 1.4971e+00,  4.9561e-02, -2.0137e+00,  ..., -5.3369e-01, -8.3057e-01, -9.2041e-01]],

         [[-1.1895e+00, -2.8149e-01, -6.2622e-02,  ..., -6.7627e-02, -1.4038e-01, -3.3643e-01],
          [-1.2432e+00, -3.0651e-03,  6.5430e-01,  ..., -3.0371e-01,  8.0518e-01, -6.4795e-01],
          [ 6.6147e-03,  1.7456e-01, -4.5215e-01,  ...,  8.3643e-01,  7.2021e-01, -5.6580e-02],
          ...,
          [-9.4055e-02, -2.1992e+00,  2.4182e-01,  ..., -2.9297e-01, -1.6602e-01,  1.2822e+00],
          [-1.3831e-01, -5.9570e-01,  1.1670e+00,  ..., -8.9502e-01, -7.2363e-01, -9.7754e-01],
          [ 9.1211e-01,  4.9957e-02,  1.1172e+00,  ..., -6.6699e-01, -1.0801e+00, -3.6792e-01]],

         [[-3.9185e-01, -1.0322e+00, -1.0137e+00,  ..., -6.8848e-02,  1.1621e+00,  2.8418e-01],
          [-7.7783e-01, -2.1985e-01, -4.7656e-01,  ...,  2.1582e-01,  3.0273e-01, -6.7139e-01],
          [ 9.2651e-02, -4.0186e-01,  1.0498e+00,  ..., -4.7168e-01,  9.0088e-01, -1.4629e+00],
          ...,
          [-3.8892e-01,  8.3447e-01,  8.2959e-01,  ...,  2.2485e-01,  9.8145e-01, -5.2734e-01],
          [-5.0537e-01, -2.5342e-01,  6.1475e-01,  ..., -1.9836e-01, -8.3789e-01, -7.9736e-01],
          [ 8.3008e-01, -4.2676e-01,  3.0811e-01,  ..., -9.5703e-01, -1.0039e+00, -3.3545e-01]]],


        [[[ 1.0645e+00,  4.5312e-01, -6.0596e-01,  ...,  1.4392e-01, -1.7395e-01,  1.1348e+00],
          [ 1.1084e+00,  1.7834e-01,  1.3123e-01,  ...,  5.9277e-01,  1.0947e+00,  5.9473e-01],
          [ 2.2949e-01,  3.4351e-01,  1.5723e+00,  ..., -9.8242e-01,  2.7905e-01, -7.5391e-01],
          ...,
          [-5.3772e-02,  1.5820e-01,  4.1675e-01,  ...,  1.3477e+00, -3.8989e-01, -1.3809e+00],
          [-7.4170e-01, -7.1924e-01, -9.6289e-01,  ..., -3.0762e-01,  2.6587e-01, -2.7051e-01],
          [-1.9014e+00,  2.8955e-01,  1.2073e-01,  ...,  1.3613e+00,  5.5566e-01,  9.3994e-01]],

         [[-2.9004e-01,  1.2886e-02, -2.6416e-01,  ..., -2.3950e-01, -7.9834e-01, -1.6577e-01],
          [ 1.8223e+00,  1.1250e+00,  5.7520e-01,  ...,  1.3184e-01, -1.2197e+00, -6.5088e-01],
          [ 1.5459e+00,  1.0674e+00,  2.6245e-01,  ..., -5.6104e-01, -1.0332e+00,  7.5342e-01],
          ...,
          [ 9.7754e-01,  3.1982e-01,  6.3672e-01,  ..., -2.8857e-01, -8.2129e-01,  5.9863e-01],
          [-3.2568e-01, -1.1367e+00, -1.2080e+00,  ..., -1.2480e+00, -7.3193e-01,  1.2695e-01],
          [-1.1504e+00, -1.0278e-01,  7.1094e-01,  ..., -1.1230e+00, -1.7070e+00, -4.3115e-01]],

         [[-5.6104e-01, -5.0830e-01, -5.2002e-01,  ..., -9.7412e-01, -5.2490e-01,  3.8916e-01],
          [ 5.3857e-01, -1.7949e+00,  6.8018e-01,  ..., -1.3174e+00, -6.6162e-01, -1.0332e+00],
          [-1.0498e+00, -7.4121e-01,  1.8018e-01,  ..., -4.4653e-01,  7.0984e-02, -3.2690e-01],
          ...,
          [-1.4148e-01,  1.4870e-02,  1.2412e+00,  ...,  3.8135e-01,  1.5222e-01, -7.9053e-01],
          [-5.7373e-01,  3.5706e-02,  6.9971e-01,  ...,  8.8037e-01,  1.7422e+00, -3.1421e-01],
          [ 1.7383e-01, -2.8149e-01, -7.2070e-01,  ..., -1.1826e+00,  3.3862e-01,  8.3838e-01]],

         ...,

         [[ 1.8811e-01,  5.6104e-01, -7.4707e-02,  ...,  4.5630e-01,  8.5107e-01,  1.5100e-01],
          [ 3.8818e-01,  5.4248e-01,  8.2129e-01,  ...,  2.4438e-01,  4.4702e-01, -5.6396e-01],
          [-2.3169e-01,  4.6204e-02,  3.8605e-02,  ...,  6.7871e-01,  1.1699e+00,  6.5498e-03],
          ...,
          [-7.0166e-01,  1.4209e-01, -4.4434e-01,  ..., -5.6543e-01,  1.0391e+00,  1.5430e+00],
          [ 2.0776e-01, -8.3887e-01, -4.1968e-01,  ...,  3.8971e-02,  1.2021e+00,  1.3369e+00],
          [ 9.4678e-01,  4.5923e-01, -2.5684e-01,  ..., -8.4668e-01,  4.2407e-01,  7.0117e-01]],

         [[ 4.4702e-01, -5.4590e-01,  1.5771e+00,  ..., -2.9248e-01, -5.9235e-02, -2.2637e+00],
          [-1.8970e-01, -3.4912e-01, -6.9885e-02,  ...,  7.7759e-02, -1.7617e+00, -4.6582e-01],
          [-6.6748e-01, -4.6118e-01, -8.6426e-01,  ...,  8.9453e-01, -1.6711e-01, -7.3047e-01],
          ...,
          [ 1.4844e+00,  8.6279e-01,  1.2256e-01,  ..., -4.0503e-01, -1.1650e+00,  8.9417e-02],
          [ 1.5244e+00,  2.6147e-01,  9.1748e-01,  ..., -6.0547e-01, -6.4355e-01,  4.6631e-01],
          [-1.2129e+00, -6.5576e-01,  5.0732e-01,  ..., -5.5371e-01,  5.6946e-02,  2.9077e-01]],

         [[-2.9834e-01, -4.2310e-01,  8.8440e-02,  ..., -4.1504e-01, -1.4307e+00,  4.6069e-01],
          [-6.7920e-01, -6.4746e-01,  9.7803e-01,  ..., -9.8877e-01, -1.6504e+00, -1.9910e-01],
          [-4.0283e-01, -1.1975e-01,  4.8193e-01,  ...,  1.1621e+00,  1.2061e+00,  8.4082e-01],
          ...,
          [-5.1367e-01, -3.2642e-01,  2.4475e-01,  ...,  2.5317e-01,  8.8318e-02,  5.8447e-01],
          [-1.0420e+00,  6.7383e-01,  1.0625e+00,  ...,  8.8086e-01,  3.1079e-01,  2.0032e-01],
          [-1.5173e-01,  9.6664e-03, -5.7922e-02,  ...,  9.4922e-01,  6.1914e-01,  1.3428e+00]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 19, 128, 256]), dtype=torch.float16)
tensor([[[[-2.0630e-01,  5.6580e-02,  2.4941e+00,  ...,  2.0361e-01,  3.9844e-01,  1.4180e+00],
          [ 3.7329e-01,  3.5791e-01, -2.0813e-01,  ...,  4.3042e-01, -1.2578e+00,  3.9917e-01],
          [ 5.7959e-01,  9.2969e-01, -1.4258e-01,  ..., -1.4172e-01, -3.2642e-01, -7.4414e-01],
          ...,
          [-9.9548e-02, -4.9365e-01,  6.8506e-01,  ..., -7.1436e-01, -2.8711e-01, -1.2715e+00],
          [ 6.3037e-01, -5.7080e-01, -3.1934e-01,  ...,  9.0869e-01, -1.1631e+00, -8.0469e-01],
          [-8.0469e-01, -1.0674e+00,  7.0679e-02,  ...,  5.4590e-01, -1.9324e-01,  5.9619e-01]],

         [[ 5.3497e-02,  3.1250e-01,  4.2334e-01,  ...,  8.9941e-01, -5.5420e-01, -8.4570e-01],
          [ 2.2583e-02,  7.2656e-01,  1.2822e+00,  ..., -5.1025e-02,  2.8320e-01, -6.5918e-01],
          [ 6.9971e-01,  2.6660e-01, -1.3354e-01,  ..., -1.6113e-02,  3.0420e-01, -4.7314e-01],
          ...,
          [-6.2354e-01, -6.5088e-01,  4.4482e-01,  ..., -6.3916e-01,  1.0117e+00,  1.7393e+00],
          [-1.1201e+00, -7.8564e-01, -3.6133e-01,  ..., -7.7832e-01, -6.8848e-01,  1.5129e-02],
          [-1.0273e+00, -3.2324e-01, -2.6416e-01,  ...,  6.7725e-01,  1.4756e+00,  1.6074e+00]],

         [[ 9.1406e-01,  8.3057e-01, -1.0234e+00,  ...,  5.6641e-01, -1.1621e+00, -6.6650e-01],
          [-4.0381e-01,  1.5906e-01,  1.0469e+00,  ..., -6.8701e-01, -1.3125e+00, -3.7549e-01],
          [-2.2888e-01, -1.0864e-01,  1.3057e+00,  ...,  1.7798e-01,  2.0264e-01,  3.1348e-01],
          ...,
          [ 2.2559e+00, -4.6948e-01,  6.2549e-01,  ..., -2.5659e-01,  5.8740e-01, -5.7275e-01],
          [ 2.6221e-01, -1.2197e+00, -3.4790e-02,  ...,  8.4656e-02, -9.3945e-01,  4.5728e-01],
          [-1.1875e+00, -1.7920e-01, -2.9785e-01,  ..., -1.0381e+00, -9.4116e-02, -8.5266e-02]],

         ...,

         [[ 3.0823e-03, -1.0098e+00, -3.0396e-02,  ..., -1.2656e+00,  3.2129e-01, -1.0322e+00],
          [ 1.1436e+00, -4.1089e-01, -4.7827e-01,  ...,  1.0947e+00,  6.7578e-01,  1.0492e-01],
          [-1.0815e-01, -1.2871e+00, -5.5713e-01,  ...,  1.0674e+00,  1.6699e-01, -6.9092e-01],
          ...,
          [-1.8232e+00, -1.7700e-01,  1.2129e+00,  ..., -2.2083e-01,  1.3066e+00,  1.0000e+00],
          [-1.4980e+00, -1.9501e-02, -3.5010e-01,  ...,  4.1162e-01,  1.0664e+00, -3.2764e-01],
          [-2.4731e-01, -1.8872e-01,  9.4336e-01,  ..., -3.1372e-01,  1.1631e+00,  1.7051e+00]],

         [[ 2.2766e-01, -2.3584e-01, -4.9268e-01,  ...,  6.1401e-02,  1.1011e-01,  1.1689e+00],
          [ 6.4893e-01,  1.4482e+00,  1.8176e-01,  ...,  9.1113e-01,  4.6631e-01,  4.7705e-01],
          [-1.4102e+00,  6.9238e-01, -8.1104e-01,  ...,  2.0410e+00,  4.0820e-01,  2.9175e-01],
          ...,
          [ 7.5317e-02,  3.7964e-01, -7.3975e-01,  ...,  1.0010e+00, -8.1177e-02, -3.2935e-01],
          [-1.3611e-01,  1.6172e+00, -5.3516e-01,  ...,  7.7490e-01,  9.5801e-01,  2.9639e-01],
          [ 5.8545e-01,  1.5508e+00,  2.7832e-01,  ..., -1.6138e-01, -2.1130e-01,  1.3906e+00]],

         [[ 5.1904e-01,  1.5762e+00,  2.9199e-01,  ..., -7.0752e-01, -1.0459e+00,  1.8994e-01],
          [ 2.4780e-01, -6.0596e-01,  1.1973e+00,  ...,  1.4062e-01,  7.1167e-02,  1.3867e+00],
          [ 1.5527e-01, -1.3428e-01,  3.7280e-01,  ...,  1.4141e+00,  2.5879e-01,  1.7549e+00],
          ...,
          [ 1.7664e-01, -4.6411e-01, -4.0356e-01,  ..., -8.5986e-01, -8.7988e-01,  4.1528e-01],
          [-1.3740e+00, -1.7041e+00,  9.1553e-03,  ..., -8.2129e-01,  5.2979e-02,  1.8066e-01],
          [ 7.1582e-01,  4.2871e-01, -9.3750e-02,  ...,  1.2329e-01,  1.3135e-01,  2.3120e-01]]],


        [[[ 1.6650e-01,  8.9990e-01,  9.5068e-01,  ...,  4.6118e-01, -7.2266e-02, -1.3848e+00],
          [-8.4656e-02, -9.6387e-01, -1.3159e-01,  ..., -2.5195e-01,  1.1143e+00, -1.4136e-01],
          [-1.3367e-01, -5.0488e-01, -5.3320e-01,  ...,  5.2295e-01,  7.7454e-02,  8.2275e-01],
          ...,
          [-5.1666e-02,  7.7454e-02, -9.4678e-01,  ..., -5.2979e-01,  2.5098e-01,  3.4521e-01],
          [ 6.6309e-01,  2.1558e-01, -2.0349e-01,  ...,  6.7627e-02, -5.6592e-01,  1.3545e+00],
          [-2.6001e-01,  4.5508e-01,  5.4297e-01,  ..., -1.5710e-01, -2.0142e-01, -3.4448e-01]],

         [[-1.1611e+00, -7.8027e-01, -8.1738e-01,  ..., -4.5752e-01, -4.2529e-01,  1.5527e+00],
          [ 3.1128e-01,  9.2773e-01, -5.1660e-01,  ..., -2.4451e-01,  8.3496e-01,  7.9346e-04],
          [-9.9561e-01, -1.0801e+00, -1.0771e+00,  ...,  3.4363e-02, -8.9600e-02, -8.9648e-01],
          ...,
          [-1.6174e-01, -1.3086e+00,  1.7139e-01,  ...,  1.1993e-01,  8.1421e-02,  1.1011e-01],
          [-6.9141e-01,  1.1682e-01,  2.9980e-01,  ...,  7.0703e-01,  3.9551e-01, -1.7920e-01],
          [ 1.1348e+00,  5.8545e-01,  2.8467e-01,  ..., -2.8418e-01, -3.5425e-01, -5.4980e-01]],

         [[-5.0391e-01,  8.9160e-01, -2.9785e-01,  ..., -8.8574e-01, -9.9548e-02,  7.8271e-01],
          [-2.4292e-01, -1.4541e+00, -8.4961e-01,  ...,  5.8691e-01,  1.2939e+00, -1.7944e-01],
          [ 7.3047e-01, -6.1572e-01, -6.4600e-01,  ..., -4.5605e-01, -2.2168e-01,  4.8169e-01],
          ...,
          [-7.4023e-01, -6.7871e-01,  3.2349e-01,  ...,  3.7354e-01, -3.5303e-01,  1.9397e-01],
          [-8.9893e-01,  1.1680e+00,  1.0537e+00,  ..., -2.0742e+00, -1.0010e+00,  1.1279e+00],
          [-8.3643e-01, -1.1260e+00, -4.0991e-01,  ..., -1.9961e+00, -1.7529e-01, -1.2610e-01]],

         ...,

         [[-2.3303e-01, -6.5613e-02,  6.4453e-01,  ..., -1.2146e-02, -7.3535e-01,  2.8198e-01],
          [-1.2305e+00, -3.4106e-01,  3.3252e-01,  ...,  1.5405e-01, -4.6777e-01, -1.6699e+00],
          [-9.3066e-01, -1.8628e-01,  2.6416e-01,  ..., -1.0518e+00, -5.4883e-01, -9.7021e-01],
          ...,
          [-2.8540e-01,  6.1768e-01, -1.5967e-01,  ...,  4.9268e-01, -4.6411e-01, -2.3418e+00],
          [ 1.9678e+00, -2.9590e-01,  2.9053e-01,  ...,  3.1836e-01, -8.5498e-01, -1.2871e+00],
          [ 1.0615e+00, -1.5098e+00,  7.8125e-01,  ..., -1.2646e+00, -5.0928e-01, -5.1318e-01]],

         [[-3.4863e-01,  8.8086e-01,  2.0166e-01,  ..., -2.1790e-01,  3.2446e-01, -8.3801e-02],
          [-1.6797e-01,  5.3955e-01,  1.4990e+00,  ...,  8.8281e-01,  8.9160e-01,  9.9121e-01],
          [ 4.3750e-01,  7.6221e-01,  6.7480e-01,  ...,  2.1265e-01,  3.7500e-01, -8.0762e-01],
          ...,
          [-8.8135e-02,  3.9722e-01, -6.5918e-03,  ..., -9.2346e-02, -7.0752e-01, -1.3740e+00],
          [ 4.5142e-01, -2.7148e-01, -7.7393e-01,  ...,  3.3105e-01,  2.4365e-01, -3.2471e-01],
          [-6.7920e-01, -5.9668e-01, -1.1367e+00,  ..., -3.8965e-01, -4.3555e-01,  4.5532e-01]],

         [[-7.4707e-01,  9.5508e-01,  2.1484e-01,  ..., -1.6543e+00, -6.6504e-01,  1.3906e+00],
          [-1.0859e+00,  2.6306e-02,  5.9717e-01,  ..., -5.2344e-01,  1.2433e-01,  2.2327e-01],
          [ 2.5269e-01,  5.3589e-02,  8.2764e-01,  ...,  9.5605e-01, -3.9624e-01,  7.1228e-02],
          ...,
          [ 1.3564e+00,  3.5913e-01, -6.7090e-01,  ..., -7.5317e-02,  4.7925e-01, -8.4033e-01],
          [ 8.7939e-01,  8.8477e-01,  2.3853e-01,  ...,  8.4766e-01,  1.1914e+00, -5.2051e-01],
          [-9.2468e-02,  5.9570e-01, -1.1270e+00,  ...,  2.0398e-01, -4.0234e-01,  2.2205e-01]]],


        [[[-6.1584e-02, -1.3965e+00, -1.4746e-01,  ..., -8.4814e-01,  8.3862e-02,  7.6660e-01],
          [-1.0297e-01, -1.4636e-01,  1.1053e-01,  ..., -8.1299e-01,  7.7393e-01,  8.5986e-01],
          [-6.6992e-01, -5.1514e-01,  5.4932e-04,  ..., -1.9458e-01, -4.3384e-01, -8.0713e-01],
          ...,
          [-8.2422e-01,  1.2666e+00, -3.1494e-02,  ...,  3.1470e-01, -1.0236e-01, -5.2295e-01],
          [-6.7920e-01,  2.4255e-01, -9.1553e-01,  ..., -2.9663e-01,  1.7664e-01,  3.4985e-01],
          [-1.2139e+00, -1.3306e-01, -8.6914e-01,  ..., -1.4050e-01,  5.6543e-01,  1.5210e-01]],

         [[-1.2070e+00, -1.5107e+00, -2.6738e+00,  ..., -1.4050e-01, -2.2031e+00, -1.4932e+00],
          [ 1.4917e-01,  8.4180e-01,  3.4912e-02,  ..., -1.5781e+00,  2.8290e-02,  1.6846e-02],
          [-7.8906e-01,  3.9771e-01,  1.3301e+00,  ..., -3.2520e-01,  1.3662e+00,  9.7852e-01],
          ...,
          [-1.0225e+00, -1.6309e-01, -1.7676e-01,  ..., -4.3945e-01, -5.5713e-01,  5.7983e-02],
          [-5.4736e-01, -3.8574e-01, -1.1113e+00,  ...,  1.9131e+00,  5.1465e-01,  1.3342e-01],
          [-2.4084e-01, -3.4131e-01,  1.8579e-01,  ..., -1.7461e+00, -4.7046e-01, -1.0510e-01]],

         [[-6.7139e-01, -7.2876e-02, -9.0625e-01,  ...,  6.5234e-01,  5.3418e-01,  6.2012e-01],
          [ 7.8076e-01, -9.5825e-02,  2.0166e-01,  ..., -1.8555e-01,  4.2529e-01, -7.8613e-02],
          [-1.5662e-01, -4.3848e-01,  1.1639e-01,  ...,  3.9087e-01, -9.4727e-02, -1.1445e+00],
          ...,
          [-4.7607e-03, -1.3545e+00, -2.0117e-01,  ..., -1.3242e+00,  6.8701e-01, -2.1912e-02],
          [ 5.7812e-01, -1.1523e+00,  6.1401e-02,  ..., -1.0996e+00, -2.9541e-01, -1.3965e+00],
          [-8.8257e-02, -6.7627e-01, -1.6016e-01,  ..., -7.6465e-01, -8.7952e-02,  6.4404e-01]],

         ...,

         [[-1.1445e+00,  1.2830e-01, -1.3196e-01,  ..., -4.4067e-01, -1.7078e-01,  1.4248e+00],
          [ 4.9927e-01,  2.3059e-01,  6.0156e-01,  ..., -4.5605e-01,  2.0691e-01,  2.8259e-02],
          [ 2.5586e-01,  1.1445e+00,  2.2930e+00,  ...,  6.2866e-02,  1.5540e-01,  1.2061e-01],
          ...,
          [ 1.9170e+00,  2.3438e-02,  1.0137e+00,  ..., -2.6221e-01,  6.0547e-02,  5.3271e-01],
          [ 1.5352e+00,  5.7227e-01,  1.2695e-01,  ...,  1.4639e+00, -7.4268e-01,  2.5330e-03],
          [ 1.5068e+00,  5.1361e-02, -2.0312e+00,  ..., -5.4004e-01, -8.3447e-01, -9.2627e-01]],

         [[-1.1963e+00, -2.8491e-01, -7.1045e-02,  ..., -6.6101e-02, -1.4209e-01, -3.4131e-01],
          [-1.2588e+00, -3.7842e-03,  6.6846e-01,  ..., -3.0737e-01,  8.1299e-01, -6.5088e-01],
          [ 6.8054e-03,  1.7456e-01, -4.5605e-01,  ...,  8.4180e-01,  7.2412e-01, -5.9235e-02],
          ...,
          [-9.4238e-02, -2.2324e+00,  2.4414e-01,  ..., -2.9736e-01, -1.6724e-01,  1.3018e+00],
          [-1.3806e-01, -6.0645e-01,  1.1797e+00,  ..., -9.0137e-01, -7.3242e-01, -9.8633e-01],
          [ 9.1699e-01,  4.8950e-02,  1.1260e+00,  ..., -6.8164e-01, -1.0879e+00, -3.6890e-01]],

         [[-3.9453e-01, -1.0449e+00, -1.0225e+00,  ..., -7.0557e-02,  1.1777e+00,  2.9004e-01],
          [-7.8467e-01, -2.2302e-01, -4.8584e-01,  ...,  2.1997e-01,  3.0640e-01, -6.7969e-01],
          [ 8.9966e-02, -4.0723e-01,  1.0586e+00,  ..., -4.7510e-01,  9.0918e-01, -1.4756e+00],
          ...,
          [-3.9282e-01,  8.4326e-01,  8.3838e-01,  ...,  2.2583e-01,  9.9512e-01, -5.2783e-01],
          [-5.1172e-01, -2.5488e-01,  6.1768e-01,  ..., -2.0068e-01, -8.4326e-01, -8.0762e-01],
          [ 8.3545e-01, -4.2432e-01,  3.1201e-01,  ..., -9.6045e-01, -1.0186e+00, -3.4180e-01]]],


        [[[ 1.0742e+00,  4.5776e-01, -6.1084e-01,  ...,  1.4209e-01, -1.7651e-01,  1.1465e+00],
          [ 1.1133e+00,  1.7932e-01,  1.2988e-01,  ...,  6.0010e-01,  1.1064e+00,  6.0400e-01],
          [ 2.3523e-01,  3.4814e-01,  1.5830e+00,  ..., -9.8975e-01,  2.8491e-01, -7.5537e-01],
          ...,
          [-5.3955e-02,  1.5747e-01,  4.2090e-01,  ...,  1.3672e+00, -3.9185e-01, -1.3975e+00],
          [-7.4609e-01, -7.2510e-01, -9.7021e-01,  ..., -3.1201e-01,  2.7100e-01, -2.7441e-01],
          [-1.9150e+00,  2.8784e-01,  1.2054e-01,  ...,  1.3701e+00,  5.5615e-01,  9.4434e-01]],

         [[-2.9248e-01,  9.5215e-03, -2.6807e-01,  ..., -2.4414e-01, -8.0518e-01, -1.6455e-01],
          [ 1.8320e+00,  1.1357e+00,  5.8398e-01,  ...,  1.3757e-01, -1.2314e+00, -6.6260e-01],
          [ 1.5586e+00,  1.0811e+00,  2.6685e-01,  ..., -5.6738e-01, -1.0459e+00,  7.6123e-01],
          ...,
          [ 9.8047e-01,  3.2104e-01,  6.4844e-01,  ..., -2.8418e-01, -8.3057e-01,  6.0352e-01],
          [-3.2178e-01, -1.1484e+00, -1.2256e+00,  ..., -1.2637e+00, -7.3584e-01,  1.3147e-01],
          [-1.1572e+00, -1.0583e-01,  7.1680e-01,  ..., -1.1328e+00, -1.7246e+00, -4.4263e-01]],

         [[-5.6494e-01, -5.0488e-01, -5.2686e-01,  ..., -9.8242e-01, -5.3271e-01,  3.9380e-01],
          [ 5.4248e-01, -1.8135e+00,  6.8799e-01,  ..., -1.3320e+00, -6.6748e-01, -1.0439e+00],
          [-1.0547e+00, -7.4609e-01,  1.8115e-01,  ..., -4.5312e-01,  6.7993e-02, -3.3105e-01],
          ...,
          [-1.4233e-01,  1.7670e-02,  1.2568e+00,  ...,  3.8477e-01,  1.5137e-01, -8.0322e-01],
          [-5.7959e-01,  3.5828e-02,  7.0898e-01,  ...,  8.8916e-01,  1.7559e+00, -3.1689e-01],
          [ 1.7749e-01, -2.8516e-01, -7.2461e-01,  ..., -1.1895e+00,  3.4082e-01,  8.4326e-01]],

         ...,

         [[ 1.8921e-01,  5.6836e-01, -7.8613e-02,  ...,  4.6118e-01,  8.5840e-01,  1.5479e-01],
          [ 3.9111e-01,  5.4785e-01,  8.2715e-01,  ...,  2.4731e-01,  4.5093e-01, -5.7178e-01],
          [-2.3242e-01,  4.8645e-02,  3.9276e-02,  ...,  6.8945e-01,  1.1797e+00,  8.1482e-03],
          ...,
          [-7.0898e-01,  1.4526e-01, -4.5215e-01,  ..., -5.7178e-01,  1.0488e+00,  1.5635e+00],
          [ 2.0984e-01, -8.4766e-01, -4.2334e-01,  ...,  3.7964e-02,  1.2139e+00,  1.3516e+00],
          [ 9.5117e-01,  4.6216e-01, -2.6025e-01,  ..., -8.5156e-01,  4.3237e-01,  7.1826e-01]],

         [[ 4.4946e-01, -5.5664e-01,  1.5938e+00,  ..., -2.9297e-01, -5.6152e-02, -2.2910e+00],
          [-1.9165e-01, -3.5596e-01, -6.8481e-02,  ...,  8.0505e-02, -1.7773e+00, -4.7485e-01],
          [-6.6797e-01, -4.6240e-01, -8.7207e-01,  ...,  8.9795e-01, -1.7224e-01, -7.3242e-01],
          ...,
          [ 1.5010e+00,  8.7061e-01,  1.2451e-01,  ..., -4.0991e-01, -1.1807e+00,  8.7708e-02],
          [ 1.5410e+00,  2.6782e-01,  9.2432e-01,  ..., -6.1377e-01, -6.5039e-01,  4.6924e-01],
          [-1.2188e+00, -6.6016e-01,  5.1709e-01,  ..., -5.6396e-01,  5.5206e-02,  3.0200e-01]],

         [[-2.9883e-01, -4.2358e-01,  8.8562e-02,  ..., -4.1553e-01, -1.4424e+00,  4.6533e-01],
          [-6.8359e-01, -6.5430e-01,  9.8828e-01,  ..., -1.0049e+00, -1.6709e+00, -2.0349e-01],
          [-4.0723e-01, -1.2415e-01,  4.8486e-01,  ...,  1.1797e+00,  1.2178e+00,  8.5449e-01],
          ...,
          [-5.1709e-01, -3.3081e-01,  2.4487e-01,  ...,  2.6099e-01,  9.1187e-02,  5.8838e-01],
          [-1.0547e+00,  6.7725e-01,  1.0801e+00,  ...,  8.7988e-01,  3.1055e-01,  2.0544e-01],
          [-1.5088e-01,  1.7166e-02, -5.6885e-02,  ...,  9.6338e-01,  6.2793e-01,  1.3516e+00]]]], dtype=torch.float16)

2025-06-10 00:13:32.590950 GPU 5 156012 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 256, 256],"float16"), list[1024,1024,], mode="bilinear", align_corners=False, )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 19, 256, 256],"float16"), list[1024,1024,], mode="bilinear", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12944 / 4980736 (0.3%)
Greatest absolute difference: 0.05078125 at index (0, 17, 138, 104) (up to 0.01 allowed)
Greatest relative difference: 6.70703125 at index (2, 18, 132, 249) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 19, 256, 256]), dtype=torch.float16)
tensor([[[[-1.0754e-01,  2.5244e-01,  3.0685e-02,  ..., -1.0732e+00,  7.3242e-02, -1.0898e+00],
          [-5.2295e-01, -9.8755e-02, -8.3984e-01,  ...,  9.3262e-02,  8.5693e-01,  2.7734e-01],
          [-1.1292e-01, -6.7871e-01,  8.6475e-01,  ..., -5.0488e-01,  1.4961e+00, -4.2236e-02],
          ...,
          [ 8.6670e-02, -7.6025e-01,  5.7220e-02,  ..., -1.4197e-01, -3.7305e-01, -4.2651e-01],
          [-9.0967e-01, -1.0361e+00, -8.2520e-01,  ..., -1.3586e-01,  6.6455e-01,  5.0488e-01],
          [ 6.4648e-01, -1.0684e+00, -1.7002e+00,  ..., -1.5537e+00, -7.9980e-01, -4.8047e-01]],

         [[ 9.6826e-01, -5.2979e-01,  2.5171e-01,  ...,  2.3975e-01, -3.6743e-02, -1.0371e+00],
          [ 6.8164e-01,  1.7029e-01,  9.4971e-01,  ..., -1.4575e-01,  7.6855e-01, -5.5225e-01],
          [-9.1797e-01, -1.2589e-03,  7.8418e-01,  ...,  4.0210e-01,  3.8379e-01,  9.4482e-01],
          ...,
          [ 4.7729e-01,  6.1377e-01,  1.5955e-01,  ...,  2.0557e-01,  6.6406e-02, -1.4062e-01],
          [ 1.0553e-01, -6.0107e-01,  3.2324e-01,  ..., -1.0391e+00,  7.7979e-01,  8.0664e-01],
          [-3.2654e-02,  1.1660e+00,  1.6836e+00,  ..., -1.9541e+00,  8.2715e-01,  3.8501e-01]],

         [[-9.8828e-01, -9.4727e-02,  2.6929e-01,  ..., -6.8311e-01, -1.5259e-01, -8.9551e-01],
          [-5.6592e-01,  3.4760e-02,  1.2720e-01,  ...,  6.6748e-01, -1.1689e+00,  1.4492e+00],
          [-2.7808e-01, -7.7197e-01,  1.7896e-01,  ...,  4.2822e-01, -1.2354e+00,  5.8301e-01],
          ...,
          [-1.6577e-01,  2.3877e-01,  1.6919e-01,  ...,  1.1465e+00,  5.1367e-01,  1.9031e-01],
          [ 1.2266e+00,  1.2070e+00,  1.3076e+00,  ...,  1.0850e+00,  2.5708e-01,  6.3525e-01],
          [-1.8135e+00,  2.6392e-01,  1.1289e+00,  ..., -9.1602e-01, -9.7607e-01,  9.1553e-02]],

         ...,

         [[ 1.1924e+00,  4.3530e-01,  5.7764e-01,  ...,  1.6094e+00, -2.5952e-01,  3.3789e-01],
          [-3.1250e-01,  2.6904e-01,  6.0547e-01,  ...,  5.5371e-01, -2.8491e-01,  6.7334e-01],
          [ 1.6785e-01,  1.0049e+00,  4.9829e-01,  ...,  6.0986e-01,  3.7671e-01,  5.1660e-01],
          ...,
          [-1.0410e+00, -3.3838e-01,  1.6162e+00,  ...,  9.3701e-01, -9.9561e-01,  7.2510e-01],
          [-6.9092e-02,  5.1562e-01,  8.1494e-01,  ..., -1.4619e+00, -1.4648e+00,  5.8496e-01],
          [-7.7197e-01, -8.6426e-01,  1.0967e+00,  ...,  4.8169e-01, -7.3584e-01, -3.3374e-01]],

         [[-9.4141e-01, -4.7729e-01, -1.0752e+00,  ..., -4.1040e-01, -8.6279e-01,  5.1611e-01],
          [ 1.1094e+00, -2.0020e-01, -6.7627e-01,  ...,  1.0469e+00, -4.1040e-01,  4.5776e-01],
          [ 3.8745e-01, -4.0112e-01,  3.0933e-01,  ...,  4.6924e-01, -8.6475e-01, -5.1123e-01],
          ...,
          [-2.9358e-02,  8.4033e-01,  5.3986e-02,  ..., -3.2422e-01,  3.4814e-01, -7.3975e-01],
          [ 1.2451e+00, -2.6929e-01,  2.2168e-01,  ..., -9.5337e-02, -8.4180e-01,  2.9736e-01],
          [ 1.3760e+00, -9.6436e-01,  3.6792e-01,  ...,  1.2871e+00,  3.3081e-01, -6.3843e-02]],

         [[-1.8848e+00, -2.3254e-01, -1.7051e+00,  ..., -5.6445e-01,  6.0303e-01, -3.6450e-01],
          [ 1.2451e+00,  1.9268e+00, -1.8311e-01,  ..., -9.7168e-01, -1.7639e-01,  2.2485e-01],
          [ 1.6836e+00, -2.1301e-01,  2.3633e-01,  ...,  5.1849e-02,  5.2393e-01, -1.7881e+00],
          ...,
          [-1.7715e+00,  3.4009e-01, -1.4375e+00,  ..., -1.7539e+00, -6.9275e-02,  6.0059e-01],
          [-1.2656e+00, -5.5145e-02, -9.3164e-01,  ...,  2.2964e-02, -9.8877e-01, -4.9121e-01],
          [-4.7266e-01, -1.1367e+00, -1.1755e-01,  ..., -3.5645e-01, -4.3921e-01,  1.1426e+00]]],


        [[[ 6.1279e-01, -9.0869e-01, -1.5527e+00,  ..., -1.5625e+00,  3.9478e-01, -8.1348e-01],
          [-1.7749e-01, -1.2188e+00, -5.5273e-01,  ..., -1.0352e+00,  2.6025e-01,  8.9307e-01],
          [-8.4619e-01, -1.4443e+00, -4.0869e-01,  ..., -1.1641e+00,  4.1699e-01, -1.0742e+00],
          ...,
          [-1.7468e-01, -9.2920e-01,  1.1279e-01,  ...,  6.8457e-01,  2.0276e-01, -5.4639e-01],
          [-1.0205e+00, -1.2588e+00, -4.5990e-02,  ..., -1.0089e-01,  2.8687e-01, -4.2261e-01],
          [ 3.7207e-01, -1.7847e-01,  2.1887e-01,  ..., -7.9980e-01, -1.2148e+00, -1.1074e+00]],

         [[-2.9175e-01, -6.8701e-01, -6.0938e-01,  ..., -3.9282e-01, -1.1846e+00, -5.5762e-01],
          [-6.4502e-01, -1.4893e-01, -1.0928e+00,  ...,  9.9548e-02,  8.7646e-01,  1.2952e-01],
          [-7.5098e-01,  3.1763e-01, -7.5146e-01,  ..., -3.1525e-02,  1.0225e+00,  5.9235e-02],
          ...,
          [-1.1221e+00,  6.9385e-01,  3.2373e-01,  ...,  1.4668e+00, -1.8701e-01,  3.3374e-01],
          [ 5.5176e-01,  1.1074e+00,  5.6201e-01,  ...,  1.2878e-01, -1.6924e+00, -6.4307e-01],
          [ 5.6104e-01,  7.2363e-01,  7.0068e-02,  ..., -2.0664e+00, -2.4395e+00, -2.1069e-01]],

         [[-1.0205e+00, -9.2676e-01, -4.2090e-01,  ...,  6.6699e-01,  8.9905e-02, -4.7559e-01],
          [-3.6865e-01,  3.0396e-01,  1.5527e-01,  ..., -4.2285e-01, -1.2656e+00, -1.7285e+00],
          [-3.9429e-01, -1.3501e-01, -1.1523e-01,  ...,  9.9561e-01,  8.8184e-01,  1.9421e-01],
          ...,
          [-1.3271e+00, -2.7734e-01, -9.3408e-01,  ...,  5.9033e-01,  1.6504e-01,  7.4219e-01],
          [-1.0869e+00, -4.5947e-01, -8.2568e-01,  ..., -6.5674e-01, -5.1074e-01,  9.8730e-01],
          [ 3.7402e-01, -9.9023e-01,  1.0781e+00,  ..., -1.0137e+00, -8.1604e-02, -3.4814e-01]],

         ...,

         [[ 3.4521e-01, -4.0942e-01, -1.3311e+00,  ..., -3.6084e-01, -1.5127e+00,  1.6138e-01],
          [ 8.4000e-03, -6.8164e-01, -4.9854e-01,  ...,  2.2791e-01,  8.2666e-01, -7.4023e-01],
          [ 1.1240e+00,  1.4758e-01,  6.8848e-01,  ..., -7.1582e-01, -6.4844e-01, -1.2480e+00],
          ...,
          [-8.2031e-01,  1.7920e+00,  4.1016e-01,  ..., -2.7393e-01,  1.3994e+00,  3.5010e-01],
          [-1.0303e-01,  6.7773e-01, -5.6946e-02,  ...,  3.2812e-01,  1.4023e+00, -6.0986e-01],
          [-6.9092e-01,  7.6141e-03,  2.0752e-02,  ...,  6.8408e-01, -8.4326e-01, -1.6611e+00]],

         [[-3.7329e-01,  1.2598e-01,  6.8741e-03,  ..., -4.5020e-01, -3.0960e-02, -1.8188e-01],
          [ 1.3257e-01,  1.1445e+00,  1.0352e+00,  ..., -7.3145e-01,  4.6094e-01, -9.3604e-01],
          [ 2.7954e-01,  3.7085e-01,  8.5400e-01,  ..., -7.3779e-01,  7.8906e-01, -1.6541e-01],
          ...,
          [-1.4248e+00, -1.5898e+00, -1.2041e+00,  ..., -8.8916e-01, -4.9268e-01,  8.5156e-01],
          [-9.3311e-01,  9.7461e-01,  6.7090e-01,  ..., -5.5762e-01,  3.8940e-01,  8.5840e-01],
          [-9.6680e-01, -1.6523e+00,  4.8364e-01,  ...,  1.8516e+00,  1.6094e+00,  1.0918e+00]],

         [[ 5.2338e-02, -2.7637e-01, -2.0715e-01,  ..., -4.6936e-02, -9.5166e-01,  8.8135e-01],
          [ 6.2012e-01, -3.7061e-01, -2.6343e-01,  ...,  6.3660e-02, -3.2129e-01, -1.9409e-01],
          [-6.1670e-01, -7.1655e-02, -6.5137e-01,  ...,  1.1016e+00,  7.3730e-02,  2.8442e-01],
          ...,
          [-9.7949e-01, -1.0859e+00, -1.6370e-01,  ...,  2.5024e-01,  6.1279e-01,  5.2979e-01],
          [-1.9983e-01,  6.6748e-01,  1.4092e+00,  ...,  7.9834e-01, -7.4219e-01,  5.6641e-01],
          [ 6.3379e-01,  3.8135e-01,  3.6938e-01,  ...,  5.0293e-01, -3.6108e-01,  7.4609e-01]]],


        [[[-4.2310e-01, -1.2256e-01,  4.8859e-02,  ..., -1.4209e-01, -3.0713e-01,  1.1914e+00],
          [ 5.1855e-01,  5.8105e-01,  9.0527e-01,  ..., -1.0345e-01, -1.0566e+00,  5.2539e-01],
          [ 6.4453e-02,  5.7764e-01, -5.9375e-01,  ...,  8.3691e-01,  1.4541e+00,  3.3008e+00],
          ...,
          [-1.7930e+00, -1.3293e-01, -2.1899e-01,  ..., -3.8672e-01, -9.9335e-03, -1.2090e+00],
          [-9.6680e-01, -1.2842e+00, -9.7949e-01,  ..., -1.2817e-01, -2.0605e-01, -8.6523e-01],
          [ 1.0469e+00,  1.6143e+00, -2.6392e-01,  ...,  1.8518e-01,  1.0645e+00, -1.7314e+00]],

         [[-2.6953e-01,  9.0527e-01,  1.1152e+00,  ..., -3.0444e-01, -1.1143e+00, -2.3193e-01],
          [-1.1240e+00,  1.2725e+00,  1.4414e+00,  ..., -5.6396e-01,  1.5417e-01, -5.1953e-01],
          [ 2.4829e-01,  5.5371e-01, -2.1191e-01,  ...,  5.3027e-01,  2.5537e-01, -1.2031e+00],
          ...,
          [ 4.1943e-01,  1.0742e+00, -1.7786e-01,  ..., -1.2158e+00, -4.0308e-01, -1.9821e-02],
          [ 1.4863e+00,  2.2188e+00, -1.5503e-01,  ...,  1.0557e+00,  9.1504e-01,  1.1855e+00],
          [ 2.4590e+00,  1.9863e+00, -1.2617e+00,  ...,  9.6094e-01,  1.6982e+00,  1.1924e+00]],

         [[ 3.7744e-01, -3.1030e-01,  3.3783e-02,  ...,  3.6621e-01, -2.4258e+00, -1.1250e+00],
          [-7.5342e-01, -2.6221e-01, -3.5425e-01,  ...,  2.6538e-01, -1.4189e+00, -1.6250e+00],
          [-2.0581e-01, -3.9526e-01, -5.5322e-01,  ...,  1.8721e+00, -1.6248e-01, -8.4619e-01],
          ...,
          [-6.5576e-01, -6.9678e-01,  7.8906e-01,  ...,  6.6797e-01,  4.7852e-01, -5.4590e-01],
          [-5.1660e-01, -4.6417e-02, -3.1421e-01,  ...,  6.2061e-01,  5.0732e-01,  9.8572e-02],
          [ 7.8613e-01,  1.8672e+00, -1.3340e+00,  ...,  3.7915e-01, -1.4441e-01, -6.5857e-02]],

         ...,

         [[-1.8506e-01,  2.3865e-01,  1.2494e-01,  ..., -7.2021e-01, -7.5146e-01, -9.3750e-01],
          [ 1.7468e-01,  6.7627e-01, -4.7949e-01,  ..., -5.7520e-01,  3.3740e-01,  4.4678e-01],
          [ 1.2598e+00,  1.5615e+00,  9.2969e-01,  ..., -4.6240e-01,  1.8689e-01,  5.0391e-01],
          ...,
          [ 7.4561e-01,  4.1968e-01,  4.4409e-01,  ...,  4.7192e-01,  7.3364e-02, -4.3304e-02],
          [ 1.0645e+00, -4.7705e-01, -3.7744e-01,  ...,  6.2988e-01,  1.2539e+00, -1.0266e-01],
          [-3.7781e-02, -5.9357e-02, -2.8857e-01,  ..., -5.0391e-01,  6.6553e-01,  8.2422e-01]],

         [[-1.4619e+00, -9.9609e-01, -8.2080e-01,  ..., -6.2988e-01,  1.0345e-01, -5.1514e-01],
          [-7.4854e-01, -9.0918e-01,  3.5059e-01,  ...,  2.0776e-01,  1.0518e+00, -1.0059e+00],
          [-2.9248e-01,  7.8223e-01,  9.8193e-01,  ...,  1.1094e+00,  5.9912e-01, -1.6865e+00],
          ...,
          [ 3.4106e-01,  2.6611e-01,  1.3008e+00,  ..., -8.2178e-01, -4.0771e-01, -1.3931e-02],
          [-1.6760e-01,  2.9099e-02, -6.4355e-01,  ..., -1.5173e-01,  1.9556e-01,  6.1096e-02],
          [ 1.1191e+00,  5.6104e-01, -1.3008e+00,  ..., -4.6692e-02,  2.2803e-01,  5.3174e-01]],

         [[-1.1074e+00,  8.7842e-01,  8.8037e-01,  ...,  8.3301e-01, -1.3115e+00, -4.2871e-01],
          [ 5.9131e-01, -1.0479e+00,  1.7314e+00,  ..., -4.7729e-02, -9.3079e-02, -5.2783e-01],
          [ 6.4014e-01, -6.9434e-01,  1.4307e+00,  ...,  5.7129e-01, -8.9014e-01, -2.2778e-01],
          ...,
          [ 2.4628e-02,  6.3672e-01, -1.1338e+00,  ..., -6.0449e-01, -7.2900e-01, -6.0364e-02],
          [ 7.1729e-01,  1.9250e-01, -8.2959e-01,  ..., -6.8018e-01, -1.3047e+00, -1.0312e+00],
          [ 1.4121e+00, -9.3018e-01,  9.6863e-02,  ..., -8.8928e-02, -8.6475e-01,  8.3154e-01]]],


        [[[ 6.1432e-02, -7.9736e-01, -1.2683e-01,  ..., -2.4033e-02,  1.3457e+00, -3.8159e-01],
          [-4.1290e-02, -8.0078e-01, -3.5962e-01,  ...,  2.7295e-01, -5.3662e-01, -1.2783e+00],
          [ 8.1970e-02, -3.4943e-02, -3.0713e-01,  ...,  2.2449e-01, -4.4141e-01, -1.3641e-02],
          ...,
          [ 9.9756e-01,  6.6406e-01,  1.0098e+00,  ..., -4.3652e-01, -1.2246e+00, -1.0767e-01],
          [ 1.4619e+00,  2.5000e-01,  1.6212e-03,  ..., -2.8784e-01, -2.7573e-02, -1.5107e+00],
          [ 4.1473e-02,  7.6318e-01,  5.7422e-01,  ..., -6.2158e-01, -8.1787e-02,  2.4463e-01]],

         [[-2.4329e-01,  1.2852e+00, -8.7769e-02,  ..., -4.2725e-02, -5.6494e-01,  3.7622e-01],
          [ 2.0471e-01, -4.7021e-01, -6.3477e-01,  ..., -9.6130e-02, -3.4839e-01, -7.9004e-01],
          [-3.6621e-01, -4.1650e-01, -1.9336e-01,  ...,  9.5654e-01,  1.0371e+00,  6.5527e-01],
          ...,
          [ 1.1533e+00,  5.5542e-02,  5.7764e-01,  ...,  1.1133e+00, -6.6260e-01,  3.7695e-01],
          [ 4.5654e-01,  1.0840e+00,  4.3237e-01,  ..., -2.4805e+00, -2.7441e-01,  1.1250e+00],
          [ 3.5815e-01,  6.4697e-01,  1.6914e+00,  ..., -1.8770e+00,  9.8340e-01,  7.6660e-01]],

         [[-6.6467e-02,  3.4937e-01, -3.3276e-01,  ..., -1.2021e+00, -8.0615e-01, -1.2334e+00],
          [-2.3706e-01, -3.5303e-01,  2.8244e-02,  ...,  2.1863e-01, -9.3567e-02, -3.1226e-01],
          [-8.2703e-03, -9.9707e-01, -8.6182e-02,  ...,  4.4092e-01,  1.8591e-01,  1.0388e-01],
          ...,
          [-8.2910e-01,  5.1660e-01,  3.1201e-01,  ...,  5.1074e-01,  9.9365e-01, -2.1252e-01],
          [-5.9668e-01, -1.3318e-01,  2.9565e-01,  ...,  8.6133e-01,  3.5132e-01, -2.2400e-02],
          [-5.4541e-01,  9.4055e-02,  6.3574e-01,  ...,  1.1143e+00,  2.4915e-01,  1.5420e+00]],

         ...,

         [[-3.5736e-02, -7.0215e-01,  6.3281e-01,  ..., -5.1270e-01,  1.9983e-01, -1.4099e-01],
          [ 8.2568e-01, -8.2764e-01, -9.0381e-01,  ...,  1.0195e+00, -1.3818e-01,  5.1514e-01],
          [ 1.0492e-01, -1.3057e+00, -7.7051e-01,  ...,  2.3352e-01, -5.3613e-01, -7.8906e-01],
          ...,
          [ 8.4570e-01,  2.7881e-01,  1.3711e+00,  ...,  1.8347e-01,  1.0439e+00, -9.1260e-01],
          [ 4.9805e-02, -1.6772e-01, -1.5198e-01,  ...,  1.3955e+00,  1.0706e-01,  1.1318e+00],
          [-1.0713e+00, -1.9006e-01, -1.6826e+00,  ...,  6.6455e-01,  5.1758e-01,  1.3643e+00]],

         [[-9.9548e-02, -1.4014e+00, -4.5190e-01,  ...,  1.9561e+00,  2.1826e-01,  2.6318e-01],
          [ 1.1627e-01, -3.5522e-01, -7.3730e-01,  ...,  4.4128e-02,  9.5459e-01,  8.0615e-01],
          [ 1.2871e+00,  7.6904e-01, -9.4629e-01,  ...,  1.7932e-01,  4.1455e-01,  1.0293e+00],
          ...,
          [-5.7526e-02,  1.4624e-01,  9.0479e-01,  ...,  7.5635e-01, -2.8613e-01, -1.8594e+00],
          [-9.8730e-01,  1.3940e-01,  9.6436e-01,  ...,  1.2012e+00,  7.6562e-01, -6.8164e-01],
          [ 5.6671e-02, -9.0234e-01,  9.1064e-01,  ...,  8.7549e-01,  4.3970e-01, -2.2485e-01]],

         [[-7.7881e-02, -2.9858e-01, -1.0410e+00,  ..., -9.7559e-01,  6.9775e-01, -1.3486e+00],
          [-1.0908e+00, -1.1738e+00, -3.7695e-01,  ...,  2.4826e-02, -1.0791e+00, -3.1860e-01],
          [ 1.6711e-01, -1.3418e+00, -1.6191e+00,  ...,  1.7422e+00,  4.5483e-01, -1.2793e+00],
          ...,
          [-1.3213e+00, -1.6846e+00, -8.9502e-01,  ..., -9.4452e-03,  1.5759e-01, -1.1855e+00],
          [ 5.0537e-01, -3.5352e-01, -9.3799e-01,  ..., -2.7954e-01,  1.8506e-01,  6.1328e-01],
          [-1.9775e+00, -1.3457e+00, -1.0400e+00,  ..., -1.6113e-01, -1.0225e+00,  3.0542e-01]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 19, 256, 256]), dtype=torch.float16)
tensor([[[[-1.0992e-01,  2.5269e-01,  3.0518e-02,  ..., -1.0840e+00,  7.1533e-02, -1.1074e+00],
          [-5.2783e-01, -9.3262e-02, -8.4863e-01,  ...,  9.1064e-02,  8.6328e-01,  2.8101e-01],
          [-1.1743e-01, -6.8555e-01,  8.7305e-01,  ..., -5.0732e-01,  1.5117e+00, -4.4830e-02],
          ...,
          [ 8.8989e-02, -7.6855e-01,  5.7617e-02,  ..., -1.4404e-01, -3.7842e-01, -4.3384e-01],
          [-9.1895e-01, -1.0488e+00, -8.3057e-01,  ..., -1.3794e-01,  6.7236e-01,  5.1172e-01],
          [ 6.5576e-01, -1.0693e+00, -1.7148e+00,  ..., -1.5625e+00, -8.0371e-01, -4.8267e-01]],

         [[ 9.7656e-01, -5.3418e-01,  2.5293e-01,  ...,  2.4060e-01, -4.0649e-02, -1.0469e+00],
          [ 6.8750e-01,  1.7322e-01,  9.5996e-01,  ..., -1.4697e-01,  7.7881e-01, -5.6104e-01],
          [-9.2627e-01, -2.4567e-03,  7.9004e-01,  ...,  4.0674e-01,  3.8843e-01,  9.5605e-01],
          ...,
          [ 4.7949e-01,  6.2158e-01,  1.6321e-01,  ...,  2.0825e-01,  6.5063e-02, -1.4233e-01],
          [ 1.0852e-01, -6.0986e-01,  3.2935e-01,  ..., -1.0449e+00,  7.8760e-01,  8.1104e-01],
          [-3.2898e-02,  1.1738e+00,  1.6904e+00,  ..., -1.9883e+00,  8.3643e-01,  3.8892e-01]],

         [[-9.9707e-01, -9.3384e-02,  2.7588e-01,  ..., -6.9287e-01, -1.5210e-01, -9.0674e-01],
          [-5.7129e-01,  3.6987e-02,  1.2659e-01,  ...,  6.7432e-01, -1.1807e+00,  1.4668e+00],
          [-2.8052e-01, -7.8125e-01,  1.8188e-01,  ...,  4.3311e-01, -1.2461e+00,  5.8887e-01],
          ...,
          [-1.7139e-01,  2.4207e-01,  1.7065e-01,  ...,  1.1562e+00,  5.1221e-01,  1.9678e-01],
          [ 1.2402e+00,  1.2246e+00,  1.3223e+00,  ...,  1.1104e+00,  2.6538e-01,  6.3818e-01],
          [-1.8232e+00,  2.6416e-01,  1.1484e+00,  ..., -9.2822e-01, -9.8145e-01,  9.2529e-02]],

         ...,

         [[ 1.2021e+00,  4.4238e-01,  5.8496e-01,  ...,  1.6240e+00, -2.5879e-01,  3.4302e-01],
          [-3.1421e-01,  2.6709e-01,  6.1133e-01,  ...,  5.6152e-01, -2.8955e-01,  6.8018e-01],
          [ 1.6919e-01,  1.0127e+00,  5.0537e-01,  ...,  6.1719e-01,  3.8110e-01,  5.2100e-01],
          ...,
          [-1.0527e+00, -3.4253e-01,  1.6279e+00,  ...,  9.4727e-01, -1.0029e+00,  7.3438e-01],
          [-7.0374e-02,  5.2246e-01,  8.2031e-01,  ..., -1.4766e+00, -1.4834e+00,  5.9082e-01],
          [-7.7637e-01, -8.7549e-01,  1.1143e+00,  ...,  4.7656e-01, -7.4609e-01, -3.3545e-01]],

         [[-9.4873e-01, -4.8169e-01, -1.0840e+00,  ..., -4.1431e-01, -8.7451e-01,  5.2393e-01],
          [ 1.1152e+00, -2.0361e-01, -6.8457e-01,  ...,  1.0566e+00, -4.1162e-01,  4.6118e-01],
          [ 3.9502e-01, -4.0430e-01,  3.1274e-01,  ...,  4.7363e-01, -8.7354e-01, -5.1562e-01],
          ...,
          [-3.0823e-02,  8.4912e-01,  5.5328e-02,  ..., -3.2715e-01,  3.5107e-01, -7.4854e-01],
          [ 1.2539e+00, -2.6831e-01,  2.2412e-01,  ..., -9.8511e-02, -8.4863e-01,  2.9956e-01],
          [ 1.3896e+00, -9.7266e-01,  3.7158e-01,  ...,  1.3027e+00,  3.2910e-01, -6.3354e-02]],

         [[-1.9014e+00, -2.3523e-01, -1.7207e+00,  ..., -5.6689e-01,  6.1133e-01, -3.6743e-01],
          [ 1.2559e+00,  1.9414e+00, -1.9141e-01,  ..., -9.8535e-01, -1.8005e-01,  2.2485e-01],
          [ 1.6953e+00, -2.0898e-01,  2.4133e-01,  ...,  5.2124e-02,  5.2881e-01, -1.7979e+00],
          ...,
          [-1.7881e+00,  3.4326e-01, -1.4502e+00,  ..., -1.7803e+00, -6.7017e-02,  6.0596e-01],
          [-1.2773e+00, -5.6519e-02, -9.4629e-01,  ...,  2.1423e-02, -9.9756e-01, -4.9219e-01],
          [-4.7534e-01, -1.1465e+00, -1.1603e-01,  ..., -3.5425e-01, -4.5410e-01,  1.1455e+00]]],


        [[[ 6.1865e-01, -9.1846e-01, -1.5684e+00,  ..., -1.5801e+00,  3.9844e-01, -8.2324e-01],
          [-1.7883e-01, -1.2314e+00, -5.5811e-01,  ..., -1.0459e+00,  2.6074e-01,  8.9893e-01],
          [-8.5400e-01, -1.4600e+00, -4.1138e-01,  ..., -1.1768e+00,  4.1943e-01, -1.0820e+00],
          ...,
          [-1.7578e-01, -9.3506e-01,  1.1249e-01,  ...,  6.9043e-01,  2.0105e-01, -5.5566e-01],
          [-1.0312e+00, -1.2764e+00, -4.7791e-02,  ..., -9.8755e-02,  2.9102e-01, -4.2310e-01],
          [ 3.7207e-01, -1.8286e-01,  2.2119e-01,  ..., -8.0762e-01, -1.2227e+00, -1.1162e+00]],

         [[-2.9199e-01, -6.9238e-01, -6.1621e-01,  ..., -3.9746e-01, -1.2041e+00, -5.6543e-01],
          [-6.4990e-01, -1.5503e-01, -1.1035e+00,  ...,  1.0242e-01,  8.8574e-01,  1.3171e-01],
          [-7.5830e-01,  3.2080e-01, -7.6123e-01,  ..., -3.0930e-02,  1.0352e+00,  6.2500e-02],
          ...,
          [-1.1396e+00,  6.9824e-01,  3.2568e-01,  ...,  1.4785e+00, -1.8762e-01,  3.4082e-01],
          [ 5.5762e-01,  1.1211e+00,  5.7324e-01,  ...,  1.3428e-01, -1.7031e+00, -6.5479e-01],
          [ 5.6201e-01,  7.3242e-01,  7.3975e-02,  ..., -2.0859e+00, -2.4570e+00, -2.1216e-01]],

         [[-1.0322e+00, -9.4043e-01, -4.2725e-01,  ...,  6.8018e-01,  8.8867e-02, -4.7754e-01],
          [-3.7354e-01,  3.0371e-01,  1.5527e-01,  ..., -4.2627e-01, -1.2793e+00, -1.7490e+00],
          [-3.9795e-01, -1.3477e-01, -1.0962e-01,  ...,  1.0020e+00,  8.8623e-01,  1.9226e-01],
          ...,
          [-1.3379e+00, -2.7490e-01, -9.4189e-01,  ...,  5.9375e-01,  1.6650e-01,  7.4756e-01],
          [-1.0977e+00, -4.6631e-01, -8.3301e-01,  ..., -6.5918e-01, -5.1709e-01,  9.9902e-01],
          [ 3.7231e-01, -1.0029e+00,  1.0811e+00,  ..., -1.0332e+00, -8.2397e-02, -3.4766e-01]],

         ...,

         [[ 3.5181e-01, -4.1211e-01, -1.3477e+00,  ..., -3.6182e-01, -1.5342e+00,  1.6248e-01],
          [ 3.3970e-03, -6.9238e-01, -5.0830e-01,  ...,  2.2986e-01,  8.3447e-01, -7.4707e-01],
          [ 1.1377e+00,  1.4856e-01,  6.9824e-01,  ..., -7.2217e-01, -6.5430e-01, -1.2617e+00],
          ...,
          [-8.2764e-01,  1.8057e+00,  4.1699e-01,  ..., -2.7905e-01,  1.4072e+00,  3.5278e-01],
          [-1.0400e-01,  6.8848e-01, -5.8411e-02,  ...,  3.3081e-01,  1.4219e+00, -6.0986e-01],
          [-6.9189e-01,  1.0254e-02,  2.1057e-02,  ...,  6.9043e-01, -8.4717e-01, -1.6807e+00]],

         [[-3.7646e-01,  1.2378e-01,  5.3711e-03,  ..., -4.5605e-01, -3.4912e-02, -1.7896e-01],
          [ 1.3293e-01,  1.1631e+00,  1.0449e+00,  ..., -7.3828e-01,  4.6484e-01, -9.5068e-01],
          [ 2.8198e-01,  3.7500e-01,  8.6230e-01,  ..., -7.4316e-01,  7.9639e-01, -1.6663e-01],
          ...,
          [-1.4355e+00, -1.6074e+00, -1.2246e+00,  ..., -8.9746e-01, -4.9805e-01,  8.5449e-01],
          [-9.3652e-01,  9.8682e-01,  6.8164e-01,  ..., -5.6494e-01,  3.9209e-01,  8.6865e-01],
          [-9.7852e-01, -1.6641e+00,  4.8291e-01,  ...,  1.8594e+00,  1.6260e+00,  1.1006e+00]],

         [[ 5.0842e-02, -2.8442e-01, -2.1033e-01,  ..., -4.7485e-02, -9.5850e-01,  8.9453e-01],
          [ 6.2939e-01, -3.6890e-01, -2.6343e-01,  ...,  6.4209e-02, -3.2739e-01, -1.9702e-01],
          [-6.2207e-01, -7.6416e-02, -6.6309e-01,  ...,  1.1133e+00,  7.4951e-02,  2.8613e-01],
          ...,
          [-9.8730e-01, -1.1006e+00, -1.6736e-01,  ...,  2.5366e-01,  6.1768e-01,  5.3369e-01],
          [-2.0190e-01,  6.7139e-01,  1.4238e+00,  ...,  8.0615e-01, -7.5000e-01,  5.7617e-01],
          [ 6.3623e-01,  3.8281e-01,  3.7231e-01,  ...,  5.1270e-01, -3.6377e-01,  7.4707e-01]]],


        [[[-4.2676e-01, -1.2372e-01,  4.8279e-02,  ..., -1.4478e-01, -3.0859e-01,  1.2061e+00],
          [ 5.2295e-01,  5.8789e-01,  9.1846e-01,  ..., -1.0541e-01, -1.0732e+00,  5.2734e-01],
          [ 6.5979e-02,  5.8203e-01, -6.0303e-01,  ...,  8.4521e-01,  1.4648e+00,  3.3438e+00],
          ...,
          [-1.8037e+00, -1.3281e-01, -2.2180e-01,  ..., -3.9307e-01, -1.2451e-02, -1.2246e+00],
          [-9.8242e-01, -1.3008e+00, -9.9023e-01,  ..., -1.2585e-01, -2.0776e-01, -8.7158e-01],
          [ 1.0625e+00,  1.6328e+00, -2.6733e-01,  ...,  1.8311e-01,  1.0771e+00, -1.7490e+00]],

         [[-2.7295e-01,  9.1406e-01,  1.1309e+00,  ..., -3.0811e-01, -1.1338e+00, -2.3303e-01],
          [-1.1328e+00,  1.2842e+00,  1.4541e+00,  ..., -5.7178e-01,  1.5552e-01, -5.2344e-01],
          [ 2.4890e-01,  5.6201e-01, -2.0679e-01,  ...,  5.3613e-01,  2.5903e-01, -1.2197e+00],
          ...,
          [ 4.2285e-01,  1.0869e+00, -1.8079e-01,  ..., -1.2305e+00, -4.0674e-01, -1.6418e-02],
          [ 1.4941e+00,  2.2422e+00, -1.5417e-01,  ...,  1.0625e+00,  9.1943e-01,  1.1904e+00],
          [ 2.4844e+00,  2.0078e+00, -1.2715e+00,  ...,  9.7852e-01,  1.7148e+00,  1.2090e+00]],

         [[ 3.8013e-01, -3.1738e-01,  3.3997e-02,  ...,  3.7109e-01, -2.4551e+00, -1.1318e+00],
          [-7.5684e-01, -2.6270e-01, -3.5669e-01,  ...,  2.6660e-01, -1.4355e+00, -1.6455e+00],
          [-2.0923e-01, -4.0063e-01, -5.6738e-01,  ...,  1.8887e+00, -1.6504e-01, -8.5547e-01],
          ...,
          [-6.6357e-01, -6.9727e-01,  7.9785e-01,  ...,  6.7627e-01,  4.8169e-01, -5.5029e-01],
          [-5.2100e-01, -4.9683e-02, -3.1421e-01,  ...,  6.2158e-01,  5.1367e-01,  9.7107e-02],
          [ 7.8711e-01,  1.8838e+00, -1.3447e+00,  ...,  3.8721e-01, -1.4502e-01, -6.6406e-02]],

         ...,

         [[-1.8567e-01,  2.4036e-01,  1.2573e-01,  ..., -7.2559e-01, -7.6025e-01, -9.4238e-01],
          [ 1.7334e-01,  6.8359e-01, -4.8218e-01,  ..., -5.7959e-01,  3.3960e-01,  4.4849e-01],
          [ 1.2666e+00,  1.5781e+00,  9.3652e-01,  ..., -4.6753e-01,  1.8970e-01,  5.0635e-01],
          ...,
          [ 7.5146e-01,  4.2529e-01,  4.5264e-01,  ...,  4.7510e-01,  7.4097e-02, -4.1229e-02],
          [ 1.0752e+00, -4.8145e-01, -3.7915e-01,  ...,  6.4062e-01,  1.2627e+00, -1.0382e-01],
          [-3.9062e-02, -5.7373e-02, -2.9053e-01,  ..., -5.0732e-01,  6.7236e-01,  8.2910e-01]],

         [[-1.4707e+00, -1.0088e+00, -8.3740e-01,  ..., -6.3672e-01,  1.0559e-01, -5.1855e-01],
          [-7.5391e-01, -9.2188e-01,  3.5913e-01,  ...,  2.0703e-01,  1.0605e+00, -1.0156e+00],
          [-2.9395e-01,  7.8809e-01,  9.8633e-01,  ...,  1.1221e+00,  6.0840e-01, -1.6953e+00],
          ...,
          [ 3.4082e-01,  2.7002e-01,  1.3135e+00,  ..., -8.3203e-01, -4.0771e-01, -1.2428e-02],
          [-1.6687e-01,  2.8625e-02, -6.4844e-01,  ..., -1.5039e-01,  1.9360e-01,  5.9692e-02],
          [ 1.1240e+00,  5.6836e-01, -1.3066e+00,  ..., -4.8889e-02,  2.3010e-01,  5.3223e-01]],

         [[-1.1230e+00,  8.8770e-01,  8.8623e-01,  ...,  8.4424e-01, -1.3271e+00, -4.3384e-01],
          [ 5.9570e-01, -1.0605e+00,  1.7480e+00,  ..., -4.9805e-02, -9.5215e-02, -5.3320e-01],
          [ 6.4648e-01, -7.0361e-01,  1.4463e+00,  ...,  5.8301e-01, -8.9453e-01, -2.2925e-01],
          ...,
          [ 2.4353e-02,  6.4258e-01, -1.1436e+00,  ..., -6.1279e-01, -7.3730e-01, -6.0455e-02],
          [ 7.2119e-01,  1.9873e-01, -8.3887e-01,  ..., -6.8750e-01, -1.3223e+00, -1.0479e+00],
          [ 1.4189e+00, -9.4043e-01,  9.6191e-02,  ..., -9.5337e-02, -8.7305e-01,  8.3594e-01]]],


        [[[ 6.3660e-02, -8.0176e-01, -1.2622e-01,  ..., -2.7588e-02,  1.3662e+00, -3.7744e-01],
          [-4.2053e-02, -8.1152e-01, -3.6621e-01,  ...,  2.7783e-01, -5.3955e-01, -1.2949e+00],
          [ 8.2520e-02, -4.1992e-02, -3.0811e-01,  ...,  2.2510e-01, -4.4629e-01, -1.5076e-02],
          ...,
          [ 1.0059e+00,  6.6992e-01,  1.0166e+00,  ..., -4.4043e-01, -1.2373e+00, -1.0486e-01],
          [ 1.4785e+00,  2.5635e-01,  2.7161e-03,  ..., -2.9102e-01, -2.5940e-02, -1.5264e+00],
          [ 4.2419e-02,  7.6367e-01,  5.7861e-01,  ..., -6.2402e-01, -8.1665e-02,  2.4463e-01]],

         [[-2.4719e-01,  1.2988e+00, -8.7402e-02,  ..., -4.3579e-02, -5.7031e-01,  3.8281e-01],
          [ 2.0764e-01, -4.6826e-01, -6.4160e-01,  ..., -9.9121e-02, -3.5400e-01, -7.9736e-01],
          [-3.7012e-01, -4.2285e-01, -1.9604e-01,  ...,  9.6777e-01,  1.0469e+00,  6.6162e-01],
          ...,
          [ 1.1641e+00,  4.9683e-02,  5.8350e-01,  ...,  1.1309e+00, -6.7090e-01,  3.7622e-01],
          [ 4.5947e-01,  1.0957e+00,  4.3457e-01,  ..., -2.5098e+00, -2.7930e-01,  1.1387e+00],
          [ 3.5962e-01,  6.5674e-01,  1.7109e+00,  ..., -1.8965e+00,  9.8975e-01,  7.7393e-01]],

         [[-6.7932e-02,  3.5181e-01, -3.3594e-01,  ..., -1.2236e+00, -8.1494e-01, -1.2500e+00],
          [-2.3914e-01, -3.5498e-01,  2.7161e-02,  ...,  2.2095e-01, -9.9060e-02, -3.2056e-01],
          [-8.6975e-03, -1.0098e+00, -8.5571e-02,  ...,  4.4434e-01,  1.9177e-01,  1.0693e-01],
          ...,
          [-8.3398e-01,  5.2637e-01,  3.1494e-01,  ...,  5.2100e-01,  1.0049e+00, -2.1558e-01],
          [-6.0107e-01, -1.3550e-01,  2.9883e-01,  ...,  8.6572e-01,  3.5693e-01, -2.3575e-02],
          [-5.4639e-01,  9.8450e-02,  6.4111e-01,  ...,  1.1240e+00,  2.5171e-01,  1.5547e+00]],

         ...,

         [[-3.8025e-02, -7.1045e-01,  6.4111e-01,  ..., -5.2490e-01,  2.0349e-01, -1.3782e-01],
          [ 8.3594e-01, -8.3398e-01, -9.0869e-01,  ...,  1.0342e+00, -1.3892e-01,  5.2051e-01],
          [ 1.0675e-01, -1.3223e+00, -7.7734e-01,  ...,  2.3523e-01, -5.4102e-01, -7.9590e-01],
          ...,
          [ 8.5254e-01,  2.8076e-01,  1.3828e+00,  ...,  1.8555e-01,  1.0605e+00, -9.2480e-01],
          [ 5.2948e-02, -1.6589e-01, -1.5125e-01,  ...,  1.4033e+00,  1.0779e-01,  1.1455e+00],
          [-1.0801e+00, -1.9922e-01, -1.7012e+00,  ...,  6.6895e-01,  5.1953e-01,  1.3711e+00]],

         [[-1.0205e-01, -1.4170e+00, -4.5361e-01,  ...,  1.9736e+00,  2.2107e-01,  2.6733e-01],
          [ 1.1530e-01, -3.6133e-01, -7.4609e-01,  ...,  4.4678e-02,  9.6387e-01,  8.1055e-01],
          [ 1.2969e+00,  7.7539e-01, -9.6045e-01,  ...,  1.8152e-01,  4.2261e-01,  1.0439e+00],
          ...,
          [-5.5267e-02,  1.4526e-01,  9.1064e-01,  ...,  7.6123e-01, -2.9199e-01, -1.8750e+00],
          [-9.9756e-01,  1.4453e-01,  9.7363e-01,  ...,  1.2168e+00,  7.7588e-01, -6.9287e-01],
          [ 5.8136e-02, -9.1113e-01,  9.2090e-01,  ...,  8.8916e-01,  4.4165e-01, -2.2607e-01]],

         [[-7.7820e-02, -3.0103e-01, -1.0547e+00,  ..., -9.8584e-01,  7.0850e-01, -1.3701e+00],
          [-1.1006e+00, -1.1846e+00, -3.7793e-01,  ...,  2.2461e-02, -1.0928e+00, -3.2031e-01],
          [ 1.6675e-01, -1.3535e+00, -1.6387e+00,  ...,  1.7617e+00,  4.5801e-01, -1.2969e+00],
          ...,
          [-1.3359e+00, -1.6973e+00, -8.9990e-01,  ..., -9.6436e-03,  1.5894e-01, -1.2012e+00],
          [ 5.0977e-01, -3.5645e-01, -9.5166e-01,  ..., -2.7954e-01,  1.8774e-01,  6.1719e-01],
          [-1.9873e+00, -1.3545e+00, -1.0459e+00,  ..., -1.6821e-01, -1.0283e+00,  3.1299e-01]]]], dtype=torch.float16)

2025-06-10 00:13:32.776399 GPU 4 156011 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 256, 256],"float16"), size=list[1024,1024,], mode="bilinear", align_corners=False, )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 19, 256, 256],"float16"), size=list[1024,1024,], mode="bilinear", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12967 / 4980736 (0.3%)
Greatest absolute difference: 0.048828125 at index (1, 3, 234, 100) (up to 0.01 allowed)
Greatest relative difference: 7.50390625 at index (1, 5, 42, 19) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 19, 256, 256]), dtype=torch.float16)
tensor([[[[-1.7004e-01,  6.6602e-01,  2.8242e+00,  ...,  1.6973e+00,  3.4937e-01,  2.3223e+00],
          [-1.1025e+00,  9.8633e-01,  8.6621e-01,  ...,  8.7549e-01, -6.8970e-02,  1.0869e+00],
          [ 3.7671e-01, -3.3130e-01, -6.3525e-01,  ...,  2.0203e-01,  6.2109e-01,  5.7861e-01],
          ...,
          [-1.1270e+00, -6.7432e-01, -6.1707e-02,  ..., -4.4263e-01,  1.2891e-01, -1.0223e-01],
          [ 1.8936e+00,  4.6387e-01, -3.9844e-01,  ...,  2.8174e-01,  8.3350e-01,  8.1006e-01],
          [ 8.8623e-01,  1.9373e-01, -6.6602e-01,  ..., -4.0820e-01, -5.7715e-01, -5.3223e-01]],

         [[ 1.3477e+00, -1.2080e+00, -5.9180e-01,  ...,  1.1992e+00,  1.0215e+00,  7.3096e-01],
          [ 1.4170e+00, -1.3657e-02,  6.2622e-02,  ...,  1.1934e+00,  9.3848e-01,  1.3008e+00],
          [ 6.4746e-01, -3.0005e-01,  1.4087e-01,  ..., -3.0991e-02,  8.4277e-01,  9.7717e-02],
          ...,
          [ 8.6719e-01,  8.3252e-01,  8.1787e-01,  ...,  8.0811e-01, -8.3069e-02,  6.0645e-01],
          [ 1.2000e-01, -9.8389e-01,  5.1318e-01,  ..., -4.8828e-01, -1.2568e+00, -7.8564e-01],
          [-5.7617e-01, -5.5908e-01, -1.0461e-01,  ..., -2.3301e+00, -1.1602e+00, -1.3398e+00]],

         [[ 1.8320e+00, -1.1992e+00, -4.7827e-01,  ...,  4.4238e-01,  8.2910e-01,  7.6782e-02],
          [-7.7393e-01, -4.8291e-01, -8.1201e-01,  ..., -1.2236e+00,  7.9834e-01, -1.0876e-01],
          [ 1.1680e+00,  4.7583e-01, -2.6074e-01,  ..., -6.0596e-01,  2.5803e-02, -1.1328e+00],
          ...,
          [ 1.0508e+00, -4.9512e-01, -4.1919e-01,  ...,  1.3291e+00, -2.5952e-01,  6.8311e-01],
          [ 1.8750e+00, -3.1592e-01,  1.3086e+00,  ...,  1.1895e+00, -1.0022e-01,  3.0542e-01],
          [ 9.6045e-01, -1.9690e-01,  4.8047e-01,  ..., -1.7981e-01, -1.8872e-01,  2.5244e-01]],

         ...,

         [[-1.5117e+00, -2.2766e-01,  1.9202e-01,  ..., -7.8125e-01,  1.7419e-01,  1.7236e-01],
          [ 7.2998e-02,  1.2051e+00,  6.2012e-01,  ..., -3.8599e-01, -4.5557e-01,  1.2915e-01],
          [-3.7134e-01,  6.6699e-01,  1.1191e+00,  ...,  5.5029e-01,  9.1248e-02,  2.9370e-01],
          ...,
          [-2.4329e-01,  3.4253e-01, -2.8638e-01,  ..., -4.3384e-01,  4.1309e-01, -7.9883e-01],
          [-4.3945e-01, -1.1543e+00, -8.1421e-02,  ..., -7.4902e-01, -5.4736e-01,  2.2949e-01],
          [-6.5381e-01,  2.5610e-01, -1.2686e+00,  ..., -2.1719e+00, -1.1611e+00,  4.4751e-01]],

         [[-6.9141e-01, -3.7183e-01,  2.5879e-01,  ...,  1.7031e+00,  1.7078e-01,  1.9177e-01],
          [ 2.5391e-01, -1.8753e-02,  1.9458e-01,  ...,  7.3792e-02, -2.8296e-01, -1.0114e-01],
          [ 7.2021e-01,  9.6533e-01, -3.4204e-01,  ...,  2.4744e-01, -1.2964e-01,  3.4229e-01],
          ...,
          [ 6.3965e-02, -1.4185e-01,  1.3440e-01,  ..., -4.4556e-01,  4.6655e-01,  4.7583e-01],
          [ 9.8816e-02, -1.3428e+00, -3.1323e-01,  ...,  7.7515e-02,  6.4258e-01, -4.7559e-01],
          [ 3.8159e-01,  4.2017e-01, -5.1300e-02,  ...,  7.4268e-01, -4.4116e-01,  9.5520e-02]],

         [[-7.9492e-01,  8.0615e-01, -8.0444e-02,  ...,  6.6113e-01, -4.4189e-02,  3.5278e-01],
          [-5.1562e-01, -8.4912e-01, -8.7402e-01,  ...,  1.8271e+00, -2.7359e-02,  5.8350e-01],
          [ 5.1807e-01, -4.4116e-01, -1.4590e+00,  ...,  1.3213e+00, -7.2119e-01,  5.1221e-01],
          ...,
          [ 1.5742e+00,  7.0850e-01,  1.4026e-01,  ...,  7.3682e-01,  6.3623e-01,  1.6396e+00],
          [ 1.3174e+00, -1.1641e+00,  3.2135e-02,  ...,  5.9277e-01,  8.7988e-01,  1.5889e+00],
          [-7.4805e-01, -2.3792e-01, -6.5723e-01,  ...,  2.8809e-01, -2.5415e-01, -3.6597e-01]]],


        [[[-6.9531e-01,  7.6514e-01,  6.1914e-01,  ..., -1.7646e+00, -3.4766e-01,  5.4248e-01],
          [-3.7939e-01,  2.6147e-01, -1.5068e+00,  ..., -2.0679e-01, -4.8267e-01, -1.2959e+00],
          [ 6.9141e-01,  1.2275e+00, -3.2422e-01,  ...,  8.7500e-01, -4.5142e-01, -6.4307e-01],
          ...,
          [ 2.8784e-01, -8.7256e-01,  9.6436e-02,  ..., -1.3220e-01,  2.7686e-01,  1.0254e+00],
          [ 4.4281e-02, -4.3213e-01, -6.5088e-01,  ...,  6.2842e-01,  1.6855e+00,  7.9297e-01],
          [ 1.2910e+00,  1.2090e+00,  1.5918e+00,  ..., -5.7275e-01,  1.2842e+00,  1.2148e+00]],

         [[-1.7109e+00, -5.7422e-01,  7.4023e-01,  ...,  4.3530e-01,  6.7188e-01, -2.1863e-01],
          [ 2.0544e-01,  5.9033e-01,  3.5620e-01,  ...,  1.3398e+00,  9.9756e-01, -7.0996e-01],
          [ 4.4287e-01,  9.3701e-01,  5.6543e-01,  ..., -4.9194e-01, -9.5264e-01, -5.5371e-01],
          ...,
          [-1.3691e+00, -1.2256e+00,  1.5906e-01,  ..., -4.6460e-01, -8.0273e-01,  5.5450e-02],
          [ 1.3397e-02, -5.6006e-01, -8.4619e-01,  ..., -6.6748e-01,  4.8975e-01, -3.6060e-01],
          [ 1.6992e+00,  1.3879e-01, -1.9617e-01,  ..., -9.3262e-01,  3.4131e-01,  4.4897e-01]],

         [[ 2.6025e-01,  9.2627e-01,  1.3611e-01,  ..., -4.0527e-01, -1.3000e-01,  1.7441e+00],
          [ 1.6523e+00,  9.0186e-01, -1.1367e+00,  ..., -1.6611e+00,  6.2402e-01,  1.7603e-01],
          [ 2.0764e-01,  1.2246e+00, -6.2305e-01,  ..., -7.0312e-01, -4.8706e-01,  1.1484e+00],
          ...,
          [ 1.4951e+00, -2.3828e-01,  2.4316e-01,  ...,  2.6978e-01,  8.9697e-01, -7.8613e-01],
          [ 6.2939e-01, -2.4194e-01,  1.1494e+00,  ..., -1.3647e-01,  1.1243e-01, -5.7227e-01],
          [-7.0374e-02, -2.6270e-01,  2.3145e+00,  ...,  2.1313e-01,  8.6475e-01,  1.0732e+00]],

         ...,

         [[ 2.6562e-01,  2.7515e-01, -8.0420e-01,  ..., -6.3086e-01,  6.9678e-01,  9.8193e-01],
          [ 4.9194e-01,  7.2754e-01,  6.9482e-01,  ..., -8.7109e-01, -2.2913e-01, -5.3955e-01],
          [ 1.9507e-01,  5.9424e-01, -7.4463e-01,  ..., -4.1040e-01, -6.1182e-01,  2.2412e-01],
          ...,
          [ 1.7041e-01,  3.2135e-02, -6.0498e-01,  ...,  6.1768e-01, -2.4951e-01,  7.9736e-01],
          [ 7.9590e-01, -4.6509e-01, -4.2212e-01,  ..., -1.8042e-01, -2.3364e-01, -1.8335e-01],
          [-1.0626e-01, -7.7100e-01,  7.2070e-01,  ..., -9.0381e-01,  5.4590e-01, -2.0605e+00]],

         [[-1.2236e+00, -7.0361e-01, -5.5176e-01,  ...,  1.0425e-01,  8.3545e-01,  5.7959e-01],
          [-1.6504e+00, -2.2424e-01,  9.7559e-01,  ..., -3.4619e-01, -6.8457e-01,  3.2153e-01],
          [ 1.8787e-01, -1.1055e+00,  1.3311e+00,  ..., -1.0391e+00, -7.8076e-01,  6.7383e-01],
          ...,
          [-5.3320e-01,  5.8716e-02,  1.1973e+00,  ..., -1.6191e+00, -6.9971e-01,  1.3018e+00],
          [-6.8994e-01,  1.8835e-01,  1.9385e-01,  ..., -5.2930e-01, -1.1719e+00,  1.4026e-01],
          [-4.4098e-02,  1.1719e+00, -1.3684e-01,  ...,  4.2041e-01, -2.0117e-01, -1.6541e-01]],

         [[ 8.3691e-01, -3.0103e-01, -2.8711e-01,  ..., -6.9336e-01, -3.1714e-01, -8.4717e-01],
          [ 2.6055e+00,  1.1650e+00,  1.3623e+00,  ...,  4.5630e-01, -4.8877e-01, -5.8643e-01],
          [ 6.4941e-01,  7.0508e-01,  4.4922e-01,  ...,  1.8372e-02,  2.9175e-01,  5.4590e-01],
          ...,
          [-1.3496e+00,  6.6711e-02,  1.4785e+00,  ..., -7.8320e-01,  1.7090e-01, -7.4158e-02],
          [-2.5586e+00, -4.5825e-01,  3.3032e-01,  ..., -3.8867e-01,  5.0439e-01,  6.4941e-01],
          [-1.7295e+00, -7.3682e-01, -1.0625e+00,  ...,  2.7271e-01,  2.4475e-01, -3.9722e-01]]],


        [[[ 5.4785e-01, -1.2482e-01,  1.8030e-01,  ..., -5.6885e-01, -8.8623e-01,  6.5430e-02],
          [ 4.5386e-01, -9.1602e-01, -2.1143e-01,  ..., -5.0977e-01, -6.9434e-01,  1.0248e-01],
          [-2.1729e-01,  6.2061e-01,  1.5222e-01,  ..., -4.5319e-02, -1.4807e-01,  1.0938e+00],
          ...,
          [ 3.9307e-01,  3.7671e-01,  1.0986e+00,  ...,  7.1826e-01,  1.8774e-01,  1.5293e+00],
          [-5.0732e-01,  2.3816e-01,  1.5576e+00,  ..., -7.0190e-02, -1.0303e+00,  1.0947e+00],
          [-1.1855e+00, -6.1475e-01,  4.5874e-01,  ..., -6.7383e-01, -1.2168e+00,  5.3809e-01]],

         [[-2.7051e-01, -4.5361e-01, -5.9033e-01,  ..., -6.7871e-01, -9.4141e-01,  7.9053e-01],
          [-1.6870e-01,  5.0537e-01,  1.2384e-01,  ..., -4.2065e-01, -2.2441e+00, -5.0781e-01],
          [-1.9153e-01, -2.4475e-01,  3.3252e-01,  ..., -1.0445e-02, -1.1270e+00, -2.2681e-01],
          ...,
          [ 9.1748e-01,  4.7852e-01, -2.2473e-01,  ..., -1.1621e+00, -6.6309e-01,  8.2715e-01],
          [ 1.5342e+00,  6.3184e-01,  3.6957e-02,  ..., -1.2559e+00,  3.0289e-02, -1.0381e+00],
          [-8.8037e-01, -1.3867e+00, -9.4971e-01,  ..., -1.0527e+00, -4.8267e-01, -7.0068e-01]],

         [[ 4.5850e-01,  1.5701e-02,  2.0532e-01,  ...,  1.8933e-01,  2.9175e-01,  1.6152e+00],
          [-1.9226e-01,  5.1172e-01,  1.9570e+00,  ...,  3.5205e-01,  7.8516e-01,  3.6060e-01],
          [-1.0869e+00,  5.0439e-01, -1.6211e-01,  ..., -8.4277e-01,  7.3340e-01,  7.5977e-01],
          ...,
          [ 3.9520e-02,  2.3987e-01,  9.8047e-01,  ..., -9.0759e-02,  4.2432e-01,  7.5098e-01],
          [ 5.8563e-02, -8.8623e-02,  1.8066e+00,  ...,  1.1436e+00,  4.3140e-01,  7.4121e-01],
          [-1.0059e+00,  3.0884e-01, -1.7517e-01,  ..., -1.1064e+00, -2.1113e+00,  5.5469e-01]],

         ...,

         [[ 1.1926e-01,  7.2656e-01,  5.3320e-01,  ..., -6.4941e-01, -2.3516e+00, -2.4785e+00],
          [-1.2334e+00, -1.3350e+00, -1.0046e-01,  ...,  6.7236e-01, -1.0195e+00, -3.8965e-01],
          [-2.3975e-01, -1.8396e-01,  3.1543e-01,  ..., -9.2871e-01,  1.6907e-01, -2.3645e-01],
          ...,
          [-1.0488e+00, -1.1660e+00,  9.8047e-01,  ...,  4.8657e-01,  1.7021e+00,  4.2358e-01],
          [-8.5254e-01, -4.5044e-01, -2.1225e-02,  ...,  2.8369e-01,  6.6455e-01, -7.9712e-02],
          [-1.6680e+00,  1.7402e+00,  6.4307e-01,  ...,  4.8926e-01,  4.0991e-01,  8.7708e-02]],

         [[ 7.0117e-01, -7.3877e-01,  7.3145e-01,  ...,  1.8640e-01,  6.6357e-01, -2.7598e+00],
          [-1.1797e+00, -2.3096e-01,  9.6191e-01,  ...,  8.7585e-02, -1.3164e+00, -1.6396e+00],
          [-5.6982e-01, -3.7061e-01, -6.7773e-01,  ...,  1.3037e+00, -9.5947e-01, -4.3427e-02],
          ...,
          [ 1.0742e+00,  9.8633e-01,  1.2529e+00,  ..., -1.1182e+00,  1.6309e-01, -7.0605e-01],
          [-1.7637e+00,  6.0449e-01,  3.3447e-01,  ..., -9.9756e-01,  3.1567e-01,  1.4697e+00],
          [ 4.9243e-01,  3.2959e-01,  1.0898e+00,  ..., -2.0752e-02,  1.7920e+00,  7.5879e-01]],

         [[ 1.0869e+00,  1.7539e+00, -4.7314e-01,  ..., -1.0439e+00,  6.0364e-02,  7.9468e-02],
          [ 7.4463e-01, -7.0557e-01,  5.5957e-01,  ..., -1.3262e+00,  1.9421e-01,  8.1250e-01],
          [ 1.6504e+00, -7.3779e-01,  5.3320e-01,  ...,  5.2539e-01,  9.4629e-01,  1.4092e+00],
          ...,
          [ 1.5889e+00,  5.0488e-01, -3.0762e-01,  ..., -9.1476e-03,  6.3770e-01,  4.8877e-01],
          [-1.8311e-01, -1.1592e+00,  4.1138e-01,  ..., -8.1934e-01, -9.4141e-01,  1.1377e+00],
          [ 4.7754e-01, -2.9614e-01, -9.3872e-02,  ..., -2.3792e-01, -3.0713e-01,  1.3867e-01]]],


        [[[-1.7256e+00, -1.5215e+00, -3.8574e-01,  ..., -4.3793e-02,  3.9624e-01,  1.0488e+00],
          [-2.3828e-01,  2.5146e-01, -2.4841e-01,  ..., -2.0605e-01, -9.1162e-01,  9.9121e-01],
          [ 7.0557e-01,  9.7168e-01, -3.0981e-01,  ..., -5.8777e-02, -5.6836e-01, -3.2886e-01],
          ...,
          [ 1.0215e+00,  1.0693e-01,  1.0034e-01,  ..., -2.4023e-01, -8.8477e-01,  7.2815e-02],
          [-1.8350e+00,  3.7018e-02,  8.2178e-01,  ...,  2.0605e-01, -1.5540e-01,  2.2449e-01],
          [-1.7217e+00, -9.9121e-01,  3.3032e-01,  ...,  3.6621e-01, -2.7905e-01,  7.7881e-01]],

         [[-2.3767e-01, -8.6084e-01,  9.3994e-01,  ..., -5.6104e-01,  8.2910e-01, -1.2656e+00],
          [ 1.9446e-01, -6.2012e-01,  3.5962e-01,  ..., -9.7351e-02,  4.5850e-01,  9.1406e-01],
          [-9.6143e-01, -1.8311e+00, -5.5859e-01,  ...,  4.6729e-01, -1.6296e-01,  1.2266e+00],
          ...,
          [-1.2861e+00, -7.7734e-01, -2.3157e-01,  ...,  8.1116e-02,  9.4482e-02,  2.0215e+00],
          [-1.7324e+00, -1.5928e+00, -1.7236e-01,  ...,  3.2178e-01,  3.5742e-01,  5.0342e-01],
          [-1.2383e+00, -8.7256e-01,  1.2510e+00,  ...,  1.2285e+00,  2.7656e+00,  3.7695e-01]],

         [[-8.2520e-01, -1.7197e+00, -3.8696e-01,  ...,  1.0773e-02, -4.1821e-01, -4.5093e-01],
          [-1.5293e+00, -4.3042e-01, -3.8525e-01,  ..., -3.8452e-01, -5.3809e-01, -1.0293e+00],
          [-1.1025e+00,  3.8403e-01, -9.8828e-01,  ...,  6.1523e-01,  3.8599e-01,  8.8867e-02],
          ...,
          [ 7.7148e-01,  3.3301e-01, -5.1807e-01,  ..., -3.7622e-01, -7.6514e-01, -9.5703e-01],
          [ 1.3390e-02, -1.2383e+00, -3.0371e-01,  ..., -8.9355e-01,  7.7197e-01, -9.7168e-01],
          [-1.1523e+00, -1.2051e+00, -7.9736e-01,  ..., -1.2915e-01, -8.3203e-01, -1.5156e+00]],

         ...,

         [[-9.4238e-01, -1.5161e-01, -2.4487e-01,  ..., -5.6543e-01, -6.5234e-01, -5.5469e-01],
          [ 1.3740e+00,  5.3125e-01,  6.6284e-02,  ...,  9.8926e-01,  2.1069e-01, -3.6011e-01],
          [-3.2715e-01,  1.1953e+00,  8.9209e-01,  ...,  4.2358e-01,  3.4424e-01,  1.9226e-01],
          ...,
          [ 1.6318e+00, -2.5391e-01,  3.4985e-01,  ..., -3.5327e-01, -1.3623e-01,  3.5645e-01],
          [ 1.8887e+00,  1.7109e+00,  1.0088e+00,  ..., -3.3667e-01,  7.6855e-01,  4.4287e-01],
          [ 1.1774e-01, -1.0638e-01,  1.1455e+00,  ..., -9.0625e-01, -8.4766e-01,  1.0938e+00]],

         [[-7.6953e-01,  5.2002e-01,  4.1626e-01,  ..., -6.8799e-01,  1.5295e-01, -1.5781e+00],
          [ 2.5977e-01,  3.2837e-01,  9.3079e-03,  ..., -1.1731e-01, -1.2070e+00, -5.2881e-01],
          [ 1.1895e+00, -5.4413e-02, -1.0068e+00,  ..., -5.3467e-01, -1.1768e+00,  5.3955e-02],
          ...,
          [-4.5801e-01, -1.0830e+00, -3.7866e-01,  ...,  9.3018e-01,  4.5679e-01,  3.4424e-01],
          [-4.9097e-01, -1.9299e-01,  3.8745e-01,  ...,  2.3865e-01,  1.3340e+00,  5.2930e-01],
          [-2.0325e-02,  5.1855e-01,  6.0986e-01,  ..., -1.2031e+00, -1.3275e-03,  1.7529e-01]],

         [[-8.7891e-01,  1.1064e+00,  4.0802e-02,  ...,  3.4937e-01,  2.1758e+00,  2.9541e-01],
          [-2.9980e-01,  4.5947e-01,  3.8379e-01,  ..., -7.6318e-01, -3.3594e-01,  1.6094e+00],
          [-2.0923e-01,  7.2266e-01, -3.7671e-01,  ..., -3.8916e-01, -1.3555e+00,  5.1025e-01],
          ...,
          [ 1.2012e+00,  9.8926e-01, -3.7134e-01,  ..., -2.1652e-02,  5.0098e-01,  8.8623e-01],
          [ 3.9233e-01,  1.7959e+00,  5.5713e-01,  ...,  1.4414e+00,  1.7119e+00,  6.5479e-01],
          [-8.5266e-02,  3.7085e-01,  2.3047e-01,  ...,  5.9424e-01,  6.6504e-01, -1.0771e+00]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 19, 256, 256]), dtype=torch.float16)
tensor([[[[-1.6565e-01,  6.7236e-01,  2.8594e+00,  ...,  1.7119e+00,  3.5107e-01,  2.3516e+00],
          [-1.1182e+00,  9.9561e-01,  8.7891e-01,  ...,  8.8574e-01, -7.0007e-02,  1.1016e+00],
          [ 3.7915e-01, -3.3105e-01, -6.4355e-01,  ...,  2.0776e-01,  6.2695e-01,  5.8154e-01],
          ...,
          [-1.1436e+00, -6.8408e-01, -6.5491e-02,  ..., -4.4702e-01,  1.2793e-01, -1.0358e-01],
          [ 1.9072e+00,  4.7168e-01, -3.9673e-01,  ...,  2.8564e-01,  8.4668e-01,  8.1787e-01],
          [ 8.8867e-01,  1.9360e-01, -6.8262e-01,  ..., -4.1309e-01, -5.8496e-01, -5.3516e-01]],

         [[ 1.3574e+00, -1.2207e+00, -6.0107e-01,  ...,  1.2119e+00,  1.0293e+00,  7.4121e-01],
          [ 1.4307e+00, -1.1963e-02,  6.2683e-02,  ...,  1.2090e+00,  9.5166e-01,  1.3164e+00],
          [ 6.5527e-01, -3.0566e-01,  1.4429e-01,  ..., -3.0029e-02,  8.4912e-01,  9.8145e-02],
          ...,
          [ 8.6963e-01,  8.4229e-01,  8.2227e-01,  ...,  8.1787e-01, -8.0811e-02,  6.1328e-01],
          [ 1.2286e-01, -9.9219e-01,  5.2100e-01,  ..., -4.9023e-01, -1.2715e+00, -7.9102e-01],
          [-5.8008e-01, -5.6738e-01, -1.0596e-01,  ..., -2.3555e+00, -1.1768e+00, -1.3584e+00]],

         [[ 1.8506e+00, -1.2168e+00, -4.8242e-01,  ...,  4.4727e-01,  8.3691e-01,  7.5317e-02],
          [-7.8467e-01, -4.9097e-01, -8.2129e-01,  ..., -1.2334e+00,  8.0615e-01, -1.0803e-01],
          [ 1.1816e+00,  4.8291e-01, -2.6611e-01,  ..., -6.1377e-01,  2.7405e-02, -1.1406e+00],
          ...,
          [ 1.0615e+00, -5.0049e-01, -4.2236e-01,  ...,  1.3457e+00, -2.6074e-01,  6.9092e-01],
          [ 1.8867e+00, -3.2056e-01,  1.3223e+00,  ...,  1.2080e+00, -1.0107e-01,  3.0688e-01],
          [ 9.7070e-01, -2.0093e-01,  4.8169e-01,  ..., -1.8042e-01, -1.9128e-01,  2.5562e-01]],

         ...,

         [[-1.5254e+00, -2.3511e-01,  1.9592e-01,  ..., -7.8760e-01,  1.7603e-01,  1.7603e-01],
          [ 7.1960e-02,  1.2227e+00,  6.2598e-01,  ..., -3.9453e-01, -4.5825e-01,  1.3147e-01],
          [-3.7305e-01,  6.7773e-01,  1.1377e+00,  ...,  5.5762e-01,  9.0210e-02,  2.9297e-01],
          ...,
          [-2.4194e-01,  3.5107e-01, -2.8491e-01,  ..., -4.3604e-01,  4.1992e-01, -8.1543e-01],
          [-4.4458e-01, -1.1709e+00, -8.4229e-02,  ..., -7.5488e-01, -5.5078e-01,  2.3450e-01],
          [-6.5479e-01,  2.6196e-01, -1.2803e+00,  ..., -2.1914e+00, -1.1748e+00,  4.5288e-01]],

         [[-6.9580e-01, -3.7207e-01,  2.5977e-01,  ...,  1.7197e+00,  1.7285e-01,  1.9507e-01],
          [ 2.5220e-01, -2.1744e-02,  1.9739e-01,  ...,  7.5256e-02, -2.8540e-01, -1.0284e-01],
          [ 7.2656e-01,  9.7559e-01, -3.4375e-01,  ...,  2.4805e-01, -1.3330e-01,  3.4814e-01],
          ...,
          [ 6.4270e-02, -1.4258e-01,  1.3550e-01,  ..., -4.4897e-01,  4.7095e-01,  4.7900e-01],
          [ 1.0126e-01, -1.3574e+00, -3.1689e-01,  ...,  7.6721e-02,  6.5771e-01, -4.7803e-01],
          [ 3.8037e-01,  4.2334e-01, -5.4199e-02,  ...,  7.4756e-01, -4.4727e-01,  8.9233e-02]],

         [[-8.0078e-01,  8.1641e-01, -8.0200e-02,  ...,  6.6650e-01, -4.3457e-02,  3.5303e-01],
          [-5.2100e-01, -8.5596e-01, -8.8037e-01,  ...,  1.8398e+00, -2.5879e-02,  5.9766e-01],
          [ 5.2393e-01, -4.4824e-01, -1.4736e+00,  ...,  1.3379e+00, -7.2900e-01,  5.1221e-01],
          ...,
          [ 1.5869e+00,  7.1729e-01,  1.4319e-01,  ...,  7.4463e-01,  6.4209e-01,  1.6543e+00],
          [ 1.3291e+00, -1.1777e+00,  3.1799e-02,  ...,  6.0107e-01,  8.8867e-01,  1.6016e+00],
          [-7.5244e-01, -2.4463e-01, -6.5869e-01,  ...,  2.8760e-01, -2.5049e-01, -3.6523e-01]]],


        [[[-7.0068e-01,  7.7441e-01,  6.2842e-01,  ..., -1.7812e+00, -3.5107e-01,  5.5420e-01],
          [-3.8354e-01,  2.6221e-01, -1.5195e+00,  ..., -2.1179e-01, -4.8730e-01, -1.3076e+00],
          [ 6.9727e-01,  1.2422e+00, -3.2935e-01,  ...,  8.8379e-01, -4.5703e-01, -6.4600e-01],
          ...,
          [ 2.9126e-01, -8.7988e-01,  9.9304e-02,  ..., -1.3354e-01,  2.7783e-01,  1.0312e+00],
          [ 4.3030e-02, -4.3945e-01, -6.6113e-01,  ...,  6.3330e-01,  1.6992e+00,  8.0469e-01],
          [ 1.3018e+00,  1.2188e+00,  1.6055e+00,  ..., -5.7617e-01,  1.2979e+00,  1.2148e+00]],

         [[-1.7246e+00, -5.8154e-01,  7.4951e-01,  ...,  4.3848e-01,  6.8018e-01, -2.2009e-01],
          [ 2.0520e-01,  5.9570e-01,  3.5864e-01,  ...,  1.3525e+00,  1.0098e+00, -7.1777e-01],
          [ 4.4678e-01,  9.5020e-01,  5.7080e-01,  ..., -4.9463e-01, -9.6045e-01, -5.5957e-01],
          ...,
          [-1.3818e+00, -1.2383e+00,  1.5991e-01,  ..., -4.6851e-01, -8.1055e-01,  5.8807e-02],
          [ 1.1002e-02, -5.6396e-01, -8.5596e-01,  ..., -6.7432e-01,  4.9609e-01, -3.7036e-01],
          [ 1.7119e+00,  1.3892e-01, -1.9873e-01,  ..., -9.4678e-01,  3.4180e-01,  4.5459e-01]],

         [[ 2.6123e-01,  9.3701e-01,  1.3977e-01,  ..., -4.1089e-01, -1.3525e-01,  1.7686e+00],
          [ 1.6670e+00,  9.0820e-01, -1.1484e+00,  ..., -1.6777e+00,  6.3086e-01,  1.7725e-01],
          [ 2.0764e-01,  1.2393e+00, -6.3281e-01,  ..., -7.1045e-01, -4.8730e-01,  1.1602e+00],
          ...,
          [ 1.5049e+00, -2.3792e-01,  2.4878e-01,  ...,  2.6709e-01,  9.0430e-01, -7.9297e-01],
          [ 6.3818e-01, -2.4463e-01,  1.1572e+00,  ..., -1.3684e-01,  1.1487e-01, -5.7910e-01],
          [-6.9824e-02, -2.6733e-01,  2.3398e+00,  ...,  2.1619e-01,  8.6475e-01,  1.0732e+00]],

         ...,

         [[ 2.6904e-01,  2.7979e-01, -8.1836e-01,  ..., -6.3623e-01,  7.0508e-01,  9.9316e-01],
          [ 4.9121e-01,  7.3193e-01,  7.0410e-01,  ..., -8.7793e-01, -2.3047e-01, -5.4297e-01],
          [ 1.9983e-01,  6.0303e-01, -7.5195e-01,  ..., -4.1406e-01, -6.1670e-01,  2.1985e-01],
          ...,
          [ 1.7053e-01,  2.8564e-02, -6.0889e-01,  ...,  6.2793e-01, -2.4976e-01,  8.0566e-01],
          [ 8.0127e-01, -4.6509e-01, -4.2896e-01,  ..., -1.8396e-01, -2.3987e-01, -1.8347e-01],
          [-1.0547e-01, -7.7588e-01,  7.2559e-01,  ..., -9.0918e-01,  5.5225e-01, -2.0840e+00]],

         [[-1.2334e+00, -7.1191e-01, -5.5811e-01,  ...,  1.0638e-01,  8.4766e-01,  5.8594e-01],
          [-1.6631e+00, -2.2461e-01,  9.8291e-01,  ..., -3.4888e-01, -6.9043e-01,  3.2324e-01],
          [ 1.8848e-01, -1.1201e+00,  1.3447e+00,  ..., -1.0498e+00, -7.8955e-01,  6.8066e-01],
          ...,
          [-5.3662e-01,  5.9204e-02,  1.2168e+00,  ..., -1.6338e+00, -7.0312e-01,  1.3203e+00],
          [-6.9385e-01,  1.8701e-01,  1.9714e-01,  ..., -5.3223e-01, -1.1865e+00,  1.3965e-01],
          [-4.5868e-02,  1.1836e+00, -1.4099e-01,  ...,  4.1992e-01, -2.0715e-01, -1.6614e-01]],

         [[ 8.4521e-01, -3.0518e-01, -2.9126e-01,  ..., -7.0508e-01, -3.1860e-01, -8.5645e-01],
          [ 2.6211e+00,  1.1777e+00,  1.3799e+00,  ...,  4.5996e-01, -4.9438e-01, -5.9326e-01],
          [ 6.6162e-01,  7.1289e-01,  4.5508e-01,  ...,  2.0264e-02,  2.9419e-01,  5.4932e-01],
          ...,
          [-1.3584e+00,  6.7261e-02,  1.4932e+00,  ..., -7.9297e-01,  1.6833e-01, -7.8003e-02],
          [-2.5801e+00, -4.6143e-01,  3.3789e-01,  ..., -3.9624e-01,  5.1172e-01,  6.5576e-01],
          [-1.7402e+00, -7.4121e-01, -1.0732e+00,  ...,  2.7588e-01,  2.4658e-01, -3.8745e-01]]],


        [[[ 5.5273e-01, -1.2488e-01,  1.8030e-01,  ..., -5.7178e-01, -8.9355e-01,  6.8787e-02],
          [ 4.5508e-01, -9.2725e-01, -2.1191e-01,  ..., -5.1611e-01, -6.9873e-01,  1.0059e-01],
          [-2.1606e-01,  6.2598e-01,  1.5369e-01,  ..., -4.6051e-02, -1.5234e-01,  1.1064e+00],
          ...,
          [ 3.9844e-01,  3.7964e-01,  1.1094e+00,  ...,  7.2803e-01,  1.8518e-01,  1.5430e+00],
          [-5.1270e-01,  2.4219e-01,  1.5713e+00,  ..., -7.0923e-02, -1.0381e+00,  1.1074e+00],
          [-1.1953e+00, -6.2207e-01,  4.6533e-01,  ..., -6.8018e-01, -1.2324e+00,  5.3857e-01]],

         [[-2.7197e-01, -4.5947e-01, -5.9912e-01,  ..., -6.8506e-01, -9.5020e-01,  8.0420e-01],
          [-1.7102e-01,  5.0928e-01,  1.2524e-01,  ..., -4.2554e-01, -2.2656e+00, -5.1416e-01],
          [-1.9128e-01, -2.4292e-01,  3.3618e-01,  ..., -9.1095e-03, -1.1426e+00, -2.3181e-01],
          ...,
          [ 9.2285e-01,  4.8242e-01, -2.2681e-01,  ..., -1.1768e+00, -6.6992e-01,  8.4180e-01],
          [ 1.5469e+00,  6.4209e-01,  3.7964e-02,  ..., -1.2705e+00,  2.8397e-02, -1.0479e+00],
          [-8.8135e-01, -1.3955e+00, -9.5654e-01,  ..., -1.0684e+00, -4.8267e-01, -7.0703e-01]],

         [[ 4.6362e-01,  1.5320e-02,  2.0386e-01,  ...,  1.9092e-01,  2.9541e-01,  1.6348e+00],
          [-1.9263e-01,  5.1465e-01,  1.9756e+00,  ...,  3.5352e-01,  7.9053e-01,  3.6157e-01],
          [-1.0967e+00,  5.1318e-01, -1.5979e-01,  ..., -8.5059e-01,  7.4121e-01,  7.7295e-01],
          ...,
          [ 3.9673e-02,  2.3608e-01,  9.8535e-01,  ..., -9.7107e-02,  4.2578e-01,  7.5488e-01],
          [ 5.9967e-02, -8.6914e-02,  1.8271e+00,  ...,  1.1602e+00,  4.3994e-01,  7.4805e-01],
          [-1.0107e+00,  3.0957e-01, -1.7383e-01,  ..., -1.1211e+00, -2.1328e+00,  5.5566e-01]],

         ...,

         [[ 1.1694e-01,  7.3584e-01,  5.4004e-01,  ..., -6.5723e-01, -2.3750e+00, -2.5020e+00],
          [-1.2422e+00, -1.3447e+00, -1.0120e-01,  ...,  6.8408e-01, -1.0342e+00, -3.9917e-01],
          [-2.4170e-01, -1.8970e-01,  3.1738e-01,  ..., -9.3945e-01,  1.6943e-01, -2.3315e-01],
          ...,
          [-1.0566e+00, -1.1777e+00,  9.9170e-01,  ...,  4.9146e-01,  1.7227e+00,  4.2822e-01],
          [-8.5889e-01, -4.6240e-01, -1.9531e-02,  ...,  2.8882e-01,  6.7822e-01, -7.5806e-02],
          [-1.6807e+00,  1.7559e+00,  6.4697e-01,  ...,  4.9121e-01,  4.0820e-01,  8.4839e-02]],

         [[ 7.0801e-01, -7.5000e-01,  7.3633e-01,  ...,  1.8921e-01,  6.7285e-01, -2.7891e+00],
          [-1.1865e+00, -2.3254e-01,  9.7998e-01,  ...,  8.6365e-02, -1.3340e+00, -1.6650e+00],
          [-5.7910e-01, -3.7451e-01, -6.8555e-01,  ...,  1.3203e+00, -9.6924e-01, -4.3030e-02],
          ...,
          [ 1.0879e+00,  9.9609e-01,  1.2705e+00,  ..., -1.1260e+00,  1.6272e-01, -7.1387e-01],
          [-1.7734e+00,  6.1426e-01,  3.3496e-01,  ..., -1.0146e+00,  3.1763e-01,  1.4805e+00],
          [ 4.8779e-01,  3.3130e-01,  1.0996e+00,  ..., -1.9409e-02,  1.8076e+00,  7.6758e-01]],

         [[ 1.0928e+00,  1.7773e+00, -4.7388e-01,  ..., -1.0557e+00,  6.0242e-02,  8.2886e-02],
          [ 7.5244e-01, -7.1143e-01,  5.6689e-01,  ..., -1.3369e+00,  1.9849e-01,  8.1738e-01],
          [ 1.6621e+00, -7.5146e-01,  5.3662e-01,  ...,  5.3027e-01,  9.5020e-01,  1.4170e+00],
          ...,
          [ 1.6045e+00,  5.1270e-01, -3.1006e-01,  ..., -1.2085e-02,  6.4307e-01,  4.9097e-01],
          [-1.8518e-01, -1.1748e+00,  4.1284e-01,  ..., -8.2422e-01, -9.5166e-01,  1.1582e+00],
          [ 4.8340e-01, -3.0200e-01, -9.3323e-02,  ..., -2.4927e-01, -3.1396e-01,  1.3550e-01]]],


        [[[-1.7393e+00, -1.5371e+00, -3.8989e-01,  ..., -4.3640e-02,  4.0186e-01,  1.0615e+00],
          [-2.4231e-01,  2.5366e-01, -2.4805e-01,  ..., -2.0654e-01, -9.2090e-01,  1.0068e+00],
          [ 7.1191e-01,  9.8486e-01, -3.1445e-01,  ..., -5.9570e-02, -5.7324e-01, -3.3081e-01],
          ...,
          [ 1.0283e+00,  1.0571e-01,  1.0083e-01,  ..., -2.4622e-01, -8.9648e-01,  7.3181e-02],
          [-1.8477e+00,  4.2664e-02,  8.2861e-01,  ...,  2.0850e-01, -1.5796e-01,  2.2510e-01],
          [-1.7393e+00, -1.0078e+00,  3.3130e-01,  ...,  3.6987e-01, -2.7759e-01,  7.8711e-01]],

         [[-2.3901e-01, -8.7598e-01,  9.4971e-01,  ..., -5.6299e-01,  8.3252e-01, -1.2812e+00],
          [ 1.9495e-01, -6.2256e-01,  3.6426e-01,  ..., -9.8511e-02,  4.6411e-01,  9.1846e-01],
          [-9.6436e-01, -1.8555e+00, -5.6152e-01,  ...,  4.6973e-01, -1.6174e-01,  1.2500e+00],
          ...,
          [-1.2998e+00, -7.8516e-01, -2.3267e-01,  ...,  8.0994e-02,  9.5459e-02,  2.0430e+00],
          [-1.7461e+00, -1.6123e+00, -1.7603e-01,  ...,  3.2471e-01,  3.5913e-01,  5.1123e-01],
          [-1.2490e+00, -8.8428e-01,  1.2666e+00,  ...,  1.2441e+00,  2.7891e+00,  3.8110e-01]],

         [[-8.3203e-01, -1.7334e+00, -3.8989e-01,  ...,  1.1841e-02, -4.2090e-01, -4.5312e-01],
          [-1.5420e+00, -4.4385e-01, -3.8867e-01,  ..., -3.8989e-01, -5.4346e-01, -1.0439e+00],
          [-1.1133e+00,  3.8989e-01, -1.0000e+00,  ...,  6.2500e-01,  3.8672e-01,  9.0942e-02],
          ...,
          [ 7.7734e-01,  3.3789e-01, -5.2295e-01,  ..., -3.7939e-01, -7.7148e-01, -9.6777e-01],
          [ 1.7807e-02, -1.2490e+00, -3.1104e-01,  ..., -9.0088e-01,  7.7881e-01, -9.8047e-01],
          [-1.1631e+00, -1.2256e+00, -8.0029e-01,  ..., -1.3257e-01, -8.3203e-01, -1.5234e+00]],

         ...,

         [[-9.5166e-01, -1.5332e-01, -2.4683e-01,  ..., -5.7227e-01, -6.6113e-01, -5.6396e-01],
          [ 1.3887e+00,  5.3564e-01,  6.5979e-02,  ...,  9.9609e-01,  2.1313e-01, -3.6133e-01],
          [-3.2886e-01,  1.2080e+00,  8.9697e-01,  ...,  4.3213e-01,  3.4717e-01,  1.9189e-01],
          ...,
          [ 1.6416e+00, -2.6123e-01,  3.5010e-01,  ..., -3.6108e-01, -1.4197e-01,  3.5913e-01],
          [ 1.9004e+00,  1.7285e+00,  1.0195e+00,  ..., -3.3789e-01,  7.7734e-01,  4.5020e-01],
          [ 1.2012e-01, -1.0449e-01,  1.1592e+00,  ..., -9.2041e-01, -8.5205e-01,  1.0977e+00]],

         [[-7.7393e-01,  5.2393e-01,  4.1968e-01,  ..., -6.9336e-01,  1.5564e-01, -1.5928e+00],
          [ 2.6074e-01,  3.3203e-01,  9.7046e-03,  ..., -1.1768e-01, -1.2148e+00, -5.3516e-01],
          [ 1.1992e+00, -5.0659e-02, -1.0195e+00,  ..., -5.4199e-01, -1.1934e+00,  5.1300e-02],
          ...,
          [-4.6484e-01, -1.0957e+00, -3.8135e-01,  ...,  9.3408e-01,  4.6191e-01,  3.4766e-01],
          [-4.9414e-01, -1.9580e-01,  3.8818e-01,  ...,  2.4463e-01,  1.3506e+00,  5.3760e-01],
          [-1.8005e-02,  5.2393e-01,  6.1621e-01,  ..., -1.2139e+00,  9.7656e-04,  1.7273e-01]],

         [[-8.8623e-01,  1.1211e+00,  3.9124e-02,  ...,  3.5645e-01,  2.2090e+00,  2.9736e-01],
          [-2.9932e-01,  4.6484e-01,  3.9062e-01,  ..., -7.7344e-01, -3.3838e-01,  1.6240e+00],
          [-2.1130e-01,  7.2754e-01, -3.8330e-01,  ..., -3.9209e-01, -1.3721e+00,  5.2637e-01],
          ...,
          [ 1.2158e+00,  9.9707e-01, -3.7329e-01,  ..., -2.3438e-02,  5.0391e-01,  8.9209e-01],
          [ 3.9795e-01,  1.8115e+00,  5.6396e-01,  ...,  1.4512e+00,  1.7236e+00,  6.6895e-01],
          [-8.4656e-02,  3.7598e-01,  2.3291e-01,  ...,  6.0352e-01,  6.6943e-01, -1.0918e+00]]]], dtype=torch.float16)

2025-06-10 00:13:32.889125 GPU 5 156018 test begin: paddle.nn.functional.interpolate(Tensor([4, 2, 128, 128],"float16"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 2, 128, 128],"float16"), list[512,512,], mode="bilinear", align_corners=False, data_format="NCHW", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 343 / 131072 (0.3%)
Greatest absolute difference: 0.04296875 at index (0, 0, 55, 102) (up to 0.01 allowed)
Greatest relative difference: 1.92578125 at index (1, 1, 62, 125) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 2, 128, 128]), dtype=torch.float16)
tensor([[[[-1.2012, -0.1417,  0.3455,  ..., -0.2035, -1.1572,  1.8672],
          [-0.0368,  0.3970,  0.0934,  ...,  0.0509, -0.6606, -0.6328],
          [ 1.8008, -0.2264, -0.2944,  ..., -0.4102,  0.2876, -0.9438],
          ...,
          [ 0.1831,  1.0225, -0.3323,  ...,  0.4326,  0.6655, -1.1689],
          [ 0.7695,  0.5391, -0.1899,  ..., -0.1232,  1.5791, -0.5298],
          [-0.6006,  0.0607,  0.4336,  ...,  0.8140,  1.3164, -1.7529]],

         [[ 0.6597,  1.0879,  0.0135,  ...,  0.7598,  0.9092, -0.0600],
          [-0.1569, -0.5161, -0.7007,  ..., -1.0547, -0.2129,  0.2234],
          [-0.7192,  0.9849, -0.0421,  ...,  0.1428,  0.2162, -0.2983],
          ...,
          [-0.6831, -0.6572, -1.4473,  ...,  1.7676,  0.6543, -0.6709],
          [-0.5967, -0.0261, -0.4126,  ...,  1.0469,  1.1973,  0.7114],
          [-0.0942, -0.6157, -0.8916,  ..., -0.9614, -0.4878,  0.2434]]],


        [[[-1.2520,  0.4211,  0.0117,  ...,  0.5571,  0.6421, -1.0771],
          [-0.7056, -1.5781,  0.2532,  ..., -0.9399, -0.4661, -0.5142],
          [ 0.3562, -0.8486,  0.7163,  ..., -0.2202, -0.5508, -0.1760],
          ...,
          [-1.1416,  0.1425,  1.6836,  ...,  0.6582,  0.4104,  0.6011],
          [ 0.0429, -0.0799, -2.0625,  ..., -0.1439, -0.0296, -0.6367],
          [ 1.5186, -0.1128, -1.8320,  ..., -0.1660, -0.5186, -0.4165]],

         [[ 0.8926,  0.5898,  1.2412,  ..., -1.1455,  1.3340, -0.1866],
          [ 0.7837,  0.8101,  0.6133,  ..., -0.6118,  0.0876,  0.4812],
          [ 0.1249,  1.4199, -0.1041,  ...,  0.6616,  0.2776,  0.0836],
          ...,
          [ 0.4648,  1.4482,  0.7627,  ..., -0.7129, -1.3789,  0.4595],
          [-0.1910,  0.3660,  0.5444,  ..., -0.7031, -1.4277,  0.5664],
          [-0.2136,  1.0518, -0.0937,  ...,  0.2585, -0.4087,  0.8311]]],


        [[[ 0.4258,  1.5342, -0.3567,  ..., -0.3059, -1.0000, -1.3838],
          [-0.1396,  0.5127, -0.2352,  ...,  0.2308, -0.2546, -1.1328],
          [ 0.3862, -0.3828,  0.2808,  ...,  0.3389, -0.2444, -1.6660],
          ...,
          [ 0.3953, -0.4177,  0.3652,  ...,  0.5596, -0.5278,  1.6738],
          [ 0.4495,  0.4509,  1.2852,  ...,  0.5298,  0.7842,  0.4016],
          [ 0.3064, -0.4214, -0.1548,  ...,  0.0788,  1.4365, -0.8394]],

         [[ 0.8809,  1.3730,  1.2998,  ..., -0.6040,  0.1080, -1.3887],
          [ 0.6318,  0.8633,  1.7471,  ...,  0.6992,  1.0361, -0.3240],
          [-0.0233, -0.4102, -0.4006,  ..., -0.2229,  1.1807,  0.5986],
          ...,
          [ 0.7847,  0.7974,  0.3381,  ..., -0.5698, -0.4060, -0.2361],
          [ 1.1973,  0.1740,  0.4004,  ..., -0.4985,  0.6724, -1.2852],
          [ 1.4082,  0.4697,  0.4563,  ..., -0.1192,  0.5913, -0.2625]]],


        [[[ 1.9971,  0.8726, -0.8887,  ..., -0.0090, -0.6343,  0.2715],
          [-0.4009,  1.4736,  0.2703,  ..., -0.4910, -0.4663,  0.6802],
          [-0.0797,  0.2253,  0.5049,  ..., -0.9263, -0.5005,  0.6758],
          ...,
          [ 0.2969,  0.5493,  0.7183,  ...,  0.1963,  1.3438,  1.2236],
          [ 0.5659,  0.3259,  0.8032,  ..., -0.1534, -0.2029,  1.0137],
          [ 0.4036, -1.6973, -0.6372,  ..., -0.0977, -1.0859, -0.2250]],

         [[ 0.5791, -1.3447, -0.8760,  ..., -0.1901, -0.7031,  0.8091],
          [ 1.3340, -0.7373, -1.6113,  ...,  0.0378,  0.9146,  0.4636],
          [ 0.4429,  0.0759, -1.0566,  ...,  0.9722,  0.6519,  0.3420],
          ...,
          [ 0.3308,  1.3066,  1.3125,  ..., -0.4160,  1.8525, -0.1749],
          [-0.5503, -1.0322, -0.2817,  ..., -0.6182,  0.5830, -1.6240],
          [-1.7148, -0.6392,  0.1815,  ...,  1.2939,  0.6787, -0.9995]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 2, 128, 128]), dtype=torch.float16)
tensor([[[[-1.2090, -0.1404,  0.3508,  ..., -0.2073, -1.1729,  1.8926],
          [-0.0414,  0.3960,  0.0949,  ...,  0.0532, -0.6689, -0.6431],
          [ 1.8154, -0.2246, -0.2952,  ..., -0.4143,  0.2900, -0.9512],
          ...,
          [ 0.1833,  1.0312, -0.3364,  ...,  0.4353,  0.6724, -1.1826],
          [ 0.7759,  0.5508, -0.1901,  ..., -0.1257,  1.5986, -0.5371],
          [-0.6045,  0.0531,  0.4285,  ...,  0.8213,  1.3350, -1.7617]],

         [[ 0.6650,  1.1006,  0.0161,  ...,  0.7676,  0.9175, -0.0597],
          [-0.1544, -0.5225, -0.7085,  ..., -1.0684, -0.2133,  0.2275],
          [-0.7241,  0.9980, -0.0434,  ...,  0.1431,  0.2180, -0.3037],
          ...,
          [-0.6885, -0.6641, -1.4648,  ...,  1.7842,  0.6606, -0.6826],
          [-0.6006, -0.0246, -0.4146,  ...,  1.0635,  1.2129,  0.7197],
          [-0.0976, -0.6211, -0.9038,  ..., -0.9697, -0.4907,  0.2484]]],


        [[[-1.2686,  0.4316,  0.0120,  ...,  0.5654,  0.6499, -1.0859],
          [-0.7114, -1.5996,  0.2539,  ..., -0.9507, -0.4709, -0.5229],
          [ 0.3555, -0.8560,  0.7236,  ..., -0.2228, -0.5581, -0.1741],
          ...,
          [-1.1533,  0.1436,  1.7021,  ...,  0.6626,  0.4138,  0.6055],
          [ 0.0405, -0.0800, -2.0781,  ..., -0.1449, -0.0271, -0.6445],
          [ 1.5332, -0.1118, -1.8486,  ..., -0.1631, -0.5215, -0.4148]],

         [[ 0.8979,  0.5952,  1.2549,  ..., -1.1543,  1.3535, -0.1904],
          [ 0.7891,  0.8169,  0.6211,  ..., -0.6182,  0.0887,  0.4893],
          [ 0.1260,  1.4375, -0.1043,  ...,  0.6689,  0.2793,  0.0812],
          ...,
          [ 0.4685,  1.4639,  0.7705,  ..., -0.7148, -1.3945,  0.4634],
          [-0.1934,  0.3704,  0.5522,  ..., -0.7183, -1.4424,  0.5747],
          [-0.2111,  1.0596, -0.0947,  ...,  0.2620, -0.4194,  0.8335]]],


        [[[ 0.4294,  1.5508, -0.3601,  ..., -0.3074, -1.0176, -1.4004],
          [-0.1423,  0.5205, -0.2373,  ...,  0.2295, -0.2534, -1.1436],
          [ 0.3901, -0.3892,  0.2827,  ...,  0.3430, -0.2483, -1.6875],
          ...,
          [ 0.3972, -0.4253,  0.3674,  ...,  0.5664, -0.5352,  1.6875],
          [ 0.4536,  0.4565,  1.3027,  ...,  0.5332,  0.7910,  0.4121],
          [ 0.3079, -0.4268, -0.1589,  ...,  0.0805,  1.4561, -0.8433]],

         [[ 0.8872,  1.3906,  1.3135,  ..., -0.6118,  0.1095, -1.4082],
          [ 0.6377,  0.8740,  1.7607,  ...,  0.7036,  1.0439, -0.3286],
          [-0.0220, -0.4126, -0.4021,  ..., -0.2229,  1.1973,  0.6074],
          ...,
          [ 0.7896,  0.8086,  0.3384,  ..., -0.5762, -0.4097, -0.2378],
          [ 1.2070,  0.1741,  0.3999,  ..., -0.5024,  0.6797, -1.2998],
          [ 1.4209,  0.4800,  0.4653,  ..., -0.1252,  0.5942, -0.2617]]],


        [[[ 2.0176,  0.8813, -0.8950,  ..., -0.0090, -0.6401,  0.2754],
          [-0.4014,  1.4893,  0.2705,  ..., -0.4944, -0.4746,  0.6846],
          [-0.0838,  0.2291,  0.5156,  ..., -0.9341, -0.5034,  0.6831],
          ...,
          [ 0.3003,  0.5591,  0.7266,  ...,  0.1984,  1.3584,  1.2354],
          [ 0.5693,  0.3320,  0.8149,  ..., -0.1539, -0.2031,  1.0215],
          [ 0.4111, -1.7109, -0.6436,  ..., -0.1022, -1.0967, -0.2209]],

         [[ 0.5811, -1.3584, -0.8804,  ..., -0.1917, -0.7139,  0.8135],
          [ 1.3457, -0.7466, -1.6260,  ...,  0.0373,  0.9238,  0.4751],
          [ 0.4453,  0.0753, -1.0674,  ...,  0.9839,  0.6621,  0.3413],
          ...,
          [ 0.3340,  1.3223,  1.3242,  ..., -0.4160,  1.8721, -0.1721],
          [-0.5527, -1.0410, -0.2803,  ..., -0.6299,  0.5869, -1.6406],
          [-1.7314, -0.6465,  0.1750,  ...,  1.3027,  0.6792, -1.0039]]]], dtype=torch.float16)

2025-06-10 00:13:32.990925 GPU 6 156013 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 16, 16],"float16"), size=list[64,64,], mode="bilinear", )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 256, 16, 16],"float16"), size=list[64,64,], mode="bilinear", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 747 / 262144 (0.3%)
Greatest absolute difference: 0.044921875 at index (1, 78, 0, 10) (up to 0.01 allowed)
Greatest relative difference: 1.5244140625 at index (2, 127, 15, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 256, 16, 16]), dtype=torch.float16)
tensor([[[[-2.5952e-01,  3.2935e-01,  1.6516e-01,  ..., -7.4023e-01,  1.3916e-02, -9.7119e-01],
          [-2.7124e-01,  1.0771e+00,  5.9619e-01,  ...,  7.0605e-01,  1.1975e-01, -1.5271e-01],
          [ 1.2793e+00,  1.1777e+00, -1.0020e+00,  ...,  3.7085e-01,  1.7639e-02, -8.6548e-02],
          ...,
          [-7.2449e-02,  1.6858e-01,  3.7964e-02,  ...,  7.4609e-01,  1.4014e+00, -1.6211e+00],
          [ 2.4746e+00,  1.6455e+00, -1.7554e-01,  ..., -6.9385e-01, -9.2432e-01, -3.8135e-01],
          [-1.4685e-01,  3.3905e-02,  7.1228e-02,  ...,  2.9639e-01,  2.9175e-01, -6.3721e-01]],

         [[ 1.1709e+00, -3.1030e-01,  1.4717e+00,  ..., -3.1152e-01,  2.6733e-01,  1.2244e-01],
          [ 2.8320e-01, -6.4014e-01,  4.9658e-01,  ...,  3.9355e-01,  8.4814e-01,  2.9688e-01],
          [ 5.5762e-01, -9.7900e-01, -8.4033e-01,  ...,  4.4995e-01,  3.5962e-01,  4.8730e-01],
          ...,
          [-8.3008e-01, -2.5537e-01, -8.0811e-01,  ...,  6.2061e-01,  3.0737e-01, -4.4604e-01],
          [-3.7964e-01,  2.6953e-01,  1.6143e+00,  ..., -1.5106e-03,  3.4668e-02, -4.7583e-01],
          [-1.4219e+00, -4.3945e-01,  1.6182e+00,  ..., -4.4434e-01, -6.1719e-01, -1.2773e+00]],

         [[ 7.9248e-01,  1.0781e+00,  2.1948e-01,  ...,  1.3467e+00,  1.0498e+00,  4.5630e-01],
          [-3.9331e-01,  7.3340e-01,  6.6797e-01,  ...,  1.8884e-01, -1.5703e+00, -5.7220e-02],
          [ 8.4131e-01,  2.0096e-02, -1.0181e-01,  ..., -2.8003e-01, -1.2334e+00,  1.1084e-01],
          ...,
          [ 1.0596e+00, -3.1445e-01, -1.1658e-01,  ..., -2.2913e-01, -1.6101e-01,  4.0576e-01],
          [ 9.9561e-01, -1.3086e-01,  2.1033e-01,  ...,  9.6826e-01,  1.9983e-01, -1.4902e+00],
          [ 6.7334e-01,  1.5918e+00, -1.2412e+00,  ...,  1.2910e+00,  1.7061e+00,  6.0205e-01]],

         ...,

         [[ 1.2637e+00, -1.1016e+00,  2.7173e-01,  ...,  8.5889e-01, -4.7778e-01,  2.5684e-01],
          [ 2.0000e+00, -8.2910e-01,  6.7090e-01,  ...,  3.4937e-01,  3.2349e-01, -2.6050e-01],
          [-2.1558e-01, -7.6611e-01,  4.9097e-01,  ...,  1.3594e+00,  1.4980e+00, -1.3076e+00],
          ...,
          [-1.2781e-01,  2.5830e-01, -4.3408e-01,  ...,  1.0518e+00,  1.5459e+00,  1.3928e-01],
          [ 1.2861e+00,  5.8301e-01,  5.4102e-01,  ...,  1.1689e+00,  1.7090e-01,  1.3086e+00],
          [-3.5034e-01, -6.1816e-01, -3.4399e-01,  ...,  1.2637e+00,  1.2178e+00,  4.8364e-01]],

         [[ 6.8457e-01,  2.5223e-02,  7.7832e-01,  ..., -1.1768e+00,  2.0645e+00,  1.9365e+00],
          [-5.6934e-01,  1.5967e-01, -5.0830e-01,  ..., -1.1719e+00, -4.7119e-01,  1.2158e+00],
          [-1.5427e-02,  6.1914e-01,  1.2949e+00,  ..., -1.3887e+00,  3.6230e-01, -1.6235e-01],
          ...,
          [ 1.2217e+00,  7.2412e-01, -7.9443e-01,  ..., -3.3740e-01, -4.2578e-01, -6.7529e-01],
          [-8.2642e-02,  8.2703e-02,  2.2571e-01,  ..., -1.1743e-01, -2.5195e-01,  1.3877e+00],
          [ 7.3926e-01,  1.5247e-01, -7.5879e-01,  ..., -8.3691e-01, -1.0723e+00,  1.6882e-01]],

         [[-1.0654e+00, -3.7524e-01,  8.2861e-01,  ...,  6.7529e-01, -1.0420e+00,  1.5312e+00],
          [-6.5674e-01,  4.3799e-01, -2.7664e-02,  ...,  2.1934e+00,  6.4893e-01,  1.6855e+00],
          [ 9.1992e-01, -2.3987e-01, -6.9141e-01,  ...,  1.1367e+00, -6.6553e-01, -7.2070e-01],
          ...,
          [-1.2299e-02, -3.5669e-01,  8.1836e-01,  ..., -2.5391e-01,  4.8560e-01,  2.8223e-01],
          [ 7.2803e-01,  9.5605e-01, -3.9844e-01,  ..., -1.1152e+00, -1.0828e-01, -1.3306e-01],
          [ 5.8447e-01, -9.6130e-02, -6.8799e-01,  ...,  3.8232e-01, -2.5952e-01, -9.8926e-01]]],


        [[[-7.5244e-01,  6.2549e-01,  7.6562e-01,  ..., -2.6953e-01, -3.2422e-01,  9.1858e-02],
          [-3.9038e-01, -1.8707e-02, -4.1333e-01,  ...,  8.2275e-01,  3.1274e-01, -7.4170e-01],
          [-1.0674e+00, -1.2915e-01, -5.0391e-01,  ...,  3.5083e-01,  7.0117e-01, -3.2129e-01],
          ...,
          [ 1.6699e-01,  1.3281e+00, -3.1055e-01,  ..., -3.3984e-01, -1.3467e+00,  2.2156e-01],
          [-4.7046e-01,  4.4312e-01, -7.6416e-02,  ..., -6.6846e-01,  5.5127e-01,  1.4636e-01],
          [-9.8096e-01,  8.7769e-02,  4.2065e-01,  ..., -9.9756e-01, -2.2681e-01,  5.0195e-01]],

         [[ 5.3857e-01, -6.2646e-01,  3.8513e-02,  ..., -1.2979e+00, -1.4092e+00, -1.6129e-02],
          [ 9.6924e-01, -5.3809e-01,  2.6172e-01,  ..., -7.6562e-01, -2.5854e-01, -1.6846e+00],
          [ 1.4326e+00,  9.8572e-02,  1.2024e-02,  ...,  3.7378e-01, -8.7646e-01,  5.4834e-01],
          ...,
          [-8.6670e-01,  2.1289e-01, -4.3970e-01,  ..., -1.1432e-01,  5.4932e-01,  4.0259e-01],
          [-1.0205e-01, -3.7671e-01, -8.8684e-02,  ...,  9.7852e-01, -2.1619e-01,  5.3467e-01],
          [-5.4053e-01, -1.7119e+00, -1.7275e+00,  ...,  1.1865e+00, -1.2598e-01,  1.3306e-01]],

         [[-1.7354e+00, -9.5337e-02,  6.3818e-01,  ...,  2.9272e-01, -9.1113e-01,  1.9983e-01],
          [ 1.2529e+00, -3.3203e-01, -1.2067e-01,  ..., -5.1239e-02, -5.8008e-01, -2.4634e-01],
          [ 3.5736e-02, -8.7744e-01, -3.3228e-01,  ...,  8.7842e-01,  7.6953e-01,  7.0996e-01],
          ...,
          [ 2.9565e-01, -1.1846e+00,  3.1592e-01,  ...,  8.2568e-01,  1.4248e+00,  9.4299e-02],
          [ 1.4922e+00,  8.7842e-01,  8.7012e-01,  ...,  8.3008e-01,  5.8252e-01, -1.9760e-02],
          [-1.0557e+00, -2.8027e-01,  5.5225e-01,  ...,  1.6455e-01,  1.2109e+00,  3.5327e-01]],

         ...,

         [[ 1.2002e+00, -6.1426e-01, -3.1738e-01,  ..., -1.2900e+00, -1.2744e+00,  8.9844e-02],
          [ 8.0469e-01, -8.0420e-01, -3.2153e-01,  ..., -8.5889e-01, -2.3026e-02,  8.6621e-01],
          [-2.3691e+00, -8.3887e-01,  2.3987e-01,  ...,  2.7026e-01,  9.4092e-01, -2.1619e-01],
          ...,
          [-4.5972e-01, -1.1836e+00, -4.3896e-01,  ..., -9.9792e-02, -3.6377e-01, -6.6016e-01],
          [ 1.3711e+00,  2.6953e-01,  9.1064e-01,  ...,  4.5947e-01, -5.0928e-01, -9.3457e-01],
          [-6.6406e-01,  1.0127e+00,  2.4536e-01,  ..., -4.8828e-01,  3.1836e-01, -1.4346e+00]],

         [[-7.7148e-02, -4.7998e-01, -8.4229e-01,  ...,  4.0698e-01, -3.7695e-01,  6.5283e-01],
          [-1.0654e+00,  3.6646e-01, -2.6932e-02,  ..., -6.2744e-02,  1.3293e-01, -6.4600e-01],
          [ 2.4438e-01,  1.0583e-01,  7.4170e-01,  ..., -7.8979e-02, -3.8159e-01,  3.9331e-01],
          ...,
          [ 1.1758e+00,  7.2266e-01,  6.6528e-02,  ..., -9.9854e-01,  1.3369e+00, -6.9238e-01],
          [ 1.9648e+00,  3.6816e-01, -9.6313e-02,  ...,  6.3281e-01, -1.6455e-01, -1.2646e+00],
          [ 6.4111e-01, -2.2534e-01,  6.3232e-02,  ...,  1.5664e+00,  1.9653e-01, -1.2773e+00]],

         [[-5.3223e-01, -5.7715e-01, -5.7227e-01,  ..., -3.4717e-01, -4.6143e-01, -1.2067e-01],
          [ 9.3213e-01,  6.7578e-01, -3.4985e-01,  ..., -3.2227e-01, -2.7954e-01, -4.6191e-01],
          [ 1.0830e+00,  4.7900e-01, -5.6250e-01,  ...,  6.9678e-01,  4.9707e-01,  3.6743e-01],
          ...,
          [ 2.6760e-03,  3.8062e-01, -5.9961e-01,  ...,  1.7410e-02,  2.1594e-01, -1.3418e+00],
          [ 2.8638e-01,  2.6538e-01,  6.2305e-01,  ...,  2.5610e-01,  6.8799e-01,  9.9268e-01],
          [-7.2412e-01, -4.2969e-01,  7.0117e-01,  ...,  5.0537e-01, -6.0010e-01, -5.5615e-01]]],


        [[[-1.6248e-01,  5.9619e-01,  4.5746e-02,  ...,  8.5205e-01, -2.2021e-01, -5.5713e-01],
          [ 7.6318e-01, -6.9678e-01, -8.7402e-01,  ...,  7.1680e-01,  1.5857e-01, -1.6377e+00],
          [ 8.7354e-01, -5.4883e-01, -2.1953e+00,  ...,  3.3228e-01,  5.9717e-01,  3.8013e-01],
          ...,
          [-1.0488e+00,  1.0537e+00,  1.7542e-01,  ..., -1.4355e+00,  8.0420e-01,  7.1338e-01],
          [-4.7827e-01,  3.2080e-01, -3.0472e-02,  ..., -1.6760e-01, -7.4268e-01, -5.2979e-01],
          [-1.0488e+00, -5.4443e-01,  2.7661e-01,  ..., -6.3818e-01,  2.3572e-01,  5.9717e-01]],

         [[-4.9878e-01, -1.3721e+00,  6.4600e-01,  ...,  2.4170e-01, -3.0200e-01,  1.7261e-01],
          [-1.0303e+00,  2.1069e-01, -2.9883e-01,  ..., -5.5176e-01, -2.2266e-01, -3.8989e-01],
          [-1.4912e+00, -5.7178e-01,  7.7286e-03,  ..., -2.8369e-01, -2.8931e-01,  2.6367e-01],
          ...,
          [ 1.0576e+00,  9.4043e-01,  1.8982e-01,  ...,  7.5586e-01,  2.9938e-02, -5.5664e-01],
          [ 1.8369e+00,  5.4199e-01, -9.8975e-01,  ..., -8.9417e-02, -1.1836e+00, -1.4727e+00],
          [ 1.6260e+00,  5.4492e-01,  3.1250e-01,  ...,  1.0322e+00, -3.5156e-01, -8.9014e-01]],

         [[-1.8835e-01, -5.9961e-01, -1.8770e+00,  ..., -4.8804e-01,  8.7842e-01, -5.8887e-01],
          [-1.1780e-01,  2.4695e-01, -4.0723e-01,  ..., -5.0391e-01, -6.4990e-01,  2.8540e-01],
          [ 6.0303e-01,  1.1279e-01, -3.5400e-01,  ..., -1.1719e+00, -8.4045e-02,  6.0303e-01],
          ...,
          [ 2.5903e-01,  1.2529e+00,  1.3701e+00,  ..., -1.3916e+00, -5.3760e-01,  1.1182e-01],
          [ 2.1814e-01, -2.9297e-01, -1.9348e-01,  ..., -7.7051e-01,  2.2290e-01,  7.1240e-01],
          [-4.0356e-01,  1.5186e-01,  1.5459e+00,  ...,  4.4604e-01, -5.9326e-01,  5.5322e-01]],

         ...,

         [[-2.1350e-01,  4.8291e-01, -9.3506e-01,  ...,  1.1920e-01, -1.5381e+00, -7.5146e-01],
          [ 1.6357e-01, -1.2031e+00,  3.2812e-01,  ...,  7.0361e-01,  8.2617e-01,  7.6562e-01],
          [ 1.9470e-01, -5.4297e-01, -7.2217e-01,  ...,  6.9971e-01,  9.9707e-01, -1.5732e+00],
          ...,
          [ 5.0781e-01,  1.0382e-01,  1.9568e-01,  ...,  2.3901e-01, -6.4697e-01,  1.6006e+00],
          [-7.8125e-01, -2.0752e-01, -1.0254e+00,  ..., -3.2520e-01,  2.2827e-01, -5.5664e-01],
          [-6.5186e-01, -7.6611e-01,  1.0785e-01,  ..., -3.1226e-01, -8.7646e-01, -8.2520e-01]],

         [[-2.9199e+00, -9.7705e-01, -1.0586e+00,  ..., -1.4824e+00,  1.7627e+00,  1.5293e+00],
          [-7.6172e-01,  3.7573e-01,  7.6709e-01,  ..., -3.0713e-01,  1.6982e+00,  1.5449e+00],
          [ 1.4316e+00,  1.6279e+00, -1.2329e-01,  ...,  1.6937e-02,  4.8926e-01,  6.9397e-02],
          ...,
          [-7.8711e-01, -8.8672e-01,  4.8828e-01,  ..., -4.0375e-02,  1.3457e+00, -8.3740e-01],
          [-1.9121e+00, -1.2949e+00, -7.4072e-01,  ..., -9.0771e-01, -3.6377e-01, -1.3701e+00],
          [ 7.0508e-01, -1.2256e-01, -6.8457e-01,  ..., -2.0762e+00, -1.5449e+00,  8.6719e-01]],

         [[ 3.9209e-01, -8.4668e-01,  8.6719e-01,  ..., -5.5176e-01,  2.4841e-01,  1.0332e+00],
          [ 6.0254e-01, -5.1666e-02,  2.6367e-01,  ...,  1.6553e+00,  1.7129e+00,  7.2144e-02],
          [-1.1680e+00,  9.5215e-01,  1.3486e+00,  ...,  1.9580e+00,  2.9761e-01, -8.9307e-01],
          ...,
          [-7.6172e-01,  5.3955e-01, -6.3721e-01,  ..., -1.4316e+00,  2.6245e-02,  7.1094e-01],
          [-6.7773e-01, -5.6396e-01,  2.0618e-01,  ..., -2.5879e-02,  5.9998e-02,  1.5254e+00],
          [-9.4824e-01, -1.5996e+00, -4.1553e-01,  ..., -5.6201e-01,  4.9292e-01, -1.1729e+00]]],


        [[[ 1.5879e+00,  3.7305e-01,  6.0840e-01,  ..., -1.5400e+00, -4.1895e-01, -4.0063e-01],
          [-2.1753e-01,  6.1621e-01, -1.5957e+00,  ..., -2.5244e-01, -4.4971e-01, -4.5776e-01],
          [-5.4053e-01, -1.5479e-01,  9.5410e-01,  ...,  8.9404e-01,  2.8320e-01,  1.5166e+00],
          ...,
          [-1.7065e-01,  4.7388e-01, -4.3408e-01,  ..., -2.2803e-01,  5.3406e-03, -5.2979e-01],
          [-3.7769e-01,  6.1328e-01, -1.2878e-01,  ...,  9.1748e-01,  2.7637e-01, -4.1235e-01],
          [-1.8330e+00, -1.0107e+00,  7.7148e-01,  ..., -4.7021e-01, -5.4736e-01, -1.0518e+00]],

         [[-1.5898e+00, -7.0264e-01,  2.0142e-01,  ..., -4.0479e-01,  2.1055e+00,  2.8296e-01],
          [-2.1367e+00, -1.2021e+00, -1.7261e-01,  ..., -5.8008e-01,  6.0889e-01, -4.9414e-01],
          [-7.6025e-01, -5.2637e-01, -1.7029e-01,  ..., -3.4375e-01,  9.0723e-01,  4.0308e-01],
          ...,
          [-2.3206e-01,  1.2168e+00, -3.3264e-02,  ...,  4.7998e-01,  1.1890e-01,  4.4873e-01],
          [ 9.8828e-01,  1.4531e+00,  1.3350e+00,  ...,  1.3037e+00,  1.4912e+00,  1.3281e-01],
          [-1.9153e-01,  1.4941e-01,  3.6597e-01,  ...,  2.5234e+00,  8.9893e-01, -9.4971e-01]],

         [[-1.3525e+00,  8.1836e-01, -1.6711e-01,  ...,  1.5283e+00, -5.6787e-01, -1.8896e-01],
          [-5.1270e-01, -7.2168e-01, -1.5352e+00,  ...,  4.8022e-01, -6.0059e-01,  1.0101e-02],
          [ 9.3164e-01,  6.3660e-02,  1.1641e+00,  ...,  1.1951e-01,  2.1988e-02, -2.3584e-01],
          ...,
          [ 3.3984e-01,  5.5878e-02, -1.6382e-01,  ..., -7.6758e-01,  4.0503e-01,  8.1543e-01],
          [ 4.1309e-01,  8.1689e-01, -9.9976e-02,  ..., -1.3330e+00, -1.1395e-01,  1.0049e+00],
          [ 9.7473e-02,  7.9883e-01,  6.4844e-01,  ...,  8.3984e-02,  1.7664e-01, -2.2891e+00]],

         ...,

         [[-1.3379e-01,  1.2588e+00, -5.0977e-01,  ..., -1.6235e-02,  1.4990e+00, -3.1281e-02],
          [ 1.8604e+00, -1.0850e+00,  4.5502e-02,  ...,  7.8918e-02,  5.4785e-01, -6.1719e-01],
          [ 7.2327e-02, -4.4946e-01, -2.6807e-01,  ..., -6.5234e-01, -6.8408e-01, -6.6748e-01],
          ...,
          [-3.6450e-01, -1.6919e-01, -6.0889e-01,  ..., -6.8164e-01, -2.8442e-01,  9.4824e-01],
          [-6.6113e-01,  5.5371e-01,  3.1616e-01,  ..., -6.2891e-01, -6.4941e-01,  1.4893e-02],
          [ 1.1768e+00,  2.0898e+00,  7.2607e-01,  ..., -7.1729e-01, -8.7207e-01,  4.9500e-02]],

         [[-7.0801e-01,  7.6172e-01,  3.7158e-01,  ...,  6.0840e-01,  2.2144e-01, -9.4287e-01],
          [ 2.0435e-01,  1.5112e-01, -1.0625e+00,  ...,  6.0107e-01,  3.5791e-01,  1.2695e+00],
          [-2.6978e-02, -2.9419e-01,  4.9731e-01,  ..., -9.9902e-01,  4.4409e-01,  8.4619e-01],
          ...,
          [-2.3450e-01,  2.8760e-01,  1.3340e+00,  ..., -7.7087e-02, -2.0156e+00, -2.1504e+00],
          [-1.0605e+00, -5.2637e-01, -8.3496e-02,  ...,  1.9739e-01,  1.4141e+00,  1.7456e-01],
          [ 4.9805e-01, -3.2056e-01, -4.2993e-01,  ...,  3.3594e-01,  1.6113e-01,  2.2473e-01]],

         [[-1.3594e+00, -1.5259e-05, -3.7170e-02,  ...,  5.8887e-01,  1.2927e-01, -4.6387e-01],
          [-1.8945e-01, -1.3708e-01, -4.8904e-03,  ..., -2.1948e-01, -6.0693e-01,  1.1289e+00],
          [-6.2061e-01,  7.5195e-01,  3.3154e-01,  ...,  5.0732e-01, -3.3838e-01, -3.7598e-01],
          ...,
          [-1.1104e+00,  4.8682e-01,  7.1289e-01,  ...,  7.4951e-01, -4.5728e-01, -5.7617e-01],
          [-1.2305e+00,  1.1920e-01, -4.6582e-01,  ...,  3.1830e-02, -4.1797e-01,  5.1172e-01],
          [-7.4524e-02, -4.6802e-01,  3.6108e-01,  ...,  7.2559e-01, -5.4346e-01,  7.7344e-01]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 256, 16, 16]), dtype=torch.float16)
tensor([[[[-2.6318e-01,  3.3301e-01,  1.6577e-01,  ..., -7.4854e-01,  1.4771e-02, -9.8535e-01],
          [-2.7271e-01,  1.0879e+00,  6.0693e-01,  ...,  7.1143e-01,  1.2354e-01, -1.5601e-01],
          [ 1.2881e+00,  1.1895e+00, -1.0146e+00,  ...,  3.7744e-01,  1.7319e-02, -8.2458e-02],
          ...,
          [-7.3181e-02,  1.7261e-01,  4.6204e-02,  ...,  7.5488e-01,  1.4199e+00, -1.6367e+00],
          [ 2.5000e+00,  1.6582e+00, -1.7920e-01,  ..., -7.0410e-01, -9.3604e-01, -3.8623e-01],
          [-1.4648e-01,  3.9124e-02,  7.4951e-02,  ...,  2.9907e-01,  2.9639e-01, -6.4502e-01]],

         [[ 1.1865e+00, -3.1226e-01,  1.4873e+00,  ..., -3.1763e-01,  2.7051e-01,  1.2476e-01],
          [ 2.8467e-01, -6.4746e-01,  5.0488e-01,  ...,  3.9746e-01,  8.5693e-01,  3.0054e-01],
          [ 5.5957e-01, -9.8828e-01, -8.4814e-01,  ...,  4.5825e-01,  3.6426e-01,  4.8901e-01],
          ...,
          [-8.3838e-01, -2.5684e-01, -8.1738e-01,  ...,  6.2598e-01,  3.0786e-01, -4.4922e-01],
          [-3.8159e-01,  2.7148e-01,  1.6240e+00,  ...,  1.7090e-03,  3.5889e-02, -4.8096e-01],
          [-1.4297e+00, -4.4531e-01,  1.6367e+00,  ..., -4.5337e-01, -6.2305e-01, -1.2852e+00]],

         [[ 7.9785e-01,  1.0869e+00,  2.2168e-01,  ...,  1.3662e+00,  1.0693e+00,  4.6143e-01],
          [-3.9697e-01,  7.4658e-01,  6.7822e-01,  ...,  1.9287e-01, -1.5898e+00, -6.0425e-02],
          [ 8.4912e-01,  1.8265e-02, -1.0333e-01,  ..., -2.7979e-01, -1.2471e+00,  1.1212e-01],
          ...,
          [ 1.0635e+00, -3.1763e-01, -1.2360e-01,  ..., -2.3425e-01, -1.6211e-01,  4.1553e-01],
          [ 1.0078e+00, -1.3257e-01,  2.1423e-01,  ...,  9.7705e-01,  1.9690e-01, -1.5059e+00],
          [ 6.7578e-01,  1.6045e+00, -1.2510e+00,  ...,  1.3105e+00,  1.7188e+00,  6.0986e-01]],

         ...,

         [[ 1.2744e+00, -1.1123e+00,  2.7466e-01,  ...,  8.7158e-01, -4.8340e-01,  2.5806e-01],
          [ 2.0215e+00, -8.3691e-01,  6.7529e-01,  ...,  3.4961e-01,  3.2202e-01, -2.6367e-01],
          [-2.1777e-01, -7.7734e-01,  4.9658e-01,  ...,  1.3760e+00,  1.5146e+00, -1.3213e+00],
          ...,
          [-1.3220e-01,  2.6001e-01, -4.3945e-01,  ...,  1.0664e+00,  1.5684e+00,  1.4563e-01],
          [ 1.2949e+00,  5.8887e-01,  5.4736e-01,  ...,  1.1777e+00,  1.7383e-01,  1.3125e+00],
          [-3.5083e-01, -6.1768e-01, -3.4644e-01,  ...,  1.2822e+00,  1.2256e+00,  4.9707e-01]],

         [[ 6.8848e-01,  2.4658e-02,  7.8613e-01,  ..., -1.1865e+00,  2.0918e+00,  1.9561e+00],
          [-5.7178e-01,  1.5784e-01, -5.1416e-01,  ..., -1.1865e+00, -4.7583e-01,  1.2285e+00],
          [-1.9318e-02,  6.2695e-01,  1.3076e+00,  ..., -1.4014e+00,  3.6255e-01, -1.6333e-01],
          ...,
          [ 1.2344e+00,  7.3535e-01, -7.9980e-01,  ..., -3.4521e-01, -4.2969e-01, -6.8311e-01],
          [-8.3679e-02,  8.4351e-02,  2.2791e-01,  ..., -1.1432e-01, -2.5586e-01,  1.3984e+00],
          [ 7.4512e-01,  1.5552e-01, -7.6416e-01,  ..., -8.4668e-01, -1.0869e+00,  1.7542e-01]],

         [[-1.0703e+00, -3.8135e-01,  8.3643e-01,  ...,  6.8066e-01, -1.0576e+00,  1.5420e+00],
          [-6.6455e-01,  4.4556e-01, -2.6978e-02,  ...,  2.2285e+00,  6.5820e-01,  1.7031e+00],
          [ 9.2480e-01, -2.4646e-01, -7.0020e-01,  ...,  1.1533e+00, -6.7090e-01, -7.3047e-01],
          ...,
          [-1.3428e-02, -3.6035e-01,  8.2568e-01,  ..., -2.5635e-01,  4.8999e-01,  2.8931e-01],
          [ 7.3682e-01,  9.6582e-01, -4.0039e-01,  ..., -1.1221e+00, -1.0779e-01, -1.3501e-01],
          [ 5.8643e-01, -9.3567e-02, -6.9678e-01,  ...,  3.8452e-01, -2.6123e-01, -9.9805e-01]]],


        [[[-7.6172e-01,  6.3281e-01,  7.7490e-01,  ..., -2.7124e-01, -3.3032e-01,  9.6375e-02],
          [-3.9233e-01, -1.8311e-02, -4.1772e-01,  ...,  8.2568e-01,  3.1641e-01, -7.4951e-01],
          [-1.0762e+00, -1.2976e-01, -5.0635e-01,  ...,  3.5889e-01,  7.0703e-01, -3.2422e-01],
          ...,
          [ 1.6650e-01,  1.3467e+00, -3.0908e-01,  ..., -3.4009e-01, -1.3652e+00,  2.2021e-01],
          [-4.6997e-01,  4.4653e-01, -8.1604e-02,  ..., -6.7676e-01,  5.5811e-01,  1.4734e-01],
          [-9.9023e-01,  8.9722e-02,  4.2651e-01,  ..., -1.0059e+00, -2.2974e-01,  5.0830e-01]],

         [[ 5.4395e-01, -6.3379e-01,  3.6865e-02,  ..., -1.3135e+00, -1.4297e+00, -1.2924e-02],
          [ 9.7510e-01, -5.4004e-01,  2.6392e-01,  ..., -7.7734e-01, -2.5928e-01, -1.6992e+00],
          [ 1.4424e+00,  9.6191e-02,  1.0742e-02,  ...,  3.7769e-01, -8.9160e-01,  5.4883e-01],
          ...,
          [-8.7695e-01,  2.1826e-01, -4.4360e-01,  ..., -1.1255e-01,  5.5908e-01,  4.0918e-01],
          [-1.0272e-01, -3.7891e-01, -8.8867e-02,  ...,  9.8535e-01, -2.1899e-01,  5.4199e-01],
          [-5.4639e-01, -1.7275e+00, -1.7441e+00,  ...,  1.1982e+00, -1.2482e-01,  1.3232e-01]],

         [[-1.7480e+00, -9.2529e-02,  6.4551e-01,  ...,  2.9346e-01, -9.2188e-01,  2.0715e-01],
          [ 1.2637e+00, -3.3594e-01, -1.2170e-01,  ..., -4.8096e-02, -5.8691e-01, -2.5464e-01],
          [ 3.5858e-02, -8.8818e-01, -3.3447e-01,  ...,  8.8330e-01,  7.7344e-01,  7.1826e-01],
          ...,
          [ 2.9492e-01, -1.2021e+00,  3.1787e-01,  ...,  8.3496e-01,  1.4434e+00,  9.2102e-02],
          [ 1.5059e+00,  8.8525e-01,  8.7744e-01,  ...,  8.3447e-01,  5.8887e-01, -1.5259e-02],
          [-1.0625e+00, -2.8491e-01,  5.5518e-01,  ...,  1.6614e-01,  1.2236e+00,  3.4985e-01]],

         ...,

         [[ 1.2100e+00, -6.2207e-01, -3.2080e-01,  ..., -1.3115e+00, -1.2930e+00,  8.8745e-02],
          [ 8.1299e-01, -8.1299e-01, -3.2568e-01,  ..., -8.6621e-01, -2.2034e-02,  8.7744e-01],
          [-2.3906e+00, -8.4766e-01,  2.4243e-01,  ...,  2.7002e-01,  9.4385e-01, -2.1680e-01],
          ...,
          [-4.6143e-01, -1.1953e+00, -4.4604e-01,  ..., -1.0278e-01, -3.7354e-01, -6.7334e-01],
          [ 1.3809e+00,  2.6611e-01,  9.1895e-01,  ...,  4.6460e-01, -5.1514e-01, -9.3848e-01],
          [-6.5918e-01,  1.0264e+00,  2.4829e-01,  ..., -4.9170e-01,  3.2227e-01, -1.4463e+00]],

         [[-7.6477e-02, -4.8633e-01, -8.4863e-01,  ...,  4.0820e-01, -3.8208e-01,  6.6309e-01],
          [-1.0742e+00,  3.7085e-01, -2.8687e-02,  ..., -6.0791e-02,  1.3379e-01, -6.5137e-01],
          [ 2.4524e-01,  1.0443e-01,  7.4756e-01,  ..., -8.0444e-02, -3.8672e-01,  3.9526e-01],
          ...,
          [ 1.1836e+00,  7.3193e-01,  6.6772e-02,  ..., -1.0088e+00,  1.3564e+00, -6.9922e-01],
          [ 1.9775e+00,  3.7305e-01, -9.9243e-02,  ...,  6.3574e-01, -1.6626e-01, -1.2861e+00],
          [ 6.4795e-01, -2.2339e-01,  6.6772e-02,  ...,  1.5801e+00,  1.9604e-01, -1.2852e+00]],

         [[-5.3467e-01, -5.8594e-01, -5.7861e-01,  ..., -3.4668e-01, -4.6387e-01, -1.2323e-01],
          [ 9.3555e-01,  6.8506e-01, -3.5181e-01,  ..., -3.2886e-01, -2.8369e-01, -4.6289e-01],
          [ 1.0908e+00,  4.8047e-01, -5.6836e-01,  ...,  7.0703e-01,  5.0391e-01,  3.6890e-01],
          ...,
          [ 4.2496e-03,  3.8379e-01, -6.0889e-01,  ...,  1.7639e-02,  2.1521e-01, -1.3564e+00],
          [ 2.8833e-01,  2.7075e-01,  6.3184e-01,  ...,  2.5781e-01,  6.9482e-01,  1.0039e+00],
          [-7.2852e-01, -4.3774e-01,  7.0703e-01,  ...,  5.1025e-01, -6.0498e-01, -5.6689e-01]]],


        [[[-1.6455e-01,  6.0303e-01,  4.4922e-02,  ...,  8.5742e-01, -2.2205e-01, -5.6592e-01],
          [ 7.7051e-01, -7.0068e-01, -8.7402e-01,  ...,  7.2559e-01,  1.6089e-01, -1.6543e+00],
          [ 8.7744e-01, -5.6250e-01, -2.2188e+00,  ...,  3.3740e-01,  6.0303e-01,  3.8257e-01],
          ...,
          [-1.0664e+00,  1.0645e+00,  1.7603e-01,  ..., -1.4531e+00,  8.1201e-01,  7.1826e-01],
          [-4.7949e-01,  3.2397e-01, -3.1982e-02,  ..., -1.6833e-01, -7.4756e-01, -5.3369e-01],
          [-1.0645e+00, -5.4785e-01,  2.8662e-01,  ..., -6.4648e-01,  2.3767e-01,  6.0352e-01]],

         [[-5.0098e-01, -1.3887e+00,  6.5137e-01,  ...,  2.4170e-01, -3.0420e-01,  1.7432e-01],
          [-1.0371e+00,  2.1582e-01, -2.9858e-01,  ..., -5.5518e-01, -2.2510e-01, -3.9600e-01],
          [-1.5068e+00, -5.8057e-01,  4.9210e-03,  ..., -2.9395e-01, -2.9346e-01,  2.6636e-01],
          ...,
          [ 1.0654e+00,  9.5508e-01,  1.9922e-01,  ...,  7.6611e-01,  4.0039e-02, -5.6055e-01],
          [ 1.8477e+00,  5.4492e-01, -1.0029e+00,  ..., -9.1919e-02, -1.2031e+00, -1.4873e+00],
          [ 1.6387e+00,  5.5371e-01,  3.0811e-01,  ...,  1.0498e+00, -3.5303e-01, -8.9844e-01]],

         [[-1.8933e-01, -6.1035e-01, -1.8984e+00,  ..., -4.9072e-01,  8.9307e-01, -5.9668e-01],
          [-1.1932e-01,  2.4878e-01, -4.1577e-01,  ..., -5.1074e-01, -6.5918e-01,  2.8882e-01],
          [ 6.0791e-01,  1.1322e-01, -3.5498e-01,  ..., -1.1846e+00, -8.3557e-02,  6.0986e-01],
          ...,
          [ 2.6050e-01,  1.2676e+00,  1.3828e+00,  ..., -1.4082e+00, -5.4834e-01,  1.0767e-01],
          [ 2.2058e-01, -2.9590e-01, -1.9336e-01,  ..., -7.8125e-01,  2.2668e-01,  7.2070e-01],
          [-4.0698e-01,  1.5015e-01,  1.5576e+00,  ...,  4.4580e-01, -5.9766e-01,  5.5762e-01]],

         ...,

         [[-2.1594e-01,  4.8853e-01, -9.4824e-01,  ...,  1.2073e-01, -1.5586e+00, -7.6172e-01],
          [ 1.6528e-01, -1.2119e+00,  3.3130e-01,  ...,  7.0850e-01,  8.3203e-01,  7.7295e-01],
          [ 1.9592e-01, -5.5664e-01, -7.2998e-01,  ...,  7.1045e-01,  1.0127e+00, -1.5859e+00],
          ...,
          [ 5.1270e-01,  9.9487e-02,  1.9653e-01,  ...,  2.3999e-01, -6.5576e-01,  1.6191e+00],
          [-7.8564e-01, -2.0654e-01, -1.0391e+00,  ..., -3.2617e-01,  2.3145e-01, -5.5859e-01],
          [-6.5771e-01, -7.7979e-01,  1.0724e-01,  ..., -3.1689e-01, -8.8428e-01, -8.3350e-01]],

         [[-2.9512e+00, -9.8633e-01, -1.0791e+00,  ..., -1.5000e+00,  1.7734e+00,  1.5420e+00],
          [-7.7148e-01,  3.7646e-01,  7.7539e-01,  ..., -3.1201e-01,  1.7148e+00,  1.5664e+00],
          [ 1.4414e+00,  1.6436e+00, -1.2659e-01,  ...,  1.8295e-02,  4.9756e-01,  7.7942e-02],
          ...,
          [-7.9004e-01, -8.9160e-01,  4.9854e-01,  ..., -3.8605e-02,  1.3633e+00, -8.4521e-01],
          [-1.9277e+00, -1.3174e+00, -7.5098e-01,  ..., -9.1846e-01, -3.6670e-01, -1.3877e+00],
          [ 7.1191e-01, -1.1810e-01, -6.8848e-01,  ..., -2.0918e+00, -1.5547e+00,  8.6523e-01]],

         [[ 3.9648e-01, -8.5840e-01,  8.7744e-01,  ..., -5.5762e-01,  2.5098e-01,  1.0449e+00],
          [ 6.0840e-01, -5.4260e-02,  2.6318e-01,  ...,  1.6670e+00,  1.7275e+00,  7.8491e-02],
          [-1.1768e+00,  9.6582e-01,  1.3613e+00,  ...,  1.9746e+00,  3.0420e-01, -9.0088e-01],
          ...,
          [-7.6709e-01,  5.4297e-01, -6.4258e-01,  ..., -1.4492e+00,  2.6245e-02,  7.1533e-01],
          [-6.8213e-01, -5.6641e-01,  2.0923e-01,  ..., -2.6703e-02,  6.0181e-02,  1.5420e+00],
          [-9.5312e-01, -1.6211e+00, -4.2334e-01,  ..., -5.6738e-01,  4.9683e-01, -1.1777e+00]]],


        [[[ 1.6016e+00,  3.7769e-01,  6.2207e-01,  ..., -1.5566e+00, -4.2090e-01, -3.9917e-01],
          [-2.1851e-01,  6.2744e-01, -1.6123e+00,  ..., -2.5415e-01, -4.5483e-01, -4.6826e-01],
          [-5.4199e-01, -1.5576e-01,  9.6631e-01,  ...,  9.0527e-01,  2.8540e-01,  1.5322e+00],
          ...,
          [-1.7224e-01,  4.7827e-01, -4.3457e-01,  ..., -2.3328e-01,  5.8594e-03, -5.3418e-01],
          [-3.7793e-01,  6.2256e-01, -1.3245e-01,  ...,  9.2480e-01,  2.8003e-01, -4.1650e-01],
          [-1.8477e+00, -1.0195e+00,  7.7979e-01,  ..., -4.6631e-01, -5.5811e-01, -1.0615e+00]],

         [[-1.5967e+00, -7.0898e-01,  2.0239e-01,  ..., -4.0723e-01,  2.1328e+00,  2.8955e-01],
          [-2.1543e+00, -1.2148e+00, -1.7407e-01,  ..., -5.8936e-01,  6.1914e-01, -5.0049e-01],
          [-7.6660e-01, -5.3418e-01, -1.6956e-01,  ..., -3.4521e-01,  9.1504e-01,  4.0820e-01],
          ...,
          [-2.3828e-01,  1.2246e+00, -3.5126e-02,  ...,  4.8389e-01,  1.2183e-01,  4.5679e-01],
          [ 9.9561e-01,  1.4727e+00,  1.3496e+00,  ...,  1.3184e+00,  1.5029e+00,  1.3464e-01],
          [-1.9080e-01,  1.5515e-01,  3.7451e-01,  ...,  2.5566e+00,  9.0967e-01, -9.5557e-01]],

         [[-1.3633e+00,  8.3105e-01, -1.6443e-01,  ...,  1.5410e+00, -5.7275e-01, -1.8762e-01],
          [-5.1855e-01, -7.2949e-01, -1.5479e+00,  ...,  4.8877e-01, -6.0938e-01,  8.3313e-03],
          [ 9.3506e-01,  6.2866e-02,  1.1748e+00,  ...,  1.2061e-01,  2.2125e-02, -2.3669e-01],
          ...,
          [ 3.4131e-01,  5.5908e-02, -1.6797e-01,  ..., -7.7441e-01,  4.1064e-01,  8.2129e-01],
          [ 4.1675e-01,  8.2666e-01, -1.0046e-01,  ..., -1.3486e+00, -1.1615e-01,  1.0205e+00],
          [ 9.9121e-02,  8.0225e-01,  6.5039e-01,  ...,  8.3862e-02,  1.8286e-01, -2.3145e+00]],

         ...,

         [[-1.3525e-01,  1.2705e+00, -5.1514e-01,  ..., -1.6113e-02,  1.5166e+00, -3.3203e-02],
          [ 1.8721e+00, -1.0967e+00,  4.4250e-02,  ...,  7.9102e-02,  5.5811e-01, -6.2207e-01],
          [ 7.7454e-02, -4.5605e-01, -2.6465e-01,  ..., -6.5771e-01, -6.9141e-01, -6.7871e-01],
          ...,
          [-3.6743e-01, -1.7114e-01, -6.2012e-01,  ..., -6.8555e-01, -2.8369e-01,  9.5801e-01],
          [-6.6602e-01,  5.5664e-01,  3.1836e-01,  ..., -6.3721e-01, -6.5674e-01,  1.5839e-02],
          [ 1.1797e+00,  2.1113e+00,  7.3389e-01,  ..., -7.2949e-01, -8.8672e-01,  4.7729e-02]],

         [[-7.1240e-01,  7.6562e-01,  3.7695e-01,  ...,  6.1230e-01,  2.2375e-01, -9.5703e-01],
          [ 2.0337e-01,  1.5503e-01, -1.0781e+00,  ...,  6.1328e-01,  3.5986e-01,  1.2842e+00],
          [-2.6886e-02, -2.9858e-01,  5.0684e-01,  ..., -1.0068e+00,  4.5361e-01,  8.5645e-01],
          ...,
          [-2.3401e-01,  2.9370e-01,  1.3564e+00,  ..., -7.6294e-02, -2.0469e+00, -2.1855e+00],
          [-1.0693e+00, -5.2979e-01, -8.0933e-02,  ...,  1.9958e-01,  1.4277e+00,  1.7456e-01],
          [ 4.9438e-01, -3.2104e-01, -4.4092e-01,  ...,  3.3789e-01,  1.6357e-01,  2.2314e-01]],

         [[-1.3730e+00,  2.4414e-04, -3.4180e-02,  ...,  5.9375e-01,  1.3037e-01, -4.7607e-01],
          [-1.8835e-01, -1.3892e-01, -7.9346e-03,  ..., -2.2119e-01, -6.1279e-01,  1.1396e+00],
          [-6.2939e-01,  7.6221e-01,  3.3789e-01,  ...,  5.1123e-01, -3.4131e-01, -3.7769e-01],
          ...,
          [-1.1240e+00,  4.8706e-01,  7.2266e-01,  ...,  7.5732e-01, -4.6021e-01, -5.8301e-01],
          [-1.2412e+00,  1.2231e-01, -4.7021e-01,  ...,  3.3691e-02, -4.2236e-01,  5.1514e-01],
          [-7.4036e-02, -4.7021e-01,  3.6182e-01,  ...,  7.3096e-01, -5.5518e-01,  7.7734e-01]]]], dtype=torch.float16)

2025-06-10 00:13:33.321636 GPU 6 156010 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 64, 64],"float16"), size=list[256,256,], mode="bilinear", align_corners=False, )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([4, 256, 64, 64],"float16"), size=list[256,256,], mode="bilinear", align_corners=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 11186 / 4194304 (0.3%)
Greatest absolute difference: 0.05078125 at index (1, 68, 55, 42) (up to 0.01 allowed)
Greatest relative difference: 30.953125 at index (2, 109, 39, 34) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 256, 64, 64]), dtype=torch.float16)
tensor([[[[-6.9275e-02,  6.8066e-01,  8.5010e-01,  ..., -3.6572e-01, -4.0112e-01, -6.3379e-01],
          [ 8.5547e-01,  2.9370e-01,  5.4053e-01,  ..., -4.6875e-01, -1.1396e+00, -6.7444e-02],
          [ 9.0869e-01, -9.9512e-01,  1.4609e+00,  ...,  1.8018e-01,  3.0859e-01, -3.4473e-01],
          ...,
          [ 6.9238e-01,  9.5557e-01, -5.8301e-01,  ..., -8.1152e-01, -6.7236e-01,  1.5735e-01],
          [-4.9658e-01,  1.4766e+00, -3.1104e-01,  ...,  1.2529e+00, -7.4219e-01,  8.2617e-01],
          [-3.9526e-01,  1.1455e+00,  1.4248e+00,  ...,  1.5059e+00,  3.5919e-02, -3.4131e-01]],

         [[-4.8413e-01, -4.7778e-01, -1.4541e+00,  ...,  6.3135e-01, -4.1138e-01,  1.1548e-01],
          [-6.9678e-01, -9.8730e-01, -7.1094e-01,  ...,  5.6836e-01,  8.5938e-01, -9.9072e-01],
          [ 7.2900e-01, -4.2944e-01, -6.6040e-02,  ..., -4.6753e-02,  4.8169e-01,  8.7158e-02],
          ...,
          [ 1.6836e+00, -1.0767e-01,  3.1519e-01,  ..., -5.1123e-01, -1.0137e+00, -9.1113e-01],
          [ 4.9976e-01, -6.1230e-01,  2.4353e-01,  ...,  1.3428e+00,  1.1055e+00, -4.8926e-01],
          [-9.1992e-01,  3.4814e-01,  1.8994e-01,  ...,  4.9731e-01,  1.5684e+00,  9.2334e-01]],

         [[ 1.1641e+00, -7.5012e-02, -1.2910e+00,  ...,  1.0869e+00,  1.0381e+00,  2.7246e-01],
          [ 5.0732e-01,  2.7832e-01, -4.7192e-01,  ...,  1.3269e-01,  8.1152e-01,  3.6719e-01],
          [-1.5635e+00, -1.4951e+00, -3.8306e-01,  ..., -5.7910e-01, -6.6162e-01,  1.3174e+00],
          ...,
          [ 2.1436e-01,  1.0771e+00, -1.5186e-01,  ...,  2.9590e-01, -3.0542e-01,  3.5156e-02],
          [ 1.1602e+00, -2.2354e-02, -4.3604e-01,  ...,  1.7542e-01, -2.9712e-01,  2.6562e-01],
          [-2.9297e-01,  1.0342e+00,  3.6572e-01,  ..., -1.1359e-01,  5.6091e-02, -2.3962e-01]],

         ...,

         [[-7.0947e-01, -3.3936e-01, -1.9897e-01,  ..., -1.4941e+00, -7.0898e-01,  3.9160e-01],
          [-5.0732e-01, -1.0967e+00, -7.0752e-01,  ...,  1.9189e+00,  1.0425e-01,  7.2070e-01],
          [ 5.0964e-02, -1.0811e+00, -2.3303e-01,  ...,  8.1445e-01,  5.9180e-01,  3.8867e-01],
          ...,
          [-1.1006e+00, -2.4353e-01,  3.8727e-02,  ..., -6.9824e-01, -1.2280e-01,  1.0928e+00],
          [-5.9521e-01, -6.5869e-01, -7.0215e-01,  ..., -1.4922e+00,  5.4688e-01,  1.6455e+00],
          [ 7.6074e-01,  5.9961e-01, -6.0303e-01,  ..., -5.3076e-01,  4.9487e-01, -6.5283e-01]],

         [[ 7.7515e-02,  2.5732e-01,  1.2148e+00,  ...,  1.1982e+00,  4.4922e-01,  1.0352e+00],
          [ 9.0485e-03,  8.1885e-01,  9.3066e-01,  ..., -8.1348e-01, -1.0654e+00,  8.9258e-01],
          [ 1.6650e+00,  2.1055e+00,  1.5942e-01,  ..., -1.8753e-02, -6.4551e-01,  2.2217e-01],
          ...,
          [ 2.0471e-01,  1.2773e+00,  6.1607e-03,  ..., -2.8418e-01,  6.9922e-01, -7.5586e-01],
          [ 2.5781e-01,  8.0908e-01,  2.9834e-01,  ...,  1.7981e-01,  1.6650e+00,  7.9834e-01],
          [ 1.9580e+00, -9.9854e-02, -1.7617e+00,  ...,  2.8784e-01,  6.7993e-02,  1.1353e-01]],

         [[ 1.1292e-02, -1.8760e+00, -2.5977e-01,  ..., -5.8008e-01, -7.3975e-01, -7.9199e-01],
          [ 2.6001e-01, -1.1299e-02,  4.9561e-02,  ..., -1.7637e+00, -3.1372e-01,  5.6592e-01],
          [ 1.4668e+00,  3.2080e-01,  8.2129e-01,  ..., -1.1943e+00, -1.2012e+00,  1.3196e-01],
          ...,
          [ 3.1909e-01,  1.3245e-01,  1.4673e-01,  ..., -4.2334e-01,  2.2986e-01,  8.3398e-01],
          [-8.9014e-01,  2.2925e-01,  7.2754e-01,  ..., -1.0449e+00, -8.3154e-01, -9.8193e-01],
          [-1.6270e+00, -1.0176e+00,  3.2568e-01,  ...,  4.8438e-01, -6.1572e-01,  1.8711e+00]]],


        [[[ 5.2441e-01,  1.2539e+00, -1.1113e+00,  ...,  5.0830e-01,  1.5078e+00,  1.2490e+00],
          [-1.0872e-02,  3.1909e-01,  2.7954e-01,  ...,  5.2344e-01,  8.9014e-01,  1.2637e+00],
          [ 2.6953e-01,  7.6562e-01,  2.2656e+00,  ..., -1.0078e+00,  4.8462e-02, -2.4939e-01],
          ...,
          [-6.8652e-01,  2.7637e-01, -1.3635e-01,  ...,  8.6865e-01,  4.3945e-01,  2.9492e-01],
          [-6.9141e-01, -4.3066e-01, -3.2764e-01,  ..., -3.1836e-01, -3.7305e-01,  8.3301e-01],
          [-3.8623e-01,  3.3618e-01, -4.3579e-01,  ..., -1.8677e-01,  9.5166e-01,  1.2878e-01]],

         [[ 9.1846e-01, -8.8623e-02, -7.9834e-01,  ...,  2.2253e-01,  1.6638e-01,  3.5693e-01],
          [ 9.4580e-01,  1.3513e-01,  6.3086e-01,  ...,  7.0508e-01, -2.1210e-02, -8.2520e-01],
          [ 5.8447e-01, -1.0996e+00,  1.0303e+00,  ...,  3.2861e-01,  7.8613e-01, -1.1438e-01],
          ...,
          [ 1.9727e+00,  8.7988e-01,  6.6406e-01,  ..., -5.2344e-01, -5.0586e-01, -5.6152e-01],
          [ 7.7441e-01,  3.2007e-01, -1.5410e+00,  ..., -1.1543e+00,  1.5076e-02,  1.1963e+00],
          [ 2.9774e-03,  2.0166e-01, -1.0156e+00,  ..., -1.7554e-01,  6.7773e-01,  8.5596e-01]],

         [[-9.1699e-01, -4.4922e-02,  9.6973e-01,  ..., -6.3538e-02, -1.0225e+00, -5.8838e-01],
          [-1.4267e-03,  1.4170e+00,  2.2595e-01,  ..., -1.6523e+00, -1.3926e+00,  3.8184e-01],
          [ 1.0492e-01, -6.5369e-02,  3.6224e-02,  ..., -2.7969e+00, -6.5088e-01,  2.7817e-02],
          ...,
          [-1.2266e+00,  5.5371e-01,  7.2900e-01,  ..., -1.0176e+00, -5.4736e-01,  2.2969e+00],
          [ 1.9128e-01, -7.6318e-01, -7.7295e-01,  ..., -9.6143e-01, -8.6816e-01, -2.5806e-01],
          [-5.9912e-01,  8.3252e-01, -1.2236e+00,  ..., -6.6895e-01,  4.9805e-01,  6.0699e-02]],

         ...,

         [[-4.8218e-01, -7.8369e-02, -8.1543e-01,  ..., -7.4463e-01, -1.7021e+00, -1.3799e+00],
          [ 1.3809e+00,  2.9639e-01, -3.7933e-02,  ..., -1.0615e+00, -1.2734e+00, -7.7930e-01],
          [-4.0955e-02,  2.0459e-01, -8.6523e-01,  ...,  6.6943e-01,  1.5051e-01, -3.8940e-01],
          ...,
          [-1.0977e+00, -1.0615e+00,  4.3750e-01,  ..., -1.3076e+00, -1.4343e-01,  1.5488e+00],
          [ 3.9404e-01,  1.5352e+00,  5.9717e-01,  ..., -2.0798e-02, -2.9224e-01,  1.5762e+00],
          [ 1.0303e+00, -5.9174e-02, -1.5808e-01,  ..., -3.4595e-01, -1.8448e-02,  1.2656e+00]],

         [[ 4.3042e-01, -5.0171e-02, -8.6768e-01,  ...,  1.9395e+00,  1.4766e+00,  3.7183e-01],
          [-3.8062e-01, -5.3955e-01, -3.4033e-01,  ...,  5.1465e-01,  2.5244e-01, -1.5156e+00],
          [-3.0029e-01, -9.6973e-01, -8.8672e-01,  ...,  6.2256e-01,  7.0898e-01, -3.9795e-01],
          ...,
          [-2.3157e-01,  2.3425e-01,  5.2148e-01,  ..., -8.4912e-01,  3.5059e-01, -6.2842e-01],
          [ 5.1611e-01,  3.9087e-01,  6.1670e-01,  ..., -8.7598e-01, -9.0430e-01, -9.9658e-01],
          [-9.0869e-01, -8.3838e-01,  2.7710e-01,  ..., -5.7764e-01, -6.7627e-02, -4.8169e-01]],

         [[ 1.5010e+00,  2.0557e-01, -8.0859e-01,  ...,  4.3262e-01, -9.4385e-01,  4.8047e-01],
          [ 7.8711e-01,  3.0273e-01,  6.7139e-02,  ...,  4.0918e-01,  2.5830e-01, -4.3335e-01],
          [ 8.5547e-01, -1.4197e-01, -2.5146e-01,  ..., -5.6122e-02,  1.4061e-02,  4.7461e-01],
          ...,
          [-7.8564e-01,  4.2822e-01,  6.6748e-01,  ..., -1.7070e+00,  4.0070e-02,  1.4893e+00],
          [-1.1621e+00, -1.8506e+00,  4.4385e-01,  ..., -6.4404e-01, -6.7236e-01,  1.0186e+00],
          [-1.5029e+00,  6.1084e-01,  2.4255e-01,  ...,  4.1431e-01,  6.6992e-01,  4.4751e-01]]],


        [[[ 1.7588e+00,  1.4270e-01, -1.5784e-01,  ...,  1.2598e-01, -6.8604e-01,  1.8036e-02],
          [-2.5952e-01, -5.7251e-02,  1.3870e-02,  ...,  1.3318e-01,  7.5049e-01, -1.4775e+00],
          [ 4.6826e-01,  7.8809e-01,  9.8877e-01,  ..., -4.3304e-02, -7.5195e-01, -1.0264e+00],
          ...,
          [-8.5205e-02, -3.8818e-01,  2.3865e-01,  ..., -1.1914e-01,  7.6855e-01,  1.0742e+00],
          [-1.5381e+00, -8.3984e-01, -4.9927e-01,  ..., -8.1934e-01, -9.3311e-01,  1.0234e+00],
          [-1.2830e-01, -3.7012e-01,  1.3398e+00,  ...,  4.4409e-01,  8.8501e-02, -3.8623e-01]],

         [[ 3.8257e-01, -7.6367e-01, -2.3477e+00,  ..., -9.9854e-02, -2.4261e-02,  2.2461e-01],
          [-1.8054e-01, -3.8501e-01,  6.0840e-01,  ...,  3.1226e-01, -1.8623e+00, -1.0762e+00],
          [ 9.6777e-01, -4.0063e-01,  7.0801e-01,  ...,  1.1016e+00,  1.7102e-01, -1.7725e-01],
          ...,
          [-4.0674e-01, -4.4092e-01, -1.2041e+00,  ..., -3.9282e-01,  3.3984e-01, -4.0674e-01],
          [-7.9150e-01,  3.7012e-01,  8.5938e-01,  ..., -7.9102e-01,  5.9776e-03,  5.8057e-01],
          [ 6.7090e-01, -1.6982e+00,  3.3356e-02,  ..., -9.3994e-01, -1.9897e-01,  5.3516e-01]],

         [[ 5.7715e-01, -2.9541e-01, -1.5137e+00,  ...,  1.1536e-01,  6.1005e-02,  2.8149e-01],
          [-6.8408e-01, -9.0869e-01,  1.6104e+00,  ..., -8.2568e-01,  6.2354e-01, -1.2195e-01],
          [-3.1860e-01, -9.7363e-01,  1.2383e+00,  ...,  3.3447e-01,  1.4639e+00, -6.5967e-01],
          ...,
          [ 5.3680e-02, -3.1543e-01,  1.2949e+00,  ...,  1.4673e-01, -3.5229e-01, -1.8438e+00],
          [-1.5264e+00, -1.0195e+00, -2.8296e-01,  ..., -4.2212e-01, -2.8809e-01, -6.9727e-01],
          [-1.0801e+00, -6.5088e-01,  1.2231e-01,  ...,  1.0459e+00, -4.8730e-01, -1.0822e-01]],

         ...,

         [[-1.0693e+00, -4.2212e-01, -6.5576e-01,  ...,  3.5327e-01, -2.0532e-01,  6.3135e-01],
          [-5.3809e-01, -5.4541e-01,  5.4248e-01,  ..., -2.0972e-01,  2.6733e-01,  6.3574e-01],
          [-5.2588e-01,  6.1084e-01,  1.0840e+00,  ...,  1.3701e+00, -6.4270e-02,  3.8300e-02],
          ...,
          [-3.8403e-01,  9.0723e-01, -7.1436e-01,  ..., -7.0508e-01, -1.0781e+00, -7.9053e-01],
          [-1.4844e+00, -2.2791e-01,  2.3755e-01,  ...,  4.7144e-01, -1.2490e+00,  1.6931e-01],
          [-1.3220e-01, -9.7839e-02,  8.8721e-01,  ...,  6.7529e-01, -1.1224e-01,  1.2256e+00]],

         [[-1.7354e+00,  9.1064e-01, -1.7102e-01,  ..., -1.1016e+00, -7.1777e-01, -1.5596e+00],
          [-1.0332e+00,  1.2715e+00, -3.0298e-01,  ..., -3.3960e-01,  1.0391e+00, -4.1895e-01],
          [ 2.2986e-01,  6.7578e-01, -9.8291e-01,  ...,  1.2676e+00,  1.0029e+00,  2.5146e-01],
          ...,
          [-7.7881e-01,  8.8184e-01,  3.0396e-01,  ...,  4.3115e-01, -5.9229e-01, -1.0713e+00],
          [ 1.6248e-01, -4.2090e-01, -4.7632e-01,  ...,  1.6687e-01, -2.8540e-01,  5.3369e-01],
          [-7.7209e-02, -2.8247e-01,  1.8250e-01,  ...,  9.3311e-01,  6.8701e-01,  5.0488e-01]],

         [[-1.3452e-01, -8.6475e-01, -7.5098e-01,  ..., -6.8701e-01, -3.8354e-01, -7.0703e-01],
          [ 5.8252e-01,  1.1816e+00,  1.6525e-02,  ...,  5.0195e-01, -6.3721e-01, -2.4731e-01],
          [-5.5615e-01, -4.8853e-01, -3.9062e-01,  ...,  6.1523e-01, -2.3262e+00, -1.8604e+00],
          ...,
          [-6.9678e-01,  5.2551e-02,  5.0684e-01,  ...,  8.1982e-01, -3.1592e-01,  1.0664e+00],
          [ 7.0068e-01,  4.2822e-01,  1.1230e+00,  ...,  5.9723e-02,  4.8633e-01,  2.7856e-01],
          [-4.9512e-01,  2.2070e-01,  6.7676e-01,  ...,  7.6123e-01,  1.1709e+00,  1.9785e+00]]],


        [[[ 9.6094e-01, -2.0349e-01,  1.2720e-01,  ...,  8.5449e-01,  1.4258e+00, -1.2510e+00],
          [ 1.0333e-01, -3.5010e-01,  1.6328e+00,  ...,  2.1460e-01,  1.7566e-01, -1.5127e+00],
          [ 1.7859e-01, -1.4331e-01,  1.2598e+00,  ...,  4.5728e-01,  1.0078e+00, -9.5068e-01],
          ...,
          [ 7.9248e-01,  1.5283e-01,  5.2490e-01,  ..., -1.5576e-01, -1.3018e+00,  8.5986e-01],
          [ 8.7891e-01,  4.6729e-01,  6.4990e-01,  ...,  4.7339e-01, -4.7607e-01,  1.3562e-01],
          [-8.0566e-01, -1.7578e-01, -9.0625e-01,  ...,  6.2354e-01, -3.0396e-01,  1.1807e+00]],

         [[-5.0635e-01, -1.4758e-01, -3.5913e-01,  ...,  4.0527e-01, -8.5498e-01, -3.7988e-01],
          [-1.1904e+00, -7.5867e-02,  6.7969e-01,  ...,  2.9102e-01,  2.4185e-02,  8.5840e-01],
          [ 9.9707e-01, -3.9429e-02,  7.2949e-01,  ..., -1.1316e-01, -2.2083e-01, -5.3613e-01],
          ...,
          [-9.0820e-01, -1.3611e-01,  3.7524e-01,  ...,  6.6504e-01,  7.0703e-01, -3.8483e-02],
          [-6.4014e-01, -7.2070e-01, -3.2593e-01,  ...,  7.2363e-01,  1.6660e+00,  8.8770e-01],
          [-6.8945e-01, -8.5645e-01, -1.0452e-02,  ...,  5.1221e-01,  3.5791e-01, -3.0859e-01]],

         [[ 9.0881e-02, -3.2446e-01, -8.3203e-01,  ..., -5.7324e-01, -6.2012e-01,  6.4697e-01],
          [ 1.0557e+00,  3.0243e-02, -1.6736e-01,  ...,  1.2588e+00, -7.2314e-01, -1.1328e+00],
          [-9.1736e-02,  5.5225e-01, -9.4360e-02,  ...,  3.4570e-01, -7.6562e-01,  2.3022e-01],
          ...,
          [ 4.7925e-01,  4.8682e-01,  4.5312e-01,  ..., -6.0889e-01, -2.8833e-01,  3.3569e-01],
          [-1.4343e-03, -6.9092e-01, -4.1650e-01,  ..., -1.2383e+00,  2.2974e-01,  8.6670e-01],
          [ 2.3865e-01,  1.2607e+00,  2.0520e-01,  ..., -6.4331e-02, -9.1797e-02, -6.4453e-01]],

         ...,

         [[-1.0459e+00,  2.6855e-01, -1.1709e+00,  ...,  2.5854e-01, -5.0635e-01,  1.8174e+00],
          [-1.0801e+00, -1.1064e+00,  5.5615e-01,  ...,  2.4805e-01, -5.3955e-01,  7.3535e-01],
          [-4.8730e-01, -8.9111e-01, -7.5781e-01,  ...,  6.1963e-01,  1.5247e-01,  3.7451e-01],
          ...,
          [ 1.0234e+00,  4.7339e-01,  4.7876e-01,  ...,  7.1680e-01, -3.4033e-01, -4.7754e-01],
          [ 4.1260e-01, -1.3135e-01, -1.0732e+00,  ..., -3.4961e-01,  1.1553e+00, -3.6304e-01],
          [ 3.2471e-01, -7.8552e-02,  6.0059e-02,  ..., -3.7903e-02, -1.7444e-01, -1.2773e+00]],

         [[-3.0054e-01, -1.9932e+00,  2.7496e-02,  ..., -7.5342e-01, -9.9951e-01,  1.0713e+00],
          [-8.2666e-01,  1.5850e+00, -4.4678e-01,  ..., -1.3504e-02, -4.4238e-01,  8.3447e-01],
          [ 3.2495e-01,  1.1943e+00, -6.3843e-02,  ...,  7.2559e-01,  1.8408e-01, -2.4817e-01],
          ...,
          [ 3.6133e-01, -9.4189e-01, -3.5449e-01,  ..., -3.7646e-01,  1.3878e-02, -5.4492e-01],
          [ 8.2568e-01, -7.0605e-01, -1.0830e+00,  ..., -5.2148e-01, -2.1790e-01, -1.0566e+00],
          [-1.5918e+00, -9.7266e-01, -1.7422e+00,  ...,  2.2559e-01, -2.5177e-03, -1.0225e+00]],

         [[-1.1807e+00, -1.6260e+00, -5.8496e-01,  ..., -5.8203e-01,  6.6699e-01,  4.8926e-01],
          [-9.8938e-02, -3.6694e-01,  6.7139e-01,  ..., -5.6299e-01,  2.6074e-01, -2.4561e-01],
          [-6.5430e-01,  3.8892e-01,  1.3196e-01,  ..., -3.1079e-01,  7.9248e-01,  5.4016e-03],
          ...,
          [ 3.2202e-01, -2.8760e-01,  2.1313e-01,  ..., -4.6460e-01,  1.0684e+00, -1.0406e-01],
          [-9.6826e-01, -6.5820e-01,  5.2539e-01,  ...,  1.1807e+00,  2.7075e-01,  3.6670e-01],
          [-1.9150e+00, -1.3174e+00,  1.4463e+00,  ..., -8.6035e-01,  1.5955e-01, -6.3049e-02]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 256, 64, 64]), dtype=torch.float16)
tensor([[[[-7.0557e-02,  6.8457e-01,  8.5889e-01,  ..., -3.6865e-01, -4.0454e-01, -6.4111e-01],
          [ 8.6279e-01,  3.0078e-01,  5.5029e-01,  ..., -4.7437e-01, -1.1543e+00, -6.9885e-02],
          [ 9.1553e-01, -1.0088e+00,  1.4717e+00,  ...,  1.8262e-01,  3.1152e-01, -3.4521e-01],
          ...,
          [ 6.9971e-01,  9.6094e-01, -5.9082e-01,  ..., -8.2666e-01, -6.8066e-01,  1.5454e-01],
          [-5.0244e-01,  1.4932e+00, -3.1665e-01,  ...,  1.2676e+00, -7.4805e-01,  8.3398e-01],
          [-3.9600e-01,  1.1641e+00,  1.4385e+00,  ...,  1.5205e+00,  3.3875e-02, -3.4326e-01]],

         [[-4.8901e-01, -4.7900e-01, -1.4717e+00,  ...,  6.3818e-01, -4.1650e-01,  1.1804e-01],
          [-7.0410e-01, -9.9658e-01, -7.1924e-01,  ...,  5.7422e-01,  8.6523e-01, -9.9756e-01],
          [ 7.3486e-01, -4.3481e-01, -7.0190e-02,  ..., -4.9072e-02,  4.8853e-01,  8.3496e-02],
          ...,
          [ 1.6973e+00, -1.0583e-01,  3.2129e-01,  ..., -5.1855e-01, -1.0293e+00, -9.1699e-01],
          [ 5.0586e-01, -6.1963e-01,  2.4207e-01,  ...,  1.3574e+00,  1.1211e+00, -4.9561e-01],
          [-9.2383e-01,  3.4961e-01,  1.9763e-01,  ...,  5.0439e-01,  1.5781e+00,  9.3164e-01]],

         [[ 1.1748e+00, -7.7942e-02, -1.3057e+00,  ...,  1.1035e+00,  1.0488e+00,  2.7441e-01],
          [ 5.1562e-01,  2.8345e-01, -4.7754e-01,  ...,  1.3416e-01,  8.2031e-01,  3.7305e-01],
          [-1.5742e+00, -1.5078e+00, -3.8770e-01,  ..., -5.8203e-01, -6.7139e-01,  1.3262e+00],
          ...,
          [ 2.1606e-01,  1.0918e+00, -1.5112e-01,  ...,  3.0054e-01, -3.1006e-01,  3.4760e-02],
          [ 1.1719e+00, -2.1240e-02, -4.4336e-01,  ...,  1.7688e-01, -3.0176e-01,  2.6465e-01],
          [-2.9468e-01,  1.0430e+00,  3.7988e-01,  ..., -1.1224e-01,  6.2744e-02, -2.4097e-01]],

         ...,

         [[-7.1631e-01, -3.4351e-01, -2.0166e-01,  ..., -1.5078e+00, -7.2070e-01,  3.9697e-01],
          [-5.1318e-01, -1.1094e+00, -7.1240e-01,  ...,  1.9287e+00,  1.0632e-01,  7.2705e-01],
          [ 5.2856e-02, -1.0996e+00, -2.3560e-01,  ...,  8.2324e-01,  5.9668e-01,  3.9307e-01],
          ...,
          [-1.1104e+00, -2.4609e-01,  3.9001e-02,  ..., -7.0752e-01, -1.2646e-01,  1.1045e+00],
          [-6.0205e-01, -6.6553e-01, -7.0459e-01,  ..., -1.5068e+00,  5.5029e-01,  1.6611e+00],
          [ 7.6318e-01,  6.0449e-01, -6.1230e-01,  ..., -5.3760e-01,  5.0146e-01, -6.5674e-01]],

         [[ 7.7759e-02,  2.5830e-01,  1.2324e+00,  ...,  1.2158e+00,  4.5483e-01,  1.0508e+00],
          [ 8.2550e-03,  8.2617e-01,  9.4092e-01,  ..., -8.2031e-01, -1.0752e+00,  8.9795e-01],
          [ 1.6797e+00,  2.1309e+00,  1.6150e-01,  ..., -2.2583e-02, -6.5527e-01,  2.2778e-01],
          ...,
          [ 2.0618e-01,  1.2988e+00,  4.1199e-03,  ..., -2.8735e-01,  7.0508e-01, -7.6709e-01],
          [ 2.5830e-01,  8.1592e-01,  3.0469e-01,  ...,  1.8188e-01,  1.6855e+00,  8.0615e-01],
          [ 1.9697e+00, -1.0107e-01, -1.7773e+00,  ...,  2.9126e-01,  6.5063e-02,  1.1798e-01]],

         [[ 1.0475e-02, -1.8867e+00, -2.6416e-01,  ..., -5.8398e-01, -7.4902e-01, -8.0176e-01],
          [ 2.6074e-01, -2.0264e-02,  4.7607e-02,  ..., -1.7773e+00, -3.1519e-01,  5.7031e-01],
          [ 1.4824e+00,  3.2690e-01,  8.3154e-01,  ..., -1.2090e+00, -1.2158e+00,  1.3354e-01],
          ...,
          [ 3.2056e-01,  1.3293e-01,  1.4819e-01,  ..., -4.2480e-01,  2.3340e-01,  8.4570e-01],
          [-8.9648e-01,  2.3083e-01,  7.3340e-01,  ..., -1.0557e+00, -8.3838e-01, -9.9365e-01],
          [-1.6338e+00, -1.0254e+00,  3.2788e-01,  ...,  4.8389e-01, -6.1670e-01,  1.8809e+00]]],


        [[[ 5.3027e-01,  1.2734e+00, -1.1260e+00,  ...,  5.1416e-01,  1.5273e+00,  1.2666e+00],
          [-1.1284e-02,  3.2251e-01,  2.7661e-01,  ...,  5.3174e-01,  9.0039e-01,  1.2803e+00],
          [ 2.7173e-01,  7.7295e-01,  2.2949e+00,  ..., -1.0195e+00,  5.1636e-02, -2.5073e-01],
          ...,
          [-6.9238e-01,  2.8027e-01, -1.3525e-01,  ...,  8.7891e-01,  4.4922e-01,  2.9663e-01],
          [-6.9629e-01, -4.3604e-01, -3.3154e-01,  ..., -3.2080e-01, -3.7695e-01,  8.4180e-01],
          [-3.9478e-01,  3.3765e-01, -4.4189e-01,  ..., -1.8872e-01,  9.5361e-01,  1.2646e-01]],

         [[ 9.2432e-01, -8.9844e-02, -8.0566e-01,  ...,  2.2913e-01,  1.7065e-01,  3.6304e-01],
          [ 9.5264e-01,  1.3843e-01,  6.3525e-01,  ...,  7.1094e-01, -2.5635e-02, -8.3887e-01],
          [ 5.9033e-01, -1.1133e+00,  1.0459e+00,  ...,  3.2861e-01,  7.9980e-01, -1.1359e-01],
          ...,
          [ 1.9873e+00,  8.8916e-01,  6.7480e-01,  ..., -5.2832e-01, -5.0879e-01, -5.6787e-01],
          [ 7.8516e-01,  3.2471e-01, -1.5547e+00,  ..., -1.1729e+00,  1.1719e-02,  1.2090e+00],
          [ 9.1553e-05,  1.9824e-01, -1.0312e+00,  ..., -1.7712e-01,  6.8506e-01,  8.6426e-01]],

         [[-9.2480e-01, -4.6387e-02,  9.8047e-01,  ..., -6.2988e-02, -1.0352e+00, -5.9375e-01],
          [-3.8757e-03,  1.4307e+00,  2.3242e-01,  ..., -1.6621e+00, -1.4072e+00,  3.8647e-01],
          [ 1.0657e-01, -6.2744e-02,  3.5278e-02,  ..., -2.8301e+00, -6.6113e-01,  2.8122e-02],
          ...,
          [-1.2373e+00,  5.6250e-01,  7.4170e-01,  ..., -1.0254e+00, -5.5029e-01,  2.3301e+00],
          [ 1.9165e-01, -7.6953e-01, -7.8369e-01,  ..., -9.7119e-01, -8.8086e-01, -2.5684e-01],
          [-5.9912e-01,  8.3887e-01, -1.2305e+00,  ..., -6.7578e-01,  5.0195e-01,  5.8960e-02]],

         ...,

         [[-4.8535e-01, -7.5317e-02, -8.2080e-01,  ..., -7.5000e-01, -1.7168e+00, -1.4004e+00],
          [ 1.3945e+00,  2.9688e-01, -4.0283e-02,  ..., -1.0801e+00, -1.2891e+00, -7.8711e-01],
          [-3.9917e-02,  2.1094e-01, -8.7402e-01,  ...,  6.7773e-01,  1.5015e-01, -3.9624e-01],
          ...,
          [-1.1094e+00, -1.0820e+00,  4.4067e-01,  ..., -1.3232e+00, -1.4465e-01,  1.5664e+00],
          [ 3.9478e-01,  1.5469e+00,  6.0645e-01,  ..., -2.1484e-02, -2.9492e-01,  1.5869e+00],
          [ 1.0371e+00, -6.0364e-02, -1.5881e-01,  ..., -3.5449e-01, -1.9257e-02,  1.2812e+00]],

         [[ 4.3555e-01, -4.5166e-02, -8.7500e-01,  ...,  1.9609e+00,  1.4912e+00,  3.7402e-01],
          [-3.8257e-01, -5.4883e-01, -3.4570e-01,  ...,  5.2197e-01,  2.5952e-01, -1.5273e+00],
          [-3.0347e-01, -9.7705e-01, -8.9258e-01,  ...,  6.2939e-01,  7.1533e-01, -4.1113e-01],
          ...,
          [-2.3193e-01,  2.3389e-01,  5.2539e-01,  ..., -8.5742e-01,  3.5840e-01, -6.3330e-01],
          [ 5.2100e-01,  3.9429e-01,  6.2354e-01,  ..., -8.8525e-01, -9.1357e-01, -1.0088e+00],
          [-9.1211e-01, -8.4326e-01,  2.7783e-01,  ..., -5.8008e-01, -6.8848e-02, -4.8315e-01]],

         [[ 1.5117e+00,  2.0654e-01, -8.1592e-01,  ...,  4.3555e-01, -9.5410e-01,  4.9194e-01],
          [ 7.9150e-01,  3.0420e-01,  6.7566e-02,  ...,  4.1357e-01,  2.6099e-01, -4.4092e-01],
          [ 8.6523e-01, -1.4185e-01, -2.5171e-01,  ..., -5.4565e-02,  1.4801e-02,  4.8169e-01],
          ...,
          [-7.9150e-01,  4.3359e-01,  6.7432e-01,  ..., -1.7236e+00,  3.9917e-02,  1.5020e+00],
          [-1.1738e+00, -1.8652e+00,  4.4824e-01,  ..., -6.5381e-01, -6.7920e-01,  1.0322e+00],
          [-1.5166e+00,  6.0840e-01,  2.5000e-01,  ...,  4.1675e-01,  6.7383e-01,  4.4873e-01]]],


        [[[ 1.7744e+00,  1.4978e-01, -1.5649e-01,  ...,  1.2720e-01, -6.9336e-01,  2.1942e-02],
          [-2.6123e-01, -6.0913e-02,  8.5449e-03,  ...,  1.3379e-01,  7.6074e-01, -1.4961e+00],
          [ 4.6948e-01,  7.9150e-01,  1.0029e+00,  ..., -4.4434e-02, -7.6025e-01, -1.0352e+00],
          ...,
          [-8.6365e-02, -3.9160e-01,  2.4036e-01,  ..., -1.2085e-01,  7.7539e-01,  1.0820e+00],
          [-1.5488e+00, -8.4570e-01, -5.0537e-01,  ..., -8.2861e-01, -9.3994e-01,  1.0400e+00],
          [-1.3135e-01, -3.7744e-01,  1.3418e+00,  ...,  4.4385e-01,  8.0505e-02, -3.8940e-01]],

         [[ 3.8403e-01, -7.7490e-01, -2.3887e+00,  ..., -1.0095e-01, -2.0569e-02,  2.2681e-01],
          [-1.8079e-01, -3.8965e-01,  6.1084e-01,  ...,  3.1543e-01, -1.8857e+00, -1.0869e+00],
          [ 9.7998e-01, -4.0283e-01,  7.1631e-01,  ...,  1.1094e+00,  1.6833e-01, -1.8018e-01],
          ...,
          [-4.1211e-01, -4.4531e-01, -1.2158e+00,  ..., -3.9453e-01,  3.4204e-01, -4.1699e-01],
          [-8.0078e-01,  3.7500e-01,  8.6084e-01,  ..., -8.0029e-01,  8.1482e-03,  5.9180e-01],
          [ 6.7920e-01, -1.7100e+00,  3.3813e-02,  ..., -9.5508e-01, -2.0850e-01,  5.3955e-01]],

         [[ 5.8350e-01, -2.9712e-01, -1.5312e+00,  ...,  1.1670e-01,  6.3782e-02,  2.8857e-01],
          [-6.8848e-01, -9.1895e-01,  1.6211e+00,  ..., -8.3350e-01,  6.2744e-01, -1.2573e-01],
          [-3.2129e-01, -9.8389e-01,  1.2559e+00,  ...,  3.3496e-01,  1.4814e+00, -6.6406e-01],
          ...,
          [ 5.4230e-02, -3.2080e-01,  1.3105e+00,  ...,  1.5015e-01, -3.5498e-01, -1.8604e+00],
          [-1.5381e+00, -1.0312e+00, -2.8320e-01,  ..., -4.2798e-01, -2.9443e-01, -7.1045e-01],
          [-1.0889e+00, -6.5723e-01,  1.2103e-01,  ...,  1.0645e+00, -4.8877e-01, -1.0345e-01]],

         ...,

         [[-1.0762e+00, -4.2578e-01, -6.6309e-01,  ...,  3.6084e-01, -2.0691e-01,  6.3818e-01],
          [-5.4395e-01, -5.4980e-01,  5.4443e-01,  ..., -2.1411e-01,  2.7148e-01,  6.4307e-01],
          [-5.3076e-01,  6.1133e-01,  1.0977e+00,  ...,  1.3906e+00, -6.4819e-02,  4.2114e-02],
          ...,
          [-3.8550e-01,  9.2578e-01, -7.2021e-01,  ..., -7.1191e-01, -1.0918e+00, -7.9736e-01],
          [-1.4961e+00, -2.3145e-01,  2.3523e-01,  ...,  4.7827e-01, -1.2666e+00,  1.7114e-01],
          [-1.3513e-01, -9.6313e-02,  8.9697e-01,  ...,  6.8066e-01, -1.1377e-01,  1.2324e+00]],

         [[-1.7510e+00,  9.1797e-01, -1.7383e-01,  ..., -1.1104e+00, -7.2266e-01, -1.5801e+00],
          [-1.0420e+00,  1.2861e+00, -3.0347e-01,  ..., -3.4863e-01,  1.0459e+00, -4.2456e-01],
          [ 2.3035e-01,  6.8506e-01, -9.9316e-01,  ...,  1.2842e+00,  1.0156e+00,  2.5317e-01],
          ...,
          [-7.8613e-01,  8.9160e-01,  3.0469e-01,  ...,  4.3750e-01, -5.9766e-01, -1.0859e+00],
          [ 1.6309e-01, -4.2505e-01, -4.7900e-01,  ...,  1.6895e-01, -2.9077e-01,  5.3662e-01],
          [-7.6538e-02, -2.8418e-01,  1.8213e-01,  ...,  9.4336e-01,  6.9824e-01,  5.0879e-01]],

         [[-1.3599e-01, -8.7500e-01, -7.5781e-01,  ..., -6.9434e-01, -3.8770e-01, -7.1191e-01],
          [ 5.8789e-01,  1.1924e+00,  1.6296e-02,  ...,  5.0293e-01, -6.4209e-01, -2.4768e-01],
          [-5.6006e-01, -4.9072e-01, -3.8965e-01,  ...,  6.2402e-01, -2.3516e+00, -1.8760e+00],
          ...,
          [-7.0410e-01,  5.1300e-02,  5.1123e-01,  ...,  8.2910e-01, -3.1787e-01,  1.0771e+00],
          [ 7.0459e-01,  4.3604e-01,  1.1348e+00,  ...,  6.0120e-02,  4.8779e-01,  2.8174e-01],
          [-4.9829e-01,  2.2217e-01,  6.8262e-01,  ...,  7.6465e-01,  1.1777e+00,  1.9902e+00]]],


        [[[ 9.7168e-01, -2.0496e-01,  1.3135e-01,  ...,  8.6084e-01,  1.4463e+00, -1.2627e+00],
          [ 1.0242e-01, -3.5840e-01,  1.6475e+00,  ...,  2.1924e-01,  1.7688e-01, -1.5254e+00],
          [ 1.8250e-01, -1.4441e-01,  1.2764e+00,  ...,  4.6240e-01,  1.0195e+00, -9.6484e-01],
          ...,
          [ 7.9785e-01,  1.5112e-01,  5.2734e-01,  ..., -1.5405e-01, -1.3115e+00,  8.7207e-01],
          [ 8.8672e-01,  4.7266e-01,  6.6162e-01,  ...,  4.7290e-01, -4.8584e-01,  1.3550e-01],
          [-8.1152e-01, -1.8066e-01, -9.1748e-01,  ...,  6.3379e-01, -3.0322e-01,  1.1963e+00]],

         [[-5.1270e-01, -1.5051e-01, -3.6475e-01,  ...,  4.0869e-01, -8.6475e-01, -3.8672e-01],
          [-1.1982e+00, -7.6355e-02,  6.8555e-01,  ...,  2.9419e-01,  2.5818e-02,  8.6475e-01],
          [ 1.0010e+00, -3.9856e-02,  7.3730e-01,  ..., -1.1395e-01, -2.2498e-01, -5.4346e-01],
          ...,
          [-9.1211e-01, -1.3831e-01,  3.7354e-01,  ...,  6.7285e-01,  7.1094e-01, -4.0680e-02],
          [-6.4746e-01, -7.2900e-01, -3.2715e-01,  ...,  7.2998e-01,  1.6836e+00,  8.9404e-01],
          [-6.9238e-01, -8.5889e-01, -7.6904e-03,  ...,  5.1465e-01,  3.7329e-01, -3.0322e-01]],

         [[ 9.3628e-02, -3.2324e-01, -8.3887e-01,  ..., -5.8789e-01, -6.2695e-01,  6.5674e-01],
          [ 1.0625e+00,  2.7832e-02, -1.7163e-01,  ...,  1.2695e+00, -7.3096e-01, -1.1494e+00],
          [-8.9905e-02,  5.6006e-01, -9.4543e-02,  ...,  3.5645e-01, -7.7441e-01,  2.3193e-01],
          ...,
          [ 4.8560e-01,  4.9487e-01,  4.5728e-01,  ..., -6.1719e-01, -2.9150e-01,  3.3521e-01],
          [-2.8992e-03, -7.0020e-01, -4.1797e-01,  ..., -1.2520e+00,  2.2900e-01,  8.7891e-01],
          [ 2.4316e-01,  1.2754e+00,  2.0459e-01,  ..., -6.2866e-02, -8.4961e-02, -6.5625e-01]],

         ...,

         [[-1.0557e+00,  2.7832e-01, -1.1875e+00,  ...,  2.6416e-01, -5.1465e-01,  1.8359e+00],
          [-1.0918e+00, -1.1279e+00,  5.6250e-01,  ...,  2.4561e-01, -5.4395e-01,  7.4609e-01],
          [-4.9170e-01, -9.0039e-01, -7.6465e-01,  ...,  6.2891e-01,  1.5210e-01,  3.7744e-01],
          ...,
          [ 1.0332e+00,  4.8047e-01,  4.8462e-01,  ...,  7.2070e-01, -3.4399e-01, -4.8730e-01],
          [ 4.1479e-01, -1.3354e-01, -1.0859e+00,  ..., -3.5010e-01,  1.1699e+00, -3.6182e-01],
          [ 3.2861e-01, -7.5806e-02,  5.8472e-02,  ..., -3.6743e-02, -1.7554e-01, -1.2920e+00]],

         [[-3.0591e-01, -2.0332e+00,  2.6611e-02,  ..., -7.5977e-01, -1.0176e+00,  1.0850e+00],
          [-8.3545e-01,  1.6006e+00, -4.5190e-01,  ..., -1.5137e-02, -4.4189e-01,  8.4229e-01],
          [ 3.2666e-01,  1.2158e+00, -6.1707e-02,  ...,  7.3584e-01,  1.8494e-01, -2.4951e-01],
          ...,
          [ 3.6255e-01, -9.5264e-01, -3.5986e-01,  ..., -3.7793e-01,  2.2552e-02, -5.4736e-01],
          [ 8.3350e-01, -7.1387e-01, -1.0967e+00,  ..., -5.2539e-01, -2.2375e-01, -1.0684e+00],
          [-1.5986e+00, -9.8779e-01, -1.7568e+00,  ...,  2.2974e-01, -1.2207e-03, -1.0391e+00]],

         [[-1.1953e+00, -1.6465e+00, -5.9814e-01,  ..., -5.8643e-01,  6.7725e-01,  4.9780e-01],
          [-9.8145e-02, -3.6938e-01,  6.7822e-01,  ..., -5.7373e-01,  2.6172e-01, -2.4622e-01],
          [-6.6406e-01,  3.8916e-01,  1.2988e-01,  ..., -3.1201e-01,  8.0078e-01,  6.0120e-03],
          ...,
          [ 3.2202e-01, -2.9028e-01,  2.1692e-01,  ..., -4.7559e-01,  1.0771e+00, -1.0486e-01],
          [-9.7314e-01, -6.6260e-01,  5.3027e-01,  ...,  1.2012e+00,  2.7490e-01,  3.7036e-01],
          [-1.9297e+00, -1.3262e+00,  1.4629e+00,  ..., -8.6670e-01,  1.5674e-01, -6.1340e-02]]]], dtype=torch.float16)

2025-06-10 00:13:33.332637 GPU 7 156019 test begin: paddle.nn.functional.interpolate(Tensor([512, 40, 4, 3],"float16"), size=None, scale_factor=8, mode="nearest", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
[accuracy error] backward  paddle.nn.functional.interpolate(Tensor([512, 40, 4, 3],"float16"), size=None, scale_factor=8, mode="nearest", align_corners=False, align_mode=0, data_format="NCHW", name=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 58645 / 245760 (23.9%)
Greatest absolute difference: 0.140625 at index (352, 37, 1, 0) (up to 0.01 allowed)
Greatest relative difference: 509.25 at index (405, 6, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([512, 40, 4, 3]), dtype=torch.float16)
tensor([[[[-2.7422e+00, -1.6904e+00,  1.2363e+00],
          [ 2.1953e+00, -7.9932e-01, -1.8457e+00],
          [ 3.5508e+00,  1.3896e+00,  1.8701e+00],
          [ 2.8848e+00,  3.3535e+00,  4.3594e+00]],

         [[ 3.2544e-01,  2.0264e-01,  3.5215e+00],
          [-1.0840e+00, -2.6777e+00, -1.4795e-01],
          [ 1.0020e+00, -1.0977e+00,  3.0156e+00],
          [ 3.5376e-01, -7.8125e-01,  1.4441e-01]],

         [[ 3.4551e+00, -1.1230e-02, -7.1045e-01],
          [ 2.1035e+00, -5.9912e-01,  4.0703e+00],
          [ 6.7871e-01,  4.7500e+00, -2.8535e+00],
          [ 2.6777e+00,  2.6387e+00, -3.2324e-01]],

         ...,

         [[-1.2754e+00,  7.5098e-01,  2.5215e+00],
          [-2.6719e+00, -4.6016e+00, -2.1230e+00],
          [ 2.5723e+00, -2.9375e+00, -1.9116e-01],
          [ 1.4502e+00, -9.0918e-01,  4.1211e-01]],

         [[ 3.7476e-01, -2.9414e+00,  1.7979e+00],
          [-3.4297e+00, -8.3643e-01,  8.8379e-01],
          [ 4.4531e+00, -6.6553e-01, -1.9863e+00],
          [ 2.9375e+00, -4.0117e+00,  4.2617e+00]],

         [[ 5.5225e-01,  4.6289e+00, -2.8379e+00],
          [-3.5195e+00,  2.1211e+00,  1.4854e+00],
          [-3.8027e+00,  5.4688e+00, -2.1133e+00],
          [ 4.4971e-01,  2.8223e+00,  2.7266e+00]]],


        [[[-1.7402e+00, -3.2764e-01, -1.7969e-01],
          [-2.5879e-01,  2.5918e+00, -2.3105e+00],
          [ 2.9346e-01, -1.4807e-01, -6.1865e-01],
          [-2.3496e+00,  2.3770e+00, -9.1504e-01]],

         [[-1.4590e+00, -7.9375e+00,  5.6689e-01],
          [ 2.5830e-01,  9.1614e-02, -1.0508e+00],
          [ 5.9219e+00,  6.4688e+00, -1.7715e+00],
          [ 2.2363e+00, -1.9805e+00,  2.7617e+00]],

         [[ 2.3645e-01,  6.9531e-01, -9.5508e-01],
          [ 1.3945e+00,  3.6348e+00, -2.7344e+00],
          [ 1.7061e+00,  1.8701e+00, -3.0762e-02],
          [ 3.0840e+00,  4.1836e+00,  1.7861e+00]],

         ...,

         [[ 1.4590e+00,  8.4839e-02,  8.9600e-02],
          [-1.2158e+00, -1.9714e-01,  1.8926e+00],
          [ 3.7109e+00,  3.3555e+00, -3.7109e+00],
          [-3.9766e+00,  7.6025e-01,  1.4368e-01]],

         [[-2.1699e+00, -1.4189e+00,  5.8945e+00],
          [-9.8584e-01,  5.9219e+00,  2.3516e+00],
          [-5.8984e-01,  1.2500e+00, -2.0664e+00],
          [-3.8359e+00,  1.5889e+00,  2.8149e-01]],

         [[ 6.1133e-01, -2.7070e+00,  2.0703e+00],
          [ 4.1953e+00,  5.3828e+00, -2.5703e+00],
          [-6.0986e-01, -5.7227e+00,  1.3701e+00],
          [-2.3066e+00,  7.5781e-01,  2.0251e-01]]],


        [[[-8.9844e-01,  3.6841e-01,  9.5068e-01],
          [-1.5820e+00,  1.5264e+00,  1.5198e-01],
          [-3.2373e-01, -1.1895e+00,  2.1230e+00],
          [-6.6260e-01,  4.2969e+00,  4.0781e+00]],

         [[-7.8906e-01, -9.3066e-01,  1.1465e+00],
          [ 1.7004e-01,  2.8589e-01, -2.9883e+00],
          [-1.8408e+00,  1.8184e+00,  3.5742e-01],
          [-2.0728e-01,  3.3418e+00,  1.3457e+00]],

         [[ 8.2764e-01, -2.0825e-01, -4.3633e+00],
          [-5.3955e-01, -1.7412e+00,  2.0254e+00],
          [ 1.9785e+00, -4.8364e-01,  6.5820e-01],
          [ 3.1763e-01,  6.3721e-01,  2.8516e-01]],

         ...,

         [[-1.4707e+00,  1.9531e-03, -1.6562e+00],
          [ 4.5728e-01,  8.1348e-01, -7.3242e-01],
          [-3.1934e+00,  2.1094e+00,  3.0098e+00],
          [-1.3242e+00, -3.1719e+00,  2.8438e+00]],

         [[-2.8828e+00, -2.7324e+00, -2.2520e+00],
          [-1.0215e+00,  2.9238e+00,  5.7666e-01],
          [ 1.3115e+00,  2.7578e+00, -1.8232e+00],
          [-4.5000e+00, -2.1875e+00, -6.6162e-01]],

         [[ 2.0762e+00, -1.9014e+00, -2.9297e-03],
          [ 1.8389e+00, -2.3496e+00,  5.8655e-02],
          [ 3.1855e+00,  2.4434e+00, -5.6836e-01],
          [ 4.3789e+00, -2.8784e-01,  6.2158e-01]]],


        ...,


        [[[-4.3945e-02, -6.2402e-01,  4.1719e+00],
          [-1.1406e+00, -5.9766e-01, -7.8320e-01],
          [-5.2393e-01, -8.9160e-01, -5.1836e+00],
          [-1.0664e+00,  1.7852e+00, -1.0801e+00]],

         [[-1.0020e+00, -1.8779e+00,  6.3867e+00],
          [ 6.2207e-01,  5.7266e+00, -1.4219e+00],
          [-3.1113e+00,  4.0820e+00, -1.8340e+00],
          [ 6.8994e-01, -2.4766e+00,  4.2651e-01]],

         [[-1.7451e+00,  1.8477e+00, -9.4238e-02],
          [ 1.6006e+00,  6.5479e-01,  2.3809e+00],
          [ 3.7402e+00,  1.3164e+00,  4.6172e+00],
          [ 1.9521e+00,  3.6953e+00,  3.1270e+00]],

         ...,

         [[-6.1890e-02,  9.1846e-01, -1.2549e+00],
          [ 1.3477e+00, -2.4648e+00, -4.2578e+00],
          [ 1.9814e+00, -2.6289e+00, -1.9409e-02],
          [ 1.5908e+00, -1.5889e+00, -4.8901e-01]],

         [[-8.7769e-02,  1.0449e-01, -1.3535e+00],
          [ 1.0898e+00,  1.4512e+00, -2.9414e+00],
          [ 8.2080e-01,  1.3447e+00,  3.4648e+00],
          [-2.1934e+00,  2.5156e+00,  2.2021e-01]],

         [[-1.7598e+00,  1.4814e+00,  1.2900e+00],
          [-1.6338e+00,  1.8555e-01, -3.9824e+00],
          [ 3.1250e-02,  2.4883e+00, -1.8457e+00],
          [ 4.5156e+00, -3.9199e+00, -8.0176e-01]]],


        [[[-3.2910e-01, -5.7148e+00, -1.8433e-02],
          [-8.3838e-01,  1.2080e+00,  3.6758e+00],
          [ 1.6123e+00,  3.1934e-01, -1.7764e+00],
          [-3.9648e-01, -5.5518e-01,  3.3164e+00]],

         [[-2.1621e+00,  2.6309e+00,  9.0454e-02],
          [ 2.4160e+00, -3.2031e+00, -5.7324e-01],
          [ 6.2402e-01, -1.8799e+00,  1.0898e+00],
          [-5.1855e-01, -1.3750e+00, -1.5417e-01]],

         [[-1.1348e+00,  2.1973e+00,  5.2734e-02],
          [-9.7559e-01, -2.7949e+00,  2.2852e+00],
          [ 5.8887e-01, -5.6250e-01, -3.0996e+00],
          [ 1.1680e+00,  2.0996e+00,  3.2383e+00]],

         ...,

         [[-1.5674e+00,  3.6777e+00, -2.3145e+00],
          [ 3.4473e+00, -8.1836e-01, -6.6406e-01],
          [ 6.5674e-02, -1.0576e+00, -2.1777e+00],
          [ 5.0430e+00, -2.0630e-01, -7.1777e-01]],

         [[ 5.9326e-01, -7.1387e-01,  2.5957e+00],
          [ 1.1328e+00,  3.7773e+00,  2.7393e-01],
          [ 1.3037e+00, -3.7012e+00,  2.5757e-01],
          [ 1.6260e+00,  4.2188e+00,  5.4639e-01]],

         [[-9.1162e-01,  3.4521e-01, -2.4648e+00],
          [-2.1270e+00,  4.2930e+00,  3.6133e+00],
          [-6.1035e-02, -1.5830e+00, -2.6582e+00],
          [ 9.4434e-01, -2.2871e+00,  1.2480e+00]]],


        [[[-3.9531e+00, -2.0645e+00,  1.9521e+00],
          [-1.0752e+00,  2.8687e-01, -5.1797e+00],
          [ 9.4678e-01, -1.5420e+00,  2.3320e+00],
          [-5.7910e-01, -4.3945e+00, -6.6406e+00]],

         [[ 2.0840e+00,  3.0371e-01,  1.1025e+00],
          [ 1.8135e+00,  2.5234e+00,  2.2832e+00],
          [-6.9453e+00,  4.2656e+00,  8.1152e-01],
          [-5.5781e+00, -1.3696e-01,  1.5312e+00]],

         [[-7.7539e-01,  5.4102e-01, -1.0518e+00],
          [-2.8574e+00, -1.8955e+00, -1.8496e+00],
          [ 2.0879e+00,  5.7764e-01, -4.4219e+00],
          [ 6.0791e-01, -9.4482e-01,  3.2500e+00]],

         ...,

         [[-2.4785e+00, -4.8945e+00,  6.1367e+00],
          [-3.4688e+00, -8.6475e-01,  1.9033e+00],
          [-9.7656e-03, -4.2734e+00,  3.1201e-01],
          [-7.5537e-01, -3.2051e+00, -6.1572e-01]],

         [[-2.6152e+00, -6.5137e-01, -1.2822e+00],
          [-4.3286e-01,  5.3750e+00,  1.4121e+00],
          [ 6.9043e-01, -2.5449e+00,  1.2168e+00],
          [ 1.1090e-01,  4.2227e+00, -1.1694e-01]],

         [[ 9.6826e-01,  9.9170e-01, -1.1475e+00],
          [ 1.4160e-02,  5.5420e-02,  3.5605e+00],
          [ 3.5859e+00, -9.5264e-01,  3.8867e+00],
          [-7.3535e-01,  6.1133e-01,  1.4521e+00]]]], dtype=torch.float16)
DESIRED: (shape=torch.Size([512, 40, 4, 3]), dtype=torch.float16)
tensor([[[[-2.7676, -1.6963,  1.2412],
          [ 2.2383, -0.8081, -1.8799],
          [ 3.5723,  1.3965,  1.9189],
          [ 2.9180,  3.3672,  4.3984]],

         [[ 0.3154,  0.2211,  3.5723],
          [-1.0957, -2.6914, -0.1492],
          [ 1.0059, -1.1104,  3.0684],
          [ 0.3538, -0.7881,  0.1440]],

         [[ 3.4961,  0.0137, -0.6953],
          [ 2.1562, -0.6431,  4.0859],
          [ 0.6782,  4.8125, -2.8906],
          [ 2.7070,  2.6699, -0.3435]],

         ...,

         [[-1.2520,  0.7568,  2.5508],
          [-2.7012, -4.6523, -2.1465],
          [ 2.5859, -2.9668, -0.1868],
          [ 1.4492, -0.9146,  0.4045]],

         [[ 0.3652, -2.9766,  1.7979],
          [-3.4531, -0.8540,  0.8945],
          [ 4.4805, -0.6621, -1.9980],
          [ 2.9512, -4.0312,  4.2852]],

         [[ 0.5498,  4.6992, -2.8555],
          [-3.5410,  2.1270,  1.5137],
          [-3.8203,  5.5391, -2.1465],
          [ 0.4561,  2.8613,  2.7480]]],


        [[[-1.7666, -0.3530, -0.2052],
          [-0.2527,  2.6172, -2.3262],
          [ 0.2939, -0.1594, -0.6167],
          [-2.3672,  2.3789, -0.9160]],

         [[-1.4580, -8.0000,  0.5771],
          [ 0.2556,  0.0609, -1.0586],
          [ 6.0195,  6.5547, -1.7666],
          [ 2.2480, -2.0137,  2.8027]],

         [[ 0.2186,  0.7080, -0.9497],
          [ 1.4014,  3.6562, -2.7520],
          [ 1.7344,  1.8818, -0.0330],
          [ 3.1289,  4.2617,  1.7979]],

         ...,

         [[ 1.4736,  0.0895,  0.0964],
          [-1.2324, -0.2019,  1.9082],
          [ 3.7734,  3.3926, -3.7363],
          [-4.0391,  0.7754,  0.1432]],

         [[-2.2012, -1.4268,  5.9688],
          [-0.9824,  5.9961,  2.3848],
          [-0.6099,  1.2744, -2.0820],
          [-3.8633,  1.6113,  0.2861]],

         [[ 0.6431, -2.7344,  2.0938],
          [ 4.2461,  5.4336, -2.6133],
          [-0.6064, -5.7773,  1.3867],
          [-2.3379,  0.7539,  0.1895]]],


        [[[-0.9189,  0.3484,  0.9697],
          [-1.6270,  1.5508,  0.1322],
          [-0.3298, -1.2139,  2.1426],
          [-0.6646,  4.3320,  4.1250]],

         [[-0.7856, -0.9443,  1.1895],
          [ 0.1960,  0.2964, -3.0215],
          [-1.8389,  1.8330,  0.3572],
          [-0.2117,  3.3594,  1.3496]],

         [[ 0.8433, -0.2039, -4.3984],
          [-0.5532, -1.7754,  2.0469],
          [ 1.9854, -0.4900,  0.6572],
          [ 0.2939,  0.6348,  0.2886]],

         ...,

         [[-1.4893,  0.0226, -1.6865],
          [ 0.4441,  0.8223, -0.7275],
          [-3.2148,  2.1289,  3.0547],
          [-1.3164, -3.2129,  2.8809]],

         [[-2.9375, -2.7715, -2.2754],
          [-1.0234,  2.9512,  0.5737],
          [ 1.3223,  2.7812, -1.8477],
          [-4.5625, -2.1836, -0.6587]],

         [[ 2.0996, -1.8848,  0.0223],
          [ 1.8418, -2.3867,  0.0628],
          [ 3.2051,  2.4980, -0.5688],
          [ 4.4375, -0.3003,  0.6133]]],


        ...,


        [[[-0.0351, -0.6104,  4.1914],
          [-1.1533, -0.5879, -0.7808],
          [-0.5229, -0.9106, -5.2383],
          [-1.0752,  1.7910, -1.0850]],

         [[-1.0010, -1.8799,  6.4570],
          [ 0.6270,  5.7891, -1.4316],
          [-3.1621,  4.1367, -1.8633],
          [ 0.6797, -2.5293,  0.4382]],

         [[-1.7510,  1.8535, -0.1044],
          [ 1.6045,  0.6489,  2.4297],
          [ 3.7617,  1.3193,  4.6602],
          [ 1.9863,  3.7305,  3.1602]],

         ...,

         [[-0.0683,  0.9478, -1.2432],
          [ 1.3916, -2.4902, -4.2812],
          [ 2.0195, -2.6543, -0.0298],
          [ 1.6006, -1.5977, -0.5015]],

         [[-0.0852,  0.1081, -1.3555],
          [ 1.0967,  1.4854, -2.9746],
          [ 0.8257,  1.3584,  3.4785],
          [-2.2109,  2.5352,  0.2235]],

         [[-1.7734,  1.5010,  1.2842],
          [-1.6455,  0.1880, -4.0156],
          [ 0.0426,  2.5195, -1.8730],
          [ 4.5469, -3.9844, -0.7954]]],


        [[[-0.3474, -5.7969, -0.0235],
          [-0.8760,  1.2158,  3.7070],
          [ 1.6465,  0.3391, -1.8193],
          [-0.4114, -0.5557,  3.3398]],

         [[-2.2012,  2.6621,  0.0815],
          [ 2.4336, -3.2383, -0.5771],
          [ 0.6392, -1.8975,  1.0879],
          [-0.5259, -1.3809, -0.1543]],

         [[-1.1768,  2.2246,  0.0542],
          [-0.9766, -2.8203,  2.2832],
          [ 0.5972, -0.5659, -3.1270],
          [ 1.1699,  2.1230,  3.2559]],

         ...,

         [[-1.6025,  3.7090, -2.3457],
          [ 3.4590, -0.8354, -0.6538],
          [ 0.0783, -1.0752, -2.1895],
          [ 5.0977, -0.2144, -0.7397]],

         [[ 0.5972, -0.7339,  2.6133],
          [ 1.1436,  3.7949,  0.2820],
          [ 1.3154, -3.7461,  0.2585],
          [ 1.6309,  4.2539,  0.5317]],

         [[-0.9019,  0.3684, -2.4824],
          [-2.1367,  4.3242,  3.6660],
          [-0.0598, -1.5928, -2.6777],
          [ 0.9844, -2.2910,  1.2549]]],


        [[[-3.9980, -2.0742,  1.9766],
          [-1.0898,  0.2805, -5.2461],
          [ 0.9556, -1.5361,  2.3594],
          [-0.5781, -4.4336, -6.7227]],

         [[ 2.0820,  0.3035,  1.1387],
          [ 1.8389,  2.5391,  2.3047],
          [-7.0000,  4.3359,  0.8184],
          [-5.6406, -0.1539,  1.5527]],

         [[-0.7710,  0.5381, -1.0615],
          [-2.8945, -1.9131, -1.8545],
          [ 2.0918,  0.5889, -4.4609],
          [ 0.6045, -0.9541,  3.2949]],

         ...,

         [[-2.4941, -4.9570,  6.1758],
          [-3.5273, -0.8384,  1.9395],
          [-0.0177, -4.3008,  0.3132],
          [-0.7197, -3.2422, -0.6079]],

         [[-2.6289, -0.6455, -1.2861],
          [-0.4299,  5.4336,  1.4102],
          [ 0.7119, -2.5547,  1.2148],
          [ 0.1050,  4.2500, -0.1233]],

         [[ 1.0088,  1.0312, -1.1660],
          [ 0.0262,  0.0471,  3.6094],
          [ 3.6523, -0.9556,  3.9336],
          [-0.7241,  0.5864,  1.4531]]]], dtype=torch.float16)

2025-06-10 00:13:33.357449 GPU 4 157147 test begin: paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, fastemit_lambda=0.0, reduction="none", name=None, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, fastemit_lambda=0.0, reduction="none", name=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: 9.672027587890625 at index (2,) (up to 0.01 allowed)
Greatest relative difference: 2.326272964477539 at index (2,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float32)
tensor([-5.4131, -5.1953, -5.5143])
DESIRED: (shape=torch.Size([3]), dtype=torch.float32)
tensor([4.1674, 4.1955, 4.1577])

2025-06-10 00:13:33.563990 GPU 6 156017 test begin: paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="mean", fastemit_lambda=0.0, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="mean", fastemit_lambda=0.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected 4.26412296295166 but got -5.760981559753418.
Absolute difference: 10.025104522705078 (up to 0.01 allowed)
Relative difference: 2.351035514174202 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-5.760981559753418
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
4.26412296295166

2025-06-10 00:13:33.633898 GPU 5 156018 test begin: paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="sum", fastemit_lambda=0.0, )
One of the differentiated Tensors does not require grad
[accuracy error] paddle.nn.functional.rnnt_loss(Tensor([3, 4, 3, 3],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int32"), Tensor([3],"int32"), blank=0, reduction="sum", fastemit_lambda=0.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Scalars are not close!

Expected 13.128751754760742 but got -16.92229461669922.
Absolute difference: 30.05104637145996 (up to 0.01 allowed)
Relative difference: 2.288949241542545 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
-16.92229461669922
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
13.128751754760742

2025-06-10 00:13:34.649397 GPU 5 156018 test begin: paddle.sort(Tensor([3, 10000],"float32"), descending=True, )
[accuracy error] backward  paddle.sort(Tensor([3, 10000],"float32"), descending=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 6 / 30000 (0.0%)
Greatest absolute difference: 0.8022726774215698 at index (0, 133) (up to 0.01 allowed)
Greatest relative difference: 4.64130973815918 at index (2, 6446) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 10000]), dtype=torch.float32)
tensor([[-0.4213, -0.1061,  0.1171,  ..., -0.1526,  0.2721, -0.1549],
        [-0.0541, -0.1028, -0.3423,  ..., -0.1028,  0.4160, -0.3471],
        [-0.4484, -0.2084, -0.4334,  ...,  0.0883, -0.3997,  0.3513]])
DESIRED: (shape=torch.Size([3, 10000]), dtype=torch.float32)
tensor([[-0.4213, -0.1061,  0.1171,  ..., -0.1526,  0.2721, -0.1549],
        [-0.0541, -0.1028, -0.3423,  ..., -0.1028,  0.4160, -0.3471],
        [-0.4484, -0.2084, -0.4334,  ...,  0.0883, -0.3997,  0.3513]])

2025-06-10 00:13:34.656086 GPU 4 156016 test begin: paddle.sort(Tensor([35968],"float32"), 0, )
[accuracy error] backward  paddle.sort(Tensor([35968],"float32"), 0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 14 / 35968 (0.0%)
Greatest absolute difference: 0.9516134262084961 at index (10524,) (up to 0.01 allowed)
Greatest relative difference: 4.90602970123291 at index (22401,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([35968]), dtype=torch.float32)
tensor([ 3.3223e-01,  1.1685e-01, -1.1943e-03,  ..., -2.1839e-02,  3.6598e-04,  4.6405e-01])
DESIRED: (shape=torch.Size([35968]), dtype=torch.float32)
tensor([ 3.3223e-01,  1.1685e-01, -1.1943e-03,  ..., -2.1839e-02,  3.6598e-04,  4.6405e-01])

2025-06-10 00:13:34.679321 GPU 4 157147 test begin: paddle.sort(Tensor([380086],"float32"), )
[accuracy error] backward  paddle.sort(Tensor([380086],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1342 / 380086 (0.4%)
Greatest absolute difference: 0.9658920764923096 at index (5427,) (up to 0.01 allowed)
Greatest relative difference: 8144.88330078125 at index (223040,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([380086]), dtype=torch.float32)
tensor([ 0.4353,  0.0237,  0.3936,  ..., -0.4636, -0.4111, -0.0986])
DESIRED: (shape=torch.Size([380086]), dtype=torch.float32)
tensor([ 0.4353,  0.0237,  0.3936,  ..., -0.4636, -0.4111, -0.0986])

2025-06-10 00:13:34.763929 GPU 5 155999 test begin: paddle.sort(Tensor([401899],"float32"), )
[accuracy error] backward  paddle.sort(Tensor([401899],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1488 / 401899 (0.4%)
Greatest absolute difference: 0.9552021622657776 at index (203442,) (up to 0.01 allowed)
Greatest relative difference: 944.5874633789062 at index (11118,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([401899]), dtype=torch.float32)
tensor([-0.1536,  0.3549, -0.2641,  ...,  0.0386, -0.1533, -0.3369])
DESIRED: (shape=torch.Size([401899]), dtype=torch.float32)
tensor([-0.1536,  0.3549, -0.2641,  ...,  0.0386, -0.1533, -0.3369])

2025-06-10 00:13:34.765729 GPU 6 156013 test begin: paddle.sort(Tensor([403187],"float32"), )
[accuracy error] backward  paddle.sort(Tensor([403187],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1585 / 403187 (0.4%)
Greatest absolute difference: 0.9654260873794556 at index (237290,) (up to 0.01 allowed)
Greatest relative difference: 883.8982543945312 at index (98237,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([403187]), dtype=torch.float32)
tensor([-0.4569,  0.1881, -0.1920,  ...,  0.1346, -0.4553,  0.0814])
DESIRED: (shape=torch.Size([403187]), dtype=torch.float32)
tensor([-0.4569,  0.1881, -0.1920,  ...,  0.1346, -0.4553,  0.0814])

2025-06-10 00:13:34.834953 GPU 6 156017 test begin: paddle.sort(Tensor([406580],"float32"), )
[accuracy error] backward  paddle.sort(Tensor([406580],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 1665 / 406580 (0.4%)
Greatest absolute difference: 0.9492859840393066 at index (349229,) (up to 0.01 allowed)
Greatest relative difference: 764.8751831054688 at index (148097,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([406580]), dtype=torch.float32)
tensor([ 0.1605, -0.1932, -0.3896,  ..., -0.3301,  0.3241, -0.0514])
DESIRED: (shape=torch.Size([406580]), dtype=torch.float32)
tensor([ 0.1605, -0.1932, -0.3896,  ..., -0.3301,  0.3241, -0.0514])

2025-06-10 00:13:34.870555 GPU 5 156018 test begin: paddle.sort(Tensor([5, 12000],"float32"), descending=True, )
[accuracy error] backward  paddle.sort(Tensor([5, 12000],"float32"), descending=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2 / 60000 (0.0%)
Greatest absolute difference: 0.6169500350952148 at index (1, 2100) (up to 0.01 allowed)
Greatest relative difference: 2.9448485374450684 at index (1, 2100) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 12000]), dtype=torch.float32)
tensor([[-0.0420, -0.3431,  0.1135,  ...,  0.4451,  0.2183, -0.4690],
        [-0.1956, -0.4092, -0.1006,  ...,  0.1947,  0.0856,  0.4788],
        [-0.1135,  0.1965,  0.3771,  ..., -0.4304, -0.3245,  0.3735],
        [ 0.0972, -0.3745, -0.0853,  ...,  0.4568, -0.1259, -0.4342],
        [-0.3307,  0.1056,  0.1296,  ..., -0.4155, -0.1947, -0.2927]])
DESIRED: (shape=torch.Size([5, 12000]), dtype=torch.float32)
tensor([[-0.0420, -0.3431,  0.1135,  ...,  0.4451,  0.2183, -0.4690],
        [-0.1956, -0.4092, -0.1006,  ...,  0.1947,  0.0856,  0.4788],
        [-0.1135,  0.1965,  0.3771,  ..., -0.4304, -0.3245,  0.3735],
        [ 0.0972, -0.3745, -0.0853,  ...,  0.4568, -0.1259, -0.4342],
        [-0.3307,  0.1056,  0.1296,  ..., -0.4155, -0.1947, -0.2927]])

2025-06-10 12:00:53.176016 GPU 3 78431 test begin: paddle.strided_slice(Tensor([6, 6],"int64"), axes=list[0,1,], starts=list[8,-1,], ends=list[1,-5,], strides=list[-2,-3,], )
element 0 of tensors does not require grad and does not have a grad_fn
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[2, 2] and strides=[-12, -3]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f4a659101b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f4a658b9a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f4a3c7816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f4a3d441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f4a3d442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f4a3c77cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f4a3c77cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f4a6680e8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f4a6627d5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: _PyEval_EvalFrameDefault + 0xd02 (0x529512 in /root/miniconda3/envs/paddle/bin/python)
frame #10: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #11: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #12: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #13: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #14: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #15: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #16: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #17: __libc_start_main + 0xe7 (0x7f4bb976cc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #18: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528053 (unix time) try "date -d @1749528053" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1325f) received by PID 78431 (TID 0x7f4bba715740) from PID 78431 ***]


2025-06-10 12:00:53.238553 GPU 3 78426 test begin: paddle.strided_slice(Tensor([6, 7, 8],"int64"), axes=list[0,2,], starts=list[7,-1,], ends=list[2,-5,], strides=list[-2,-3,], )
element 0 of tensors does not require grad and does not have a grad_fn
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[2, 7, 2] and strides=[-112, 8, -3]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f3a265101b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f3a264b9a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f39fc7816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f39fd441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f39fd442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f39fc77cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f39fc77cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f3a2740e8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f3a26e7d5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: _PyEval_EvalFrameDefault + 0xd02 (0x529512 in /root/miniconda3/envs/paddle/bin/python)
frame #10: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #11: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #12: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #13: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #14: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #15: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #16: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #17: __libc_start_main + 0xe7 (0x7f3b7a41ec87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #18: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528053 (unix time) try "date -d @1749528053" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1325a) received by PID 78426 (TID 0x7f3b7b3c7740) from PID 78426 ***]


2025-06-10 12:00:53.382646 GPU 3 78429 test begin: paddle.strided_slice(x=Tensor([5, 8, 6, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[-3,3,4,], ends=list[3,0,1,], strides=list[-1,-1,-2,], )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 2, 3, 4, 2, 2] and strides=[2304, -288, -48, 12, 6, -2]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9bed6101b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f9bed5b9a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f9bd47816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f9bd5441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f9bd5442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f9bd477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f9bd477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f9bee50e8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f9bedf7d5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: _PyEval_EvalFrameDefault + 0xd02 (0x529512 in /root/miniconda3/envs/paddle/bin/python)
frame #10: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #11: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #12: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #13: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #14: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #15: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #16: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #17: __libc_start_main + 0xe7 (0x7f9d4d493c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #18: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528053 (unix time) try "date -d @1749528053" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1325d) received by PID 78429 (TID 0x7f9d4e43c740) from PID 78429 ***]


2025-06-10 12:00:53.469009 GPU 3 78425 test begin: paddle.strided_slice(x=Tensor([5, 8, 6, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[6,5,4,], ends=list[2,0,1,], strides=list[-1,-2,-3,], )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 4, 3, 4, 2, 1] and strides=[2304, -288, -96, 12, 6, 1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f9d28e281b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f9d28dd1a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f9cfc7816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f9cfd441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f9cfd442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f9cfc77cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f9cfc77cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f9d238388e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f9d232a75f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: _PyEval_EvalFrameDefault + 0xd02 (0x529512 in /root/miniconda3/envs/paddle/bin/python)
frame #10: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #11: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #12: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #13: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #14: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #15: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #16: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #17: __libc_start_main + 0xe7 (0x7f9e776b3c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #18: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528053 (unix time) try "date -d @1749528053" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13259) received by PID 78425 (TID 0x7f9e7865c740) from PID 78425 ***]


2025-06-10 00:14:25.971962 GPU 5 156012 test begin: paddle.trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=None, axis=-1, )
[accuracy error] backward  paddle.trapezoid(y=Tensor([2, 3],"float32"), x=None, dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 6 (50.0%)
Greatest absolute difference: 0.5807682275772095 at index (1, 1) (up to 0.01 allowed)
Greatest relative difference: 1.1774439811706543 at index (1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[-0.0438, -0.0875, -0.0438],
        [-0.0438, -0.0875, -0.0438]])
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[-0.0438, -0.0875, -0.0438],
        [ 0.2466,  0.4932,  0.2466]])

2025-06-10 00:14:25.987559 GPU 7 158411 test begin: paddle.trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, )
[accuracy error] backward  paddle.trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 6 (50.0%)
Greatest absolute difference: 0.07241073250770569 at index (1, 0) (up to 0.01 allowed)
Greatest relative difference: 6.587549686431885 at index (1, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[-0.0419, -0.0126,  0.0293],
        [-0.0419, -0.0126,  0.0293]])
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float32)
tensor([[-0.0419, -0.0126,  0.0293],
        [ 0.0305,  0.0344,  0.0039]])

2025-06-10 00:14:25.996976 GPU 4 156002 test begin: paddle.trapezoid(y=Tensor([2, 3],"float64"), x=None, dx=None, axis=-1, )
W0610 00:14:26.105412 156002 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] backward  paddle.trapezoid(y=Tensor([2, 3],"float64"), x=None, dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 3 / 6 (50.0%)
Greatest absolute difference: 0.5497920509779376 at index (1, 1) (up to 0.01 allowed)
Greatest relative difference: 2.166121704912436 at index (1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[-0.1480, -0.2960, -0.1480],
        [-0.1480, -0.2960, -0.1480]], dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[-0.1480, -0.2960, -0.1480],
        [ 0.1269,  0.2538,  0.1269]], dtype=torch.float64)

2025-06-10 00:14:26.007940 GPU 4 156000 test begin: paddle.trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
[accuracy error] backward  paddle.trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 2 / 6 (33.3%)
Greatest absolute difference: 0.04384030315663599 at index (1, 1) (up to 0.01 allowed)
Greatest relative difference: 23.04458926629219 at index (1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[ 0.0375,  0.0307, -0.0068],
        [ 0.0375,  0.0307, -0.0068]], dtype=torch.float64)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float64)
tensor([[ 0.0375,  0.0307, -0.0068],
        [-0.0017, -0.0131, -0.0114]], dtype=torch.float64)

2025-06-10 00:14:26.012670 GPU 6 156956 test begin: paddle.trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
[accuracy error] backward  paddle.trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Tensor-likes are not close!

Mismatched elements: 12 / 36 (33.3%)
Greatest absolute difference: 0.06984260678291321 at index (2, 2, 2) (up to 0.01 allowed)
Greatest relative difference: 17.85518455505371 at index (1, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3, 4]), dtype=torch.float32)
tensor([[[ 0.0045, -0.0031, -0.0009,  0.0002],
         [-0.0357,  0.0243,  0.0073, -0.0017],
         [-0.0402,  0.0273,  0.0083, -0.0019]],

        [[ 0.0045, -0.0031, -0.0009,  0.0002],
         [-0.0357,  0.0243,  0.0073, -0.0017],
         [-0.0402,  0.0273,  0.0083, -0.0019]],

        [[ 0.0045, -0.0031, -0.0009,  0.0002],
         [-0.0357,  0.0243,  0.0073, -0.0017],
         [-0.0402,  0.0273,  0.0083, -0.0019]]])
DESIRED: (shape=torch.Size([3, 3, 4]), dtype=torch.float32)
tensor([[[ 0.0045, -0.0031, -0.0009,  0.0002],
         [-0.0357,  0.0243,  0.0073, -0.0017],
         [-0.0402,  0.0273,  0.0083, -0.0019]],

        [[ 0.0002,  0.0030,  0.0021, -0.0001],
         [-0.0019, -0.0236, -0.0166,  0.0009],
         [-0.0021, -0.0266, -0.0187,  0.0011]],

        [[ 0.0053, -0.0084,  0.0070, -0.0048],
         [-0.0414,  0.0657, -0.0546,  0.0376],
         [-0.0467,  0.0740, -0.0616,  0.0424]]])

2025-06-10 12:00:54.381727 GPU 3 78430 test begin: paddle.vander(Tensor([5],"complex128"), 2, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 2] and strides=[2, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fb5e54101b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7fb5e53b9a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7fb5bc7816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7fb5bd441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7fb5bd442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7fb5bc77cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7fb5bc77cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7fb5e630e8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7fb5e5d7d5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: _PyEval_EvalFrameDefault + 0xd02 (0x529512 in /root/miniconda3/envs/paddle/bin/python)
frame #10: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #11: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #12: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #13: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #14: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #15: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #16: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #17: __libc_start_main + 0xe7 (0x7fb739247c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #18: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528054 (unix time) try "date -d @1749528054" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1325e) received by PID 78430 (TID 0x7fb73a1f0740) from PID 78430 ***]


2025-06-10 12:00:57.112906 GPU 3 78427 test begin: paddle.vander(Tensor([5],"complex128"), 3, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 3] and strides=[3, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f247222e1b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f24721d7a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f24447816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f2445441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f2445442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f244477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f244477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f247315e8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f2472bcd5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f25c2135c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528057 (unix time) try "date -d @1749528057" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1325b) received by PID 78427 (TID 0x7f25c30de740) from PID 78427 ***]


2025-06-10 12:00:58.225637 GPU 3 79152 test begin: paddle.vander(Tensor([5],"complex128"), 4, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 4] and strides=[4, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f25048081b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f25047b1a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f24d47816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f24d5441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f24d5442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f24d477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f24d477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f25057388e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f25051a75f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f265460dc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528075 (unix time) try "date -d @1749528075" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13530) received by PID 79152 (TID 0x7f26555b6740) from PID 79152 ***]


2025-06-10 12:00:58.656299 GPU 3 79181 test begin: paddle.vander(Tensor([5],"float32"), 2, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 2] and strides=[2, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7ffa029761b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7ffa0291fa76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7ff9d47816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7ff9d5441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7ff9d5442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7ff9d477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7ff9d477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7ffa038a68e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7ffa033155f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7ffb5287bc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528075 (unix time) try "date -d @1749528075" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1354d) received by PID 79181 (TID 0x7ffb53824740) from PID 79181 ***]


2025-06-10 12:00:58.775979 GPU 3 79209 test begin: paddle.vander(Tensor([5],"float32"), 3, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 3] and strides=[3, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f88d44be1b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f88d4467a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f88a47816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f88a5441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f88a5442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f88a477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f88a477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f88d53ee8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f88d4e5d5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f8a242c3c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528076 (unix time) try "date -d @1749528076" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13569) received by PID 79209 (TID 0x7f8a2526c740) from PID 79209 ***]


2025-06-10 12:01:00.715268 GPU 3 79238 test begin: paddle.vander(Tensor([5],"float32"), 4, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 4] and strides=[4, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f8f301f61b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f8f3019fa76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f8f047816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f8f05441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f8f05442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f8f0477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f8f0477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f8f311268e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f8f30b955f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f907fffbc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528076 (unix time) try "date -d @1749528076" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13586) received by PID 79238 (TID 0x7f9080fa4740) from PID 79238 ***]


2025-06-10 12:01:01.026434 GPU 3 78428 test begin: paddle.vander(Tensor([5],"float32"), 5, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 5] and strides=[5, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fd74c7fa1b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7fd74c7a3a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7fd71c7816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7fd71d441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7fd71d442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7fd71c77cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7fd71c77cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7fd7478388e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7fd7472a75f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7fd89b088c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528061 (unix time) try "date -d @1749528061" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1325c) received by PID 78428 (TID 0x7fd89c031740) from PID 78428 ***]


2025-06-10 12:01:02.733680 GPU 3 79331 test begin: paddle.vander(Tensor([5],"float32"), 6, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 6] and strides=[6, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6118aa31b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f6118a4ca76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f60ec7816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f60ed441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f60ed442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f60ec77cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f60ec77cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f61138388e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f61132a75f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f626742dc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528077 (unix time) try "date -d @1749528077" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x135e3) received by PID 79331 (TID 0x7f62683d6740) from PID 79331 ***]


2025-06-10 12:01:08.296750 GPU 3 79457 test begin: paddle.vander(Tensor([5],"float32"), 7, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 7] and strides=[7, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6e0073a1b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f6e006e3a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f6dd47816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f6dd5441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f6dd5442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f6dd477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f6dd477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f6e0165e8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f6e010cd5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f6f50547c87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528081 (unix time) try "date -d @1749528081" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13661) received by PID 79457 (TID 0x7f6f514f0740) from PID 79457 ***]


2025-06-10 12:01:11.023861 GPU 3 79528 test begin: paddle.vander(Tensor([5],"float32"), 8, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 8] and strides=[8, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f2590f971b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f2590f40a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f25647816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f2565441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f2565442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f256477cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f256477cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f2591ec78e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f25919365f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f26e0eabc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528084 (unix time) try "date -d @1749528084" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x136a8) received by PID 79528 (TID 0x7f26e1e4f740) from PID 79528 ***]


2025-06-10 12:01:20.229147 GPU 3 79691 test begin: paddle.vander(Tensor([5],"float32"), None, False, )
terminate called after throwing an instance of 'c10::Error'
  what():  Storage size calculation overflowed with sizes=[5, 5] and strides=[5, -1]
Exception raised from computeStorageNbytes at /pytorch/aten/src/ATen/EmptyTensor.cpp:109 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f8595f101b6 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f8595eb9a76 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #2: at::detail::computeStorageNbytes(c10::ArrayRef<long>, c10::ArrayRef<long>, unsigned long, unsigned long) + 0x35e (0x7f856c7816ee in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #3: at::TensorMaker::computeStorageSize() const + 0xb3 (0x7f856d441f03 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #4: at::TensorMaker::make_tensor() + 0x440 (0x7f856d442390 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #5: at::fromDLPack(DLManagedTensor*, std::function<void (void*)>) + 0x354 (0x7f856c77cab4 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #6: at::fromDLPack(DLManagedTensor*) + 0x31 (0x7f856c77cf41 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)
frame #7: torch::utils::tensor_fromDLPack(_object*) + 0x40 (0x7f8596e0e8e0 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x8235f9 (0x7f859687d5f9 in /root/miniconda3/envs/paddle/lib/python3.12/site-packages/torch/lib/libtorch_python.so)
frame #9: /root/miniconda3/envs/paddle/bin/python() [0x54be6b]
frame #10: PyObject_Vectorcall + 0x51 (0x5416a1 in /root/miniconda3/envs/paddle/bin/python)
frame #11: _PyEval_EvalFrameDefault + 0x6ce (0x528ede in /root/miniconda3/envs/paddle/bin/python)
frame #12: PyEval_EvalCode + 0xae (0x5e581e in /root/miniconda3/envs/paddle/bin/python)
frame #13: /root/miniconda3/envs/paddle/bin/python() [0x60bfd7]
frame #14: /root/miniconda3/envs/paddle/bin/python() [0x6071c7]
frame #15: PyRun_StringFlags + 0x5f (0x5f694f in /root/miniconda3/envs/paddle/bin/python)
frame #16: PyRun_SimpleStringFlags + 0x3a (0x5f687a in /root/miniconda3/envs/paddle/bin/python)
frame #17: Py_RunMain + 0x45f (0x617def in /root/miniconda3/envs/paddle/bin/python)
frame #18: Py_BytesMain + 0x39 (0x5d03c9 in /root/miniconda3/envs/paddle/bin/python)
frame #19: __libc_start_main + 0xe7 (0x7f86e9dbbc87 in /lib/x86_64-linux-gnu/libc.so.6)
frame #20: /root/miniconda3/envs/paddle/bin/python() [0x5d01f9]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   torch::utils::tensor_fromDLPack(_object*)
1   at::fromDLPack(DLManagedTensor*)
2   at::fromDLPack(DLManagedTensor*, std::function<void (void*)>)
3   at::TensorMaker::make_tensor()
4   at::TensorMaker::computeStorageSize() const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749528092 (unix time) try "date -d @1749528092" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1374b) received by PID 79691 (TID 0x7f86ead64740) from PID 79691 ***]


