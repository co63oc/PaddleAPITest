paddle.allclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
paddle.atan2(Tensor([5, 17, 1, 6],"float64"), Tensor([5, 17, 0, 6],"float64"), )
paddle.atan2(Tensor([5, 17, 6],"float64"), Tensor([0, 5, 17, 6],"float64"), )
paddle.atan2(Tensor([0],"float64"), Tensor([0, 0],"float64"), )
paddle.atan2(Tensor([0, 0, 0],"float64"), Tensor([0],"float64"), )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 10164, 80],"float16"), Tensor([8, 10164, 80],"float32"), weight=Tensor([8, 10164, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 11109, 80],"float16"), Tensor([8, 11109, 80],"float32"), weight=Tensor([8, 11109, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 12096, 80],"float16"), Tensor([8, 12096, 80],"float32"), weight=Tensor([8, 12096, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 2100, 80],"float16"), Tensor([8, 2100, 80],"float32"), weight=Tensor([8, 2100, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 2541, 80],"float16"), Tensor([8, 2541, 80],"float32"), weight=Tensor([8, 2541, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 3024, 80],"float16"), Tensor([8, 3024, 80],"float32"), weight=Tensor([8, 3024, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 3549, 80],"float16"), Tensor([8, 3549, 80],"float32"), weight=Tensor([8, 3549, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 4116, 80],"float16"), Tensor([8, 4116, 80],"float32"), weight=Tensor([8, 4116, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 4725, 80],"float16"), Tensor([8, 4725, 80],"float32"), weight=Tensor([8, 4725, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 5376, 80],"float16"), Tensor([8, 5376, 80],"float32"), weight=Tensor([8, 5376, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 6069, 80],"float16"), Tensor([8, 6069, 80],"float32"), weight=Tensor([8, 6069, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 6804, 80],"float16"), Tensor([8, 6804, 80],"float32"), weight=Tensor([8, 6804, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 7581, 80],"float16"), Tensor([8, 7581, 80],"float32"), weight=Tensor([8, 7581, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 8400, 80],"float16"), Tensor([8, 8400, 80],"float32"), weight=Tensor([8, 8400, 80],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy(Tensor([8, 9261, 80],"float16"), Tensor([8, 9261, 80],"float32"), weight=Tensor([8, 9261, 80],"float32"), reduction="sum", )
paddle.cross(Tensor([0, 3],"float32"), Tensor([0, 3],"float32"), axis=1, )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), mode="gray", )
paddle.vision.ops.decode_jpeg(Tensor([142887],"uint8"), mode="rgb", )
paddle.einsum("...ab,...ba,...ab,...ab", Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), )
paddle.gather(x=Tensor([3, 4],"float64"), index=Tensor([0],"int32"), axis=0, )paddle.gather(x=Tensor([3, 4],"float64"), index=Tensor([0],"int32"), axis=0, )
paddle.nn.functional.hsigmoid_loss(Tensor([4, 8],"float64"), Tensor([4],"int64"), 6, Tensor([5, 8],"float64"), Tensor([5, 1],"float64"), Tensor([4, 5],"int64"), Tensor([4, 5],"int64"), True, )
paddle.Tensor.matmul(Tensor([125, 1],"float32"), Tensor([1, 0],"float32"), )
paddle.matmul(Tensor([1, 2, 2048, 2048],"bfloat16"), Tensor([1, 2, 2048, 128],"bfloat16"), )
paddle.matmul(x=Tensor([1, 2, 2048, 128],"bfloat16"), y=Tensor([1, 2, 2048, 128],"bfloat16"), transpose_x=False, transpose_y=True, )
paddle.matmul(x=Tensor([3, 2, 2, 5],"float64"), y=Tensor([5],"float64"), transpose_x=False, transpose_y=True, )
paddle.vision.ops.deform_conv2d(x=Tensor([12, 512, 10, 10],"float16"), offset=Tensor([12, 18, 10, 10],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([12, 9, 10, 10],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([12, 512, 20, 20],"float16"), offset=Tensor([12, 18, 10, 10],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([12, 9, 10, 10],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([20, 128, 76, 136],"float16"), offset=Tensor([20, 18, 76, 136],"float16"), weight=Tensor([64, 128, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([20, 9, 76, 136],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([20, 256, 38, 68],"float16"), offset=Tensor([20, 18, 38, 68],"float16"), weight=Tensor([128, 256, 3, 3],"float16"), bias=Tensor([128],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([20, 9, 38, 68],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([20, 512, 19, 34],"float16"), offset=Tensor([20, 18, 19, 34],"float16"), weight=Tensor([256, 512, 3, 3],"float16"), bias=Tensor([256],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([20, 9, 19, 34],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 128, 100, 100],"float16"), offset=Tensor([6, 36, 100, 100],"float16"), weight=Tensor([128, 128, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 100, 100],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 128, 200, 200],"float16"), offset=Tensor([6, 36, 100, 100],"float16"), weight=Tensor([128, 128, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 100, 100],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 256, 100, 100],"float16"), offset=Tensor([6, 36, 50, 50],"float16"), weight=Tensor([256, 256, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 50, 50],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 256, 50, 50],"float16"), offset=Tensor([6, 36, 50, 50],"float16"), weight=Tensor([256, 256, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 50, 50],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 512, 25, 25],"float16"), offset=Tensor([6, 36, 25, 25],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 25, 25],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([6, 512, 50, 50],"float16"), offset=Tensor([6, 36, 25, 25],"float16"), weight=Tensor([512, 512, 3, 3],"float16"), bias=None, stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=2, groups=1, mask=Tensor([6, 18, 25, 25],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([64, 64, 16, 16],"float16"), offset=Tensor([64, 144, 16, 16],"float16"), weight=Tensor([64, 64, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=8, groups=1, mask=Tensor([64, 72, 16, 16],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([64, 64, 32, 32],"float16"), offset=Tensor([64, 144, 32, 32],"float16"), weight=Tensor([64, 64, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=8, groups=1, mask=Tensor([64, 72, 32, 32],"float16"), )
paddle.vision.ops.deform_conv2d(x=Tensor([64, 64, 64, 64],"float16"), offset=Tensor([64, 144, 64, 64],"float16"), weight=Tensor([64, 64, 3, 3],"float16"), bias=Tensor([64],"float16"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=8, groups=1, mask=Tensor([64, 72, 64, 64],"float16"), )
paddle.cartesian_prod(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.cartesian_prod(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([3],"complex128"),Tensor([0],"complex128"),], )
paddle.cartesian_prod(list[Tensor([2],"float16"),Tensor([2],"float16"),Tensor([1],"float16"),Tensor([0],"float16"),], )
paddle.cartesian_prod(list[Tensor([2],"float64"),Tensor([4],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.cartesian_prod(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5],"complex128"),Tensor([0],"complex128"),], )
paddle.cartesian_prod(list[Tensor([3],"float64"),Tensor([5],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.cartesian_prod(list[Tensor([4],"float16"),Tensor([3],"float16"),Tensor([5],"float16"),Tensor([0],"float16"),], )
paddle.cartesian_prod(list[Tensor([4],"float32"),Tensor([2],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.cartesian_prod(list[Tensor([5],"complex64"),Tensor([2],"complex64"),Tensor([5],"complex64"),Tensor([0],"complex64"),], )
paddle.cartesian_prod(list[Tensor([5],"complex64"),Tensor([4],"complex64"),Tensor([3],"complex64"),Tensor([0],"complex64"),], )
paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 1, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), False, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), Tensor([2, 8, 16, 128, 64],"float32"), Tensor([8, 16, 1, 129],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 1, 2, 2],"float32"), dropout_rate=0, attn_dropout_rate=0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([4],"float32"), pre_ln_bias=Tensor([4],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([4],"float32"), pre_ln_bias=Tensor([4],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 2, 2],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 1, 2, 2],"float32"), dropout_rate=0, attn_dropout_rate=0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=Tensor([4],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([12],"float32"), linear_bias=Tensor([4],"float32"), cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )
paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([256],"float32"), ln_bias=Tensor([256],"float32"), pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )
paddle.index_put(Tensor([16, 21],"float64"), tuple(Tensor([16, 21],"bool"),), Tensor([2, 1],"float64"), False, )
paddle.index_put(Tensor([16, 21],"float64"), tuple(Tensor([16, 21],"bool"),), Tensor([2, 1],"float64"), True, )
paddle.linalg.eigh(Tensor([0, 0],"float32"), )
paddle.linalg.eigh(Tensor([0, 5, 5],"float32"), )
paddle.linalg.matrix_power(Tensor([0, 0],"float32"), 2, )
paddle.linalg.matrix_power(Tensor([2, 3, 0, 0],"float32"), 2, )
paddle.linalg.norm(Tensor([2, 3, 4, 5],"bfloat16"), 2.0, 1, False, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([1, 100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([1, 17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([1, 4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([1, 40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([1, 40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([1, 40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([2, 3, 40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 40],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 40],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([3, 100, 40],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([3, 17, 4],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 17, 4],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([3, 4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([3, 40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([3, 40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([3, 40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([4, 100],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([4, 100],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([4, 17],"float64"), q=2, )
paddle.linalg.pca_lowrank(Tensor([4, 17],"float64"), q=4, )
paddle.linalg.pca_lowrank(Tensor([40, 100],"float64"), q=12, )
paddle.linalg.pca_lowrank(Tensor([40, 100],"float64"), q=6, )
paddle.linalg.pca_lowrank(Tensor([40, 100],"float64"), q=8, )
paddle.linalg.pca_lowrank(Tensor([5, 5],"float64"), None, center=False, )
paddle.linalg.solve(Tensor([10, 0, 0],"float32"), Tensor([10, 0, 0],"float32"), left=False, )
paddle.linalg.svdvals(Tensor([1, 12, 10],"float32"), )
paddle.nn.functional.cross_entropy(Tensor([3, 2, 2, 5],"float64"), Tensor([3, 2, 2, 5],"float64"), soft_label=True, axis=-1, weight=Tensor([5],"float64"), reduction="mean", )
paddle.nn.functional.cross_entropy(Tensor([3, 2, 2, 5],"float64"), Tensor([3, 2, 2, 5],"float64"), soft_label=True, label_smoothing=0.18833946207874966, axis=-1, weight=Tensor([5],"float64"), reduction="mean", )
paddle.nn.functional.cross_entropy(Tensor([3, 2, 2, 5],"float64"), Tensor([3, 2, 2],"int64"), soft_label=True, label_smoothing=0.20326138379662173, axis=-1, weight=Tensor([5],"float64"), reduction="mean", )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), log_input=True, full=False, epsilon=1e-08, reduction="mean", name=None, )
paddle.nn.functional.sequence_mask(Tensor([0],"int64"), )
paddle.nn.functional.softmax(Tensor([1, 2, 2048, 2048],"bfloat16"), )
paddle.nn.quant.weight_only_linear(Tensor([1, 1, 64],"float16"), Tensor([128, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int4", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 1, 64],"float16"), Tensor([256, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int8", group_size=-1, )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([0, 3],"float32"), shifts=1, axis=0, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, )
paddle.roll(Tensor([4, 0, 3],"float32"), shifts=1, axis=0, )
paddle.Tensor.__sub__(Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.slice(Tensor([0],"float32"), axes=list[0,], starts=list[0,], ends=list[0,], )
paddle.tensordot(Tensor([1, 5, 5, 5],"float32"), Tensor([0, 5, 5, 5],"float32"), list[list[],list[],], )
paddle.view(Tensor([10, 10, 10, 20],"float32"), "uint8", )
paddle.view(Tensor([10, 10, 10, 20],"float32"), Dtype(uint8), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([1, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([1, 1, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([100, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([100, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([101, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([101, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([104, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([104, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([123, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([123, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([131, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([131, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([136, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([136, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([145, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([145, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([154, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([154, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([167, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([167, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([172, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([172, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([181, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([181, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([2, 1, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, quant_scale=0.17649085819721222, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.11210860311985016, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.12998223304748535, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1337163746356964, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.13811707496643066, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.15001465380191803, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18028168380260468, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18152809143066406, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1875457912683487, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.10790305584669113, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.11413285881280899, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.12078320235013962, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.13032963871955872, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.1428571492433548, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.16197405755519867, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([2, 64],"float16"), begin_norm_axis=1, quant_scale=0.18854722380638123, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([2, 1, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([2, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([2, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([203, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([203, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([221, 768],"float16"), norm_weight=Tensor([768],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([221, 768],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([31, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([31, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([32, 256],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([32, 256],"float16"), quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float16"), Tensor([256],"float16"), Tensor([256],"float16"), 1e-06, begin_norm_axis=1, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([32, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-06, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([32, 256],"float32"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, quant_scale=0.17649085819721222, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.11210860311985016, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.12998223304748535, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1337163746356964, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.13811707496643066, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.15001465380191803, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18028168380260468, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18152809143066406, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, bias=None, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1875457912683487, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.10790305584669113, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.11413285881280899, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.12078320235013962, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.13032963871955872, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.1428571492433548, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.16197405755519867, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([464, 64],"float16"), Tensor([64],"float16"), None, 1e-06, residual=Tensor([464, 64],"float16"), begin_norm_axis=1, quant_scale=0.18854722380638123, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([58, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([58, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([60, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([60, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([64, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([64, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([67, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([67, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([71, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([71, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([74, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([74, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([77, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([77, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([78, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([78, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([81, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([81, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([87, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([87, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([88, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([88, 64],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([89, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([89, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([92, 512],"float16"), norm_weight=Tensor([512],"float16"), norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([92, 512],"float16"), )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([97, 64],"float16"), norm_weight=Tensor([64],"float16"), norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([97, 64],"float16"), )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([1, 1, 192],"float16"), cache_kv=Tensor([2, 1, 1, 50, 64],"float16"), src_mask=Tensor([1, 1, 1, 50],"float16"), sequence_lengths=Tensor([1, 1],"int32"), rotary_tensor=Tensor([2, 1, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 1024],"float16"), cache_kv=Tensor([2, 2, 2, 32768, 128],"float16"), src_mask=Tensor([2, 1, 1, 32768],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 128],"float32"), rotary_emb_dims=1, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=None, rotary_emb_dims=0, use_neox_rotary_style=False, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 1, 192],"float16"), cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.02483507990837097, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.025167126208543777, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.030970240011811256, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03103782795369625, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03455723449587822, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03654532507061958, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.037230949848890305, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 192],"int32"), bias=None, cache_kv=Tensor([2, 2, 1, 4096, 64],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 64],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, qkv_out_scale=Tensor([192],"float32"), out_shift=None, out_smooth=None, out_scale=0.03799910843372345, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, compute_dtype="fp16", )
paddle.incubate.nn.functional.masked_multihead_attention(x=Tensor([2, 2304],"float16"), cache_kv=Tensor([2, 2, 8, 4096, 96],"float16"), src_mask=Tensor([2, 1, 1, 4096],"float16"), sequence_lengths=Tensor([2, 1],"int32"), rotary_tensor=Tensor([2, 2, 1, 1, 96],"float32"), rotary_emb_dims=1, use_neox_rotary_style=True, )
paddle.meshgrid(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([100],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([3],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([2],"float16"),Tensor([2],"float16"),Tensor([1],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([2],"float64"),Tensor([4],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([3],"complex128"),Tensor([5],"complex128"),Tensor([5],"complex128"),Tensor([0],"complex128"),], )
paddle.meshgrid(list[Tensor([3],"float64"),Tensor([5],"float64"),Tensor([3],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([4],"float16"),Tensor([3],"float16"),Tensor([5],"float16"),Tensor([0],"float16"),], )
paddle.meshgrid(list[Tensor([4],"float32"),Tensor([2],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([2],"complex64"),Tensor([5],"complex64"),Tensor([0],"complex64"),], )
paddle.meshgrid(list[Tensor([5],"complex64"),Tensor([4],"complex64"),Tensor([3],"complex64"),Tensor([0],"complex64"),], )
paddle.Tensor.__mul__(Tensor([1, 1024, 128],"bfloat16"), Tensor([128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 1, 128],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 4096],"bfloat16"), Tensor([4096],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 1, 16],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([1, 1024, 8, 96],"bfloat16"), Tensor([1, 1024, 1, 96],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([10, 2],"bfloat16"), Tensor([10, 2],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 114, 64],"bfloat16"), Tensor([64],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 768],"bfloat16"), Tensor([768],"bfloat16"), )
paddle.Tensor.__mul__(Tensor([2, 302, 8, 96],"bfloat16"), Tensor([2, 302, 1, 96],"bfloat16"), )
paddle.put_along_axis(Tensor([10, 10, 10],"uint8"), Tensor([5, 5, 5],"int64"), Tensor([5, 5, 5],"uint8"), 1, "mul", True, False, )
paddle.Tensor.__setitem__(Tensor([128, 128, 64],"float32"), tuple(Tensor([502],"int64"),Tensor([502],"int64"),), Tensor([502, 64],"float32"), )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1],"float16"), Tensor([1],"float16"), reduction="mean", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 1],"float16"), Tensor([2, 1],"float16"), reduction="mean", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 1],"float16"), Tensor([1, 1],"float16"), reduction="mean", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([8, 1],"float16"), Tensor([8, 1],"float16"), reduction="mean", ) 
paddle.nn.functional.grid_sample(Tensor([4, 128, 128, 128],"float16"), Tensor([4, 128, 128, 2],"float16"), )
paddle.nn.functional.grid_sample(Tensor([4, 128, 128, 128],"float16"), Tensor([4, 256, 256, 2],"float16"), )
paddle.expand_as(Tensor([10, 2, 30, 30],"float16"), Tensor([10, 2, 30, 30],"float16"), )
paddle.diag(Tensor([2000],"float32"), offset=-1, )
paddle.normal(0.0, 1.0, list[Tensor([],"int32"),Tensor([],"int32"),Tensor([],"int32"),], )
