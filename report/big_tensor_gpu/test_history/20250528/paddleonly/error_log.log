2025-06-08 22:42:42.865167 GPU 3 43187 test begin: paddle.copysign(Tensor([10, 429496730],"int8"), Tensor([10, 429496730],"int8"), )
[cuda error] paddle.copysign(Tensor([10, 429496730],"int8"), Tensor([10, 429496730],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393796 (unix time) try "date -d @1749393796" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xa8b3) received by PID 43187 (TID 0x7f670b76e740) from PID 43187 ***]


2025-06-08 22:43:12.557309 GPU 0 43186 test begin: paddle.copysign(Tensor([107374183, 20, 2],"int8"), Tensor([107374183, 20, 2],"int8"), )
[cuda error] paddle.copysign(Tensor([107374183, 20, 2],"int8"), Tensor([107374183, 20, 2],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393794 (unix time) try "date -d @1749393794" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xa8b2) received by PID 43186 (TID 0x7fe4ccb52740) from PID 43186 ***]


2025-06-08 22:43:14.849947 GPU 1 43188 test begin: paddle.copysign(Tensor([12, 178956971, 2],"int8"), Tensor([12, 178956971, 2],"int8"), )
[cuda error] paddle.copysign(Tensor([12, 178956971, 2],"int8"), Tensor([12, 178956971, 2],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393796 (unix time) try "date -d @1749393796" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xa8b4) received by PID 43188 (TID 0x7faca9094740) from PID 43188 ***]


2025-06-08 22:43:15.502358 GPU 2 43189 test begin: paddle.copysign(Tensor([12, 20, 17895698],"int8"), Tensor([12, 20, 17895698],"int8"), )
[cuda error] paddle.copysign(Tensor([12, 20, 17895698],"int8"), Tensor([12, 20, 17895698],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393797 (unix time) try "date -d @1749393797" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xa8b5) received by PID 43189 (TID 0x7f5b38903740) from PID 43189 ***]


2025-06-08 22:43:57.814168 GPU 3 45508 test begin: paddle.copysign(Tensor([2, 107374183, 4, 5],"int8"), Tensor([2, 107374183, 4, 5],"int8"), )
[cuda error] paddle.copysign(Tensor([2, 107374183, 4, 5],"int8"), Tensor([2, 107374183, 4, 5],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393839 (unix time) try "date -d @1749393839" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb1c4) received by PID 45508 (TID 0x7f6051338740) from PID 45508 ***]


2025-06-08 22:43:57.881826 GPU 2 45524 test begin: paddle.copysign(Tensor([2, 3, 143165577, 5],"int8"), Tensor([2, 3, 143165577, 5],"int8"), )
[cuda error] paddle.copysign(Tensor([2, 3, 143165577, 5],"int8"), Tensor([2, 3, 143165577, 5],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393840 (unix time) try "date -d @1749393840" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb1d4) received by PID 45524 (TID 0x7fb8c6135740) from PID 45524 ***]


2025-06-08 22:43:59.059885 GPU 1 45490 test begin: paddle.copysign(Tensor([2, 3, 4, 178956971],"int8"), Tensor([2, 3, 4, 178956971],"int8"), )
[cuda error] paddle.copysign(Tensor([2, 3, 4, 178956971],"int8"), Tensor([2, 3, 4, 178956971],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393840 (unix time) try "date -d @1749393840" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb1b2) received by PID 45490 (TID 0x7f066eb70740) from PID 45490 ***]


2025-06-08 22:44:24.815258 GPU 0 46019 test begin: paddle.copysign(Tensor([214748365, 20],"int8"), Tensor([214748365, 20],"int8"), )
[cuda error] paddle.copysign(Tensor([214748365, 20],"int8"), Tensor([214748365, 20],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393866 (unix time) try "date -d @1749393866" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb3c3) received by PID 46019 (TID 0x7f541b63c740) from PID 46019 ***]


2025-06-08 22:44:52.773488 GPU 0 46299 test begin: paddle.copysign(Tensor([71582789, 3, 4, 5],"int8"), Tensor([71582789, 3, 4, 5],"int8"), )
[cuda error] paddle.copysign(Tensor([71582789, 3, 4, 5],"int8"), Tensor([71582789, 3, 4, 5],"int8"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749393934 (unix time) try "date -d @1749393934" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb4db) received by PID 46299 (TID 0x7f1ffc98e740) from PID 46299 ***]


2025-06-08 22:49:08.980060 GPU 0 47111 test begin: paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 2281701379, 1, 1],"float32"), )
[paddle error] paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 2281701379, 1, 1],"float32"), ) 
 Size of label 'm' for operand 2 (32) does not match previous terms (2281701379).

2025-06-08 22:49:10.613873 GPU 0 47111 test begin: paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 71303169],"float32"), )
[paddle error] paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 71303169],"float32"), ) 
 Size of label 'y' for operand 2 (241) does not match previous terms (71303169).

2025-06-08 22:49:11.911611 GPU 2 47155 test begin: paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 71303169, 1],"float32"), )
[paddle error] paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 71303169, 1],"float32"), ) 
 Size of label 'x' for operand 2 (241) does not match previous terms (71303169).

2025-06-08 22:49:13.327432 GPU 0 47111 test begin: paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 4911, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), )
[paddle error] paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 1],"float32"), Tensor([8, 4911, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), ) 
 Size of label 'm' for operand 1 (32) does not match previous terms (4911).

2025-06-08 22:49:14.647060 GPU 0 47111 test begin: paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 2228225],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), )
[paddle error] paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 1, 2228225],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), ) 
 Size of label 'y' for operand 1 (2228225) does not match previous terms (241).

2025-06-08 22:49:15.936314 GPU 0 47111 test begin: paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 2228225, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), )
[paddle error] paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([32, 32, 2228225, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), ) 
 Size of label 'x' for operand 1 (2228225) does not match previous terms (241).

2025-06-08 22:49:17.875529 GPU 0 47111 test begin: paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([71303169, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), )
[paddle error] paddle.einsum("mixy,bmxy,kmxy->bixy", Tensor([71303169, 32, 1, 1],"float32"), Tensor([8, 32, 241, 241],"float32"), Tensor([1, 32, 1, 1],"float32"), ) 
 Size of label 'm' for operand 1 (71303169) does not match previous terms (32).

2025-06-08 22:50:09.587355 GPU 2 47155 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394211 (unix time) try "date -d @1749394211" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb833) received by PID 47155 (TID 0x7feb25ff2740) from PID 47155 ***]


2025-06-08 22:50:10.414216 GPU 1 47068 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394211 (unix time) try "date -d @1749394211" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb7dc) received by PID 47068 (TID 0x7f348e983740) from PID 47068 ***]


2025-06-08 22:50:11.216253 GPU 0 47111 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394212 (unix time) try "date -d @1749394212" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb807) received by PID 47111 (TID 0x7f899c856740) from PID 47111 ***]


2025-06-08 22:50:16.664361 GPU 1 48390 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394307 (unix time) try "date -d @1749394307" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xbd06) received by PID 48390 (TID 0x7feab9786740) from PID 48390 ***]


2025-06-08 22:50:17.707649 GPU 0 48418 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394334 (unix time) try "date -d @1749394334" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xbd22) received by PID 48418 (TID 0x7f6f13260740) from PID 48418 ***]


2025-06-08 22:50:44.466083 GPU 2 48518 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394332 (unix time) try "date -d @1749394332" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xbd86) received by PID 48518 (TID 0x7fefcc473740) from PID 48518 ***]


2025-06-08 22:50:56.301721 GPU 3 46199 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394257 (unix time) try "date -d @1749394257" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb477) received by PID 46199 (TID 0x7f8bb83b9740) from PID 46199 ***]


2025-06-08 22:51:30.464852 GPU 3 48660 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 1140850690],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394378 (unix time) try "date -d @1749394378" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xbe14) received by PID 48660 (TID 0x7f066482b740) from PID 48660 ***]


2025-06-08 22:53:52.877756 GPU 2 49182 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394435 (unix time) try "date -d @1749394435" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc01e) received by PID 49182 (TID 0x7f88986bf740) from PID 49182 ***]


2025-06-08 22:53:52.930707 GPU 0 49208 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394435 (unix time) try "date -d @1749394435" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc038) received by PID 49208 (TID 0x7f05e0795740) from PID 49208 ***]


2025-06-08 22:53:59.852556 GPU 0 49929 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394541 (unix time) try "date -d @1749394541" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc309) received by PID 49929 (TID 0x7fde934c8740) from PID 49929 ***]


2025-06-08 22:54:01.639979 GPU 1 49230 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394444 (unix time) try "date -d @1749394444" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc04e) received by PID 49230 (TID 0x7f304f070740) from PID 49230 ***]


2025-06-08 22:54:08.944752 GPU 1 49979 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394541 (unix time) try "date -d @1749394541" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc33b) received by PID 49979 (TID 0x7f407f835740) from PID 49979 ***]


2025-06-08 22:54:27.921017 GPU 2 50057 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394556 (unix time) try "date -d @1749394556" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc389) received by PID 50057 (TID 0x7f8e41595740) from PID 50057 ***]


2025-06-08 22:54:59.119550 GPU 3 49451 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394502 (unix time) try "date -d @1749394502" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc12b) received by PID 49451 (TID 0x7eff10fa0740) from PID 49451 ***]


2025-06-08 22:55:35.569455 GPU 3 50256 test begin: paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 4917460],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394621 (unix time) try "date -d @1749394621" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc450) received by PID 50256 (TID 0x7f7782a45740) from PID 50256 ***]


2025-06-08 22:58:40.347235 GPU 2 50763 test begin: paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 57042535],"int32"), bias=Tensor([10],"float16"), dequant_scales=Tensor([10],"float32"), act_method="gelu", compute_dtype="fp16", )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 57042535],"int32"), bias=Tensor([10],"float16"), dequant_scales=Tensor([10],"float32"), act_method="gelu", compute_dtype="fp16", ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394721 (unix time) try "date -d @1749394721" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc64b) received by PID 50763 (TID 0x7fac816cc740) from PID 50763 ***]


2025-06-08 22:58:41.840500 GPU 0 50685 test begin: paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 57042535],"int32"), bias=Tensor([512],"float16"), dequant_scales=Tensor([512],"float32"), shift=Tensor([512],"float16"), smooth=Tensor([512],"float16"), act_method="gelu", compute_dtype="fp16", quant_scale=0.5, quant_round_type=1, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 57042535],"int32"), bias=Tensor([512],"float16"), dequant_scales=Tensor([512],"float32"), shift=Tensor([512],"float16"), smooth=Tensor([512],"float16"), act_method="gelu", compute_dtype="fp16", quant_scale=0.5, quant_round_type=1, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394723 (unix time) try "date -d @1749394723" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc5fd) received by PID 50685 (TID 0x7fe7d6a3d740) from PID 50685 ***]


2025-06-08 22:58:47.646669 GPU 1 50827 test begin: paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 57042535],"int32"), bias=Tensor([512],"float32"), dequant_scales=Tensor([512],"float32"), shift=Tensor([512],"float32"), smooth=Tensor([512],"float32"), act_method="gelu", compute_dtype="fp32", quant_scale=0.5, quant_round_type=1, quant_max_bound=127.0, quant_min_bound=-127.0, )
[cuda error] paddle.incubate.nn.functional.fused_bias_act(x=Tensor([2, 20, 57042535],"int32"), bias=Tensor([512],"float32"), dequant_scales=Tensor([512],"float32"), shift=Tensor([512],"float32"), smooth=Tensor([512],"float32"), act_method="gelu", compute_dtype="fp32", quant_scale=0.5, quant_round_type=1, quant_max_bound=127.0, quant_min_bound=-127.0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394728 (unix time) try "date -d @1749394728" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc68b) received by PID 50827 (TID 0x7efe763ef740) from PID 50827 ***]


2025-06-08 23:00:09.263215 GPU 3 51046 test begin: paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([17409, 128, 1024],"float32"), Tensor([17409, 128, 1024],"float32"), None, Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394813 (unix time) try "date -d @1749394813" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc766) received by PID 51046 (TID 0x7fbddf384740) from PID 51046 ***]


2025-06-08 23:00:45.546578 GPU 3 52387 test begin: paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([17409, 128, 1024],"float32"), Tensor([8, 128, 1024],"float32"), None, Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394900 (unix time) try "date -d @1749394900" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcca3) received by PID 52387 (TID 0x7fcfd0949740) from PID 52387 ***]


2025-06-08 23:01:32.296613 GPU 0 51639 test begin: paddle.incubate.nn.functional.fused_bias_dropout_residual_layer_norm(Tensor([8, 278529, 1024],"float32"), Tensor([8, 128, 1024],"float32"), None, Tensor([1024],"float32"), Tensor([1024],"float32"), 0.0, 1e-05, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394894 (unix time) try "date -d @1749394894" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc9b7) received by PID 51639 (TID 0x7f166688e740) from PID 51639 ***]


2025-06-08 23:01:48.924590 GPU 1 51683 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([100, 42949673],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([100, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([100, 42949673],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([100, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394910 (unix time) try "date -d @1749394910" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc9e3) received by PID 51683 (TID 0x7f2fb0491740) from PID 51683 ***]


2025-06-08 23:02:08.065866 GPU 0 53052 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([101, 42524429],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([101, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([101, 42524429],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([101, 64],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394991 (unix time) try "date -d @1749394991" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcf3c) received by PID 53052 (TID 0x7f4b378cd740) from PID 53052 ***]


2025-06-08 23:02:10.762640 GPU 2 51761 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([101, 42524429],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([101, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([101, 42524429],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([101, 64],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394932 (unix time) try "date -d @1749394932" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xca31) received by PID 51761 (TID 0x7fd2adaec740) from PID 51761 ***]


2025-06-08 23:02:54.652564 GPU 3 52937 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([104, 41297763],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([104, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([104, 41297763],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([104, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394976 (unix time) try "date -d @1749394976" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcec9) received by PID 52937 (TID 0x7f30558f4740) from PID 52937 ***]


2025-06-08 23:03:03.093749 GPU 1 52994 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([123, 34918434],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([123, 768],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([123, 34918434],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([123, 768],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749394985 (unix time) try "date -d @1749394985" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcf02) received by PID 52994 (TID 0x7f9387400740) from PID 52994 ***]


2025-06-08 23:03:55.175182 GPU 2 53169 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([131, 32786010],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([131, 768],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([131, 32786010],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([131, 768],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395036 (unix time) try "date -d @1749395036" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcfb1) received by PID 53169 (TID 0x7f2790561740) from PID 53169 ***]


2025-06-08 23:04:13.937070 GPU 1 53261 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([136, 31580642],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([136, 768],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([136, 31580642],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([136, 768],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395055 (unix time) try "date -d @1749395055" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd00d) received by PID 53261 (TID 0x7fb70725d740) from PID 53261 ***]


2025-06-08 23:04:18.634016 GPU 1 53895 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 142606337],"float32"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([16, 256],"float32"), residual_alpha=0.69204696, )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 142606337],"float32"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([16, 256],"float32"), residual_alpha=0.69204696, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395118 (unix time) try "date -d @1749395118" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd287) received by PID 53895 (TID 0x7fd69ea76740) from PID 53895 ***]


2025-06-08 23:05:18.991310 GPU 0 53304 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 268435457],"float16"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([16, 256],"float16"), residual_alpha=0.69204696, )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 268435457],"float16"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([16, 256],"float16"), residual_alpha=0.69204696, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395120 (unix time) try "date -d @1749395120" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd038) received by PID 53304 (TID 0x7f5b02388740) from PID 53304 ***]


2025-06-08 23:05:23.086651 GPU 3 53368 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([16777217, 256],"float16"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([16, 256],"float16"), residual_alpha=0.69204696, )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([16777217, 256],"float16"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([16, 256],"float16"), residual_alpha=0.69204696, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395124 (unix time) try "date -d @1749395124" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd078) received by PID 53368 (TID 0x7f92f2665740) from PID 53368 ***]


2025-06-08 23:05:50.554469 GPU 1 54607 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([2, 2147483649],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([2, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([2, 2147483649],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([2, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395220 (unix time) try "date -d @1749395220" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd54f) received by PID 54607 (TID 0x7f59b17f7740) from PID 54607 ***]


2025-06-08 23:06:25.231404 GPU 2 53945 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([2, 2147483649],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([2, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([2, 2147483649],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([2, 64],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395187 (unix time) try "date -d @1749395187" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd2b9) received by PID 53945 (TID 0x7fc88f8f8740) from PID 53945 ***]


2025-06-08 23:06:40.528181 GPU 0 54112 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([5592406, 768],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([123, 768],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([5592406, 768],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([123, 768],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395201 (unix time) try "date -d @1749395201" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd360) received by PID 54112 (TID 0x7f5efcdb2740) from PID 54112 ***]


2025-06-08 23:06:40.864362 GPU 3 54148 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([5592406, 768],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([131, 768],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([5592406, 768],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([131, 768],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395202 (unix time) try "date -d @1749395202" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd384) received by PID 54148 (TID 0x7ffa84a51740) from PID 54148 ***]


2025-06-08 23:06:45.036155 GPU 0 54773 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([5592406, 768],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([136, 768],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([5592406, 768],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([136, 768],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395272 (unix time) try "date -d @1749395272" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd5f5) received by PID 54773 (TID 0x7efea3672740) from PID 54773 ***]


2025-06-08 23:07:58.400160 GPU 3 54787 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([59, 72796056],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([59, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([59, 72796056],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([59, 64],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395279 (unix time) try "date -d @1749395279" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd603) received by PID 54787 (TID 0x7f6dfe900740) from PID 54787 ***]


2025-06-08 23:08:05.863646 GPU 3 55458 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([60, 71582789],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([60, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([60, 71582789],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([60, 64],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395344 (unix time) try "date -d @1749395344" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd8a2) received by PID 55458 (TID 0x7f0e9bb56740) from PID 55458 ***]


2025-06-08 23:08:11.235208 GPU 2 54862 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([64, 67108865],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([64, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([64, 67108865],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([64, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395292 (unix time) try "date -d @1749395292" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd64e) received by PID 54862 (TID 0x7fc547e2c740) from PID 54862 ***]


2025-06-08 23:08:35.073896 GPU 1 54975 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67, 64103990],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([67, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67, 64103990],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([67, 64],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395316 (unix time) try "date -d @1749395316" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd6bf) received by PID 54975 (TID 0x7f400bec4740) from PID 54975 ***]


2025-06-08 23:09:25.423421 GPU 2 55515 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([101, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([101, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:26.466446 GPU 0 55565 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([2, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([2, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:26.546541 GPU 2 55515 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([59, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([59, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:27.888640 GPU 2 55515 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([60, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([60, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:27.986460 GPU 0 55565 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([67, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([67, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:29.220320 GPU 2 55515 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([67108865, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([67108865, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:29.319810 GPU 0 55565 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([1, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([1, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:30.685360 GPU 0 55565 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([101, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([101, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:31.443263 GPU 2 55515 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([67108865, 64],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([67108865, 64],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-06, begin_norm_axis=1, bias=None, residual=Tensor([67108865, 64],"float16"), ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-08 23:09:33.862598 GPU 2 55515 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([71, 60492498],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([71, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([71, 60492498],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([71, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395375 (unix time) try "date -d @1749395375" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd8db) received by PID 55515 (TID 0x7fea0e788740) from PID 55515 ***]


2025-06-08 23:09:36.535779 GPU 0 55565 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([100, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([100, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395378 (unix time) try "date -d @1749395378" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd90d) received by PID 55565 (TID 0x7fbb035cf740) from PID 55565 ***]


2025-06-08 23:09:41.237943 GPU 0 56213 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([104, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([104, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395445 (unix time) try "date -d @1749395445" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdb95) received by PID 56213 (TID 0x7f5c66fd7740) from PID 56213 ***]


2025-06-08 23:10:07.375924 GPU 2 56307 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([2, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([2, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395478 (unix time) try "date -d @1749395478" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdbf3) received by PID 56307 (TID 0x7f77d0636740) from PID 56307 ***]


2025-06-08 23:10:09.902525 GPU 3 55703 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([64, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([64, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395411 (unix time) try "date -d @1749395411" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd997) received by PID 55703 (TID 0x7f9831c36740) from PID 55703 ***]


2025-06-08 23:10:11.586443 GPU 1 55718 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([71, 512],"float16"), )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([8388609, 512],"float16"), norm_weight=None, norm_bias=None, epsilon=1e-05, begin_norm_axis=1, bias=None, residual=Tensor([71, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395412 (unix time) try "date -d @1749395412" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd9a6) received by PID 55718 (TID 0x7f21f075f740) from PID 55718 ***]


2025-06-08 23:10:43.912843 GPU 3 56454 test begin: paddle.incubate.nn.functional.fused_layer_norm(Tensor([8912897, 256],"float32"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([16, 256],"float32"), residual_alpha=0.69204696, )
[cuda error] paddle.incubate.nn.functional.fused_layer_norm(Tensor([8912897, 256],"float32"), None, None, 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([16, 256],"float32"), residual_alpha=0.69204696, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395503 (unix time) try "date -d @1749395503" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdc86) received by PID 56454 (TID 0x7f56917fc740) from PID 56454 ***]


2025-06-08 23:13:35.626522 GPU 0 56568 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 11606, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 11606, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:35.649279 GPU 1 56357 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 11606, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 11606, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 11606, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 11606, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:36.750622 GPU 0 56568 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:37.559965 GPU 1 56357 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 11606, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:38.139344 GPU 0 56568 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 46422],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 46422],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:38.992833 GPU 1 56357 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 46422],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 46422],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:39.242219 GPU 0 56568 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:40.188335 GPU 1 56357 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 46422, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:13:47.474552 GPU 0 56568 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([2281701379],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395628 (unix time) try "date -d @1749395628" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 56568 (TID 0x7feb86e9a740) from PID 0 ***]


2025-06-08 23:13:48.181890 GPU 1 56357 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([2281701379],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395629 (unix time) try "date -d @1749395629" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 56357 (TID 0x7ff4da456740) from PID 0 ***]


2025-06-08 23:13:53.180233 GPU 1 57786 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([2281701379],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395687 (unix time) try "date -d @1749395687" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 57786 (TID 0x7f09337bc740) from PID 0 ***]


2025-06-08 23:14:18.237819 GPU 3 57044 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([2281701379],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395661 (unix time) try "date -d @1749395661" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 57044 (TID 0x7f4b43efe740) from PID 0 ***]


2025-06-08 23:14:21.257906 GPU 0 57878 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([2281701379],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395715 (unix time) try "date -d @1749395715" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 57878 (TID 0x7f024fadf740) from PID 0 ***]


2025-06-08 23:14:23.655970 GPU 2 57070 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([2281701379],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395665 (unix time) try "date -d @1749395665" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 57070 (TID 0x7f737964a740) from PID 0 ***]


2025-06-08 23:14:29.395845 GPU 2 57928 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([2281701379],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395723 (unix time) try "date -d @1749395723" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 57928 (TID 0x7f575e5fc740) from PID 0 ***]


2025-06-08 23:14:50.502335 GPU 1 58009 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([2281701379],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395751 (unix time) try "date -d @1749395751" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58009 (TID 0x7fbd03840740) from PID 0 ***]


2025-06-08 23:14:52.847521 GPU 3 58045 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([2281701379],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395754 (unix time) try "date -d @1749395754" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58045 (TID 0x7f0fa41c6740) from PID 0 ***]


2025-06-08 23:15:26.759482 GPU 2 58153 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([2281701379],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395783 (unix time) try "date -d @1749395783" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58153 (TID 0x7f201fce7740) from PID 0 ***]


2025-06-08 23:15:48.638599 GPU 0 58615 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 2228225],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395808 (unix time) try "date -d @1749395808" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58615 (TID 0x7fc1f3214740) from PID 0 ***]


2025-06-08 23:15:57.703522 GPU 3 58668 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([1024, 2228225],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395811 (unix time) try "date -d @1749395811" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58668 (TID 0x7fb100131740) from PID 0 ***]


2025-06-08 23:16:24.433039 GPU 1 58763 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([2228225, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, None, 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395839 (unix time) try "date -d @1749395839" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58763 (TID 0x7f68ebc2e740) from PID 0 ***]


2025-06-08 23:16:52.094683 GPU 0 58859 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 16, 64, 1024],"float32"), Tensor([2228225, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 16, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 16, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395873 (unix time) try "date -d @1749395873" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58859 (TID 0x7fbc86994740) from PID 0 ***]


2025-06-08 23:17:47.817391 GPU 3 58893 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 17409, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 17409, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 17409, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(Tensor([8, 128, 1024],"float32"), Tensor([3, 17409, 64, 1024],"float32"), Tensor([1024, 1024],"float32"), True, Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), 1e-05, Tensor([3, 17409, 64],"float32"), Tensor([1024],"float32"), None, Tensor([8, 17409, 128, 128],"float32"), 0.0, 0.0, 1e-05, num_heads=16, transpose_qkv_wb=False, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:18:00.971965 GPU 2 58907 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([2281701379],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395883 (unix time) try "date -d @1749395883" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58907 (TID 0x7f5bc8627740) from PID 0 ***]


2025-06-08 23:18:06.704924 GPU 2 59530 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([4, 570425345],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395940 (unix time) try "date -d @1749395940" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59530 (TID 0x7f838f38b740) from PID 0 ***]


2025-06-08 23:18:07.104174 GPU 3 58893 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 2, 4],"float32"), linear_weight=Tensor([570425345, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395888 (unix time) try "date -d @1749395888" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 58893 (TID 0x7fa724212740) from PID 0 ***]


2025-06-08 23:18:11.618517 GPU 3 59572 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 95070891, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 2, 95070891, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:18:26.551210 GPU 0 59636 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 95070891, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([3, 95070891, 2, 4],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=False, name=None, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:18:45.665001 GPU 1 59465 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([2281701379],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395927 (unix time) try "date -d @1749395927" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59465 (TID 0x7f51bf4a3740) from PID 0 ***]


2025-06-08 23:19:11.799976 GPU 3 59572 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([4, 570425345],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395953 (unix time) try "date -d @1749395953" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59572 (TID 0x7f672794f740) from PID 0 ***]


2025-06-08 23:19:17.086234 GPU 3 59819 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([1, 2, 4],"float32"), qkv_weight=Tensor([4, 12],"float32"), linear_weight=Tensor([570425345, 4],"float32"), pre_layer_norm=False, pre_ln_scale=None, pre_ln_bias=None, ln_scale=Tensor([4],"float32"), ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=None, linear_bias=None, cache_kv=None, attn_mask=Tensor([1, 2, 2, 2],"float32"), dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=2, transpose_qkv_wb=True, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749396012 (unix time) try "date -d @1749396012" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59819 (TID 0x7f0760bc0740) from PID 0 ***]


2025-06-08 23:19:47.235829 GPU 0 59636 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([2281701379],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749395989 (unix time) try "date -d @1749395989" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59636 (TID 0x7fd956f89740) from PID 0 ***]


2025-06-08 23:20:05.258565 GPU 2 59754 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([2281701379],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749396006 (unix time) try "date -d @1749396006" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59754 (TID 0x7f80719fc740) from PID 0 ***]


2025-06-08 23:20:09.849909 GPU 2 60377 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([2281701379],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749396070 (unix time) try "date -d @1749396070" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 60377 (TID 0x7f1ee3bc3740) from PID 0 ***]


2025-06-08 23:20:21.257186 GPU 0 60460 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([256, 8912897],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749396083 (unix time) try "date -d @1749396083" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 60460 (TID 0x7f61dd5fc740) from PID 0 ***]


2025-06-08 23:20:22.658686 GPU 1 59839 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 16, 256],"float32"), linear_weight=Tensor([8912897, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   fused_attentionGradNodeCompat::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::imperative::Tracer::TraceOp(std::string const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&)
4   void paddle::imperative::Tracer::TraceOpImpl<egr::EagerVariable>(std::string const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, paddle::imperative::details::NameVarMapTrait<egr::EagerVariable>::Type const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >&, phi::Place const&, bool, std::map<std::string, std::string, std::less<std::string >, std::allocator<std::pair<std::string const, std::string > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > >*, bool)
5   paddle::imperative::PreparedOp::Run(std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::map<std::string, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > >, std::less<std::string >, std::allocator<std::pair<std::string const, std::vector<std::shared_ptr<egr::EagerVariable>, std::allocator<std::shared_ptr<egr::EagerVariable> > > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&, std::unordered_map<std::string, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> >, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, paddle::variant<paddle::blank, int, float, std::string, std::vector<int, std::allocator<int> >, std::vector<float, std::allocator<float> >, std::vector<std::string, std::allocator<std::string > >, bool, std::vector<bool, std::allocator<bool> >, paddle::framework::BlockDesc*, long, std::vector<paddle::framework::BlockDesc*, std::allocator<paddle::framework::BlockDesc*> >, std::vector<long, std::allocator<long> >, std::vector<double, std::allocator<double> >, paddle::framework::VarDesc*, std::vector<paddle::framework::VarDesc*, std::allocator<paddle::framework::VarDesc*> >, double, paddle::experimental::ScalarBase<paddle::Tensor>, std::vector<paddle::experimental::ScalarBase<paddle::Tensor>, std::allocator<paddle::experimental::ScalarBase<paddle::Tensor> > >, pir::Block*, std::vector<pir::Value, std::allocator<pir::Value> >, std::shared_ptr<pir::Program> > > > > const&)
6   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 3, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
7   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 4, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&)
8   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 14, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor> >(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&)
9   void phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*), &(void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*))>::KernelCallHelper<phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::TypeTag<int> >::Compute<1, 26, 0, 0, phi::GPUContext const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, paddle::optional<phi::DenseTensor>, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const, phi::DenseTensor const>(phi::KernelContext*, phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, paddle::optional<phi::DenseTensor>&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&)
10  void phi::fusion::FusedAttentionGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, bool, bool, float, float, bool, bool, int, std::string const&, float, bool, int, std::string const&, float, bool, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749396024 (unix time) try "date -d @1749396024" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x0) received by PID 59839 (TID 0x7f01fd1a2740) from PID 0 ***]


2025-06-08 23:21:19.005782 GPU 3 60417 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 185686, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 16, 185686, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, ) 
 embed_dim must be divisible by num_heads.

2025-06-08 23:21:20.154591 GPU 3 60417 test begin: paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 185686, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, )
[paddle error] paddle.incubate.nn.functional.fused_multi_head_attention(x=Tensor([8, 128, 256],"float32"), qkv_weight=Tensor([3, 185686, 16, 256],"float32"), linear_weight=Tensor([256, 256],"float32"), pre_layer_norm=True, pre_ln_scale=Tensor([256],"float32"), pre_ln_bias=Tensor([256],"float32"), ln_scale=None, ln_bias=None, pre_ln_epsilon=1e-05, qkv_bias=Tensor([3, 16, 16],"float32"), linear_bias=Tensor([256],"float32"), cache_kv=None, attn_mask=None, dropout_rate=0.0, attn_dropout_rate=0.0, ln_epsilon=1e-05, training=True, ring_id=-1, num_heads=16, transpose_qkv_wb=False, name=None, ) 
 embed_dim must be divisible by num_heads.

2025-06-09 03:34:11.184120 GPU 1 71944 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411279 (unix time) try "date -d @1749411279" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11908) received by PID 71944 (TID 0x7f676c9ad740) from PID 71944 ***]


2025-06-09 03:34:29.946872 GPU 3 60417 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), None, Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411298 (unix time) try "date -d @1749411298" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xec01) received by PID 60417 (TID 0x7fe677e64740) from PID 60417 ***]


2025-06-09 03:35:13.259847 GPU 3 94467 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411404 (unix time) try "date -d @1749411404" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17103) received by PID 94467 (TID 0x7fc2cb790740) from PID 94467 ***]


2025-06-09 03:35:17.698076 GPU 1 94495 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411397 (unix time) try "date -d @1749411397" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1711f) received by PID 94495 (TID 0x7fcc378a3740) from PID 94495 ***]


2025-06-09 03:36:34.340042 GPU 0 73164 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411419 (unix time) try "date -d @1749411419" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11dcc) received by PID 73164 (TID 0x7f2d2e0f4740) from PID 73164 ***]


2025-06-09 03:36:45.747965 GPU 2 71492 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([8, 2, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411431 (unix time) try "date -d @1749411431" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11744) received by PID 71492 (TID 0x7f36c7824740) from PID 71492 ***]


2025-06-09 03:38:33.258645 GPU 1 94581 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411588 (unix time) try "date -d @1749411588" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17175) received by PID 94581 (TID 0x7f67adeb4740) from PID 94581 ***]


2025-06-09 03:38:39.695518 GPU 2 94609 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411592 (unix time) try "date -d @1749411592" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17191) received by PID 94609 (TID 0x7f1f3b889740) from PID 94609 ***]


2025-06-09 03:38:41.066704 GPU 0 94553 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411599 (unix time) try "date -d @1749411599" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17159) received by PID 94553 (TID 0x7f8fe7168740) from PID 94553 ***]


2025-06-09 03:39:07.259072 GPU 3 94525 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), None, Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411623 (unix time) try "date -d @1749411623" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1713d) received by PID 94525 (TID 0x7f6c48d08740) from PID 94525 ***]


2025-06-09 03:42:35.817841 GPU 2 94641 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411783 (unix time) try "date -d @1749411783" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x171b1) received by PID 94641 (TID 0x7fbf52b88740) from PID 94641 ***]


2025-06-09 03:42:43.358331 GPU 0 94669 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411790 (unix time) try "date -d @1749411790" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x171cd) received by PID 94669 (TID 0x7f165b554740) from PID 94669 ***]


2025-06-09 03:43:09.669232 GPU 1 94697 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411818 (unix time) try "date -d @1749411818" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x171e9) received by PID 94697 (TID 0x7fa1aa2d4740) from PID 94697 ***]


2025-06-09 03:43:11.724241 GPU 3 94726 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([8, 1, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411867 (unix time) try "date -d @1749411867" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17206) received by PID 94726 (TID 0x7fa08c421740) from PID 94726 ***]


2025-06-09 03:43:35.857556 GPU 2 94785 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411894 (unix time) try "date -d @1749411894" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17241) received by PID 94785 (TID 0x7f70de8e3740) from PID 94785 ***]


2025-06-09 03:43:47.441194 GPU 0 94757 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411911 (unix time) try "date -d @1749411911" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17225) received by PID 94757 (TID 0x7fae82953740) from PID 94757 ***]


2025-06-09 03:44:41.447728 GPU 1 94815 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411967 (unix time) try "date -d @1749411967" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1725f) received by PID 94815 (TID 0x7f0d98161740) from PID 94815 ***]


2025-06-09 03:44:58.131620 GPU 2 94844 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8, 8912897, 4, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([8, 2, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749411976 (unix time) try "date -d @1749411976" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1727c) received by PID 94844 (TID 0x7f2440e66740) from PID 94844 ***]


2025-06-09 03:52:38.874792 GPU 0 94900 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412385 (unix time) try "date -d @1749412385" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x172b4) received by PID 94900 (TID 0x7f9d30fe0740) from PID 94900 ***]


2025-06-09 03:52:56.688828 GPU 1 94959 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), None, Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412403 (unix time) try "date -d @1749412403" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x172ef) received by PID 94959 (TID 0x7f6cd77a3740) from PID 94959 ***]


2025-06-09 03:53:36.360869 GPU 0 95017 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412494 (unix time) try "date -d @1749412494" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17329) received by PID 95017 (TID 0x7fc987734740) from PID 95017 ***]


2025-06-09 03:53:55.338941 GPU 1 94989 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([2, 8, 2, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), Tensor([1, 8, 1, 16],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412507 (unix time) try "date -d @1749412507" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1730d) received by PID 94989 (TID 0x7fe427a21740) from PID 94989 ***]


2025-06-09 04:00:05.937624 GPU 1 95047 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412832 (unix time) try "date -d @1749412832" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17347) received by PID 95047 (TID 0x7f8e0c41a740) from PID 95047 ***]


2025-06-09 04:00:09.220803 GPU 0 95075 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412837 (unix time) try "date -d @1749412837" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17363) received by PID 95075 (TID 0x7f35ca2c3740) from PID 95075 ***]


2025-06-09 04:00:41.020978 GPU 0 95105 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412918 (unix time) try "date -d @1749412918" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17381) received by PID 95105 (TID 0x7f39e3145740) from PID 95105 ***]


2025-06-09 04:00:46.238441 GPU 3 94863 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412873 (unix time) try "date -d @1749412873" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1728f) received by PID 94863 (TID 0x7fa8a604c740) from PID 94863 ***]


2025-06-09 04:01:05.856599 GPU 1 95133 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412960 (unix time) try "date -d @1749412960" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1739d) received by PID 95133 (TID 0x7f92612b9740) from PID 95133 ***]


2025-06-09 04:01:29.070569 GPU 2 94931 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), None, Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749412915 (unix time) try "date -d @1749412915" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x172d3) received by PID 94931 (TID 0x7fa57d3b5740) from PID 94931 ***]


2025-06-09 04:02:02.228846 GPU 0 95191 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413007 (unix time) try "date -d @1749413007" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x173d7) received by PID 95191 (TID 0x7fe838b90740) from PID 95191 ***]


2025-06-09 04:02:15.220060 GPU 3 95163 test begin: paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([8912897, 8, 4, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([2, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413009 (unix time) try "date -d @1749413009" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x173bb) received by PID 95163 (TID 0x7f5f8662b740) from PID 95163 ***]


2025-06-09 04:09:02.297406 GPU 2 95220 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 67108865, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1],"int32"), Tensor([1, 1],"int32"), mask=Tensor([1, 1, 50, 50],"float16"), scale=0.125, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_variable_length_memory_efficient_attention(_object*, _object*, _object*)
1   variable_length_memory_efficient_attention_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
2   paddle::experimental::variable_length_memory_efficient_attention(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
3   void phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)
4   void phi::dispatch_cutlass_forward_f16_sm80<phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1}>(phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1})
5   phi::fmha_cutlassF_variable_f16_aligned_32x128_rf_sm_mua_sm80(cutlass::gemm::kernel::DefaultFMHAGrouped<cutlass::half_t, cutlass::arch::Sm80, true, false, 32, 128, true, (cutlass::gemm::kernel::GroupScheduleMode)0, true>, phi::Params&, phi::GPUContext const&)
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413343 (unix time) try "date -d @1749413343" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x173f4) received by PID 95220 (TID 0x7f5444011740) from PID 95220 ***]


2025-06-09 04:09:29.618508 GPU 1 95250 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 33554433, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1, 35, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_variable_length_memory_efficient_attention(_object*, _object*, _object*)
1   variable_length_memory_efficient_attention_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
2   paddle::experimental::variable_length_memory_efficient_attention(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
3   void phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)
4   void phi::dispatch_cutlass_forward_f16_sm80<phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1}>(phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1})
5   phi::fmha_cutlassF_variable_f16_aligned_32x128_rf_sm_ma_sm80(cutlass::gemm::kernel::DefaultFMHAGrouped<cutlass::half_t, cutlass::arch::Sm80, true, true, 32, 128, true, (cutlass::gemm::kernel::GroupScheduleMode)0, true>, phi::Params&, phi::GPUContext const&)
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413371 (unix time) try "date -d @1749413371" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17412) received by PID 95250 (TID 0x7f65d114f740) from PID 95250 ***]


2025-06-09 04:09:35.667841 GPU 1 95337 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 33554433, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1, 39, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.125, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_variable_length_memory_efficient_attention(_object*, _object*, _object*)
1   variable_length_memory_efficient_attention_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
2   paddle::experimental::variable_length_memory_efficient_attention(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
3   void phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)
4   void phi::dispatch_cutlass_forward_f16_sm80<phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1}>(phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1})
5   phi::fmha_cutlassF_variable_f16_aligned_32x128_rf_sm_ma_sm80(cutlass::gemm::kernel::DefaultFMHAGrouped<cutlass::half_t, cutlass::arch::Sm80, true, true, 32, 128, true, (cutlass::gemm::kernel::GroupScheduleMode)0, true>, phi::Params&, phi::GPUContext const&)
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413488 (unix time) try "date -d @1749413488" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17469) received by PID 95337 (TID 0x7f9e3d626740) from PID 95337 ***]


2025-06-09 04:12:01.753219 GPU 1 95395 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1, 51, 64],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 524289, 4096],"float16"), scale=0.125, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_variable_length_memory_efficient_attention(_object*, _object*, _object*)
1   variable_length_memory_efficient_attention_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
2   paddle::experimental::variable_length_memory_efficient_attention(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
3   void phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)
4   void phi::dispatch_cutlass_forward_f16_sm80<phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1}>(phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1})
5   phi::fmha_cutlassF_variable_f16_aligned_32x128_rf_sm_ma_sm80(cutlass::gemm::kernel::DefaultFMHAGrouped<cutlass::half_t, cutlass::arch::Sm80, true, true, 32, 128, true, (cutlass::gemm::kernel::GroupScheduleMode)0, true>, phi::Params&, phi::GPUContext const&)
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413620 (unix time) try "date -d @1749413620" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x174a3) received by PID 95395 (TID 0x7f6e0540b740) from PID 95395 ***]


2025-06-09 04:14:13.552280 GPU 1 95424 test begin: paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([2, 8, 112, 96],"float16"), Tensor([2, 8, 240, 96],"float16"), Tensor([2, 8, 240, 1118482],"float16"), Tensor([2, 1],"int32"), Tensor([2, 1],"int32"), mask=Tensor([2, 1, 4096, 4096],"float16"), scale=0.10206207261596575, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(716), misaligned address. 
  [Hint: 'cudaErrorMisalignedAddress'. The device encountered a load or store instruction on a memory address which is not aligned. This leaves the process in aninconsistent state and any further CUDA work will return the same error. To continue using CUDA, the process must be terminatedand relaunched.] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_variable_length_memory_efficient_attention(_object*, _object*, _object*)
1   variable_length_memory_efficient_attention_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
2   paddle::experimental::variable_length_memory_efficient_attention(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, float, bool, int)
3   void phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)
4   void phi::dispatch_cutlass_forward_f16_sm80<phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1}>(phi::fusion::MultiHeadAttentionVariableForwardKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, float, bool, int, phi::DenseTensor*)::{lambda(auto:1, auto:2)#1})
5   phi::fmha_cutlassF_variable_f16_aligned_32x128_urf_sm_ma_sm80(cutlass::gemm::kernel::DefaultFMHAGrouped<cutlass::half_t, cutlass::arch::Sm80, true, true, 32, 128, false, (cutlass::gemm::kernel::GroupScheduleMode)0, true>, phi::Params&, phi::GPUContext const&)
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413760 (unix time) try "date -d @1749413760" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x174c0) received by PID 95424 (TID 0x7f3ab6730740) from PID 95424 ***]


2025-06-09 04:15:22.268408 GPU 3 95278 test begin: paddle.incubate.softmax_mask_fuse(Tensor([1, 8912897, 8, 32],"float32"), Tensor([1, 1, 8, 32],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413726 (unix time) try "date -d @1749413726" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1742e) received by PID 95278 (TID 0x7f9015b65740) from PID 95278 ***]


2025-06-09 04:15:26.506593 GPU 0 95307 test begin: paddle.incubate.softmax_mask_fuse(Tensor([8912897, 1, 8, 32],"float32"), Tensor([8912897, 1, 8, 32],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413731 (unix time) try "date -d @1749413731" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1744b) received by PID 95307 (TID 0x7f1c2e846740) from PID 95307 ***]


2025-06-09 04:15:38.863812 GPU 0 95452 test begin: paddle.incubate.softmax_mask_fuse(x=Tensor([2, 263173, 8, 1020],"float16"), mask=Tensor([2, 1, 8, 1020],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413798 (unix time) try "date -d @1749413798" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x174dc) received by PID 95452 (TID 0x7fe337a99740) from PID 95452 ***]


2025-06-09 04:16:11.663522 GPU 2 95365 test begin: paddle.incubate.softmax_mask_fuse(x=Tensor([2, 8388609, 8, 32],"float16"), mask=Tensor([2, 1, 8, 32],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413774 (unix time) try "date -d @1749413774" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17485) received by PID 95365 (TID 0x7f66fdba8740) from PID 95365 ***]


2025-06-09 04:17:09.309205 GPU 0 95567 test begin: paddle.incubate.softmax_mask_fuse(x=Tensor([2097153, 8, 8, 32],"float16"), mask=Tensor([2097153, 1, 8, 32],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413892 (unix time) try "date -d @1749413892" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1754f) received by PID 95567 (TID 0x7f6395154740) from PID 95567 ***]


2025-06-09 04:17:14.464272 GPU 3 95482 test begin: paddle.incubate.softmax_mask_fuse(x=Tensor([2796203, 3, 16, 32],"float16"), mask=Tensor([2796203, 1, 16, 32],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413837 (unix time) try "date -d @1749413837" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x174fa) received by PID 95482 (TID 0x7f7fa1ae3740) from PID 95482 ***]


2025-06-09 04:17:25.312951 GPU 2 95511 test begin: paddle.incubate.softmax_mask_fuse(x=Tensor([6, 2796203, 8, 32],"float16"), mask=Tensor([6, 1, 8, 32],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413847 (unix time) try "date -d @1749413847" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17517) received by PID 95511 (TID 0x7f3291655740) from PID 95511 ***]


2025-06-09 04:17:59.596643 GPU 1 95539 test begin: paddle.incubate.softmax_mask_fuse(x=Tensor([65794, 8, 8, 1020],"float16"), mask=Tensor([65794, 1, 8, 1020],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413882 (unix time) try "date -d @1749413882" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17533) received by PID 95539 (TID 0x7fefc259e740) from PID 95539 ***]


2025-06-09 04:18:16.038762 GPU 0 95654 test begin: paddle.incubate.softmax_mask_fuse(x=Tensor([7, 1198373, 16, 32],"float16"), mask=Tensor([7, 1, 16, 32],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749413961 (unix time) try "date -d @1749413961" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x175a6) received by PID 95654 (TID 0x7f2d0fedd740) from PID 95654 ***]


2025-06-09 04:19:47.526991 GPU 1 95682 test begin: paddle.index_put(Tensor([110, 42, 32, 56],"float64"), tuple(Tensor([16, 16],"int32"),Tensor([16, 16],"int32"),Tensor([2281701379],"bool"),), Tensor([16, 16, 56],"float64"), False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_index_put(_object*, _object*, _object*)
1   index_put_ad_func(paddle::Tensor const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::Tensor const&, bool)
2   paddle::experimental::index_put(paddle::Tensor const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::Tensor const&, bool)
3   void phi::IndexPutKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor const&, bool, phi::DenseTensor*)
4   void phi::LaunchIndexPutCudaKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, phi::DenseTensor const&, bool, phi::DenseTensor*)
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749414134 (unix time) try "date -d @1749414134" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x175c2) received by PID 95682 (TID 0x7f2aeba45740) from PID 95682 ***]


2025-06-09 04:22:24.888640 GPU 3 95625 test begin: paddle.matmul(x=Tensor([1431655766, 3],"float16"), y=Tensor([3],"float16"), transpose_x=False, transpose_y=True, )
W0609 04:22:28.188815 95625 backward.cc:441] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.matmul(x=Tensor([1431655766, 3],"float16"), y=Tensor([3],"float16"), transpose_x=False, transpose_y=True, ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 8589934596, memory's size is 2863311532.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):8589934596 > memory_size():2863311532.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-09 04:22:27.260511 GPU 0 95714 test begin: paddle.matmul(x=Tensor([4, 1073741825],"float16"), y=Tensor([1073741825],"float16"), transpose_x=False, transpose_y=True, )
W0609 04:22:30.443791 95714 backward.cc:441] While running Node (MatmulGradNode) raises an EnforceNotMet exception
[paddle error] paddle.matmul(x=Tensor([4, 1073741825],"float16"), y=Tensor([1073741825],"float16"), transpose_x=False, transpose_y=True, ) 
 (PreconditionNotMet) Tensor's dimension is out of bound.Tensor's dimension must be equal or less than the size of its memory.But received Tensor's dimension is 8589934600, memory's size is 8.
  [Hint: Expected numel() * SizeOf(dtype()) <= memory_size(), but received numel() * SizeOf(dtype()):8589934600 > memory_size():8.] (at ../paddle/phi/core/dense_tensor_impl.cc:48)


2025-06-09 04:22:31.777992 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([15521779, 3, 7, 7],"float32"), list[2,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool2d(Tensor([15521779, 3, 7, 7],"float32"), list[2,5,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:22:31.933116 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([15521779, 3, 7, 7],"float32"), output_size=5, data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool2d(Tensor([15521779, 3, 7, 7],"float32"), output_size=5, data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:22:32.796499 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool2d(Tensor([15521779, 3, 7, 7],"float32"), output_size=list[2,5,], data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool2d(Tensor([15521779, 3, 7, 7],"float32"), output_size=list[2,5,], data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:01.358676 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool2d(x=Tensor([15521779, 3, 7, 7],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_avg_pool2d(x=Tensor([15521779, 3, 7, 7],"float32"), output_size=5, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:03.735519 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool2d(x=Tensor([15521779, 3, 7, 7],"float32"), output_size=list[2,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool2d(x=Tensor([15521779, 3, 7, 7],"float32"), output_size=list[2,5,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:16.876976 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:20.846301 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=5, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:24.400433 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:27.817657 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:35.246100 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:36.447452 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:37.961775 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=5, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=5, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:40.301400 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:40.636986 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:40.894424 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:42.948093 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:43.272010 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:43.478285 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:44.020542 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:47.930452 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:52.235991 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:52.661531 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:53.051155 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:53.108107 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:54.243721 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:54.881829 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:55.510738 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:56.678306 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:56.739461 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:58.203096 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:58.442609 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=5, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:58.934906 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:23:59.767790 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:00.270443 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 10865245, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:02.309356 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=5, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:02.920793 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:04.960933 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:05.492061 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 10865245],"float32"), output_size=list[3,3,3,], data_format="NDHWC", ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:07.171067 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=5, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:08.191619 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:09.762614 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:11.747396 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 7760890, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:12.165703 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=5, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:15.503661 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:16.545367 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:17.322933 GPU 0 95714 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 4656534, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:17.721962 GPU 1 95743 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=5, )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=5, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:18.559043 GPU 2 95596 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:18.571019 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:20.330038 GPU 3 95625 test begin: paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
[cuda error] paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([3104356, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:20.407392 GPU 2 95596 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([285212673, 8],"float32"), Tensor([4],"int64"), Tensor([8, 3],"float32"), list[list[Tensor([8, 4],"float32"),Tensor([4, 2],"float32"),],], list[2,4,], None, )
[paddle error] paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([285212673, 8],"float32"), Tensor([4],"int64"), Tensor([8, 3],"float32"), list[list[Tensor([8, 4],"float32"),Tensor([4, 2],"float32"),],], list[2,4,], None, ) 
 Input and label should have the same size in the batch dimension.

2025-06-09 04:24:24.137225 GPU 3 95625 test begin: paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([4, 8],"float32"), Tensor([2281701379],"int64"), Tensor([8, 3],"float32"), list[list[Tensor([8, 4],"float32"),Tensor([4, 2],"float32"),],], list[2,4,], None, )
[paddle error] paddle.nn.functional.adaptive_log_softmax_with_loss(Tensor([4, 8],"float32"), Tensor([2281701379],"int64"), Tensor([8, 3],"float32"), list[list[Tensor([8, 4],"float32"),Tensor([4, 2],"float32"),],], list[2,4,], None, ) 
 Input and label should have the same size in the batch dimension.

2025-06-09 04:24:26.229445 GPU 1 95743 test begin: paddle.nn.functional.avg_pool3d(Tensor([2, 3, 11184811, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.avg_pool3d(Tensor([2, 3, 11184811, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:26.313919 GPU 0 95714 test begin: paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 11184811, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 11184811, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:26.866333 GPU 2 95596 test begin: paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 11184811],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 11184811],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:29.387525 GPU 0 95714 test begin: paddle.nn.functional.avg_pool3d(Tensor([2, 4194305, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.avg_pool3d(Tensor([2, 4194305, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:29.865406 GPU 2 95596 test begin: paddle.nn.functional.avg_pool3d(Tensor([2796203, 3, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
[cuda error] paddle.nn.functional.avg_pool3d(Tensor([2796203, 3, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:31.119885 GPU 0 95714 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 11184811, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
[cuda error] paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 11184811, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:31.609152 GPU 2 95596 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 11184811, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
[cuda error] paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 11184811, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:32.846723 GPU 0 95714 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 11184811],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
[cuda error] paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 11184811],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:33.281017 GPU 2 95596 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([2, 4194305, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
[cuda error] paddle.nn.functional.avg_pool3d(x=Tensor([2, 4194305, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:34.589908 GPU 0 95714 test begin: paddle.nn.functional.avg_pool3d(x=Tensor([2796203, 3, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
[cuda error] paddle.nn.functional.avg_pool3d(x=Tensor([2796203, 3, 8, 8, 8],"float16"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 04:24:35.011861 GPU 2 95596 test begin: paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:36.351495 GPU 0 95714 test begin: paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([119304648, 4, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:36.521249 GPU 2 95596 test begin: paddle.nn.functional.batch_norm(Tensor([1320430, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([1320430, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:40.879484 GPU 2 95596 test begin: paddle.nn.functional.batch_norm(Tensor([2, 1, 2, 570425345],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 1, 2, 570425345],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:40.953327 GPU 0 95714 test begin: paddle.nn.functional.batch_norm(Tensor([2, 1, 380283564, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 1, 380283564, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:42.115476 GPU 2 95596 test begin: paddle.nn.functional.batch_norm(Tensor([2, 190141782, 2, 3],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 190141782, 2, 3],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), Tensor([190141782],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:43.179877 GPU 3 95625 test begin: paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:43.872865 GPU 0 95714 test begin: paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 238609295, 3, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:43.888568 GPU 2 95596 test begin: paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:45.105775 GPU 0 95714 test begin: paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([2, 4, 178956971, 3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), Tensor([3],"float16"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:50.103763 GPU 3 95625 test begin: paddle.nn.functional.batch_norm(Tensor([380283564, 1, 2, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([380283564, 1, 2, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:51.036582 GPU 2 95596 test begin: paddle.nn.functional.batch_norm(Tensor([4, 1980644, 12, 24],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([4, 1980644, 12, 24],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), Tensor([1980644],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:53.797349 GPU 2 95596 test begin: paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7922575],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7922575],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:24:53.843724 GPU 0 95714 test begin: paddle.nn.functional.batch_norm(Tensor([4, 6, 3961288, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
[paddle error] paddle.nn.functional.batch_norm(Tensor([4, 6, 3961288, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/kernels/gpu/batch_norm_kernel.cu:687)


2025-06-09 04:25:49.512083 GPU 2 95596 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([1, 1, 4294967297],"float16"), label=Tensor([1, 1, 4294967297],"float16"), weight=None, reduction="mean", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749414466 (unix time) try "date -d @1749414466" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1756c) received by PID 95596 (TID 0x7f0efd351740) from PID 95596 ***]


2025-06-09 04:25:52.670607 GPU 3 95625 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([1, 2147483649, 2],"float16"), label=Tensor([1, 2147483649, 2],"float16"), weight=None, reduction="mean", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749414470 (unix time) try "date -d @1749414470" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17589) received by PID 95625 (TID 0x7f831633c740) from PID 95625 ***]


2025-06-09 04:35:47.488871 GPU 0 95714 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([143165577, 30],"float16"), Tensor([143165577, 30],"float16"), None, "mean", None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749415064 (unix time) try "date -d @1749415064" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x175e2) received by PID 95714 (TID 0x7f72a1e81740) from PID 95714 ***]


2025-06-09 04:36:04.496892 GPU 2 95800 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([143165577, 30],"float16"), Tensor([143165577, 30],"float16"), reduction="mean", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749415141 (unix time) try "date -d @1749415141" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17638) received by PID 95800 (TID 0x7fa44f687740) from PID 95800 ***]


2025-06-09 04:49:26.036744 GPU 0 95830 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([20, 214748365],"float16"), Tensor([20, 214748365],"float16"), None, "mean", None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749415944 (unix time) try "date -d @1749415944" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17656) received by PID 95830 (TID 0x7f9eb7ef6740) from PID 95830 ***]


2025-06-09 04:50:21.102917 GPU 3 95772 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([20, 214748365],"float16"), Tensor([20, 214748365],"float16"), reduction="mean", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749415935 (unix time) try "date -d @1749415935" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1761c) received by PID 95772 (TID 0x7f63c650b740) from PID 95772 ***]


2025-06-09 04:55:18.767343 GPU 0 95888 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([2147483649, 1, 2],"float16"), label=Tensor([2147483649, 1, 2],"float16"), weight=None, reduction="mean", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416289 (unix time) try "date -d @1749416289" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17690) received by PID 95888 (TID 0x7fbec24a6740) from PID 95888 ***]


2025-06-09 04:55:39.339322 GPU 2 95859 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([2147483649, 2],"float16"), Tensor([2147483649, 2],"float16"), None, "mean", None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416257 (unix time) try "date -d @1749416257" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17673) received by PID 95859 (TID 0x7f2db0e50740) from PID 95859 ***]


2025-06-09 05:03:05.752405 GPU 1 95743 test begin: paddle.nn.functional.binary_cross_entropy(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), None, "mean", None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416706 (unix time) try "date -d @1749416706" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x175ff) received by PID 95743 (TID 0x7fe3a22e3740) from PID 95743 ***]


2025-06-09 05:06:41.763382 GPU 2 95946 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 1, 30, 76056713],"float32"), Tensor([1, 1, 30, 76056713],"float32"), None, "mean", None, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416804 (unix time) try "date -d @1749416804" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x176ca) received by PID 95946 (TID 0x7ff30c9ee740) from PID 95946 ***]


2025-06-09 05:06:56.563019 GPU 0 95974 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 1, 76056713, 30],"float32"), Tensor([1, 1, 76056713, 30],"float32"), None, "mean", None, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416819 (unix time) try "date -d @1749416819" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x176e6) received by PID 95974 (TID 0x7f322d981740) from PID 95974 ***]


2025-06-09 05:07:37.583086 GPU 3 95916 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 2281701379],"float32"), Tensor([1, 2281701379],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416860 (unix time) try "date -d @1749416860" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x176ac) received by PID 95916 (TID 0x7efe5e3f5740) from PID 95916 ***]


2025-06-09 05:08:03.664753 GPU 1 96004 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 2535224, 30, 30],"float32"), Tensor([1, 2535224, 30, 30],"float32"), None, "mean", None, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416886 (unix time) try "date -d @1749416886" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17704) received by PID 96004 (TID 0x7f514df1c740) from PID 96004 ***]


2025-06-09 05:09:41.658535 GPU 0 96033 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([13, 175515491],"float32"), Tensor([13, 175515491],"float32"), None, "mean", None, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749416985 (unix time) try "date -d @1749416985" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17721) received by PID 96033 (TID 0x7f706d925740) from PID 96033 ***]


2025-06-09 05:11:34.506121 GPU 1 96091 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2281701379, 1],"float32"), Tensor([2281701379, 1],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417097 (unix time) try "date -d @1749417097" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1775b) received by PID 96091 (TID 0x7f72ffa66740) from PID 96091 ***]


2025-06-09 05:11:47.251635 GPU 2 96061 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([228170138, 10],"float32"), Tensor([228170138, 10],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417109 (unix time) try "date -d @1749417109" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1773d) received by PID 96061 (TID 0x7f8235a1a740) from PID 96061 ***]


2025-06-09 05:12:02.069315 GPU 3 96119 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2535224, 1, 30, 30],"float32"), Tensor([2535224, 1, 30, 30],"float32"), None, "mean", None, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417124 (unix time) try "date -d @1749417124" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17777) received by PID 96119 (TID 0x7f4f1787e740) from PID 96119 ***]


2025-06-09 05:12:53.764699 GPU 0 96149 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([459, 4971027],"float32"), Tensor([459, 4971027],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417177 (unix time) try "date -d @1749417177" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17795) received by PID 96149 (TID 0x7f716b1bb740) from PID 96149 ***]


2025-06-09 05:12:58.723318 GPU 2 96178 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([465, 4906885],"float32"), Tensor([465, 4906885],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417181 (unix time) try "date -d @1749417181" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x177b2) received by PID 96178 (TID 0x7f5985f43740) from PID 96178 ***]


2025-06-09 05:14:20.879995 GPU 3 96206 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([512, 4456449],"float32"), Tensor([512, 4456449],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417263 (unix time) try "date -d @1749417263" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x177ce) received by PID 96206 (TID 0x7fb2c9f15740) from PID 96206 ***]


2025-06-09 05:14:41.441510 GPU 1 96225 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([760567127, 3],"float32"), Tensor([760567127, 3],"float32"), None, "mean", None, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417285 (unix time) try "date -d @1749417285" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x177e1) received by PID 96225 (TID 0x7f98939fa740) from PID 96225 ***]


2025-06-09 05:15:27.434192 GPU 2 96263 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(logit=Tensor([2, 1140850690],"float32"), label=Tensor([2, 1140850690],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417330 (unix time) try "date -d @1749417330" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17807) received by PID 96263 (TID 0x7f091a5c8740) from PID 96263 ***]


2025-06-09 05:15:36.723912 GPU 0 96292 test begin: paddle.nn.functional.binary_cross_entropy_with_logits(logit=Tensor([2281701379, 1],"float32"), label=Tensor([2281701379, 1],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417339 (unix time) try "date -d @1749417339" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17824) received by PID 96292 (TID 0x7fa6a73d2740) from PID 96292 ***]


2025-06-09 05:16:02.469643 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([1024, 128, 3, 5803],"float32"), padding=1, groups=8, )
[paddle error] paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([1024, 128, 3, 5803],"float32"), padding=1, groups=8, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:03.810678 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([1024, 128, 5803, 3],"float32"), padding=1, groups=8, )
[paddle error] paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([1024, 128, 5803, 3],"float32"), padding=1, groups=8, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:07.683762 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 8705],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, )
[paddle error] paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 8705],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:07.741861 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 8705],"float32"), Tensor([1024, 128, 3, 8705],"float32"), padding=1, groups=8, )
[paddle error] paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 8705],"float32"), Tensor([1024, 128, 3, 8705],"float32"), padding=1, groups=8, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:09.907399 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([1, 1024, 8705, 256],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, )
[paddle error] paddle.nn.functional.conv2d(Tensor([1, 1024, 8705, 256],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:11.432991 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([1, 1024, 8705, 256],"float32"), Tensor([1024, 128, 8705, 3],"float32"), padding=1, groups=8, )
[paddle error] paddle.nn.functional.conv2d(Tensor([1, 1024, 8705, 256],"float32"), Tensor([1024, 128, 8705, 3],"float32"), padding=1, groups=8, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:15.670699 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([10, 1, 639133, 357],"float32"), Tensor([64, 1, 639133, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([10, 1, 639133, 357],"float32"), Tensor([64, 1, 639133, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:17.337026 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([10, 1, 69, 3306814],"float32"), Tensor([64, 1, 7, 3306814],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([10, 1, 69, 3306814],"float32"), Tensor([64, 1, 7, 3306814],"float32"), None, list[2,2,], 0, list[1,1,], 1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:19.222914 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([10, 1, 69, 357],"float32"), Tensor([64, 1, 5093084, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([10, 1, 69, 357],"float32"), Tensor([64, 1, 5093084, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:20.642457 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([10, 1, 69, 357],"float32"), Tensor([64, 1, 7, 5093084],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([10, 1, 69, 357],"float32"), Tensor([64, 1, 7, 5093084],"float32"), None, list[2,2,], 0, list[1,1,], 1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:22.406062 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([10, 9263, 69, 357],"float32"), Tensor([64, 9263, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([10, 9263, 69, 357],"float32"), Tensor([64, 9263, 7, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:24.492182 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([24, 1, 1418969, 67],"float32"), Tensor([1, 1, 1418969, 4],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([24, 1, 1418969, 67],"float32"), Tensor([1, 1, 1418969, 4],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:24.941125 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([24, 1, 1418969, 67],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([24, 1, 1418969, 67],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:25.737470 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([24, 1, 67, 1418969],"float32"), Tensor([1, 1, 4, 1418969],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([24, 1, 67, 1418969],"float32"), Tensor([1, 1, 4, 1418969],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:26.199465 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([24, 1, 67, 1418969],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([24, 1, 67, 1418969],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:26.971159 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([24, 1, 67, 67],"float32"), Tensor([1, 1, 4, 570425345],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([24, 1, 67, 67],"float32"), Tensor([1, 1, 4, 570425345],"float32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:27.637618 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([24, 1, 67, 67],"float32"), Tensor([1, 1, 570425345, 4],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([24, 1, 67, 67],"float32"), Tensor([1, 1, 570425345, 4],"float32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:30.392569 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([24, 21179, 67, 67],"float32"), Tensor([1, 21179, 4, 4],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([24, 21179, 67, 67],"float32"), Tensor([1, 21179, 4, 4],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:30.767479 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([273, 128, 256, 256],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([273, 128, 256, 256],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:31.616740 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([273, 128, 256, 256],"float32"), Tensor([273, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([273, 128, 256, 256],"float32"), Tensor([273, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:32.092539 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([35, 1024, 256, 256],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, )
[paddle error] paddle.nn.functional.conv2d(Tensor([35, 1024, 256, 256],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:33.552057 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([508288, 1, 67, 67],"float32"), Tensor([1, 1, 4, 4],"float32"), )
[paddle error] paddle.nn.functional.conv2d(Tensor([508288, 1, 67, 67],"float32"), Tensor([1, 1, 4, 4],"float32"), ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:34.981132 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([8, 128, 256, 256],"float32"), Tensor([128, 128, 3, 46422],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 128, 256, 256],"float32"), Tensor([128, 128, 3, 46422],"float32"), bias=None, stride=1, padding=1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:35.866684 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([8, 128, 256, 256],"float32"), Tensor([128, 128, 46422, 3],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 128, 256, 256],"float32"), Tensor([128, 128, 46422, 3],"float32"), bias=None, stride=1, padding=1, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:37.600998 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([8, 128, 256, 8705],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 128, 256, 8705],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:38.836555 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([8, 128, 256, 8705],"float32"), Tensor([128, 128, 3, 8705],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 128, 256, 8705],"float32"), Tensor([128, 128, 3, 8705],"float32"), bias=None, stride=1, padding=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:38.919251 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([8, 128, 8705, 256],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 128, 8705, 256],"float32"), Tensor([128, 128, 3, 3],"float32"), bias=None, stride=1, padding=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:40.458019 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([8, 128, 8705, 256],"float32"), Tensor([128, 128, 8705, 3],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 128, 8705, 256],"float32"), Tensor([128, 128, 8705, 3],"float32"), bias=None, stride=1, padding=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:41.856771 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([8, 3, 256, 256],"float32"), Tensor([128, 3, 1, 5941931],"float32"), bias=None, stride=1, padding=0, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 3, 256, 256],"float32"), Tensor([128, 3, 1, 5941931],"float32"), bias=None, stride=1, padding=0, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:42.413166 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([8, 3, 256, 256],"float32"), Tensor([128, 3, 5941931, 1],"float32"), bias=None, stride=1, padding=0, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 3, 256, 256],"float32"), Tensor([128, 3, 5941931, 1],"float32"), bias=None, stride=1, padding=0, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 05:16:44.377548 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([8, 3, 256, 371371],"float32"), Tensor([128, 3, 1, 371371],"float32"), bias=None, stride=1, padding=0, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 3, 256, 371371],"float32"), Tensor([128, 3, 1, 371371],"float32"), bias=None, stride=1, padding=0, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:45.651369 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([8, 3, 371371, 256],"float32"), Tensor([128, 3, 371371, 1],"float32"), bias=None, stride=1, padding=0, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 3, 371371, 256],"float32"), Tensor([128, 3, 371371, 1],"float32"), bias=None, stride=1, padding=0, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:48.186554 GPU 3 96351 test begin: paddle.nn.functional.conv2d(Tensor([8, 4353, 256, 256],"float32"), Tensor([128, 4353, 1, 1],"float32"), bias=None, stride=1, padding=0, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 4353, 256, 256],"float32"), Tensor([128, 4353, 1, 1],"float32"), bias=None, stride=1, padding=0, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:48.285875 GPU 1 96323 test begin: paddle.nn.functional.conv2d(Tensor([8, 4353, 256, 256],"float32"), Tensor([128, 4353, 3, 3],"float32"), bias=None, stride=1, padding=1, )
[paddle error] paddle.nn.functional.conv2d(Tensor([8, 4353, 256, 256],"float32"), Tensor([128, 4353, 3, 3],"float32"), bias=None, stride=1, padding=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:170)


2025-06-09 05:16:50.686532 GPU 3 96351 test begin: paddle.nn.functional.conv2d_transpose(Tensor([10496, 16, 172, 79],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([10496, 16, 172, 79],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:16:51.136337 GPU 1 96323 test begin: paddle.nn.functional.conv2d_transpose(Tensor([619, 64, 240, 240],"float32"), Tensor([64, 64, 2, 2],"float32"), bias=Tensor([64],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([619, 64, 240, 240],"float32"), Tensor([64, 64, 2, 2],"float32"), bias=Tensor([64],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:17:01.253738 GPU 2 96409 test begin: paddle.nn.functional.conv2d_transpose(Tensor([64, 16, 172, 12955],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([64, 16, 172, 12955],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:17:46.600174 GPU 1 96323 test begin: paddle.nn.functional.conv2d_transpose(Tensor([64, 16, 28206, 79],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([64, 16, 28206, 79],"float32"), Tensor([16, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:18:00.527911 GPU 0 96380 test begin: paddle.nn.functional.conv2d_transpose(Tensor([64, 2624, 172, 79],"float32"), Tensor([2624, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([64, 2624, 172, 79],"float32"), Tensor([2624, 8, 5, 5],"float32"), bias=Tensor([8],"float32"), padding=2, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:18:14.494343 GPU 1 96323 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16385],"float16"), Tensor([2048, 128, 4, 16385],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16385],"float16"), Tensor([2048, 128, 4, 16385],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:18:15.233722 GPU 3 96351 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16385],"float16"), Tensor([2048, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16385],"float16"), Tensor([2048, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:18:24.893066 GPU 2 96409 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16],"float16"), Tensor([2048, 128, 4, 4097],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417626 (unix time) try "date -d @1749417626" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17899) received by PID 96409 (TID 0x7f455d250740) from PID 96409 ***]


2025-06-09 05:18:29.243209 GPU 0 96380 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16],"float16"), Tensor([2048, 128, 4097, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417626 (unix time) try "date -d @1749417626" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1787c) received by PID 96380 (TID 0x7fd157b6d740) from PID 96380 ***]


2025-06-09 05:19:15.547440 GPU 3 96351 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16, 16],"float16"), Tensor([2048, 131073, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417674 (unix time) try "date -d @1749417674" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1785f) received by PID 96351 (TID 0x7f77efac2740) from PID 96351 ***]


2025-06-09 05:20:59.287101 GPU 2 96467 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16385, 16],"float16"), Tensor([2048, 128, 16385, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16385, 16],"float16"), Tensor([2048, 128, 16385, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:21:37.545066 GPU 0 96439 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16385, 16],"float16"), Tensor([2048, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8, 2048, 16385, 16],"float16"), Tensor([2048, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:23:00.214519 GPU 3 96496 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 2097153, 16, 16],"float16"), Tensor([2097153, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8, 2097153, 16, 16],"float16"), Tensor([2097153, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:23:41.423763 GPU 0 96439 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 18569, 240],"float32"), Tensor([64, 64, 2, 2],"float32"), bias=Tensor([64],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 18569, 240],"float32"), Tensor([64, 64, 2, 2],"float32"), bias=Tensor([64],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:23:52.532764 GPU 1 96323 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 240, 18569],"float32"), Tensor([64, 64, 2, 2],"float32"), bias=Tensor([64],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8, 64, 240, 18569],"float32"), Tensor([64, 64, 2, 2],"float32"), bias=Tensor([64],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:25:10.795165 GPU 3 96496 test begin: paddle.nn.functional.conv2d_transpose(Tensor([8193, 2048, 16, 16],"float16"), Tensor([2048, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
[paddle error] paddle.nn.functional.conv2d_transpose(Tensor([8193, 2048, 16, 16],"float16"), Tensor([2048, 128, 4, 4],"float16"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_desc.h:153)


2025-06-09 05:25:32.232124 GPU 0 96439 test begin: paddle.nn.functional.cosine_similarity(Tensor([1431655766, 1, 3],"float16"), Tensor([1, 3],"float16"), axis=0, eps=1e-08, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   MultiplyGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::multiply_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::ElementwiseMulGrad<phi::dtype::float16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, phi::DenseTensor*, int)
5   void phi::SumKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
6   void phi::SumRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
7   phi::DenseTensor::~DenseTensor()
8   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
9   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417991 (unix time) try "date -d @1749417991" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x178b7) received by PID 96439 (TID 0x7fa091b63740) from PID 96439 ***]


2025-06-09 05:26:26.716590 GPU 1 96323 test begin: paddle.nn.functional.cosine_similarity(Tensor([23, 12, 8267034],"float32"), Tensor([23, 1, 8267034],"float32"), axis=2, eps=1e-06, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   MultiplyGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::multiply_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::ElementwiseMulGrad<float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, phi::DenseTensor*, int)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749417988 (unix time) try "date -d @1749417988" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17843) received by PID 96323 (TID 0x7f00a4f6a740) from PID 96323 ***]


2025-06-09 05:27:01.585451 GPU 1 96554 test begin: paddle.nn.functional.cosine_similarity(Tensor([5, 1, 3],"float16"), Tensor([1431655766, 3],"float16"), axis=0, eps=1e-08, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DivideGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::divide_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::DivideGradKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*, phi::DenseTensor*)
5   void phi::SumKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
6   void phi::SumRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
7   phi::DenseTensor::~DenseTensor()
8   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
9   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418085 (unix time) try "date -d @1749418085" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1792a) received by PID 96554 (TID 0x7f82d0208740) from PID 96554 ***]


2025-06-09 05:27:33.069395 GPU 0 96526 test begin: paddle.nn.functional.cosine_similarity(Tensor([5, 1, 858993460],"float16"), Tensor([1, 858993460],"float16"), axis=0, eps=1e-08, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   MultiplyGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::multiply_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::ElementwiseMulGrad<phi::dtype::float16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, phi::DenseTensor*, int)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418114 (unix time) try "date -d @1749418114" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1790e) received by PID 96526 (TID 0x7f5fb39d4740) from PID 96526 ***]


2025-06-09 05:27:48.741955 GPU 2 96467 test begin: paddle.nn.functional.cosine_similarity(Tensor([5, 286331154, 3],"float16"), Tensor([1, 3],"float16"), axis=0, eps=1e-08, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   MultiplyGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::multiply_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::ElementwiseMulGrad<phi::dtype::float16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, phi::DenseTensor*, int)
5   void phi::SumKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
6   void phi::SumRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
7   phi::DenseTensor::~DenseTensor()
8   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
9   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418070 (unix time) try "date -d @1749418070" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x178d3) received by PID 96467 (TID 0x7f5e17700740) from PID 96467 ***]


2025-06-09 05:28:04.730078 GPU 3 96496 test begin: paddle.nn.functional.cosine_similarity(Tensor([5, 286331154, 3],"float16"), Tensor([286331154, 3],"float16"), axis=0, eps=1e-08, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   MultiplyGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::multiply_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::ElementwiseMulGrad<phi::dtype::float16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, phi::DenseTensor*, int)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418086 (unix time) try "date -d @1749418086" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x178f0) received by PID 96496 (TID 0x7f46d361f740) from PID 96496 ***]


2025-06-09 05:28:23.693541 GPU 2 96640 test begin: paddle.nn.functional.cross_entropy(Tensor([1, 2281701379],"float32"), Tensor([1, 1],"int64"), reduction="none", use_softmax=False, )
Error: ../paddle/phi/kernels/gpu/cross_entropy_kernel.cu:186 Assertion `lbl >= 0 && lbl < dim || lbl == ignore_idx` failed. The value of label expected >= 0 and < -2013265917, or == -100, but got 943720035. Please check label value.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(719), unspecified launch failure. 
  [Hint: 'cudaErrorLaunchFailure'. An exception occurred on the device while executing a kernel. Common causes include dereferencing an invalid device pointerand accessing out of bounds shared memory. Less common cases can be system specific - more information about these cases canbe found in the system specific user guide. This leaves the process in an inconsistent state and any further CUDA work willreturn the same error. To continue using CUDA, the process must be terminated and relaunched.] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   std::_Sp_counted_ptr_inplace<egr::AutogradMeta, std::allocator<egr::AutogradMeta>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
1   std::_Sp_counted_ptr<MultiplyGradNode*, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   phi::DenseTensor::~DenseTensor()
3   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
4   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418157 (unix time) try "date -d @1749418157" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17980) received by PID 96640 (TID 0x7f42b25e4740) from PID 96640 ***]


2025-06-09 05:30:57.797948 GPU 0 96668 test begin: paddle.nn.functional.cross_entropy(Tensor([128, 17825793],"float32"), Tensor([128, 1],"int64"), reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418259 (unix time) try "date -d @1749418259" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1799c) received by PID 96668 (TID 0x7fe601972740) from PID 96668 ***]


2025-06-09 05:31:13.950677 GPU 1 96584 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=None, reduction="mean", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_mean_all(_object*, _object*, _object*)
1   mean_all_ad_func(paddle::Tensor const&)
2   paddle::experimental::mean_all(paddle::Tensor const&)
3   void phi::MeanAllKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418446 (unix time) try "date -d @1749418446" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17948) received by PID 96584 (TID 0x7f7079d32740) from PID 96584 ***]


2025-06-09 05:31:31.572579 GPU 0 96728 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=None, reduction="none", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418461 (unix time) try "date -d @1749418461" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x179d8) received by PID 96728 (TID 0x7f60e4185740) from PID 96728 ***]


2025-06-09 05:31:33.716958 GPU 3 96604 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=Tensor([3],"float16"), reduction="mean", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_matmul(_object*, _object*, _object*)
1   matmul_ad_func(paddle::Tensor const&, paddle::Tensor const&, bool, bool)
2   paddle::Tensor::~Tensor()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418505 (unix time) try "date -d @1749418505" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1795c) received by PID 96604 (TID 0x7f47fe24b740) from PID 96604 ***]


2025-06-09 05:31:37.970406 GPU 2 96699 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, axis=-1, weight=Tensor([3],"float16"), reduction="none", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_matmul(_object*, _object*, _object*)
1   matmul_ad_func(paddle::Tensor const&, paddle::Tensor const&, bool, bool)
2   paddle::Tensor::~Tensor()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418508 (unix time) try "date -d @1749418508" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x179bb) received by PID 96699 (TID 0x7fadd2a67740) from PID 96699 ***]


2025-06-09 05:34:24.754310 GPU 0 96758 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, label_smoothing=0.5986189939413826, axis=-1, weight=None, reduction="none", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418635 (unix time) try "date -d @1749418635" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x179f6) received by PID 96758 (TID 0x7fc47e0dc740) from PID 96758 ***]


2025-06-09 05:34:39.368398 GPU 1 96786 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), soft_label=True, label_smoothing=0.8211263365048883, axis=-1, weight=Tensor([3],"float16"), reduction="mean", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_matmul(_object*, _object*, _object*)
1   matmul_ad_func(paddle::Tensor const&, paddle::Tensor const&, bool, bool)
2   paddle::Tensor::~Tensor()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418689 (unix time) try "date -d @1749418689" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17a12) received by PID 96786 (TID 0x7fe36bfea740) from PID 96786 ***]


2025-06-09 05:35:12.573664 GPU 2 96814 test begin: paddle.nn.functional.cross_entropy(Tensor([1431655766, 3],"float16"), Tensor([1431655766],"int64"), soft_label=True, label_smoothing=0.1858912794612338, axis=-1, weight=Tensor([3],"float16"), reduction="mean", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_matmul(_object*, _object*, _object*)
1   matmul_ad_func(paddle::Tensor const&, paddle::Tensor const&, bool, bool)
2   paddle::Tensor::~Tensor()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418637 (unix time) try "date -d @1749418637" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17a2e) received by PID 96814 (TID 0x7f99bddcf740) from PID 96814 ***]


2025-06-09 05:36:46.527708 GPU 3 96842 test begin: paddle.nn.functional.cross_entropy(Tensor([16, 142606337],"float32"), Tensor([16, 142606337],"float32"), soft_label=True, )
[paddle error] paddle.nn.functional.cross_entropy(Tensor([16, 142606337],"float32"), Tensor([16, 142606337],"float32"), soft_label=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_helper.h:243)


2025-06-09 05:38:15.270901 GPU 2 96873 test begin: paddle.nn.functional.cross_entropy(Tensor([2, 114085069, 10],"float32"), Tensor([2, 114085069, 1],"int64"), soft_label=False, ignore_index=4, reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418701 (unix time) try "date -d @1749418701" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17a69) received by PID 96873 (TID 0x7fca33e04740) from PID 96873 ***]


2025-06-09 05:39:22.003516 GPU 2 96931 test begin: paddle.nn.functional.cross_entropy(Tensor([2, 30, 38028357],"float32"), Tensor([2, 30, 1],"int64"), soft_label=False, ignore_index=4, reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418763 (unix time) try "date -d @1749418763" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17aa3) received by PID 96931 (TID 0x7fbdfe568740) from PID 96931 ***]


2025-06-09 05:40:07.966488 GPU 0 96902 test begin: paddle.nn.functional.cross_entropy(Tensor([228170138, 10],"float32"), Tensor([228170138, 1],"int64"), reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418813 (unix time) try "date -d @1749418813" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17a86) received by PID 96902 (TID 0x7fe5e9ddd740) from PID 96902 ***]


2025-06-09 05:40:25.683917 GPU 1 96959 test begin: paddle.nn.functional.cross_entropy(Tensor([22817014, 100],"float32"), Tensor([22817014, 1],"int64"), reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749418827 (unix time) try "date -d @1749418827" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17abf) received by PID 96959 (TID 0x7f825431f740) from PID 96959 ***]


2025-06-09 06:52:08.852562 GPU 2 97277 test begin: paddle.nn.functional.cross_entropy(Tensor([456340276, 5],"float32"), Tensor([456340276, 5],"float32"), soft_label=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_mean_all(_object*, _object*, _object*)
1   mean_all_ad_func(paddle::Tensor const&)
2   paddle::experimental::mean_all(paddle::Tensor const&)
3   void phi::MeanAllKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423227 (unix time) try "date -d @1749423227" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17bfd) received by PID 97277 (TID 0x7f45a3539740) from PID 97277 ***]


2025-06-09 06:53:09.550333 GPU 3 97214 test begin: paddle.nn.functional.cross_entropy(Tensor([5704254, 400],"float32"), Tensor([5704254, 400],"float32"), soft_label=True, )
[paddle error] paddle.nn.functional.cross_entropy(Tensor([5704254, 400],"float32"), Tensor([5704254, 400],"float32"), soft_label=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_helper.h:243)


2025-06-09 06:53:26.877120 GPU 1 97193 test begin: paddle.nn.functional.cross_entropy(Tensor([7605672, 30, 10],"float32"), Tensor([7605672, 30, 1],"int64"), soft_label=False, ignore_index=4, reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423213 (unix time) try "date -d @1749423213" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17ba9) received by PID 97193 (TID 0x7f90e1e61740) from PID 97193 ***]


2025-06-09 06:53:51.324228 GPU 2 97309 test begin: paddle.nn.functional.cross_entropy(Tensor([8, 285212673],"float32"), Tensor([8, 285212673],"float32"), soft_label=True, )
[paddle error] paddle.nn.functional.cross_entropy(Tensor([8, 285212673],"float32"), Tensor([8, 285212673],"float32"), soft_label=True, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_helper.h:243)


2025-06-09 06:55:27.358604 GPU 2 97309 test begin: paddle.nn.functional.cross_entropy(input=Tensor([1, 2281701379],"float32"), label=Tensor([1, 1],"int64"), reduction="none", use_softmax=False, )
Error: ../paddle/phi/kernels/gpu/cross_entropy_kernel.cu:186 Assertion `lbl >= 0 && lbl < dim || lbl == ignore_idx` failed. The value of label expected >= 0 and < -2013265917, or == -100, but got 714025934. Please check label value.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(719), unspecified launch failure. 
  [Hint: 'cudaErrorLaunchFailure'. An exception occurred on the device while executing a kernel. Common causes include dereferencing an invalid device pointerand accessing out of bounds shared memory. Less common cases can be system specific - more information about these cases canbe found in the system specific user guide. This leaves the process in an inconsistent state and any further CUDA work willreturn the same error. To continue using CUDA, the process must be terminated and relaunched.] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   std::_Sp_counted_ptr_inplace<egr::AutogradMeta, std::allocator<egr::AutogradMeta>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
1   std::_Sp_counted_ptr<MultiplyGradNode*, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   phi::DenseTensor::~DenseTensor()
3   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
4   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423329 (unix time) try "date -d @1749423329" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c1d) received by PID 97309 (TID 0x7f67ab29a740) from PID 97309 ***]


2025-06-09 06:56:33.734178 GPU 1 97337 test begin: paddle.nn.functional.cross_entropy(input=Tensor([2, 1140850690],"float32"), label=Tensor([2, 1],"int64"), ignore_index=-1, reduction="none", use_softmax=False, )
[cuda error] paddle.nn.functional.cross_entropy(input=Tensor([2, 1140850690],"float32"), label=Tensor([2, 1],"int64"), ignore_index=-1, reduction="none", use_softmax=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 06:56:49.836545 GPU 0 97249 test begin: paddle.nn.functional.cross_entropy(input=Tensor([2, 2147483649],"float16"), label=Tensor([2, 1],"int64"), reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423413 (unix time) try "date -d @1749423413" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17be1) received by PID 97249 (TID 0x7fee5cf03740) from PID 97249 ***]


2025-06-09 06:57:54.987098 GPU 3 97214 test begin: paddle.nn.functional.cross_entropy(input=Tensor([22369622, 102],"float32"), label=Tensor([22369622, 1],"int64"), reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423478 (unix time) try "date -d @1749423478" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17bbe) received by PID 97214 (TID 0x7ff8b66c6740) from PID 97214 ***]


2025-06-09 06:58:46.085412 GPU 1 97337 test begin: paddle.nn.functional.cross_entropy(input=Tensor([228170138, 10],"float32"), label=Tensor([228170138, 1],"int64"), reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423534 (unix time) try "date -d @1749423534" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c39) received by PID 97337 (TID 0x7f4b01a79740) from PID 97337 ***]


2025-06-09 06:58:51.752746 GPU 0 97395 test begin: paddle.nn.functional.cross_entropy(input=Tensor([42107523, 102],"float16"), label=Tensor([42107523, 1],"int64"), reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423591 (unix time) try "date -d @1749423591" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c73) received by PID 97395 (TID 0x7f297da6f740) from PID 97395 ***]


2025-06-09 06:58:53.679791 GPU 2 97367 test begin: paddle.nn.functional.cross_entropy(input=Tensor([5704254, 400],"float32"), label=Tensor([5704254, 1],"int64"), ignore_index=-1, reduction="none", use_softmax=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423535 (unix time) try "date -d @1749423535" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c57) received by PID 97367 (TID 0x7f395cf40740) from PID 97367 ***]


2025-06-09 06:59:27.693348 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([120445, 512, 37],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([120445, 512, 37],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:00:24.144200 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([240890, 256, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([240890, 256, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:00:25.783565 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 2466705, 37],"float32"), Tensor([2466705, 25],"int32"), Tensor([2466705],"int64"), Tensor([2466705],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 2466705, 37],"float32"), Tensor([2466705, 25],"int32"), Tensor([2466705],"int64"), Tensor([2466705],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:00:27.184994 GPU 3 97424 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 2466705, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 2466705, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 07:00:29.010218 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 256, 356516],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 256, 356516],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:00:31.135182 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 256, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([2281701379],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 256, 37],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([2281701379],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:01:44.720583 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 256, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([2281701379],"int64"), 0, "none", norm_by_times=False, )
[cuda error] paddle.nn.functional.ctc_loss(Tensor([25, 256, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([2281701379],"int64"), 0, "none", norm_by_times=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 07:02:09.163549 GPU 2 97454 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 512, 178258],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 512, 178258],"float32"), Tensor([512, 25],"int32"), Tensor([512],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:02:11.981547 GPU 2 97454 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 512, 37],"float32"), Tensor([512, 25],"int32"), Tensor([2281701379],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 512, 37],"float32"), Tensor([512, 25],"int32"), Tensor([2281701379],"int64"), Tensor([512],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:03:03.994438 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 950709, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 950709, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 07:03:06.892026 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([25, 950709, 96],"float32"), Tensor([950709, 25],"int32"), Tensor([950709],"int64"), Tensor([950709],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([25, 950709, 96],"float32"), Tensor([950709, 25],"int32"), Tensor([950709],"int64"), Tensor([950709],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:03:08.724569 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([2691, 128, 6625],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([2691, 128, 6625],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:03:10.654800 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([3, 3, 15],"float32"), Tensor([1140850690, 2],"int32"), Tensor([3],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([3, 3, 15],"float32"), Tensor([1140850690, 2],"int32"), Tensor([3],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:03:44.229921 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([3, 3, 15],"float32"), Tensor([3, 2],"int32"), Tensor([2281701379],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, )
[cuda error] paddle.nn.functional.ctc_loss(Tensor([3, 3, 15],"float32"), Tensor([3, 2],"int32"), Tensor([2281701379],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 07:04:24.281590 GPU 1 97482 test begin: paddle.nn.functional.ctc_loss(Tensor([3, 50704476, 15],"float32"), Tensor([3, 2],"int32"), Tensor([3],"int64"), Tensor([3],"int64"), 0, "none", norm_by_times=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_warpctc(_object*, _object*, _object*)
1   warpctc_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, int, bool)
2   paddle::experimental::warpctc_intermediate(paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, int, bool)
3   void phi::WarpctcKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, int, bool, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423867 (unix time) try "date -d @1749423867" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xab654000) received by PID 97482 (TID 0x7fd242635740) from PID 18446744072290123776 ***]


2025-06-09 07:04:24.455119 GPU 0 97512 test begin: paddle.nn.functional.ctc_loss(Tensor([4, 16777217, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="mean", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_warpctc(_object*, _object*, _object*)
1   warpctc_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, int, bool)
2   paddle::experimental::warpctc_intermediate(paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, int, bool)
3   void phi::WarpctcKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, int, bool, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423867 (unix time) try "date -d @1749423867" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f663f8bd000) received by PID 97512 (TID 0x7f6f0db11740) from PID 1066127360 ***]


2025-06-09 07:04:25.172205 GPU 2 97454 test begin: paddle.nn.functional.ctc_loss(Tensor([4, 16777217, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_warpctc(_object*, _object*, _object*)
1   warpctc_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, int, bool)
2   paddle::experimental::warpctc_intermediate(paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::optional<paddle::Tensor> const&, int, bool)
3   void phi::WarpctcKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, paddle::optional<phi::DenseTensor> const&, int, bool, phi::DenseTensor*, phi::DenseTensor*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749423868 (unix time) try "date -d @1749423868" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0xaa120000) received by PID 97454 (TID 0x7fd2e88f6740) from PID 18446744072267890688 ***]


2025-06-09 07:04:31.617426 GPU 1 97541 test begin: paddle.nn.functional.ctc_loss(Tensor([4, 4, 142606337],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="mean", )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([4, 4, 142606337],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="mean", ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:04:31.894183 GPU 2 97555 test begin: paddle.nn.functional.ctc_loss(Tensor([4, 4, 142606337],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([4, 4, 142606337],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="sum", ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:05:57.163134 GPU 2 97555 test begin: paddle.nn.functional.ctc_loss(Tensor([4, 4, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([2281701379],"int64"), blank=33, reduction="sum", )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([4, 4, 34],"float32"), Tensor([4, 4],"int32"), Tensor([4],"int64"), Tensor([2281701379],"int64"), blank=33, reduction="sum", ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:05:57.976578 GPU 1 97541 test begin: paddle.nn.functional.ctc_loss(Tensor([4, 4, 34],"float32"), Tensor([4, 570425345],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="mean", )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([4, 4, 34],"float32"), Tensor([4, 570425345],"int32"), Tensor([4],"int64"), Tensor([4],"int64"), blank=33, reduction="mean", ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:07:03.317738 GPU 1 97541 test begin: paddle.nn.functional.ctc_loss(Tensor([40, 128, 445645],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([40, 128, 445645],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:07:06.266884 GPU 1 97541 test begin: paddle.nn.functional.ctc_loss(Tensor([40, 128, 6625],"float32"), Tensor([128, 17825793],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([40, 128, 6625],"float32"), Tensor([128, 17825793],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:07:59.502543 GPU 2 97555 test begin: paddle.nn.functional.ctc_loss(Tensor([40, 8611, 6625],"float32"), Tensor([8611, 25],"int32"), Tensor([8611],"int64"), Tensor([8611],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([40, 8611, 6625],"float32"), Tensor([8611, 25],"int32"), Tensor([8611],"int64"), Tensor([8611],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:15:09.401657 GPU 2 97555 test begin: paddle.nn.functional.ctc_loss(Tensor([5, 2, 3],"float64"), labels=Tensor([2, 3],"int32"), input_lengths=Tensor([2281701379],"int64"), label_lengths=Tensor([2],"int64"), blank=0, reduction="none", )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([5, 2, 3],"float64"), labels=Tensor([2, 3],"int32"), input_lengths=Tensor([2281701379],"int64"), label_lengths=Tensor([2],"int64"), blank=0, reduction="none", ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: execution failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:3.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:26:53.671844 GPU 1 97541 test begin: paddle.nn.functional.ctc_loss(Tensor([92843, 256, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, )
[paddle error] paddle.nn.functional.ctc_loss(Tensor([92843, 256, 96],"float32"), Tensor([256, 25],"int32"), Tensor([256],"int64"), Tensor([256],"int64"), 0, "none", norm_by_times=False, ) 
 (PreconditionNotMet) warp-ctc [version 2] Error in get_workspace_size: cuda memcpy or memset failed
  [Hint: Expected CTC_STATUS_SUCCESS == status, but received CTC_STATUS_SUCCESS:0 != status:1.] (at ../paddle/phi/kernels/impl/warpctc_kernel_impl.h:194)


2025-06-09 07:26:56.579599 GPU 1 97541 test begin: paddle.nn.functional.dice_loss(Tensor([2147483649, 2],"float16"), label=Tensor([1140850690, 1],"int64"), epsilon=1e-05, )
[paddle error] paddle.nn.functional.dice_loss(Tensor([2147483649, 2],"float16"), label=Tensor([1140850690, 1],"int64"), epsilon=1e-05, ) 
 

2025-06-09 07:26:58.956673 GPU 2 97555 test begin: paddle.nn.functional.dice_loss(Tensor([2147483649, 2],"float16"), label=Tensor([2147483649, 1],"int64"), epsilon=1e-05, )
[paddle error] paddle.nn.functional.dice_loss(Tensor([2147483649, 2],"float16"), label=Tensor([2147483649, 1],"int64"), epsilon=1e-05, ) 
 

2025-06-09 07:27:06.855126 GPU 1 97541 test begin: paddle.nn.functional.dice_loss(Tensor([2147483649, 2],"float16"), label=Tensor([5, 1],"int64"), epsilon=1e-05, )
[paddle error] paddle.nn.functional.dice_loss(Tensor([2147483649, 2],"float16"), label=Tensor([5, 1],"int64"), epsilon=1e-05, ) 
 

2025-06-09 07:27:50.134978 GPU 2 97555 test begin: paddle.nn.functional.dice_loss(Tensor([5, 858993460],"float16"), label=Tensor([5, 1],"int64"), epsilon=1e-05, )
[paddle error] paddle.nn.functional.dice_loss(Tensor([5, 858993460],"float16"), label=Tensor([5, 1],"int64"), epsilon=1e-05, ) 
 

2025-06-09 07:27:52.912516 GPU 2 97555 test begin: paddle.nn.functional.dice_loss(Tensor([5, 858993460],"float16"), label=Tensor([5, 456340276],"int64"), epsilon=1e-05, )
[paddle error] paddle.nn.functional.dice_loss(Tensor([5, 858993460],"float16"), label=Tensor([5, 456340276],"int64"), epsilon=1e-05, ) 
 

2025-06-09 07:51:25.225500 GPU 2 97801 test begin: paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([570425345, 4],"float32"), padding_idx=-1, scale_grad_by_freq=True, )
[cuda error] paddle.nn.functional.embedding(Tensor([2, 3],"int64"), Tensor([570425345, 4],"float32"), padding_idx=-1, scale_grad_by_freq=True, ) 
 (External) CUDA error(1), invalid argument. 
  [Hint: 'cudaErrorInvalidValue'. This indicates that one or more of the parameters passed to the API call is not within an acceptable range of values. ] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 07:52:38.258440 GPU 0 97860 test begin: paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([570425345, 4],"float32"), padding_idx=2, scale_grad_by_freq=True, )
[cuda error] paddle.nn.functional.embedding(Tensor([2, 4],"int64"), Tensor([570425345, 4],"float32"), padding_idx=2, scale_grad_by_freq=True, ) 
 (External) CUDA error(1), invalid argument. 
  [Hint: 'cudaErrorInvalidValue'. This indicates that one or more of the parameters passed to the API call is not within an acceptable range of values. ] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 08:27:28.490691 GPU 2 98034 test begin: paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([570425345, 4],"float32"), padding_idx=5, scale_grad_by_freq=True, )
[cuda error] paddle.nn.functional.embedding(Tensor([6, 3],"int32"), Tensor([570425345, 4],"float32"), padding_idx=5, scale_grad_by_freq=True, ) 
 (External) CUDA error(1), invalid argument. 
  [Hint: 'cudaErrorInvalidValue'. This indicates that one or more of the parameters passed to the API call is not within an acceptable range of values. ] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 08:38:04.625880 GPU 2 98411 test begin: paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2, 114085069],"float32"), Tensor([10, 2, 114085069],"float32"), Tensor([10, 2, 1],"float32"), False, 1e-06, "none", None, )
[cuda error] paddle.nn.functional.gaussian_nll_loss(Tensor([10, 2, 114085069],"float32"), Tensor([10, 2, 114085069],"float32"), Tensor([10, 2, 1],"float32"), False, 1e-06, "none", None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   std::_Sp_counted_ptr_inplace<egr::AutogradMeta, std::allocator<egr::AutogradMeta>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
1   std::_Sp_counted_ptr<ScaleGradNode*, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   egr::GradNodeBase::~GradNodeBase()
3   std::_Sp_counted_ptr<AddGradNode*, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
4   egr::GradNodeBase::~GradNodeBase()
5   std::_Sp_counted_ptr<DivideGradNode*, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   phi::DenseTensor::~DenseTensor()
7   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
8   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749429545 (unix time) try "date -d @1749429545" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1806b) received by PID 98411 (TID 0x7fe5f6686740) from PID 98411 ***]


2025-06-09 08:49:01.162957 GPU 1 98381 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 128, 139265],"float32"), list[256,256,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430143 (unix time) try "date -d @1749430143" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1804d) received by PID 98381 (TID 0x7f7de5c72740) from PID 98381 ***]


2025-06-09 08:49:01.745389 GPU 0 98351 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 139265, 128],"float32"), list[256,256,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430144 (unix time) try "date -d @1749430144" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1802f) received by PID 98351 (TID 0x7ff4f0176740) from PID 98351 ***]


2025-06-09 08:49:08.748383 GPU 0 98469 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 2, 8912897],"float32"), list[128,128,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430208 (unix time) try "date -d @1749430208" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x180a5) received by PID 98469 (TID 0x7fdd23611740) from PID 98469 ***]


2025-06-09 08:49:09.598671 GPU 3 98208 test begin: paddle.nn.functional.interpolate(Tensor([1, 128, 8912897, 2],"float32"), list[128,128,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430151 (unix time) try "date -d @1749430151" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17fa0) received by PID 98208 (TID 0x7fa8ffaf1740) from PID 98208 ***]


2025-06-09 08:49:15.282253 GPU 3 98497 test begin: paddle.nn.functional.interpolate(Tensor([1, 17825793, 128],"float32"), size=list[64,], mode="linear", align_mode=1, align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430212 (unix time) try "date -d @1749430212" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x180c1) received by PID 98497 (TID 0x7f8970dcb740) from PID 98497 ***]


2025-06-09 08:49:23.029601 GPU 2 98525 test begin: paddle.nn.functional.interpolate(Tensor([1, 17825793, 128],"float32"), size=list[64,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NCW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430219 (unix time) try "date -d @1749430219" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x180dd) received by PID 98525 (TID 0x7f023ab26740) from PID 98525 ***]


2025-06-09 08:49:36.699782 GPU 1 98553 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 2228225, 512],"float32"), list[Tensor([1],"int64"),Tensor([1],"int64"),], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430231 (unix time) try "date -d @1749430231" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x180f9) received by PID 98553 (TID 0x7f34cd15c740) from PID 98553 ***]


2025-06-09 08:50:15.809278 GPU 3 98583 test begin: paddle.nn.functional.interpolate(Tensor([1, 2, 512, 2228225],"float32"), list[Tensor([1],"int64"),Tensor([1],"int64"),], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430270 (unix time) try "date -d @1749430270" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18117) received by PID 98583 (TID 0x7ff037cde740) from PID 98583 ***]


2025-06-09 08:50:41.047932 GPU 0 98669 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 1, 16777217],"float16"), list[64,64,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430302 (unix time) try "date -d @1749430302" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1816d) received by PID 98669 (TID 0x7fa38718f740) from PID 98669 ***]


2025-06-09 08:51:43.309257 GPU 3 98700 test begin: paddle.nn.functional.interpolate(Tensor([1, 256, 16777217, 1],"float16"), list[64,64,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430367 (unix time) try "date -d @1749430367" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1818c) received by PID 98700 (TID 0x7f8ad2751740) from PID 98700 ***]


2025-06-09 08:52:08.241825 GPU 1 98641 test begin: paddle.nn.functional.interpolate(Tensor([1, 32, 2, 35651585],"float32"), list[32,32,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430329 (unix time) try "date -d @1749430329" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18151) received by PID 98641 (TID 0x7f7087d81740) from PID 98641 ***]


2025-06-09 08:52:13.805524 GPU 1 98729 test begin: paddle.nn.functional.interpolate(Tensor([1, 32, 35651585, 2],"float32"), list[32,32,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430387 (unix time) try "date -d @1749430387" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x181a9) received by PID 98729 (TID 0x7f2537729740) from PID 98729 ***]


2025-06-09 08:52:48.251432 GPU 2 98612 test begin: paddle.nn.functional.interpolate(Tensor([1, 7428, 640, 480],"float32"), size=list[10,8,], )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430369 (unix time) try "date -d @1749430369" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18134) received by PID 98612 (TID 0x7f074c127740) from PID 98612 ***]


2025-06-09 08:52:53.753034 GPU 2 98786 test begin: paddle.nn.functional.interpolate(Tensor([1, 8705, 512, 512],"float32"), list[Tensor([1],"int64"),Tensor([1],"int64"),], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430428 (unix time) try "date -d @1749430428" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x181e2) received by PID 98786 (TID 0x7f9a17ff9740) from PID 98786 ***]


2025-06-09 08:53:10.495983 GPU 1 98815 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430452 (unix time) try "date -d @1749430452" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x181ff) received by PID 98815 (TID 0x7f7453232740) from PID 98815 ***]


2025-06-09 08:53:20.089278 GPU 3 98843 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430461 (unix time) try "date -d @1749430461" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1821b) received by PID 98843 (TID 0x7f794931a740) from PID 98843 ***]


2025-06-09 08:53:25.113159 GPU 0 98749 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430406 (unix time) try "date -d @1749430406" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x181bd) received by PID 98749 (TID 0x7f8cf7150740) from PID 98749 ***]


2025-06-09 08:53:29.482148 GPU 0 98872 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430483 (unix time) try "date -d @1749430483" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18238) received by PID 98872 (TID 0x7fe3bf12c740) from PID 98872 ***]


2025-06-09 08:54:15.338788 GPU 1 98902 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430529 (unix time) try "date -d @1749430529" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18256) received by PID 98902 (TID 0x7fc71f102740) from PID 98902 ***]


2025-06-09 08:54:20.190785 GPU 2 98931 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430521 (unix time) try "date -d @1749430521" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18273) received by PID 98931 (TID 0x7fa2a6922740) from PID 98931 ***]


2025-06-09 08:54:24.918150 GPU 3 98959 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430539 (unix time) try "date -d @1749430539" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1828f) received by PID 98959 (TID 0x7f9b414b1740) from PID 98959 ***]


2025-06-09 08:55:15.045718 GPU 0 98988 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430577 (unix time) try "date -d @1749430577" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x182ac) received by PID 98988 (TID 0x7f046a7d5740) from PID 98988 ***]


2025-06-09 08:55:32.734737 GPU 1 99018 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430597 (unix time) try "date -d @1749430597" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x182ca) received by PID 99018 (TID 0x7fd5d0c52740) from PID 99018 ***]


2025-06-09 08:55:42.404581 GPU 3 99047 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430606 (unix time) try "date -d @1749430606" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x182e7) received by PID 99047 (TID 0x7ff4eaabb740) from PID 99047 ***]


2025-06-09 08:55:53.643752 GPU 2 99075 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430616 (unix time) try "date -d @1749430616" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18303) received by PID 99075 (TID 0x7f69a38ce740) from PID 99075 ***]


2025-06-09 08:56:41.129712 GPU 1 99105 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749430668 (unix time) try "date -d @1749430668" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18321) received by PID 99105 (TID 0x7ff02c0da740) from PID 99105 ***]


2025-06-09 09:49:38.363437 GPU 1 105724 test begin: paddle.nn.functional.interpolate(Tensor([107374183, 10, 4],"float16"), size=Tensor([1],"int32"), scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749433779 (unix time) try "date -d @1749433779" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19cfc) received by PID 105724 (TID 0x7fc3a9c97740) from PID 105724 ***]


2025-06-09 09:50:14.330226 GPU 0 105855 test begin: paddle.nn.functional.interpolate(Tensor([1073742, 10, 10, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749433815 (unix time) try "date -d @1749433815" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19d7f) received by PID 105855 (TID 0x7f09aa50a740) from PID 105855 ***]


2025-06-09 09:50:18.611928 GPU 0 106384 test begin: paddle.nn.functional.interpolate(Tensor([1073742, 10, 10, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749433894 (unix time) try "date -d @1749433894" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19f90) received by PID 106384 (TID 0x7f6f37a0a740) from PID 106384 ***]


2025-06-09 09:51:37.660872 GPU 0 106912 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749433976 (unix time) try "date -d @1749433976" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a1a0) received by PID 106912 (TID 0x7f955d178740) from PID 106912 ***]


2025-06-09 09:51:51.011300 GPU 3 106966 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749433964 (unix time) try "date -d @1749433964" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a1d6) received by PID 106966 (TID 0x7fea80388740) from PID 106966 ***]


2025-06-09 09:52:18.875500 GPU 1 106848 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749433940 (unix time) try "date -d @1749433940" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a160) received by PID 106848 (TID 0x7fe57d5fb740) from PID 106848 ***]


2025-06-09 09:52:38.994097 GPU 2 106822 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749433960 (unix time) try "date -d @1749433960" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a146) received by PID 106822 (TID 0x7f17588b1740) from PID 106822 ***]


2025-06-09 09:52:44.188830 GPU 2 107110 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434017 (unix time) try "date -d @1749434017" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a266) received by PID 107110 (TID 0x7fcece684740) from PID 107110 ***]


2025-06-09 09:52:47.782814 GPU 3 107145 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434032 (unix time) try "date -d @1749434032" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a289) received by PID 107145 (TID 0x7f15067fc740) from PID 107145 ***]


2025-06-09 09:52:52.841762 GPU 1 107186 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434026 (unix time) try "date -d @1749434026" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a2b2) received by PID 107186 (TID 0x7f5405ffa740) from PID 107186 ***]


2025-06-09 09:53:00.363141 GPU 0 107228 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434041 (unix time) try "date -d @1749434041" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a2dc) received by PID 107228 (TID 0x7f58bff11740) from PID 107228 ***]


2025-06-09 09:53:49.708421 GPU 1 107638 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434091 (unix time) try "date -d @1749434091" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a476) received by PID 107638 (TID 0x7f4c65703740) from PID 107638 ***]


2025-06-09 09:53:55.646731 GPU 3 107680 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434091 (unix time) try "date -d @1749434091" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a4a0) received by PID 107680 (TID 0x7f41cf231740) from PID 107680 ***]


2025-06-09 09:56:20.605314 GPU 3 108526 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434234 (unix time) try "date -d @1749434234" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a7ee) received by PID 108526 (TID 0x7ffadbf32740) from PID 108526 ***]


2025-06-09 09:56:20.941924 GPU 1 108540 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434244 (unix time) try "date -d @1749434244" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a7fc) received by PID 108540 (TID 0x7f62f5a55740) from PID 108540 ***]


2025-06-09 09:57:19.037161 GPU 3 108987 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434292 (unix time) try "date -d @1749434292" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a9bb) received by PID 108987 (TID 0x7fbbf57de740) from PID 108987 ***]


2025-06-09 09:57:21.033231 GPU 0 109013 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434294 (unix time) try "date -d @1749434294" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a9d5) received by PID 109013 (TID 0x7efeff4da740) from PID 109013 ***]


2025-06-09 10:01:48.640406 GPU 0 110149 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434510 (unix time) try "date -d @1749434510" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ae45) received by PID 110149 (TID 0x7fc1fd576740) from PID 110149 ***]


2025-06-09 10:01:53.528065 GPU 0 110643 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434569 (unix time) try "date -d @1749434569" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b033) received by PID 110643 (TID 0x7f24f9902740) from PID 110643 ***]


2025-06-09 10:02:02.557494 GPU 1 110217 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434523 (unix time) try "date -d @1749434523" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ae89) received by PID 110217 (TID 0x7f3d8bfc4740) from PID 110217 ***]


2025-06-09 10:02:07.370326 GPU 1 110705 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434593 (unix time) try "date -d @1749434593" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b071) received by PID 110705 (TID 0x7f0811a06740) from PID 110705 ***]


2025-06-09 10:04:14.893608 GPU 2 111245 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434656 (unix time) try "date -d @1749434656" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b28d) received by PID 111245 (TID 0x7fcbe9c86740) from PID 111245 ***]


2025-06-09 10:04:16.128836 GPU 1 111271 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434657 (unix time) try "date -d @1749434657" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b2a7) received by PID 111271 (TID 0x7feef3de2740) from PID 111271 ***]


2025-06-09 10:04:18.126507 GPU 3 111444 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434723 (unix time) try "date -d @1749434723" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b354) received by PID 111444 (TID 0x7fe0ee522740) from PID 111444 ***]


2025-06-09 10:04:19.720855 GPU 2 111470 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434713 (unix time) try "date -d @1749434713" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b36e) received by PID 111470 (TID 0x7f8be969c740) from PID 111470 ***]


2025-06-09 10:05:15.365835 GPU 1 111499 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434717 (unix time) try "date -d @1749434717" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b38b) received by PID 111499 (TID 0x7ff742dcd740) from PID 111499 ***]


2025-06-09 10:05:16.162037 GPU 0 111527 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434717 (unix time) try "date -d @1749434717" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b3a7) received by PID 111527 (TID 0x7f1bc71e8740) from PID 111527 ***]


2025-06-09 10:06:21.796347 GPU 0 112228 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434848 (unix time) try "date -d @1749434848" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b664) received by PID 112228 (TID 0x7f7e308a7740) from PID 112228 ***]


2025-06-09 10:06:22.530356 GPU 3 112044 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434784 (unix time) try "date -d @1749434784" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b5ac) received by PID 112044 (TID 0x7fc460858740) from PID 112044 ***]


2025-06-09 10:06:40.358858 GPU 2 112118 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434802 (unix time) try "date -d @1749434802" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b5f6) received by PID 112118 (TID 0x7f4a59080740) from PID 112118 ***]


2025-06-09 10:06:45.470926 GPU 2 112338 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434859 (unix time) try "date -d @1749434859" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b6d2) received by PID 112338 (TID 0x7f660ec35740) from PID 112338 ***]


2025-06-09 10:06:50.731680 GPU 1 112373 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434863 (unix time) try "date -d @1749434863" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b6f5) received by PID 112373 (TID 0x7f13477a7740) from PID 112373 ***]


2025-06-09 10:07:34.307964 GPU 3 112270 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434855 (unix time) try "date -d @1749434855" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b68e) received by PID 112270 (TID 0x7f0130241740) from PID 112270 ***]


2025-06-09 10:07:47.684084 GPU 1 112861 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434924 (unix time) try "date -d @1749434924" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b8dd) received by PID 112861 (TID 0x7fc7c2b22740) from PID 112861 ***]


2025-06-09 10:08:00.867329 GPU 0 112921 test begin: paddle.nn.functional.interpolate(Tensor([11408507, 2, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749434935 (unix time) try "date -d @1749434935" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b919) received by PID 112921 (TID 0x7f8b77eae740) from PID 112921 ***]


2025-06-09 10:10:03.461045 GPU 0 114077 test begin: paddle.nn.functional.interpolate(Tensor([16, 160, 148549, 6],"float32"), size=list[16,12,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435068 (unix time) try "date -d @1749435068" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bd9d) received by PID 114077 (TID 0x7f0f4d22b740) from PID 114077 ***]


2025-06-09 10:10:08.369872 GPU 2 114126 test begin: paddle.nn.functional.interpolate(Tensor([16, 160, 297097, 3],"float32"), size=list[8,6,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435062 (unix time) try "date -d @1749435062" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bdce) received by PID 114126 (TID 0x7f35b2094740) from PID 114126 ***]


2025-06-09 10:10:18.836381 GPU 3 113189 test begin: paddle.nn.functional.interpolate(Tensor([16, 160, 4, 222823],"float32"), size=list[8,6,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435070 (unix time) try "date -d @1749435070" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ba25) received by PID 113189 (TID 0x7f3665eef740) from PID 113189 ***]


2025-06-09 10:11:05.791521 GPU 2 114381 test begin: paddle.nn.functional.interpolate(Tensor([16, 160, 8, 111412],"float32"), size=list[16,12,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435121 (unix time) try "date -d @1749435121" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1becd) received by PID 114381 (TID 0x7fc23a61b740) from PID 114381 ***]


2025-06-09 10:12:20.196171 GPU 3 115199 test begin: paddle.nn.functional.interpolate(Tensor([16, 356516, 20, 20],"float32"), size=list[19,19,], mode="bicubic", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435142 (unix time) try "date -d @1749435142" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c1ff) received by PID 115199 (TID 0x7f25fb820740) from PID 115199 ***]


2025-06-09 10:12:25.598007 GPU 3 115561 test begin: paddle.nn.functional.interpolate(Tensor([16, 395032, 19, 19],"float32"), size=tuple(20,20,), mode="bicubic", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435201 (unix time) try "date -d @1749435201" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c369) received by PID 115561 (TID 0x7efd98aae740) from PID 115561 ***]


2025-06-09 10:12:34.143466 GPU 2 115644 test begin: paddle.nn.functional.interpolate(Tensor([16, 40, 148549, 24],"float32"), size=list[64,48,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435207 (unix time) try "date -d @1749435207" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c3bc) received by PID 115644 (TID 0x7f6c45d28740) from PID 115644 ***]


2025-06-09 10:13:07.326325 GPU 1 115456 test begin: paddle.nn.functional.interpolate(Tensor([16, 40, 16, 222823],"float32"), size=list[32,24,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435188 (unix time) try "date -d @1749435188" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c300) received by PID 115456 (TID 0x7ff734c58740) from PID 115456 ***]


2025-06-09 10:13:21.116250 GPU 0 115533 test begin: paddle.nn.functional.interpolate(Tensor([16, 40, 297097, 12],"float32"), size=list[32,24,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435203 (unix time) try "date -d @1749435203" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c34d) received by PID 115533 (TID 0x7f1e5835d740) from PID 115533 ***]


2025-06-09 10:13:24.743350 GPU 3 116583 test begin: paddle.nn.functional.interpolate(Tensor([16, 40, 32, 111412],"float32"), size=list[64,48,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435261 (unix time) try "date -d @1749435261" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c767) received by PID 116583 (TID 0x7f12cd674740) from PID 116583 ***]


2025-06-09 10:15:24.240191 GPU 0 116627 test begin: paddle.nn.functional.interpolate(Tensor([178258, 32, 20, 20],"float32"), size=list[19,19,], mode="bicubic", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435325 (unix time) try "date -d @1749435325" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c793) received by PID 116627 (TID 0x7f86e3192740) from PID 116627 ***]


2025-06-09 10:15:36.385995 GPU 2 116663 test begin: paddle.nn.functional.interpolate(Tensor([197516, 32, 19, 19],"float32"), size=tuple(20,20,), mode="bicubic", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435337 (unix time) try "date -d @1749435337" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c7b7) received by PID 116663 (TID 0x7fbbc434b740) from PID 116663 ***]


2025-06-09 10:15:43.110450 GPU 1 118036 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 10, 2147484],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435416 (unix time) try "date -d @1749435416" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cd14) received by PID 118036 (TID 0x7f2378600740) from PID 118036 ***]


2025-06-09 10:15:56.450118 GPU 3 117081 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 10, 2147484],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435357 (unix time) try "date -d @1749435357" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c959) received by PID 117081 (TID 0x7f6c5446e740) from PID 117081 ***]


2025-06-09 10:15:58.111752 GPU 0 118132 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435433 (unix time) try "date -d @1749435433" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cd74) received by PID 118132 (TID 0x7ff1786eb740) from PID 118132 ***]


2025-06-09 10:16:29.240125 GPU 3 118292 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435451 (unix time) try "date -d @1749435451" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ce14) received by PID 118292 (TID 0x7f44fed50740) from PID 118292 ***]


2025-06-09 10:17:00.217261 GPU 1 118445 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435485 (unix time) try "date -d @1749435485" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cead) received by PID 118445 (TID 0x7fdda620e740) from PID 118445 ***]


2025-06-09 10:17:16.192768 GPU 0 119260 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749435498 (unix time) try "date -d @1749435498" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d1dc) received by PID 119260 (TID 0x7f630ca55740) from PID 119260 ***]


2025-06-09 10:28:42.266794 GPU 3 126280 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[13,2,], scale_factor=None, mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436123 (unix time) try "date -d @1749436123" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ed48) received by PID 126280 (TID 0x7f9a8fe29740) from PID 126280 ***]


2025-06-09 10:28:45.283031 GPU 1 126607 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[13,2,], scale_factor=None, mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436191 (unix time) try "date -d @1749436191" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ee8f) received by PID 126607 (TID 0x7f5017aff740) from PID 126607 ***]


2025-06-09 10:29:12.617407 GPU 2 127514 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436223 (unix time) try "date -d @1749436223" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f21a) received by PID 127514 (TID 0x7fdbfecb9740) from PID 127514 ***]


2025-06-09 10:29:54.981081 GPU 1 127716 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436259 (unix time) try "date -d @1749436259" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f2e4) received by PID 127716 (TID 0x7f37f6bf9740) from PID 127716 ***]


2025-06-09 10:30:55.559927 GPU 2 128054 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436332 (unix time) try "date -d @1749436332" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f436) received by PID 128054 (TID 0x7f0c4d17d740) from PID 128054 ***]


2025-06-09 10:31:10.852996 GPU 0 128690 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436333 (unix time) try "date -d @1749436333" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f6b2) received by PID 128690 (TID 0x7f3c75baf740) from PID 128690 ***]


2025-06-09 10:31:26.107548 GPU 3 128967 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,13,], scale_factor=None, mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436346 (unix time) try "date -d @1749436346" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f7c7) received by PID 128967 (TID 0x7f98daaeb740) from PID 128967 ***]


2025-06-09 10:31:32.099200 GPU 1 129018 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,13,], scale_factor=None, mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436354 (unix time) try "date -d @1749436354" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f7fa) received by PID 129018 (TID 0x7fd72bc46740) from PID 129018 ***]


2025-06-09 10:32:37.470639 GPU 1 129379 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436428 (unix time) try "date -d @1749436428" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f963) received by PID 129379 (TID 0x7f6474d64740) from PID 129379 ***]


2025-06-09 10:32:44.642430 GPU 2 129435 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436427 (unix time) try "date -d @1749436427" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f99b) received by PID 129435 (TID 0x7f7ab69e0740) from PID 129435 ***]


2025-06-09 10:33:23.070803 GPU 0 129228 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436404 (unix time) try "date -d @1749436404" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f8cc) received by PID 129228 (TID 0x7f6a04552740) from PID 129228 ***]


2025-06-09 10:33:50.615018 GPU 2 130449 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436492 (unix time) try "date -d @1749436492" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fd91) received by PID 130449 (TID 0x7f9e48133740) from PID 130449 ***]


2025-06-09 10:33:56.348594 GPU 0 130527 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436499 (unix time) try "date -d @1749436499" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fddf) received by PID 130527 (TID 0x7f8c7a69d740) from PID 130527 ***]


2025-06-09 10:33:58.999756 GPU 3 130565 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 21474837],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436512 (unix time) try "date -d @1749436512" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fe05) received by PID 130565 (TID 0x7f0d44902740) from PID 130565 ***]


2025-06-09 10:36:06.885927 GPU 0 1212 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 5368710, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436632 (unix time) try "date -d @1749436632" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4bc) received by PID 1212 (TID 0x7f1e64715740) from PID 1212 ***]


2025-06-09 10:36:22.615935 GPU 3 1313 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 10, 5368710, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436646 (unix time) try "date -d @1749436646" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x521) received by PID 1313 (TID 0x7f3cdb003740) from PID 1313 ***]


2025-06-09 10:36:31.954913 GPU 1 1378 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436662 (unix time) try "date -d @1749436662" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x562) received by PID 1378 (TID 0x7f46f4c59740) from PID 1378 ***]


2025-06-09 10:37:08.952568 GPU 2 1563 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436689 (unix time) try "date -d @1749436689" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x61b) received by PID 1563 (TID 0x7f514adc2740) from PID 1563 ***]


2025-06-09 10:37:29.701504 GPU 3 2417 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436714 (unix time) try "date -d @1749436714" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x971) received by PID 2417 (TID 0x7f2ded865740) from PID 2417 ***]


2025-06-09 10:37:44.615279 GPU 0 2499 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749436725 (unix time) try "date -d @1749436725" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x9c3) received by PID 2499 (TID 0x7f96c2dd6740) from PID 2499 ***]


2025-06-09 10:44:55.495178 GPU 0 6528 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437097 (unix time) try "date -d @1749437097" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1980) received by PID 6528 (TID 0x7fe143db3740) from PID 6528 ***]


2025-06-09 10:45:04.868831 GPU 2 6759 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437107 (unix time) try "date -d @1749437107" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a67) received by PID 6759 (TID 0x7f4a0bd64740) from PID 6759 ***]


2025-06-09 10:45:11.068177 GPU 2 7851 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437173 (unix time) try "date -d @1749437173" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1eab) received by PID 7851 (TID 0x7f370d03d740) from PID 7851 ***]


2025-06-09 10:45:29.744765 GPU 0 7957 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437204 (unix time) try "date -d @1749437204" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f15) received by PID 7957 (TID 0x7f651a6ef740) from PID 7957 ***]


2025-06-09 10:45:37.227166 GPU 3 6954 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437138 (unix time) try "date -d @1749437138" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b2a) received by PID 6954 (TID 0x7f6666061740) from PID 6954 ***]


2025-06-09 10:45:41.798115 GPU 1 6897 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437143 (unix time) try "date -d @1749437143" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1af1) received by PID 6897 (TID 0x7f2df5b66740) from PID 6897 ***]


2025-06-09 10:45:46.945997 GPU 1 8060 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437210 (unix time) try "date -d @1749437210" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f7c) received by PID 8060 (TID 0x7f02c7be2740) from PID 8060 ***]


2025-06-09 10:46:10.999424 GPU 3 8189 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437233 (unix time) try "date -d @1749437233" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ffd) received by PID 8189 (TID 0x7f123297e740) from PID 8189 ***]


2025-06-09 10:47:57.281292 GPU 1 8434 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437278 (unix time) try "date -d @1749437278" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20f2) received by PID 8434 (TID 0x7f0a228ea740) from PID 8434 ***]


2025-06-09 10:48:01.938092 GPU 2 8362 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437283 (unix time) try "date -d @1749437283" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20aa) received by PID 8362 (TID 0x7f90ece43740) from PID 8362 ***]


2025-06-09 10:48:06.662015 GPU 2 9547 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437351 (unix time) try "date -d @1749437351" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x254b) received by PID 9547 (TID 0x7f12fd086740) from PID 9547 ***]


2025-06-09 10:48:17.515254 GPU 0 9287 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437298 (unix time) try "date -d @1749437298" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2447) received by PID 9287 (TID 0x7f87d2143740) from PID 9287 ***]


2025-06-09 10:48:18.629698 GPU 3 9273 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437300 (unix time) try "date -d @1749437300" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2439) received by PID 9273 (TID 0x7fc5117db740) from PID 9273 ***]


2025-06-09 10:48:22.170305 GPU 0 9643 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437381 (unix time) try "date -d @1749437381" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x25ab) received by PID 9643 (TID 0x7ffbe1ca8740) from PID 9643 ***]


2025-06-09 10:48:23.103721 GPU 3 9663 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437366 (unix time) try "date -d @1749437366" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x25bf) received by PID 9663 (TID 0x7ff010337740) from PID 9663 ***]


2025-06-09 10:48:29.544323 GPU 1 9726 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437378 (unix time) try "date -d @1749437378" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x25fe) received by PID 9726 (TID 0x7fe85c8b1740) from PID 9726 ***]


2025-06-09 10:49:29.307071 GPU 3 10720 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437431 (unix time) try "date -d @1749437431" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x29e0) received by PID 10720 (TID 0x7fa64bc43740) from PID 10720 ***]


2025-06-09 10:49:41.487106 GPU 1 10798 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 107374183, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437455 (unix time) try "date -d @1749437455" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2a2e) received by PID 10798 (TID 0x7f7995b07740) from PID 10798 ***]


2025-06-09 10:49:41.890968 GPU 2 10822 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437435 (unix time) try "date -d @1749437435" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2a46) received by PID 10822 (TID 0x7f824a9bf740) from PID 10822 ***]


2025-06-09 10:49:44.916734 GPU 0 10871 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437448 (unix time) try "date -d @1749437448" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2a77) received by PID 10871 (TID 0x7f90cae54740) from PID 10871 ***]


2025-06-09 10:50:38.779972 GPU 2 11131 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437493 (unix time) try "date -d @1749437493" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2b7b) received by PID 11131 (TID 0x7f98fab1b740) from PID 11131 ***]


2025-06-09 10:50:51.891503 GPU 0 11218 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437507 (unix time) try "date -d @1749437507" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2bd2) received by PID 11218 (TID 0x7f11b5078740) from PID 11218 ***]


2025-06-09 10:50:58.280559 GPU 1 11275 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437514 (unix time) try "date -d @1749437514" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2c0b) received by PID 11275 (TID 0x7f065d00f740) from PID 11275 ***]


2025-06-09 10:51:03.753056 GPU 3 11325 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437517 (unix time) try "date -d @1749437517" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2c3d) received by PID 11325 (TID 0x7fb53e21e740) from PID 11325 ***]


2025-06-09 10:51:51.263844 GPU 0 12261 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437566 (unix time) try "date -d @1749437566" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2fe5) received by PID 12261 (TID 0x7f3a104aa740) from PID 12261 ***]


2025-06-09 10:51:57.648951 GPU 1 12320 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437574 (unix time) try "date -d @1749437574" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3020) received by PID 12320 (TID 0x7fc45646f740) from PID 12320 ***]


2025-06-09 10:52:00.978798 GPU 3 12362 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437584 (unix time) try "date -d @1749437584" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x304a) received by PID 12362 (TID 0x7f1f0b2d8740) from PID 12362 ***]


2025-06-09 10:52:05.975865 GPU 2 12418 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437588 (unix time) try "date -d @1749437588" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3082) received by PID 12418 (TID 0x7f22397b2740) from PID 12418 ***]


2025-06-09 10:52:57.782138 GPU 1 12658 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437633 (unix time) try "date -d @1749437633" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3172) received by PID 12658 (TID 0x7f484f17b740) from PID 12658 ***]


2025-06-09 10:53:08.107690 GPU 3 12731 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437644 (unix time) try "date -d @1749437644" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x31bb) received by PID 12731 (TID 0x7effa7947740) from PID 12731 ***]


2025-06-09 10:53:12.234985 GPU 2 13485 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437656 (unix time) try "date -d @1749437656" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x34ad) received by PID 13485 (TID 0x7f431f7fa740) from PID 13485 ***]


2025-06-09 10:53:18.195236 GPU 0 13534 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437651 (unix time) try "date -d @1749437651" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x34de) received by PID 13534 (TID 0x7fb7993d3740) from PID 13534 ***]


2025-06-09 10:54:07.940334 GPU 3 13779 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437705 (unix time) try "date -d @1749437705" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x35d3) received by PID 13779 (TID 0x7f84ea20e740) from PID 13779 ***]


2025-06-09 10:54:15.400070 GPU 0 13837 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437712 (unix time) try "date -d @1749437712" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x360d) received by PID 13837 (TID 0x7f83d9fcd740) from PID 13837 ***]


2025-06-09 10:55:26.919525 GPU 2 13886 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437729 (unix time) try "date -d @1749437729" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x363e) received by PID 13886 (TID 0x7f424134a740) from PID 13886 ***]


2025-06-09 10:55:29.757723 GPU 1 13942 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437731 (unix time) try "date -d @1749437731" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3676) received by PID 13942 (TID 0x7f008fed8740) from PID 13942 ***]


2025-06-09 10:55:32.736150 GPU 2 14991 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437797 (unix time) try "date -d @1749437797" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3a8f) received by PID 14991 (TID 0x7fdaa3f77740) from PID 14991 ***]


2025-06-09 10:55:35.259630 GPU 1 15031 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437789 (unix time) try "date -d @1749437789" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3ab7) received by PID 15031 (TID 0x7fd8aab16740) from PID 15031 ***]


2025-06-09 10:55:37.807926 GPU 3 15068 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437791 (unix time) try "date -d @1749437791" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3adc) received by PID 15068 (TID 0x7f66576e3740) from PID 15068 ***]


2025-06-09 10:56:13.920493 GPU 0 14887 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437775 (unix time) try "date -d @1749437775" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3a27) received by PID 14887 (TID 0x7f19ccc6f740) from PID 14887 ***]


2025-06-09 10:56:33.385492 GPU 1 15335 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437857 (unix time) try "date -d @1749437857" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3be7) received by PID 15335 (TID 0x7f2267521740) from PID 15335 ***]


2025-06-09 10:56:35.128423 GPU 3 15357 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437856 (unix time) try "date -d @1749437856" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3bfd) received by PID 15357 (TID 0x7efe7deed740) from PID 15357 ***]


2025-06-09 10:56:40.913020 GPU 2 15423 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437853 (unix time) try "date -d @1749437853" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3c3f) received by PID 15423 (TID 0x7ff353b23740) from PID 15423 ***]


2025-06-09 10:56:48.606527 GPU 0 15480 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437861 (unix time) try "date -d @1749437861" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3c78) received by PID 15480 (TID 0x7fcbb139c740) from PID 15480 ***]


2025-06-09 10:57:40.364249 GPU 3 16461 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437914 (unix time) try "date -d @1749437914" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x404d) received by PID 16461 (TID 0x7f35d3aba740) from PID 16461 ***]


2025-06-09 10:57:40.859427 GPU 1 16477 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437918 (unix time) try "date -d @1749437918" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x405d) received by PID 16477 (TID 0x7fae9a2d8740) from PID 16477 ***]


2025-06-09 10:57:45.541659 GPU 0 16533 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437921 (unix time) try "date -d @1749437921" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4095) received by PID 16533 (TID 0x7f52890f1740) from PID 16533 ***]


2025-06-09 10:58:05.964519 GPU 2 16649 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437939 (unix time) try "date -d @1749437939" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4109) received by PID 16649 (TID 0x7f4aa3510740) from PID 16649 ***]


2025-06-09 10:58:42.307488 GPU 1 16834 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437977 (unix time) try "date -d @1749437977" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x41c2) received by PID 16834 (TID 0x7f58a4277740) from PID 16834 ***]


2025-06-09 10:58:44.762944 GPU 0 16866 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437981 (unix time) try "date -d @1749437981" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x41e2) received by PID 16866 (TID 0x7f55b7ef8740) from PID 16866 ***]


2025-06-09 10:59:03.119453 GPU 2 16977 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437995 (unix time) try "date -d @1749437995" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4251) received by PID 16977 (TID 0x7ff410b50740) from PID 16977 ***]


2025-06-09 10:59:06.073778 GPU 3 17019 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749437999 (unix time) try "date -d @1749437999" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x427b) received by PID 17019 (TID 0x7f6afb5ac740) from PID 17019 ***]


2025-06-09 10:59:45.327689 GPU 0 17913 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438041 (unix time) try "date -d @1749438041" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x45f9) received by PID 17913 (TID 0x7ff1f6bbf740) from PID 17913 ***]


2025-06-09 10:59:59.267115 GPU 2 18007 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438052 (unix time) try "date -d @1749438052" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4657) received by PID 18007 (TID 0x7f801ba0e740) from PID 18007 ***]


2025-06-09 11:00:03.048514 GPU 3 18051 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438066 (unix time) try "date -d @1749438066" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4683) received by PID 18051 (TID 0x7f68342f3740) from PID 18051 ***]


2025-06-09 11:00:08.547783 GPU 1 18100 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438061 (unix time) try "date -d @1749438061" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x46b4) received by PID 18100 (TID 0x7f8be50d7740) from PID 18100 ***]


2025-06-09 11:00:56.076956 GPU 2 18326 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438110 (unix time) try "date -d @1749438110" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4796) received by PID 18326 (TID 0x7fe29dbaf740) from PID 18326 ***]


2025-06-09 11:01:05.093736 GPU 1 18393 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438129 (unix time) try "date -d @1749438129" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x47d9) received by PID 18393 (TID 0x7f159ac7c740) from PID 18393 ***]


2025-06-09 11:01:10.372816 GPU 3 18758 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438130 (unix time) try "date -d @1749438130" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4946) received by PID 18758 (TID 0x7f52c60f9740) from PID 18758 ***]


2025-06-09 11:01:12.996958 GPU 0 19202 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438134 (unix time) try "date -d @1749438134" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4b02) received by PID 19202 (TID 0x7f191c682740) from PID 19202 ***]


2025-06-09 11:02:12.966519 GPU 1 19489 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438189 (unix time) try "date -d @1749438189" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4c21) received by PID 19489 (TID 0x7f5a47bf7740) from PID 19489 ***]


2025-06-09 11:02:13.816881 GPU 3 19508 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438199 (unix time) try "date -d @1749438199" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4c34) received by PID 19508 (TID 0x7fc6976bd740) from PID 19508 ***]


2025-06-09 11:02:18.159337 GPU 0 19560 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438224 (unix time) try "date -d @1749438224" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4c68) received by PID 19560 (TID 0x7f20c45ad740) from PID 19560 ***]


2025-06-09 11:02:23.388865 GPU 2 19616 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438198 (unix time) try "date -d @1749438198" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4ca0) received by PID 19616 (TID 0x7f033cee8740) from PID 19616 ***]


2025-06-09 11:03:22.136051 GPU 2 20595 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438275 (unix time) try "date -d @1749438275" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5073) received by PID 20595 (TID 0x7f15471ae740) from PID 20595 ***]


2025-06-09 11:03:23.348073 GPU 3 20615 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749438277 (unix time) try "date -d @1749438277" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5087) received by PID 20615 (TID 0x7fbe09b3c740) from PID 20615 ***]


2025-06-09 11:19:09.696126 GPU 1 29348 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439151 (unix time) try "date -d @1749439151" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x72a4) received by PID 29348 (TID 0x7f10498be740) from PID 29348 ***]


2025-06-09 11:19:09.953176 GPU 3 29007 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439151 (unix time) try "date -d @1749439151" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x714f) received by PID 29007 (TID 0x7f6f1d59f740) from PID 29007 ***]


2025-06-09 11:19:09.992179 GPU 0 28895 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439151 (unix time) try "date -d @1749439151" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x70df) received by PID 28895 (TID 0x7fdcc7e75740) from PID 28895 ***]


2025-06-09 11:19:10.326881 GPU 2 29186 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439151 (unix time) try "date -d @1749439151" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7202) received by PID 29186 (TID 0x7fb6d6347740) from PID 29186 ***]


2025-06-09 11:19:15.223750 GPU 1 31334 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439210 (unix time) try "date -d @1749439210" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7a66) received by PID 31334 (TID 0x7f436bc6f740) from PID 31334 ***]


2025-06-09 11:19:15.694898 GPU 0 31351 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439212 (unix time) try "date -d @1749439212" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7a77) received by PID 31351 (TID 0x7fe29f4b8740) from PID 31351 ***]


2025-06-09 11:19:15.704900 GPU 2 31369 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439208 (unix time) try "date -d @1749439208" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7a89) received by PID 31369 (TID 0x7fe7d6612740) from PID 31369 ***]


2025-06-09 11:19:43.776423 GPU 3 31543 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439236 (unix time) try "date -d @1749439236" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7b37) received by PID 31543 (TID 0x7f8c70678740) from PID 31543 ***]


2025-06-09 11:20:14.482268 GPU 1 31699 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439268 (unix time) try "date -d @1749439268" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7bd3) received by PID 31699 (TID 0x7f8fa87c7740) from PID 31699 ***]


2025-06-09 11:20:15.505753 GPU 0 31719 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439271 (unix time) try "date -d @1749439271" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7be7) received by PID 31719 (TID 0x7f2f0708a740) from PID 31719 ***]


2025-06-09 11:20:39.573555 GPU 3 31863 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439291 (unix time) try "date -d @1749439291" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7c77) received by PID 31863 (TID 0x7f060e474740) from PID 31863 ***]


2025-06-09 11:20:41.216444 GPU 2 31885 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439305 (unix time) try "date -d @1749439305" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7c8d) received by PID 31885 (TID 0x7f0ac303b740) from PID 31885 ***]


2025-06-09 11:22:35.723085 GPU 1 32961 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439357 (unix time) try "date -d @1749439357" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x80c1) received by PID 32961 (TID 0x7fedf6b94740) from PID 32961 ***]


2025-06-09 11:22:36.145945 GPU 0 32794 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439358 (unix time) try "date -d @1749439358" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x801a) received by PID 32794 (TID 0x7fb134682740) from PID 32794 ***]


2025-06-09 11:22:40.757760 GPU 3 32903 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439363 (unix time) try "date -d @1749439363" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8087) received by PID 32903 (TID 0x7f551fa93740) from PID 32903 ***]


2025-06-09 11:22:42.128176 GPU 0 33270 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439417 (unix time) try "date -d @1749439417" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x81f6) received by PID 33270 (TID 0x7f47f3041740) from PID 33270 ***]


2025-06-09 11:22:42.975594 GPU 2 33018 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439365 (unix time) try "date -d @1749439365" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x80fa) received by PID 33018 (TID 0x7fb9c5979740) from PID 33018 ***]


2025-06-09 11:22:47.372652 GPU 3 33320 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439423 (unix time) try "date -d @1749439423" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8228) received by PID 33320 (TID 0x7f3d1a681740) from PID 33320 ***]


2025-06-09 11:22:48.698701 GPU 2 33346 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439424 (unix time) try "date -d @1749439424" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8242) received by PID 33346 (TID 0x7efe529ce740) from PID 33346 ***]


2025-06-09 11:23:09.311426 GPU 1 33468 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 114085069],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439443 (unix time) try "date -d @1749439443" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x82bc) received by PID 33468 (TID 0x7f51a146c740) from PID 33468 ***]


2025-06-09 11:23:46.539161 GPU 3 34360 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439491 (unix time) try "date -d @1749439491" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8638) received by PID 34360 (TID 0x7f8a1a526740) from PID 34360 ***]


2025-06-09 11:23:47.947480 GPU 2 34381 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439491 (unix time) try "date -d @1749439491" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x864d) received by PID 34381 (TID 0x7f849fbe2740) from PID 34381 ***]


2025-06-09 11:24:06.635932 GPU 1 34497 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439508 (unix time) try "date -d @1749439508" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x86c1) received by PID 34497 (TID 0x7f0a787b9740) from PID 34497 ***]


2025-06-09 11:24:10.762166 GPU 0 34539 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439524 (unix time) try "date -d @1749439524" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x86eb) received by PID 34539 (TID 0x7fca32e59740) from PID 34539 ***]


2025-06-09 11:24:54.949151 GPU 2 34756 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439560 (unix time) try "date -d @1749439560" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x87c4) received by PID 34756 (TID 0x7fa38babb740) from PID 34756 ***]


2025-06-09 11:25:11.193547 GPU 1 35557 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439574 (unix time) try "date -d @1749439574" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8ae5) received by PID 35557 (TID 0x7f2c03878740) from PID 35557 ***]


2025-06-09 11:25:23.115604 GPU 3 35637 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439592 (unix time) try "date -d @1749439592" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8b35) received by PID 35637 (TID 0x7f42fee32740) from PID 35637 ***]


2025-06-09 11:25:57.724341 GPU 0 35809 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439620 (unix time) try "date -d @1749439620" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8be1) received by PID 35809 (TID 0x7fef9c913740) from PID 35809 ***]


2025-06-09 11:26:17.599728 GPU 1 35925 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439650 (unix time) try "date -d @1749439650" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8c55) received by PID 35925 (TID 0x7f4159591740) from PID 35925 ***]


2025-06-09 11:26:33.306701 GPU 2 36019 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439667 (unix time) try "date -d @1749439667" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8cb3) received by PID 36019 (TID 0x7fbce89e3740) from PID 36019 ***]


2025-06-09 11:27:03.883302 GPU 0 36171 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439688 (unix time) try "date -d @1749439688" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8d4b) received by PID 36171 (TID 0x7f8d97a94740) from PID 36171 ***]


2025-06-09 11:27:04.749738 GPU 3 36196 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 214748365],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749439687 (unix time) try "date -d @1749439687" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8d64) received by PID 36196 (TID 0x7fb5a7081740) from PID 36196 ***]


2025-06-09 11:51:48.742720 GPU 0 53784 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 5368710, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441183 (unix time) try "date -d @1749441183" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd218) received by PID 53784 (TID 0x7efff468b740) from PID 53784 ***]


2025-06-09 11:51:50.997377 GPU 3 52618 test begin: paddle.nn.functional.interpolate(Tensor([2, 10, 5368710, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441112 (unix time) try "date -d @1749441112" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcd8a) received by PID 52618 (TID 0x7f6fe8914740) from PID 52618 ***]


2025-06-09 11:51:55.870013 GPU 3 53840 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441178 (unix time) try "date -d @1749441178" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd250) received by PID 53840 (TID 0x7f027a8dc740) from PID 53840 ***]


2025-06-09 11:52:09.994008 GPU 1 53932 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441190 (unix time) try "date -d @1749441190" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd2ac) received by PID 53932 (TID 0x7f54d1c1e740) from PID 53932 ***]


2025-06-09 11:52:24.700881 GPU 2 53636 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441146 (unix time) try "date -d @1749441146" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd184) received by PID 53636 (TID 0x7fa28f85c740) from PID 53636 ***]


2025-06-09 11:52:56.818845 GPU 2 54154 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441241 (unix time) try "date -d @1749441241" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd38a) received by PID 54154 (TID 0x7f1ae20b4740) from PID 54154 ***]


2025-06-09 11:59:28.992101 GPU 1 57909 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441570 (unix time) try "date -d @1749441570" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe235) received by PID 57909 (TID 0x7fb9c0e43740) from PID 57909 ***]


2025-06-09 11:59:33.872163 GPU 1 59195 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441638 (unix time) try "date -d @1749441638" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe73b) received by PID 59195 (TID 0x7f322a66e740) from PID 59195 ***]


2025-06-09 11:59:45.856361 GPU 0 59267 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441649 (unix time) try "date -d @1749441649" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe783) received by PID 59267 (TID 0x7ff4074ed740) from PID 59267 ***]


2025-06-09 11:59:59.624440 GPU 3 59359 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441664 (unix time) try "date -d @1749441664" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe7df) received by PID 59359 (TID 0x7f4e640ff740) from PID 59359 ***]


2025-06-09 12:00:09.955146 GPU 2 58341 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441611 (unix time) try "date -d @1749441611" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe3e5) received by PID 58341 (TID 0x7f4c6e0ba740) from PID 58341 ***]


2025-06-09 12:00:41.922693 GPU 1 59572 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[14,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441718 (unix time) try "date -d @1749441718" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe8b4) received by PID 59572 (TID 0x7f0eb5884740) from PID 59572 ***]


2025-06-09 12:00:42.814571 GPU 2 59593 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441705 (unix time) try "date -d @1749441705" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe8c9) received by PID 59593 (TID 0x7fb1d6308740) from PID 59593 ***]


2025-06-09 12:00:52.502552 GPU 0 59673 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441724 (unix time) try "date -d @1749441724" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe919) received by PID 59673 (TID 0x7f4c9b271740) from PID 59673 ***]


2025-06-09 12:02:48.437391 GPU 3 60578 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441769 (unix time) try "date -d @1749441769" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xeca2) received by PID 60578 (TID 0x7fd94da68740) from PID 60578 ***]


2025-06-09 12:03:05.001988 GPU 1 60717 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441786 (unix time) try "date -d @1749441786" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xed2d) received by PID 60717 (TID 0x7faaec6ec740) from PID 60717 ***]


2025-06-09 12:03:09.675051 GPU 1 61086 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441853 (unix time) try "date -d @1749441853" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xee9e) received by PID 61086 (TID 0x7f149c5ff740) from PID 61086 ***]


2025-06-09 12:03:11.136485 GPU 0 60775 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441792 (unix time) try "date -d @1749441792" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xed67) received by PID 60775 (TID 0x7f84de1ec740) from PID 60775 ***]


2025-06-09 12:03:15.837700 GPU 0 61846 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441866 (unix time) try "date -d @1749441866" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf196) received by PID 61846 (TID 0x7f605a3ce740) from PID 61846 ***]


2025-06-09 12:03:20.512418 GPU 3 61896 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441861 (unix time) try "date -d @1749441861" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf1c8) received by PID 61896 (TID 0x7f62b43bc740) from PID 61896 ***]


2025-06-09 12:03:20.983840 GPU 2 60846 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441802 (unix time) try "date -d @1749441802" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xedae) received by PID 60846 (TID 0x7fc7698ea740) from PID 60846 ***]


2025-06-09 12:03:25.855446 GPU 2 61946 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441876 (unix time) try "date -d @1749441876" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf1fa) received by PID 61946 (TID 0x7f11dfcca740) from PID 61946 ***]


2025-06-09 12:04:24.542057 GPU 3 62228 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441928 (unix time) try "date -d @1749441928" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf314) received by PID 62228 (TID 0x7f2196c0a740) from PID 62228 ***]


2025-06-09 12:04:30.222738 GPU 0 62278 test begin: paddle.nn.functional.interpolate(Tensor([2, 107374183, 10, 2],"float16"), size=list[26,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441934 (unix time) try "date -d @1749441934" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf346) received by PID 62278 (TID 0x7fbd777b1740) from PID 62278 ***]


2025-06-09 12:05:38.726892 GPU 1 62400 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441940 (unix time) try "date -d @1749441940" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf3c0) received by PID 62400 (TID 0x7f91d1c97740) from PID 62400 ***]


2025-06-09 12:05:43.938413 GPU 1 63411 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441999 (unix time) try "date -d @1749441999" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf7b3) received by PID 63411 (TID 0x7f8964e6d740) from PID 63411 ***]


2025-06-09 12:05:55.371222 GPU 2 63489 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442019 (unix time) try "date -d @1749442019" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf801) received by PID 63489 (TID 0x7f3251cc2740) from PID 63489 ***]


2025-06-09 12:06:00.996318 GPU 3 63540 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442014 (unix time) try "date -d @1749442014" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf834) received by PID 63540 (TID 0x7f4c92272740) from PID 63540 ***]


2025-06-09 12:06:33.706252 GPU 0 63355 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749441996 (unix time) try "date -d @1749441996" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf77b) received by PID 63355 (TID 0x7f17e14d8740) from PID 63355 ***]


2025-06-09 12:06:43.204926 GPU 1 63745 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442056 (unix time) try "date -d @1749442056" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf901) received by PID 63745 (TID 0x7fa0b268c740) from PID 63745 ***]


2025-06-09 12:06:58.559372 GPU 3 63839 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442073 (unix time) try "date -d @1749442073" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf95f) received by PID 63839 (TID 0x7fe1fa5a9740) from PID 63839 ***]


2025-06-09 12:07:02.698405 GPU 2 63889 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442085 (unix time) try "date -d @1749442085" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf991) received by PID 63889 (TID 0x7f6a5af0f740) from PID 63889 ***]


2025-06-09 12:07:08.119170 GPU 0 63938 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442081 (unix time) try "date -d @1749442081" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf9c2) received by PID 63938 (TID 0x7f41eb36a740) from PID 63938 ***]


2025-06-09 12:07:57.108207 GPU 3 64891 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442131 (unix time) try "date -d @1749442131" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfd7b) received by PID 64891 (TID 0x7f782c771740) from PID 64891 ***]


2025-06-09 12:10:32.619094 GPU 0 66512 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442288 (unix time) try "date -d @1749442288" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x103d0) received by PID 66512 (TID 0x7f3275d55740) from PID 66512 ***]


2025-06-09 12:10:53.028611 GPU 1 66627 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442308 (unix time) try "date -d @1749442308" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10443) received by PID 66627 (TID 0x7f1b176bd740) from PID 66627 ***]


2025-06-09 12:11:03.639280 GPU 2 66698 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442317 (unix time) try "date -d @1749442317" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1048a) received by PID 66698 (TID 0x7f5e81923740) from PID 66698 ***]


2025-06-09 12:11:31.751811 GPU 0 67553 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442347 (unix time) try "date -d @1749442347" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x107e1) received by PID 67553 (TID 0x7f520fb8d740) from PID 67553 ***]


2025-06-09 12:16:01.367597 GPU 2 70524 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442615 (unix time) try "date -d @1749442615" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1137c) received by PID 70524 (TID 0x7fab537f7740) from PID 70524 ***]


2025-06-09 12:16:01.735535 GPU 3 69464 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442563 (unix time) try "date -d @1749442563" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10f58) received by PID 69464 (TID 0x7fd98d36e740) from PID 69464 ***]


2025-06-09 12:16:06.661412 GPU 3 70574 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442622 (unix time) try "date -d @1749442622" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x113ae) received by PID 70574 (TID 0x7fc9ad8a4740) from PID 70574 ***]


2025-06-09 12:16:20.966886 GPU 0 70356 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442582 (unix time) try "date -d @1749442582" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x112d4) received by PID 70356 (TID 0x7fa30b93d740) from PID 70356 ***]


2025-06-09 12:18:40.245064 GPU 0 71790 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442721 (unix time) try "date -d @1749442721" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1186e) received by PID 71790 (TID 0x7fee9d432740) from PID 71790 ***]


2025-06-09 12:19:02.551701 GPU 1 71919 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442744 (unix time) try "date -d @1749442744" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x118ef) received by PID 71919 (TID 0x7ff0be745740) from PID 71919 ***]


2025-06-09 12:19:08.728668 GPU 1 72302 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442812 (unix time) try "date -d @1749442812" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11a6e) received by PID 72302 (TID 0x7f5b82ab6740) from PID 72302 ***]


2025-06-09 12:19:12.951460 GPU 0 73057 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442806 (unix time) try "date -d @1749442806" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11d61) received by PID 73057 (TID 0x7feb368f0740) from PID 73057 ***]


2025-06-09 12:19:31.138089 GPU 3 72131 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442772 (unix time) try "date -d @1749442772" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x119c3) received by PID 72131 (TID 0x7f1e3e01f740) from PID 72131 ***]


2025-06-09 12:19:31.401298 GPU 2 72057 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442773 (unix time) try "date -d @1749442773" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11979) received by PID 72057 (TID 0x7f05827ff740) from PID 72057 ***]


2025-06-09 12:20:38.529647 GPU 0 73555 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442892 (unix time) try "date -d @1749442892" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11f53) received by PID 73555 (TID 0x7f2035559740) from PID 73555 ***]


2025-06-09 12:21:13.129416 GPU 1 73411 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442874 (unix time) try "date -d @1749442874" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11ec3) received by PID 73411 (TID 0x7f592e198740) from PID 73411 ***]


2025-06-09 12:21:29.284894 GPU 2 73512 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442890 (unix time) try "date -d @1749442890" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11f28) received by PID 73512 (TID 0x7fab7cd62740) from PID 73512 ***]


2025-06-09 12:21:34.327949 GPU 2 74565 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442958 (unix time) try "date -d @1749442958" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12345) received by PID 74565 (TID 0x7f3fa0131740) from PID 74565 ***]


2025-06-09 12:21:36.491399 GPU 0 74596 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442949 (unix time) try "date -d @1749442949" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12364) received by PID 74596 (TID 0x7f696f2e1740) from PID 74596 ***]


2025-06-09 12:21:39.827634 GPU 3 74645 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749442954 (unix time) try "date -d @1749442954" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12395) received by PID 74645 (TID 0x7f1afd1ac740) from PID 74645 ***]


2025-06-09 12:22:38.300959 GPU 3 74945 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443021 (unix time) try "date -d @1749443021" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x124c1) received by PID 74945 (TID 0x7f7e812de740) from PID 74945 ***]


2025-06-09 12:22:41.728094 GPU 2 74987 test begin: paddle.nn.functional.interpolate(Tensor([2, 11408507, 10, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443024 (unix time) try "date -d @1749443024" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x124eb) received by PID 74987 (TID 0x7f4df0ece740) from PID 74987 ***]


2025-06-09 12:23:46.323584 GPU 1 76041 test begin: paddle.nn.functional.interpolate(Tensor([2, 1140851, 10, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443112 (unix time) try "date -d @1749443112" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12909) received by PID 76041 (TID 0x7f31a0e39740) from PID 76041 ***]


2025-06-09 12:23:48.224907 GPU 2 76082 test begin: paddle.nn.functional.interpolate(Tensor([2, 1140851, 10, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443082 (unix time) try "date -d @1749443082" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12932) received by PID 76082 (TID 0x7f4957113740) from PID 76082 ***]


2025-06-09 12:24:02.370884 GPU 0 76179 test begin: paddle.nn.functional.interpolate(Tensor([2, 1140851, 10, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443096 (unix time) try "date -d @1749443096" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12993) received by PID 76179 (TID 0x7f3e2e4b4740) from PID 76179 ***]


2025-06-09 12:24:52.628263 GPU 3 76418 test begin: paddle.nn.functional.interpolate(Tensor([2, 1140851, 10, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443156 (unix time) try "date -d @1749443156" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12a82) received by PID 76418 (TID 0x7f83ef119740) from PID 76418 ***]


2025-06-09 12:26:12.971134 GPU 2 77605 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443227 (unix time) try "date -d @1749443227" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12f25) received by PID 77605 (TID 0x7f79a7e04740) from PID 77605 ***]


2025-06-09 12:26:27.788339 GPU 0 77697 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443251 (unix time) try "date -d @1749443251" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12f81) received by PID 77697 (TID 0x7f8a9f5bd740) from PID 77697 ***]


2025-06-09 12:26:39.194718 GPU 1 77429 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443200 (unix time) try "date -d @1749443200" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12e75) received by PID 77429 (TID 0x7f41461e7740) from PID 77429 ***]


2025-06-09 12:26:56.157499 GPU 3 77517 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443217 (unix time) try "date -d @1749443217" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12ecd) received by PID 77517 (TID 0x7f12f2625740) from PID 77517 ***]


2025-06-09 12:27:01.424265 GPU 3 77864 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443276 (unix time) try "date -d @1749443276" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13028) received by PID 77864 (TID 0x7f7bb35fc740) from PID 77864 ***]


2025-06-09 12:27:11.595128 GPU 2 78640 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443286 (unix time) try "date -d @1749443286" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13330) received by PID 78640 (TID 0x7f3337e67740) from PID 78640 ***]


2025-06-09 12:27:14.105256 GPU 1 78682 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443287 (unix time) try "date -d @1749443287" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1335a) received by PID 78682 (TID 0x7f0283f2b740) from PID 78682 ***]


2025-06-09 12:28:00.168944 GPU 3 78905 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443344 (unix time) try "date -d @1749443344" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13439) received by PID 78905 (TID 0x7fe35f833740) from PID 78905 ***]


2025-06-09 12:28:05.230716 GPU 0 78950 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443338 (unix time) try "date -d @1749443338" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13466) received by PID 78950 (TID 0x7efdc0384740) from PID 78950 ***]


2025-06-09 12:28:09.974353 GPU 2 79006 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443355 (unix time) try "date -d @1749443355" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1349e) received by PID 79006 (TID 0x7f4c478e5740) from PID 79006 ***]


2025-06-09 12:31:05.232167 GPU 1 80698 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443529 (unix time) try "date -d @1749443529" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13b3a) received by PID 80698 (TID 0x7f16434a1740) from PID 80698 ***]


2025-06-09 12:31:08.922448 GPU 0 80741 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443524 (unix time) try "date -d @1749443524" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13b65) received by PID 80741 (TID 0x7f2d2a731740) from PID 80741 ***]


2025-06-09 12:31:17.110282 GPU 2 81513 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 12:32:08.467310 GPU 0 81751 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 12:34:33.370254 GPU 1 83028 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443674 (unix time) try "date -d @1749443674" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14454) received by PID 83028 (TID 0x7efd188c8740) from PID 83028 ***]


2025-06-09 12:34:38.379542 GPU 1 83374 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443740 (unix time) try "date -d @1749443740" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x145ae) received by PID 83374 (TID 0x7f5e94c00740) from PID 83374 ***]


2025-06-09 12:34:44.914180 GPU 2 83430 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443748 (unix time) try "date -d @1749443748" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x145e6) received by PID 83430 (TID 0x7f00bf10f740) from PID 83430 ***]


2025-06-09 12:35:15.330552 GPU 3 83237 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443716 (unix time) try "date -d @1749443716" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14525) received by PID 83237 (TID 0x7f84ead49740) from PID 83237 ***]


2025-06-09 12:35:44.500111 GPU 0 83281 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443746 (unix time) try "date -d @1749443746" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14551) received by PID 83281 (TID 0x7f59b66c7740) from PID 83281 ***]


2025-06-09 12:35:47.132299 GPU 3 84460 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443810 (unix time) try "date -d @1749443810" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x149ec) received by PID 84460 (TID 0x7fe4c59b0740) from PID 84460 ***]


2025-06-09 12:36:36.811296 GPU 1 84417 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443798 (unix time) try "date -d @1749443798" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x149c1) received by PID 84417 (TID 0x7f30c7b0c740) from PID 84417 ***]


2025-06-09 12:36:42.246854 GPU 0 84481 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443803 (unix time) try "date -d @1749443803" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14a01) received by PID 84481 (TID 0x7f97fd79b740) from PID 84481 ***]


2025-06-09 12:36:47.815840 GPU 0 84793 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443864 (unix time) try "date -d @1749443864" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14b39) received by PID 84793 (TID 0x7f9bbeb06740) from PID 84793 ***]


2025-06-09 12:36:49.363947 GPU 2 84532 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[13,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443810 (unix time) try "date -d @1749443810" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14a34) received by PID 84532 (TID 0x7fbd8e508740) from PID 84532 ***]


2025-06-09 12:37:50.775247 GPU 3 84865 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443872 (unix time) try "date -d @1749443872" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14b81) received by PID 84865 (TID 0x7fdc0db06740) from PID 84865 ***]


2025-06-09 12:37:58.652130 GPU 2 84851 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443880 (unix time) try "date -d @1749443880" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14b73) received by PID 84851 (TID 0x7f4302b69740) from PID 84851 ***]


2025-06-09 12:38:03.440498 GPU 1 84965 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443884 (unix time) try "date -d @1749443884" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14be5) received by PID 84965 (TID 0x7ff83d97a740) from PID 84965 ***]


2025-06-09 12:38:03.707431 GPU 2 85964 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443938 (unix time) try "date -d @1749443938" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14fcc) received by PID 85964 (TID 0x7f2ff1279740) from PID 85964 ***]


2025-06-09 12:38:08.342921 GPU 1 86013 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443943 (unix time) try "date -d @1749443943" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14ffd) received by PID 86013 (TID 0x7f48f0ab4740) from PID 86013 ***]


2025-06-09 12:38:16.255863 GPU 0 86077 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443950 (unix time) try "date -d @1749443950" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1503d) received by PID 86077 (TID 0x7f5a224b3740) from PID 86077 ***]


2025-06-09 12:38:50.788244 GPU 3 85904 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443932 (unix time) try "date -d @1749443932" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14f90) received by PID 85904 (TID 0x7f341f435740) from PID 85904 ***]


2025-06-09 12:39:03.055977 GPU 2 86303 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749443997 (unix time) try "date -d @1749443997" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1511f) received by PID 86303 (TID 0x7fd0ee3ba740) from PID 86303 ***]


2025-06-09 12:39:07.184976 GPU 1 86345 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 10, 57042535],"float32"), size=list[24,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444002 (unix time) try "date -d @1749444002" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15149) received by PID 86345 (TID 0x7fc8b8af1740) from PID 86345 ***]


2025-06-09 12:39:14.303126 GPU 0 87108 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 214748365, 5],"float16"), size=list[10,11,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444017 (unix time) try "date -d @1749444017" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15444) received by PID 87108 (TID 0x7fe0eeeda740) from PID 87108 ***]


2025-06-09 12:39:23.432017 GPU 3 87179 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 4, 268435457],"float16"), size=list[10,11,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444025 (unix time) try "date -d @1749444025" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1548b) received by PID 87179 (TID 0x7fac57289740) from PID 87179 ***]


2025-06-09 12:40:28.893123 GPU 3 87528 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444083 (unix time) try "date -d @1749444083" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x155e8) received by PID 87528 (TID 0x7f74aaa73740) from PID 87528 ***]


2025-06-09 12:40:30.598249 GPU 2 87548 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444094 (unix time) try "date -d @1749444094" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x155fc) received by PID 87548 (TID 0x7f11cedcc740) from PID 87548 ***]


2025-06-09 12:41:02.174843 GPU 1 87375 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444063 (unix time) try "date -d @1749444063" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1554f) received by PID 87375 (TID 0x7f11a75cd740) from PID 87375 ***]


2025-06-09 12:41:16.791290 GPU 0 87468 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444078 (unix time) try "date -d @1749444078" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x155ac) received by PID 87468 (TID 0x7f12d0d5a740) from PID 87468 ***]


2025-06-09 12:41:21.829684 GPU 0 88516 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 12:41:27.012849 GPU 3 88566 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,1.7999999999999998,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 12:41:35.651744 GPU 1 88624 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444149 (unix time) try "date -d @1749444149" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15a30) received by PID 88624 (TID 0x7f8573af1740) from PID 88624 ***]


2025-06-09 12:41:37.902253 GPU 2 88659 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444159 (unix time) try "date -d @1749444159" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15a53) received by PID 88659 (TID 0x7fce9727e740) from PID 88659 ***]


2025-06-09 12:42:17.971033 GPU 0 88516 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444140 (unix time) try "date -d @1749444140" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x159c4) received by PID 88516 (TID 0x7f6dfb14b740) from PID 88516 ***]


2025-06-09 12:42:23.372987 GPU 3 88566 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[0.6,2.9999999999999996,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444145 (unix time) try "date -d @1749444145" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x159f6) received by PID 88566 (TID 0x7f6536e21740) from PID 88566 ***]


2025-06-09 12:44:56.152989 GPU 3 90470 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444359 (unix time) try "date -d @1749444359" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16166) received by PID 90470 (TID 0x7f46d7a00740) from PID 90470 ***]


2025-06-09 12:44:57.203665 GPU 2 90498 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444359 (unix time) try "date -d @1749444359" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16182) received by PID 90498 (TID 0x7f441ffde740) from PID 90498 ***]


2025-06-09 12:44:58.090059 GPU 0 90518 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 12:45:00.774769 GPU 1 90575 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
[cuda error] paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[1.7999999999999998,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 12:47:19.578844 GPU 2 91610 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444440 (unix time) try "date -d @1749444440" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x165da) received by PID 91610 (TID 0x7fc062a97740) from PID 91610 ***]


2025-06-09 12:47:22.576165 GPU 0 91758 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444445 (unix time) try "date -d @1749444445" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1666e) received by PID 91758 (TID 0x7fa2d9e3e740) from PID 91758 ***]


2025-06-09 12:47:24.784023 GPU 2 92719 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444507 (unix time) try "date -d @1749444507" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16a2f) received by PID 92719 (TID 0x7fa75ba6d740) from PID 92719 ***]


2025-06-09 12:47:26.888335 GPU 3 92753 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=None, scale_factor=list[2.9999999999999996,0.6,], mode="bilinear", align_corners=True, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444499 (unix time) try "date -d @1749444499" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16a51) received by PID 92753 (TID 0x7f3572c9f740) from PID 92753 ***]


2025-06-09 12:48:33.089868 GPU 1 92822 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444514 (unix time) try "date -d @1749444514" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16a96) received by PID 92822 (TID 0x7f5971559740) from PID 92822 ***]


2025-06-09 12:48:33.669131 GPU 0 92792 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444515 (unix time) try "date -d @1749444515" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16a78) received by PID 92792 (TID 0x7f69a16ad740) from PID 92792 ***]


2025-06-09 12:48:52.244836 GPU 3 93294 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444586 (unix time) try "date -d @1749444586" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16c6e) received by PID 93294 (TID 0x7ff76501a740) from PID 93294 ***]


2025-06-09 12:49:32.860428 GPU 1 93179 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444574 (unix time) try "date -d @1749444574" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16bfb) received by PID 93179 (TID 0x7f8dd8313740) from PID 93179 ***]


2025-06-09 12:49:33.974220 GPU 0 93199 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444575 (unix time) try "date -d @1749444575" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16c0f) received by PID 93199 (TID 0x7ff46d285740) from PID 93199 ***]


2025-06-09 12:49:34.837273 GPU 2 93116 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[13,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444576 (unix time) try "date -d @1749444576" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16bbc) received by PID 93116 (TID 0x7f949d014740) from PID 93116 ***]


2025-06-09 12:50:08.010699 GPU 1 94418 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[2,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444662 (unix time) try "date -d @1749444662" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x170d2) received by PID 94418 (TID 0x7f0bf3817740) from PID 94418 ***]


2025-06-09 12:50:45.811800 GPU 3 94316 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444647 (unix time) try "date -d @1749444647" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1706c) received by PID 94316 (TID 0x7f2b1172e740) from PID 94316 ***]


2025-06-09 12:50:48.218718 GPU 0 94216 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[2,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444649 (unix time) try "date -d @1749444649" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17008) received by PID 94216 (TID 0x7f8c9bc35740) from PID 94216 ***]


2025-06-09 12:50:53.383342 GPU 0 94636 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444707 (unix time) try "date -d @1749444707" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x171ac) received by PID 94636 (TID 0x7f6ed337e740) from PID 94636 ***]


2025-06-09 12:51:06.359751 GPU 1 94717 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,13,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444722 (unix time) try "date -d @1749444722" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x171fd) received by PID 94717 (TID 0x7fbc32f50740) from PID 94717 ***]


2025-06-09 12:51:07.017246 GPU 2 94230 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444668 (unix time) try "date -d @1749444668" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17016) received by PID 94230 (TID 0x7f965738d740) from PID 94230 ***]


2025-06-09 12:51:12.117870 GPU 2 95477 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444728 (unix time) try "date -d @1749444728" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x174f5) received by PID 95477 (TID 0x7f6468a61740) from PID 95477 ***]


2025-06-09 12:51:20.486086 GPU 3 95539 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,24,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444734 (unix time) try "date -d @1749444734" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17533) received by PID 95539 (TID 0x7f2b9f1a3740) from PID 95539 ***]


2025-06-09 12:52:06.329764 GPU 1 95754 test begin: paddle.nn.functional.interpolate(Tensor([2, 2, 57042535, 10],"float32"), size=list[24,24,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444782 (unix time) try "date -d @1749444782" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1760a) received by PID 95754 (TID 0x7f1d1d108740) from PID 95754 ***]


2025-06-09 12:53:15.990927 GPU 3 96906 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444853 (unix time) try "date -d @1749444853" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17a8a) received by PID 96906 (TID 0x7f4f30eea740) from PID 96906 ***]


2025-06-09 12:53:19.395937 GPU 2 96948 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444855 (unix time) try "date -d @1749444855" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17ab4) received by PID 96948 (TID 0x7f5e8cab6740) from PID 96948 ***]


2025-06-09 12:53:26.699995 GPU 0 97007 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444870 (unix time) try "date -d @1749444870" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17aef) received by PID 97007 (TID 0x7ff25c57f740) from PID 97007 ***]


2025-06-09 12:53:32.683967 GPU 1 97064 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444875 (unix time) try "date -d @1749444875" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17b28) received by PID 97064 (TID 0x7f3f1b817740) from PID 97064 ***]


2025-06-09 12:54:19.604581 GPU 2 97287 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444912 (unix time) try "date -d @1749444912" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c07) received by PID 97287 (TID 0x7f3b4783e740) from PID 97287 ***]


2025-06-09 12:54:33.811825 GPU 0 97376 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444930 (unix time) try "date -d @1749444930" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c60) received by PID 97376 (TID 0x7fbec4a34740) from PID 97376 ***]


2025-06-09 12:54:38.768047 GPU 1 97422 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444942 (unix time) try "date -d @1749444942" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17c8e) received by PID 97422 (TID 0x7f383e5d6740) from PID 97422 ***]


2025-06-09 12:54:45.018758 GPU 3 97475 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444939 (unix time) try "date -d @1749444939" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17cc3) received by PID 97475 (TID 0x7f8ce9e91740) from PID 97475 ***]


2025-06-09 12:55:34.531892 GPU 0 98423 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444990 (unix time) try "date -d @1749444990" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18077) received by PID 98423 (TID 0x7fcfd53ce740) from PID 98423 ***]


2025-06-09 12:55:43.425817 GPU 3 98490 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444997 (unix time) try "date -d @1749444997" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x180ba) received by PID 98490 (TID 0x7f9770b13740) from PID 98490 ***]


2025-06-09 12:55:44.806091 GPU 2 98516 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749444997 (unix time) try "date -d @1749444997" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x180d4) received by PID 98516 (TID 0x7f033544c740) from PID 98516 ***]


2025-06-09 12:55:45.516395 GPU 1 98534 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445008 (unix time) try "date -d @1749445008" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x180e6) received by PID 98534 (TID 0x7fad4a565740) from PID 98534 ***]


2025-06-09 12:56:41.353569 GPU 3 98815 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445057 (unix time) try "date -d @1749445057" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x181ff) received by PID 98815 (TID 0x7fd820b4c740) from PID 98815 ***]


2025-06-09 12:56:41.376910 GPU 2 98829 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445058 (unix time) try "date -d @1749445058" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1820d) received by PID 98829 (TID 0x7f257ba31740) from PID 98829 ***]


2025-06-09 12:56:52.194862 GPU 1 98916 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445084 (unix time) try "date -d @1749445084" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18264) received by PID 98916 (TID 0x7f6231528740) from PID 98916 ***]


2025-06-09 12:57:02.680482 GPU 0 98989 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445077 (unix time) try "date -d @1749445077" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x182ad) received by PID 98989 (TID 0x7f485bd45740) from PID 98989 ***]


2025-06-09 12:57:42.047896 GPU 2 99880 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.9999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445115 (unix time) try "date -d @1749445115" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18628) received by PID 99880 (TID 0x7fb475e69740) from PID 99880 ***]


2025-06-09 12:58:01.545098 GPU 0 99996 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.9999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445146 (unix time) try "date -d @1749445146" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1869c) received by PID 99996 (TID 0x7f2afb82c740) from PID 99996 ***]


2025-06-09 12:58:07.943038 GPU 1 100047 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.9999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445142 (unix time) try "date -d @1749445142" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x186cf) received by PID 100047 (TID 0x7f86495fe740) from PID 100047 ***]


2025-06-09 12:58:10.388900 GPU 3 100081 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[0.9999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445153 (unix time) try "date -d @1749445153" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x186f1) received by PID 100081 (TID 0x7facd97e0740) from PID 100081 ***]


2025-06-09 12:59:05.456670 GPU 1 100343 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445198 (unix time) try "date -d @1749445198" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x187f7) received by PID 100343 (TID 0x7f1fb1a17740) from PID 100343 ***]


2025-06-09 12:59:07.409961 GPU 2 100372 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445211 (unix time) try "date -d @1749445211" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18814) received by PID 100372 (TID 0x7fe206e5b740) from PID 100372 ***]


2025-06-09 12:59:10.094514 GPU 0 100733 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445213 (unix time) try "date -d @1749445213" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1897d) received by PID 100733 (TID 0x7f436c677740) from PID 100733 ***]


2025-06-09 12:59:17.446132 GPU 3 101202 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445211 (unix time) try "date -d @1749445211" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18b52) received by PID 101202 (TID 0x7f01be09d740) from PID 101202 ***]


2025-06-09 13:00:14.738047 GPU 2 101482 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445269 (unix time) try "date -d @1749445269" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18c6a) received by PID 101482 (TID 0x7fca5c3ff740) from PID 101482 ***]


2025-06-09 13:00:14.747361 GPU 3 101468 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445269 (unix time) try "date -d @1749445269" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18c5c) received by PID 101468 (TID 0x7fc9cf7f0740) from PID 101468 ***]


2025-06-09 13:00:17.616830 GPU 0 101539 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445273 (unix time) try "date -d @1749445273" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18ca3) received by PID 101539 (TID 0x7f8a57a74740) from PID 101539 ***]


2025-06-09 13:00:29.812730 GPU 1 101610 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445284 (unix time) try "date -d @1749445284" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18cea) received by PID 101610 (TID 0x7f57bd07c740) from PID 101610 ***]


2025-06-09 13:01:13.377781 GPU 3 102542 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445326 (unix time) try "date -d @1749445326" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1908e) received by PID 102542 (TID 0x7f98af639740) from PID 102542 ***]


2025-06-09 13:01:16.921156 GPU 0 102584 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445357 (unix time) try "date -d @1749445357" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x190b8) received by PID 102584 (TID 0x7f782a834740) from PID 102584 ***]


2025-06-09 13:01:27.629104 GPU 1 102657 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445367 (unix time) try "date -d @1749445367" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19101) received by PID 102657 (TID 0x7f2e45d03740) from PID 102657 ***]


2025-06-09 13:01:42.604132 GPU 2 102762 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445361 (unix time) try "date -d @1749445361" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1916a) received by PID 102762 (TID 0x7ff6dbdf6740) from PID 102762 ***]


2025-06-09 13:02:39.351463 GPU 3 103183 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445412 (unix time) try "date -d @1749445412" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1930f) received by PID 103183 (TID 0x7f3addf38740) from PID 103183 ***]


2025-06-09 13:02:45.418549 GPU 2 103231 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445428 (unix time) try "date -d @1749445428" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1933f) received by PID 103231 (TID 0x7fe2a4ecf740) from PID 103231 ***]


2025-06-09 13:02:51.183146 GPU 1 103311 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445429 (unix time) try "date -d @1749445429" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1938f) received by PID 103311 (TID 0x7f95e7d21740) from PID 103311 ***]


2025-06-09 13:03:10.558094 GPU 0 103721 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445443 (unix time) try "date -d @1749445443" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19529) received by PID 103721 (TID 0x7f1b0c7b9740) from PID 103721 ***]


2025-06-09 13:03:52.320434 GPU 2 104337 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445485 (unix time) try "date -d @1749445485" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19791) received by PID 104337 (TID 0x7febe48fe740) from PID 104337 ***]


2025-06-09 13:03:53.538908 GPU 1 104358 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445489 (unix time) try "date -d @1749445489" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x197a6) received by PID 104358 (TID 0x7fed4dc8b740) from PID 104358 ***]


2025-06-09 13:04:04.107770 GPU 3 104438 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445507 (unix time) try "date -d @1749445507" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x197f6) received by PID 104438 (TID 0x7f251cfc4740) from PID 104438 ***]


2025-06-09 13:04:35.650084 GPU 0 104601 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445528 (unix time) try "date -d @1749445528" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19899) received by PID 104601 (TID 0x7f5aec018740) from PID 104601 ***]


2025-06-09 13:04:52.945457 GPU 1 104699 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445548 (unix time) try "date -d @1749445548" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x198fb) received by PID 104699 (TID 0x7fc7a4b80740) from PID 104699 ***]


2025-06-09 13:05:10.807112 GPU 3 105110 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445573 (unix time) try "date -d @1749445573" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19a96) received by PID 105110 (TID 0x7fa7be694740) from PID 105110 ***]


2025-06-09 13:05:17.437722 GPU 2 105564 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445570 (unix time) try "date -d @1749445570" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19c5c) received by PID 105564 (TID 0x7f78cc409740) from PID 105564 ***]


2025-06-09 13:05:51.908856 GPU 1 105737 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445616 (unix time) try "date -d @1749445616" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19d09) received by PID 105737 (TID 0x7fc369fb0740) from PID 105737 ***]


2025-06-09 13:05:58.995664 GPU 0 105794 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445612 (unix time) try "date -d @1749445612" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19d42) received by PID 105794 (TID 0x7fd15c59a740) from PID 105794 ***]


2025-06-09 13:06:17.345285 GPU 3 105904 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445630 (unix time) try "date -d @1749445630" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19db0) received by PID 105904 (TID 0x7feaee6c8740) from PID 105904 ***]


2025-06-09 13:06:42.889817 GPU 2 106034 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445657 (unix time) try "date -d @1749445657" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19e32) received by PID 106034 (TID 0x7f01bf5ae740) from PID 106034 ***]


2025-06-09 13:06:59.539242 GPU 1 106134 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445674 (unix time) try "date -d @1749445674" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x19e96) received by PID 106134 (TID 0x7fe37aac8740) from PID 106134 ***]


2025-06-09 13:07:14.321541 GPU 3 106932 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445687 (unix time) try "date -d @1749445687" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a1b4) received by PID 106932 (TID 0x7f9bbacb4740) from PID 106932 ***]


2025-06-09 13:07:24.862038 GPU 0 107003 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445699 (unix time) try "date -d @1749445699" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a1fb) received by PID 107003 (TID 0x7f214c2e0740) from PID 107003 ***]


2025-06-09 13:07:58.403061 GPU 1 107165 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445734 (unix time) try "date -d @1749445734" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a29d) received by PID 107165 (TID 0x7fc8e6aa9740) from PID 107165 ***]


2025-06-09 13:08:09.795153 GPU 2 107243 test begin: paddle.nn.functional.interpolate(Tensor([2, 285212673, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749445756 (unix time) try "date -d @1749445756" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a2eb) received by PID 107243 (TID 0x7f43cdbb6740) from PID 107243 ***]


2025-06-09 13:23:40.381460 GPU 1 116925 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446622 (unix time) try "date -d @1749446622" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c8bd) received by PID 116925 (TID 0x7f6ddcda1740) from PID 116925 ***]


2025-06-09 13:23:41.509216 GPU 0 116008 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446623 (unix time) try "date -d @1749446623" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c528) received by PID 116008 (TID 0x7effd8167740) from PID 116008 ***]


2025-06-09 13:23:46.870009 GPU 0 118226 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446679 (unix time) try "date -d @1749446679" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cdd2) received by PID 118226 (TID 0x7fa55fe46740) from PID 118226 ***]


2025-06-09 13:24:14.260849 GPU 1 118363 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 10, 2852127],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446707 (unix time) try "date -d @1749446707" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ce5b) received by PID 118363 (TID 0x7fa4a6a6d740) from PID 118363 ***]


2025-06-09 13:24:39.844134 GPU 3 116398 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446681 (unix time) try "date -d @1749446681" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c6ae) received by PID 116398 (TID 0x7fd0e77c5740) from PID 116398 ***]


2025-06-09 13:24:41.832454 GPU 2 115771 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446683 (unix time) try "date -d @1749446683" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c43b) received by PID 115771 (TID 0x7f5401a91740) from PID 115771 ***]


2025-06-09 13:24:45.347329 GPU 3 118521 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446739 (unix time) try "date -d @1749446739" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cef9) received by PID 118521 (TID 0x7f26fcbfe740) from PID 118521 ***]


2025-06-09 13:24:47.171998 GPU 2 118549 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 10, 2852127, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446742 (unix time) try "date -d @1749446742" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cf15) received by PID 118549 (TID 0x7fb262f2f740) from PID 118549 ***]


2025-06-09 13:25:10.768116 GPU 1 119061 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 2852127, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446764 (unix time) try "date -d @1749446764" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d115) received by PID 119061 (TID 0x7f3c15c50740) from PID 119061 ***]


2025-06-09 13:25:11.256308 GPU 0 119407 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 2852127, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446765 (unix time) try "date -d @1749446765" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d26f) received by PID 119407 (TID 0x7fc6ca2c1740) from PID 119407 ***]


2025-06-09 13:26:08.271187 GPU 1 119719 test begin: paddle.nn.functional.interpolate(Tensor([2, 4, 2852127, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446820 (unix time) try "date -d @1749446820" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d3a7) received by PID 119719 (TID 0x7f93dfb4f740) from PID 119719 ***]


2025-06-09 13:26:11.424071 GPU 3 119789 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446845 (unix time) try "date -d @1749446845" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d3ed) received by PID 119789 (TID 0x7fd02a951740) from PID 119789 ***]


2025-06-09 13:26:38.747545 GPU 2 119596 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446857 (unix time) try "date -d @1749446857" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d32c) received by PID 119596 (TID 0x7f8959185740) from PID 119596 ***]


2025-06-09 13:27:06.571797 GPU 0 120045 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446888 (unix time) try "date -d @1749446888" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d4ed) received by PID 120045 (TID 0x7f3100db2740) from PID 120045 ***]


2025-06-09 13:27:28.755008 GPU 3 120871 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446923 (unix time) try "date -d @1749446923" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d827) received by PID 120871 (TID 0x7fedf7e8e740) from PID 120871 ***]


2025-06-09 13:27:32.974701 GPU 1 120915 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446916 (unix time) try "date -d @1749446916" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d853) received by PID 120915 (TID 0x7fb716919740) from PID 120915 ***]


2025-06-09 13:27:41.626719 GPU 2 120984 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446922 (unix time) try "date -d @1749446922" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d898) received by PID 120984 (TID 0x7f76aa0ee740) from PID 120984 ***]


2025-06-09 13:28:39.446425 GPU 1 121252 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446981 (unix time) try "date -d @1749446981" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d9a4) received by PID 121252 (TID 0x7f3371889740) from PID 121252 ***]


2025-06-09 13:28:39.977179 GPU 0 121266 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.6000000000000001,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446983 (unix time) try "date -d @1749446983" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d9b2) received by PID 121266 (TID 0x7f77dcca8740) from PID 121266 ***]


2025-06-09 13:28:45.914497 GPU 2 121332 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446986 (unix time) try "date -d @1749446986" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d9f4) received by PID 121332 (TID 0x7fc17ea6d740) from PID 121332 ***]


2025-06-09 13:28:46.255647 GPU 3 121354 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749446988 (unix time) try "date -d @1749446988" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1da0a) received by PID 121354 (TID 0x7f8c43c8f740) from PID 121354 ***]


2025-06-09 13:29:46.355851 GPU 0 122349 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447050 (unix time) try "date -d @1749447050" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1dded) received by PID 122349 (TID 0x7fb9b7660740) from PID 122349 ***]


2025-06-09 13:29:49.990353 GPU 2 122391 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=None, scale_factor=list[0.8000000000000002,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447073 (unix time) try "date -d @1749447073" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1de17) received by PID 122391 (TID 0x7f76e10a5740) from PID 122391 ***]


2025-06-09 13:36:37.124931 GPU 0 125241 test begin: paddle.nn.functional.interpolate(Tensor([2, 536870913, 4],"float16"), size=Tensor([1],"int32"), scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447398 (unix time) try "date -d @1749447398" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1e939) received by PID 125241 (TID 0x7f59a6f40740) from PID 125241 ***]


2025-06-09 13:36:38.317555 GPU 2 126321 test begin: paddle.nn.functional.interpolate(Tensor([2, 5368710, 10, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447399 (unix time) try "date -d @1749447399" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ed71) received by PID 126321 (TID 0x7ff05e094740) from PID 126321 ***]


2025-06-09 13:36:42.380453 GPU 3 126720 test begin: paddle.nn.functional.interpolate(Tensor([2, 5368710, 10, 10, 4],"float16"), size=list[4,2,3,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NDHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447497 (unix time) try "date -d @1749447497" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ef00) received by PID 126720 (TID 0x7f9588832740) from PID 126720 ***]


2025-06-09 13:36:42.696304 GPU 1 126741 test begin: paddle.nn.functional.interpolate(Tensor([2, 85899346, 5, 5],"float16"), size=list[3,3,], mode="bicubic", align_corners=True, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447464 (unix time) try "date -d @1749447464" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ef15) received by PID 126741 (TID 0x7fd69dcb2740) from PID 126741 ***]


2025-06-09 13:38:16.493106 GPU 1 127961 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447565 (unix time) try "date -d @1749447565" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f3d9) received by PID 127961 (TID 0x7f4377cd4740) from PID 127961 ***]


2025-06-09 13:38:20.094621 GPU 3 128002 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447561 (unix time) try "date -d @1749447561" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f402) received by PID 128002 (TID 0x7ff3faef5740) from PID 128002 ***]


2025-06-09 13:38:47.532678 GPU 0 128152 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447588 (unix time) try "date -d @1749447588" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f498) received by PID 128152 (TID 0x7fa4f71c4740) from PID 128152 ***]


2025-06-09 13:38:53.677099 GPU 2 127821 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=None, scale_factor=list[0.6,0.6,], mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749447535 (unix time) try "date -d @1749447535" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f34d) received by PID 127821 (TID 0x7f378e718740) from PID 127821 ***]


2025-06-09 13:50:35.698990 GPU 2 5306 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[13,2,], scale_factor=None, mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448236 (unix time) try "date -d @1749448236" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14ba) received by PID 5306 (TID 0x7fefcccd9740) from PID 5306 ***]


2025-06-09 13:50:38.488357 GPU 1 5645 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[13,2,], scale_factor=None, mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448302 (unix time) try "date -d @1749448302" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x160d) received by PID 5645 (TID 0x7f7d5f2f8740) from PID 5645 ***]


2025-06-09 13:50:42.965092 GPU 0 5717 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448313 (unix time) try "date -d @1749448313" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1655) received by PID 5717 (TID 0x7f7fa0bcf740) from PID 5717 ***]


2025-06-09 13:50:51.334396 GPU 3 5780 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[14,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448313 (unix time) try "date -d @1749448313" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1694) received by PID 5780 (TID 0x7f42762f5740) from PID 5780 ***]


2025-06-09 13:51:57.373400 GPU 3 6838 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448381 (unix time) try "date -d @1749448381" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ab6) received by PID 6838 (TID 0x7fe81c2f2740) from PID 6838 ***]


2025-06-09 13:52:13.954752 GPU 1 6952 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,12,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448396 (unix time) try "date -d @1749448396" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b28) received by PID 6952 (TID 0x7f6871977740) from PID 6952 ***]


2025-06-09 13:53:04.480358 GPU 0 7192 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,13,], scale_factor=None, mode="bicubic", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448471 (unix time) try "date -d @1749448471" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c18) received by PID 7192 (TID 0x7f61d381c740) from PID 7192 ***]


2025-06-09 13:53:04.913777 GPU 3 7206 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,13,], scale_factor=None, mode="bicubic", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448471 (unix time) try "date -d @1749448471" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c26) received by PID 7206 (TID 0x7f8d2d7cf740) from PID 7206 ***]


2025-06-09 13:54:21.582325 GPU 1 8018 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448463 (unix time) try "date -d @1749448463" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f52) received by PID 8018 (TID 0x7fb3f99aa740) from PID 8018 ***]


2025-06-09 13:54:22.961788 GPU 2 8038 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448464 (unix time) try "date -d @1749448464" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f66) received by PID 8038 (TID 0x7f098dca5740) from PID 8038 ***]


2025-06-09 13:54:27.837415 GPU 2 8350 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448532 (unix time) try "date -d @1749448532" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x209e) received by PID 8350 (TID 0x7fe22d506740) from PID 8350 ***]


2025-06-09 13:54:34.513319 GPU 3 8405 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[2,22,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448538 (unix time) try "date -d @1749448538" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x20d5) received by PID 8405 (TID 0x7fec69daf740) from PID 8405 ***]


2025-06-09 13:55:41.852207 GPU 3 9486 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=False, align_mode=1, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448603 (unix time) try "date -d @1749448603" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x250e) received by PID 9486 (TID 0x7f7f81da1740) from PID 9486 ***]


2025-06-09 13:55:42.529449 GPU 0 9505 test begin: paddle.nn.functional.interpolate(Tensor([21474837, 10, 10, 2],"float16"), size=list[26,2,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448607 (unix time) try "date -d @1749448607" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2521) received by PID 9505 (TID 0x7f9cca954740) from PID 9505 ***]


2025-06-09 13:56:50.488870 GPU 0 9882 test begin: paddle.nn.functional.interpolate(Tensor([2147484, 5, 20, 20],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448672 (unix time) try "date -d @1749448672" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x269a) received by PID 9882 (TID 0x7f9197b35740) from PID 9882 ***]


2025-06-09 13:59:27.169077 GPU 2 11145 test begin: paddle.nn.functional.interpolate(Tensor([4, 128, 1, 8388609],"float16"), list[16,32,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448768 (unix time) try "date -d @1749448768" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2b89) received by PID 11145 (TID 0x7f94863ea740) from PID 11145 ***]


2025-06-09 13:59:28.017076 GPU 3 11112 test begin: paddle.nn.functional.interpolate(Tensor([4, 128, 8388609, 1],"float16"), list[16,32,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448769 (unix time) try "date -d @1749448769" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2b68) received by PID 11112 (TID 0x7feafa15c740) from PID 11112 ***]


2025-06-09 13:59:31.651936 GPU 2 12191 test begin: paddle.nn.functional.interpolate(Tensor([4, 150, 111849, 64],"float16"), list[512,512,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448832 (unix time) try "date -d @1749448832" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2f9f) received by PID 12191 (TID 0x7fd61f363740) from PID 12191 ***]


2025-06-09 13:59:32.741024 GPU 3 12211 test begin: paddle.nn.functional.interpolate(Tensor([4, 150, 64, 111849],"float16"), list[512,512,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448834 (unix time) try "date -d @1749448834" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2fb3) received by PID 12211 (TID 0x7fc5f109c740) from PID 12211 ***]


2025-06-09 13:59:43.947513 GPU 1 12299 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 128, 441506],"float16"), list[1024,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448845 (unix time) try "date -d @1749448845" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x300b) received by PID 12299 (TID 0x7fb172cb9740) from PID 12299 ***]


2025-06-09 13:59:53.530265 GPU 0 12370 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 16, 3532046],"float16"), list[512,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448855 (unix time) try "date -d @1749448855" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3052) received by PID 12370 (TID 0x7f4dcc7e5740) from PID 12370 ***]


2025-06-09 14:00:37.670661 GPU 3 12580 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 1766023, 32],"float16"), list[512,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448902 (unix time) try "date -d @1749448902" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3124) received by PID 12580 (TID 0x7fa6fc186740) from PID 12580 ***]


2025-06-09 14:00:48.486517 GPU 1 12659 test begin: paddle.nn.functional.interpolate(Tensor([4, 19, 441506, 128],"float16"), list[1024,1024,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448912 (unix time) try "date -d @1749448912" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3173) received by PID 12659 (TID 0x7f51980e0740) from PID 12659 ***]


2025-06-09 14:01:55.818559 GPU 1 13730 test begin: paddle.nn.functional.interpolate(Tensor([4, 25565282, 6, 7],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448980 (unix time) try "date -d @1749448980" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x35a2) received by PID 13730 (TID 0x7fcb461dd740) from PID 13730 ***]


2025-06-09 14:02:11.888590 GPU 3 13860 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 1, 4194305],"float16"), list[64,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448993 (unix time) try "date -d @1749448993" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3624) received by PID 13860 (TID 0x7fc460010740) from PID 13860 ***]


2025-06-09 14:02:12.535007 GPU 0 12731 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 131073, 32],"float16"), size=list[256,256,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448933 (unix time) try "date -d @1749448933" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x31bb) received by PID 12731 (TID 0x7f078825e740) from PID 12731 ***]


2025-06-09 14:02:16.815182 GPU 0 13904 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 32, 131073],"float16"), size=list[256,256,], mode="bilinear", align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448998 (unix time) try "date -d @1749448998" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3650) received by PID 13904 (TID 0x7f3eb8daf740) from PID 13904 ***]


2025-06-09 14:03:10.332750 GPU 2 13817 test begin: paddle.nn.functional.interpolate(Tensor([4, 256, 4194305, 1],"float16"), list[64,128,], mode="bilinear", align_corners=False, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749448991 (unix time) try "date -d @1749448991" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x35f9) received by PID 13817 (TID 0x7f54b1b09740) from PID 13817 ***]


2025-06-09 14:03:16.220520 GPU 3 14924 test begin: paddle.nn.functional.interpolate(Tensor([4, 2684355, 20, 20],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449059 (unix time) try "date -d @1749449059" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3a4c) received by PID 14924 (TID 0x7f18333e8740) from PID 14924 ***]


2025-06-09 14:03:21.286493 GPU 0 14985 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 10737419, 20],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449065 (unix time) try "date -d @1749449065" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3a89) received by PID 14985 (TID 0x7f1491507740) from PID 14985 ***]


2025-06-09 14:03:32.053309 GPU 1 15056 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 20, 10737419],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449073 (unix time) try "date -d @1749449073" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3ad0) received by PID 15056 (TID 0x7fd806f3f740) from PID 15056 ***]


2025-06-09 14:04:22.900389 GPU 2 15304 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 30678338, 7],"float16"), size=list[10,10,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NHWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449129 (unix time) try "date -d @1749449129" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3bc8) received by PID 15304 (TID 0x7f7696427740) from PID 15304 ***]


2025-06-09 14:04:28.303574 GPU 0 15360 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 30678338, 7],"float16"), size=list[100,50,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449140 (unix time) try "date -d @1749449140" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3c00) received by PID 15360 (TID 0x7fe55905c740) from PID 15360 ***]


2025-06-09 14:05:40.028222 GPU 1 16469 test begin: paddle.nn.functional.interpolate(Tensor([4, 5, 6, 35791395],"float16"), size=list[100,50,], scale_factor=None, mode="bilinear", align_corners=True, align_mode=0, data_format="NCHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449203 (unix time) try "date -d @1749449203" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4055) received by PID 16469 (TID 0x7f58d1685740) from PID 16469 ***]


2025-06-09 14:05:53.886907 GPU 3 16585 test begin: paddle.nn.functional.interpolate(Tensor([4353, 2, 512, 512],"float32"), list[Tensor([1],"int64"),Tensor([1],"int64"),], mode="bilinear", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449220 (unix time) try "date -d @1749449220" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x40c9) received by PID 16585 (TID 0x7f05645d8740) from PID 16585 ***]


2025-06-09 14:06:54.860530 GPU 2 16642 test begin: paddle.nn.functional.interpolate(Tensor([46422, 3, 64, 256],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449216 (unix time) try "date -d @1749449216" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4102) received by PID 16642 (TID 0x7f2a736a5740) from PID 16642 ***]


2025-06-09 14:07:03.518393 GPU 3 16964 test begin: paddle.nn.functional.interpolate(Tensor([512, 273, 64, 256],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449279 (unix time) try "date -d @1749449279" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4244) received by PID 16964 (TID 0x7f94a9e15740) from PID 16964 ***]


2025-06-09 14:07:14.249455 GPU 1 17741 test begin: paddle.nn.functional.interpolate(Tensor([512, 3, 5803, 256],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449300 (unix time) try "date -d @1749449300" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x454d) received by PID 17741 (TID 0x7f69be1c2740) from PID 17741 ***]


2025-06-09 14:07:39.472235 GPU 0 16513 test begin: paddle.nn.functional.interpolate(Tensor([512, 3, 64, 23211],"float32"), list[32,64,], mode="bilinear", align_corners=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449260 (unix time) try "date -d @1749449260" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4081) received by PID 16513 (TID 0x7ff857b2e740) from PID 16513 ***]


2025-06-09 14:08:03.524845 GPU 3 18002 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449339 (unix time) try "date -d @1749449339" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4652) received by PID 18002 (TID 0x7f6317a62740) from PID 18002 ***]


2025-06-09 14:08:11.393646 GPU 0 18065 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449345 (unix time) try "date -d @1749449345" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4691) received by PID 18065 (TID 0x7f0e8d840740) from PID 18065 ***]


2025-06-09 14:08:53.107482 GPU 1 18268 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449386 (unix time) try "date -d @1749449386" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x475c) received by PID 18268 (TID 0x7f2cf48ff740) from PID 18268 ***]


2025-06-09 14:09:08.881895 GPU 2 17952 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.6,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449402 (unix time) try "date -d @1749449402" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4620) received by PID 17952 (TID 0x7feb53e61740) from PID 17952 ***]


2025-06-09 14:09:09.211521 GPU 0 18363 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449406 (unix time) try "date -d @1749449406" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x47bb) received by PID 18363 (TID 0x7f8e38c1c740) from PID 18363 ***]


2025-06-09 14:09:32.320211 GPU 3 19202 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449427 (unix time) try "date -d @1749449427" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4b02) received by PID 19202 (TID 0x7f25673af740) from PID 19202 ***]


2025-06-09 14:10:06.312869 GPU 2 19370 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449462 (unix time) try "date -d @1749449462" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4baa) received by PID 19370 (TID 0x7f3a928d8740) from PID 19370 ***]


2025-06-09 14:10:10.338951 GPU 0 19411 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449474 (unix time) try "date -d @1749449474" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4bd3) received by PID 19411 (TID 0x7f8d8fbeb740) from PID 19411 ***]


2025-06-09 14:10:19.435069 GPU 1 19482 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449478 (unix time) try "date -d @1749449478" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4c1a) received by PID 19482 (TID 0x7f755432f740) from PID 19482 ***]


2025-06-09 14:11:00.481666 GPU 3 19678 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449526 (unix time) try "date -d @1749449526" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4cde) received by PID 19678 (TID 0x7fc50f7c5740) from PID 19678 ***]


2025-06-09 14:11:18.379182 GPU 0 20499 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449536 (unix time) try "date -d @1749449536" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5013) received by PID 20499 (TID 0x7f0d691fc740) from PID 20499 ***]


2025-06-09 14:11:21.935292 GPU 1 20547 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.7999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449538 (unix time) try "date -d @1749449538" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5043) received by PID 20547 (TID 0x7fe10f1b0740) from PID 20547 ***]


2025-06-09 14:11:35.436504 GPU 2 20632 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449550 (unix time) try "date -d @1749449550" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5098) received by PID 20632 (TID 0x7fbad995a740) from PID 20632 ***]


2025-06-09 14:12:20.658301 GPU 0 20844 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449596 (unix time) try "date -d @1749449596" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x516c) received by PID 20844 (TID 0x7f3666bdb740) from PID 20844 ***]


2025-06-09 14:12:21.755958 GPU 1 20866 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449598 (unix time) try "date -d @1749449598" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5182) received by PID 20866 (TID 0x7f8cbfcf6740) from PID 20866 ***]


2025-06-09 14:12:34.230603 GPU 2 20960 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[0.8999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449608 (unix time) try "date -d @1749449608" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x51e0) received by PID 20960 (TID 0x7f2ed5367740) from PID 20960 ***]


2025-06-09 14:13:35.446174 GPU 3 21002 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449617 (unix time) try "date -d @1749449617" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x520a) received by PID 21002 (TID 0x7f278db4a740) from PID 21002 ***]


2025-06-09 14:13:41.540780 GPU 3 22055 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449685 (unix time) try "date -d @1749449685" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5627) received by PID 22055 (TID 0x7f2da3b1e740) from PID 22055 ***]


2025-06-09 14:13:49.263361 GPU 0 22118 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449683 (unix time) try "date -d @1749449683" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5666) received by PID 22118 (TID 0x7f5b53d3c740) from PID 22118 ***]


2025-06-09 14:14:19.914641 GPU 1 21911 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.0999999999999999,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449662 (unix time) try "date -d @1749449662" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5597) received by PID 21911 (TID 0x7f6511bb3740) from PID 21911 ***]


2025-06-09 14:14:29.289514 GPU 2 21985 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449671 (unix time) try "date -d @1749449671" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x55e1) received by PID 21985 (TID 0x7f16461aa740) from PID 21985 ***]


2025-06-09 14:14:34.780976 GPU 2 22330 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449730 (unix time) try "date -d @1749449730" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x573a) received by PID 22330 (TID 0x7f54cfc6a740) from PID 22330 ***]


2025-06-09 14:14:46.985419 GPU 0 22408 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449752 (unix time) try "date -d @1749449752" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5788) received by PID 22408 (TID 0x7f10555bc740) from PID 22408 ***]


2025-06-09 14:14:48.579270 GPU 3 22438 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.1999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449741 (unix time) try "date -d @1749449741" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x57a6) received by PID 22438 (TID 0x7f30840d0740) from PID 22438 ***]


2025-06-09 14:14:54.662699 GPU 1 22499 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449748 (unix time) try "date -d @1749449748" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x57e3) received by PID 22499 (TID 0x7f1b2b200740) from PID 22499 ***]


2025-06-09 14:15:45.262482 GPU 3 23443 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449801 (unix time) try "date -d @1749449801" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5b93) received by PID 23443 (TID 0x7efd34378740) from PID 23443 ***]


2025-06-09 14:15:52.109628 GPU 1 23499 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449808 (unix time) try "date -d @1749449808" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5bcb) received by PID 23499 (TID 0x7f1979e97740) from PID 23499 ***]


2025-06-09 14:15:55.858637 GPU 0 23541 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.2999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449819 (unix time) try "date -d @1749449819" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5bf5) received by PID 23541 (TID 0x7f0ae5387740) from PID 23541 ***]


2025-06-09 14:16:02.193873 GPU 2 23599 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449817 (unix time) try "date -d @1749449817" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5c2f) received by PID 23599 (TID 0x7ffad641c740) from PID 23599 ***]


2025-06-09 14:16:51.635377 GPU 1 23831 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449869 (unix time) try "date -d @1749449869" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5d17) received by PID 23831 (TID 0x7f0aed08b740) from PID 23831 ***]


2025-06-09 14:17:01.319350 GPU 2 23904 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449877 (unix time) try "date -d @1749449877" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5d60) received by PID 23904 (TID 0x7f482ef8c740) from PID 23904 ***]


2025-06-09 14:17:02.800656 GPU 0 23925 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449888 (unix time) try "date -d @1749449888" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5d75) received by PID 23925 (TID 0x7f19d133f740) from PID 23925 ***]


2025-06-09 14:17:14.417330 GPU 3 24715 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449887 (unix time) try "date -d @1749449887" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x608b) received by PID 24715 (TID 0x7f90d14d2740) from PID 24715 ***]


2025-06-09 14:18:01.278379 GPU 2 24940 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449938 (unix time) try "date -d @1749449938" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x616c) received by PID 24940 (TID 0x7f2ecb578740) from PID 24940 ***]


2025-06-09 14:18:11.384570 GPU 3 25013 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449946 (unix time) try "date -d @1749449946" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x61b5) received by PID 25013 (TID 0x7f5b26ad1740) from PID 25013 ***]


2025-06-09 14:18:12.219877 GPU 0 25032 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.4999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449956 (unix time) try "date -d @1749449956" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x61c8) received by PID 25032 (TID 0x7fcab8a2b740) from PID 25032 ***]


2025-06-09 14:18:21.924415 GPU 1 25112 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749449965 (unix time) try "date -d @1749449965" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6218) received by PID 25112 (TID 0x7f0105b26740) from PID 25112 ***]


2025-06-09 14:19:10.022165 GPU 3 25639 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450004 (unix time) try "date -d @1749450004" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6427) received by PID 25639 (TID 0x7f29b5a28740) from PID 25639 ***]


2025-06-09 14:19:20.193364 GPU 0 26116 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450022 (unix time) try "date -d @1749450022" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6604) received by PID 26116 (TID 0x7f5ce8774740) from PID 26116 ***]


2025-06-09 14:19:28.841038 GPU 1 26182 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.5999999999999996,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450021 (unix time) try "date -d @1749450021" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6646) received by PID 26182 (TID 0x7f07f5c6d740) from PID 26182 ***]


2025-06-09 14:19:29.681750 GPU 2 26201 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450022 (unix time) try "date -d @1749450022" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6659) received by PID 26201 (TID 0x7f61ad2f6740) from PID 26201 ***]


2025-06-09 14:20:25.281542 GPU 1 26473 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450104 (unix time) try "date -d @1749450104" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6769) received by PID 26473 (TID 0x7f46f5f48740) from PID 26473 ***]


2025-06-09 14:20:25.637962 GPU 0 26487 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450081 (unix time) try "date -d @1749450081" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6777) received by PID 26487 (TID 0x7feb94067740) from PID 26487 ***]


2025-06-09 14:20:26.364967 GPU 2 26513 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.6999999999999997,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450081 (unix time) try "date -d @1749450081" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6791) received by PID 26513 (TID 0x7fb1522fc740) from PID 26513 ***]


2025-06-09 14:20:37.409748 GPU 3 26605 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450091 (unix time) try "date -d @1749450091" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x67ed) received by PID 26605 (TID 0x7f0b04a94740) from PID 26605 ***]


2025-06-09 14:21:25.003713 GPU 0 27537 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450139 (unix time) try "date -d @1749450139" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6b91) received by PID 27537 (TID 0x7fc6ec924740) from PID 27537 ***]


2025-06-09 14:21:34.873905 GPU 3 27609 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450152 (unix time) try "date -d @1749450152" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6bd9) received by PID 27609 (TID 0x7fc2160df740) from PID 27609 ***]


2025-06-09 14:21:48.332552 GPU 1 27698 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=None, scale_factor=list[1.7999999999999998,], mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749450171 (unix time) try "date -d @1749450171" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6c32) received by PID 27698 (TID 0x7f05d7741740) from PID 27698 ***]


2025-06-09 15:35:53.549376 GPU 1 78272 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454555 (unix time) try "date -d @1749454555" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x131c0) received by PID 78272 (TID 0x7f948f7de740) from PID 78272 ***]


2025-06-09 15:35:56.854726 GPU 0 79443 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454611 (unix time) try "date -d @1749454611" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13653) received by PID 79443 (TID 0x7f7a43cca740) from PID 79443 ***]


2025-06-09 15:36:04.232827 GPU 3 78818 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454565 (unix time) try "date -d @1749454565" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x133e2) received by PID 78818 (TID 0x7fd84dac8740) from PID 78818 ***]


2025-06-09 15:36:05.770812 GPU 2 78446 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[11,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454567 (unix time) try "date -d @1749454567" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1326e) received by PID 78446 (TID 0x7fbab90ad740) from PID 78446 ***]


2025-06-09 15:36:09.066572 GPU 3 79523 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454623 (unix time) try "date -d @1749454623" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x136a3) received by PID 79523 (TID 0x7f275cc01740) from PID 79523 ***]


2025-06-09 15:36:10.722030 GPU 2 79549 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454626 (unix time) try "date -d @1749454626" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x136bd) received by PID 79549 (TID 0x7f386fdcf740) from PID 79549 ***]


2025-06-09 15:36:28.700751 GPU 1 79659 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454651 (unix time) try "date -d @1749454651" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1372b) received by PID 79659 (TID 0x7fb799e11740) from PID 79659 ***]


2025-06-09 15:37:07.097351 GPU 3 79849 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[14,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454681 (unix time) try "date -d @1749454681" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x137e9) received by PID 79849 (TID 0x7f271d63c740) from PID 79849 ***]


2025-06-09 15:37:10.090242 GPU 2 80191 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454685 (unix time) try "date -d @1749454685" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1393f) received by PID 80191 (TID 0x7f32d6ae6740) from PID 80191 ***]


2025-06-09 15:37:23.418423 GPU 0 80675 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454697 (unix time) try "date -d @1749454697" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13b23) received by PID 80675 (TID 0x7f4f825e2740) from PID 80675 ***]


2025-06-09 15:38:04.964174 GPU 3 80878 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454749 (unix time) try "date -d @1749454749" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13bee) received by PID 80878 (TID 0x7f84ef119740) from PID 80878 ***]


2025-06-09 15:38:05.143297 GPU 1 80892 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[17,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749454738 (unix time) try "date -d @1749454738" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13bfc) received by PID 80892 (TID 0x7f40e75b0740) from PID 80892 ***]


2025-06-09 15:42:48.257723 GPU 3 83962 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455022 (unix time) try "date -d @1749455022" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x147fa) received by PID 83962 (TID 0x7f33793f6740) from PID 83962 ***]


2025-06-09 15:42:52.282950 GPU 1 84004 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455026 (unix time) try "date -d @1749455026" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14824) received by PID 84004 (TID 0x7f881f267740) from PID 84004 ***]


2025-06-09 15:43:45.635739 GPU 3 84956 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455081 (unix time) try "date -d @1749455081" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14bdc) received by PID 84956 (TID 0x7f90f7c3c740) from PID 84956 ***]


2025-06-09 15:43:50.577333 GPU 1 85000 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[5,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455084 (unix time) try "date -d @1749455084" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14c08) received by PID 85000 (TID 0x7f0b796a3740) from PID 85000 ***]


2025-06-09 15:43:53.267080 GPU 2 85044 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455097 (unix time) try "date -d @1749455097" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14c34) received by PID 85044 (TID 0x7f43b5e82740) from PID 85044 ***]


2025-06-09 15:44:09.846731 GPU 0 85136 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455114 (unix time) try "date -d @1749455114" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14c90) received by PID 85136 (TID 0x7f0fdca94740) from PID 85136 ***]


2025-06-09 15:44:47.709678 GPU 1 85268 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=True, align_mode=0, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455141 (unix time) try "date -d @1749455141" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14d14) received by PID 85268 (TID 0x7f4d82211740) from PID 85268 ***]


2025-06-09 15:45:01.407405 GPU 2 85337 test begin: paddle.nn.functional.interpolate(Tensor([57042535, 10, 4],"float32"), size=list[8,], scale_factor=None, mode="linear", align_corners=True, align_mode=1, data_format="NWC", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455157 (unix time) try "date -d @1749455157" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14d59) received by PID 85337 (TID 0x7f74c612c740) from PID 85337 ***]


2025-06-09 15:45:14.512106 GPU 3 86106 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455168 (unix time) try "date -d @1749455168" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1505a) received by PID 86106 (TID 0x7f0f94302740) from PID 86106 ***]


2025-06-09 15:45:44.822287 GPU 1 86204 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=None, scale_factor=list[0.6,0.6,0.6,], mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455197 (unix time) try "date -d @1749455197" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x150bc) received by PID 86204 (TID 0x7f1cd2907740) from PID 86204 ***]


2025-06-09 15:45:45.546029 GPU 0 86222 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=False, align_mode=1, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455210 (unix time) try "date -d @1749455210" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x150ce) received by PID 86222 (TID 0x7ff9a42fd740) from PID 86222 ***]


2025-06-09 15:46:01.035345 GPU 2 86301 test begin: paddle.nn.functional.interpolate(Tensor([570426, 4, 10, 10, 10],"float32"), size=list[2,2,2,], scale_factor=None, mode="trilinear", align_corners=True, align_mode=0, data_format="NCDHW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455223 (unix time) try "date -d @1749455223" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1511d) received by PID 86301 (TID 0x7f1d87f87740) from PID 86301 ***]


2025-06-09 15:46:41.019740 GPU 3 86497 test begin: paddle.nn.functional.interpolate(Tensor([57266231, 3, 5, 5],"float16"), size=list[3,3,], mode="bicubic", align_corners=True, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455275 (unix time) try "date -d @1749455275" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x151e1) received by PID 86497 (TID 0x7fadfa5cc740) from PID 86497 ***]


2025-06-09 15:46:54.041506 GPU 0 86579 test begin: paddle.nn.functional.interpolate(Tensor([5941931, 3, 128],"float32"), size=list[64,], mode="linear", align_mode=1, align_corners=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455270 (unix time) try "date -d @1749455270" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15233) received by PID 86579 (TID 0x7f563354d740) from PID 86579 ***]


2025-06-09 15:47:07.458741 GPU 2 86665 test begin: paddle.nn.functional.interpolate(Tensor([5941931, 3, 128],"float32"), size=list[64,], scale_factor=None, mode="linear", align_corners=False, align_mode=1, data_format="NCW", name=None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455280 (unix time) try "date -d @1749455280" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15289) received by PID 86665 (TID 0x7f7571572740) from PID 86665 ***]


2025-06-09 15:48:07.309684 GPU 1 87732 test begin: paddle.nn.functional.interpolate(Tensor([7428, 1, 640, 480],"float32"), size=list[10,8,], )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455340 (unix time) try "date -d @1749455340" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x156b4) received by PID 87732 (TID 0x7f728c111740) from PID 87732 ***]


2025-06-09 15:49:36.723083 GPU 0 87825 test begin: paddle.nn.functional.interpolate(Tensor([8, 64, 20, 419431],"float16"), size=tuple(160,160,), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455378 (unix time) try "date -d @1749455378" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15711) received by PID 87825 (TID 0x7f4d43728740) from PID 87825 ***]


2025-06-09 15:49:57.790412 GPU 3 89001 test begin: paddle.nn.functional.interpolate(Tensor([8, 64, 419431, 20],"float16"), size=tuple(160,160,), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749455461 (unix time) try "date -d @1749455461" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15ba9) received by PID 89001 (TID 0x7f9105de0740) from PID 89001 ***]


2025-06-09 15:50:11.557997 GPU 0 89116 test begin: paddle.nn.functional.interpolate(x=Tensor([15521779, 3, 7, 7],"float32"), mode="area", size=list[2,5,], )
[cuda error] paddle.nn.functional.interpolate(x=Tensor([15521779, 3, 7, 7],"float32"), mode="area", size=list[2,5,], ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 15:51:05.303000 GPU 0 89116 test begin: paddle.nn.functional.interpolate(x=Tensor([2, 3, 5, 10865245, 7],"float32"), mode="area", size=list[2,3,5,], )
[cuda error] paddle.nn.functional.interpolate(x=Tensor([2, 3, 5, 10865245, 7],"float32"), mode="area", size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 15:51:08.288145 GPU 1 89059 test begin: paddle.nn.functional.interpolate(x=Tensor([2, 3, 5, 7, 10865245],"float32"), mode="area", size=list[2,3,5,], )
[cuda error] paddle.nn.functional.interpolate(x=Tensor([2, 3, 5, 7, 10865245],"float32"), mode="area", size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 15:51:20.995564 GPU 0 89116 test begin: paddle.nn.functional.interpolate(x=Tensor([2, 3, 7760890, 7, 7],"float32"), mode="area", size=list[2,3,5,], )
[cuda error] paddle.nn.functional.interpolate(x=Tensor([2, 3, 7760890, 7, 7],"float32"), mode="area", size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 15:51:30.673294 GPU 0 89116 test begin: paddle.nn.functional.interpolate(x=Tensor([2, 4656534, 5, 7, 7],"float32"), mode="area", size=list[2,3,5,], )
[cuda error] paddle.nn.functional.interpolate(x=Tensor([2, 4656534, 5, 7, 7],"float32"), mode="area", size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 15:51:32.704909 GPU 0 89116 test begin: paddle.nn.functional.interpolate(x=Tensor([3104356, 3, 5, 7, 7],"float32"), mode="area", size=list[2,3,5,], )
[cuda error] paddle.nn.functional.interpolate(x=Tensor([3104356, 3, 5, 7, 7],"float32"), mode="area", size=list[2,3,5,], ) 
 (External) CUDA error(701), too many resources requested for launch. 
  [Hint: 'cudaErrorLaunchOutOfResources'. This indicates that a launch did not occur because it did not have appropriate resources. Although this error is similar tocudaErrorInvalidConfiguration, this error usually indicates that the user has attempted to pass too many arguments to the device kernel, or the kernellaunch specifies too many threads for the kernel's register count.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:19:04.579815 GPU 1 89059 test begin: paddle.nn.functional.log_softmax(Tensor([2, 2, 1073741825],"float16"), 0, )
[cuda error] paddle.nn.functional.log_softmax(Tensor([2, 2, 1073741825],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:20:08.695864 GPU 1 89059 test begin: paddle.nn.functional.log_softmax(Tensor([2, 2147483649, 1],"float16"), 0, )
[cuda error] paddle.nn.functional.log_softmax(Tensor([2, 2147483649, 1],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:20:11.571935 GPU 1 89059 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 4, 95070891],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457215 (unix time) try "date -d @1749457215" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15be3) received by PID 89059 (TID 0x7f266794c740) from PID 89059 ***]


2025-06-09 16:20:47.543846 GPU 1 107524 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 4, 95070891],"float32"), 1, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457302 (unix time) try "date -d @1749457302" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a404) received by PID 107524 (TID 0x7f496cecf740) from PID 107524 ***]


2025-06-09 16:22:13.335511 GPU 1 108614 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 715827883],"float16"), 0, )
[cuda error] paddle.nn.functional.log_softmax(Tensor([2, 3, 715827883],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:23:23.634097 GPU 1 108614 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 715827883],"float16"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457405 (unix time) try "date -d @1749457405" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a846) received by PID 108614 (TID 0x7f48b98ce740) from PID 108614 ***]


2025-06-09 16:23:55.684358 GPU 1 109787 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 76056713, 5],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457490 (unix time) try "date -d @1749457490" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1acdb) received by PID 109787 (TID 0x7f91f1205740) from PID 109787 ***]


2025-06-09 16:25:23.252940 GPU 1 110887 test begin: paddle.nn.functional.log_softmax(Tensor([2, 3, 76056713, 5],"float32"), 1, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457587 (unix time) try "date -d @1749457587" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b127) received by PID 110887 (TID 0x7f72988d3740) from PID 110887 ***]


2025-06-09 16:26:59.825223 GPU 1 111306 test begin: paddle.nn.functional.log_softmax(Tensor([2, 536870913, 4],"float16"), 0, )
[cuda error] paddle.nn.functional.log_softmax(Tensor([2, 536870913, 4],"float16"), 0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:28:14.855716 GPU 1 111306 test begin: paddle.nn.functional.log_softmax(Tensor([2, 536870913, 4],"float16"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457698 (unix time) try "date -d @1749457698" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b2ca) received by PID 111306 (TID 0x7f812cf10740) from PID 111306 ***]


2025-06-09 16:28:51.580662 GPU 1 112503 test begin: paddle.nn.functional.log_softmax(Tensor([2, 57042535, 4, 5],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457790 (unix time) try "date -d @1749457790" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1b777) received by PID 112503 (TID 0x7f84b5c0e740) from PID 112503 ***]


2025-06-09 16:30:23.432803 GPU 1 113770 test begin: paddle.nn.functional.log_softmax(Tensor([2, 57042535, 4, 5],"float32"), 1, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457883 (unix time) try "date -d @1749457883" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1bc6a) received by PID 113770 (TID 0x7f11eb0f4740) from PID 113770 ***]


2025-06-09 16:33:11.168153 GPU 1 114927 test begin: paddle.nn.functional.log_softmax(Tensor([357913942, 3, 4],"float16"), 0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749457996 (unix time) try "date -d @1749457996" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c0ef) received by PID 114927 (TID 0x7f4105ea4740) from PID 114927 ***]


2025-06-09 16:33:48.553614 GPU 1 116139 test begin: paddle.nn.functional.log_softmax(Tensor([357913942, 3, 4],"float16"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749458091 (unix time) try "date -d @1749458091" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c5ab) received by PID 116139 (TID 0x7f25864a9740) from PID 116139 ***]


2025-06-09 16:35:21.259264 GPU 1 117257 test begin: paddle.nn.functional.log_softmax(Tensor([38028357, 3, 4, 5],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749458175 (unix time) try "date -d @1749458175" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ca09) received by PID 117257 (TID 0x7f3a165bf740) from PID 117257 ***]


2025-06-09 16:36:47.838412 GPU 1 117640 test begin: paddle.nn.functional.log_softmax(Tensor([38028357, 3, 4, 5],"float32"), 1, None, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749458270 (unix time) try "date -d @1749458270" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cb88) received by PID 117640 (TID 0x7f78ff1ca740) from PID 117640 ***]


2025-06-09 16:38:23.503208 GPU 1 118771 test begin: paddle.nn.functional.log_softmax(Tensor([5, 3, 2, 76056713],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749458364 (unix time) try "date -d @1749458364" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1cff3) received by PID 118771 (TID 0x7fd330bad740) from PID 118771 ***]


2025-06-09 16:39:56.534949 GPU 1 119881 test begin: paddle.nn.functional.log_softmax(Tensor([5, 3, 38028357, 4],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749458450 (unix time) try "date -d @1749458450" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d449) received by PID 119881 (TID 0x7fd942b00740) from PID 119881 ***]


2025-06-09 16:41:23.515704 GPU 1 121008 test begin: paddle.nn.functional.log_softmax(Tensor([5, 57042535, 2, 4],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749458549 (unix time) try "date -d @1749458549" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d8b0) received by PID 121008 (TID 0x7f8897b79740) from PID 121008 ***]


2025-06-09 16:43:01.945355 GPU 1 121441 test begin: paddle.nn.functional.log_softmax(Tensor([95070891, 3, 2, 4],"float32"), 1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749458646 (unix time) try "date -d @1749458646" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1da61) received by PID 121441 (TID 0x7fa739e3b740) from PID 121441 ***]


2025-06-09 16:49:18.817517 GPU 0 125767 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 2, 1073741825],"float16"), axis=0, )
[cuda error] paddle.nn.functional.log_softmax(x=Tensor([2, 2, 1073741825],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:50:21.084426 GPU 0 125767 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 2147483649, 1],"float16"), axis=0, )
[cuda error] paddle.nn.functional.log_softmax(x=Tensor([2, 2147483649, 1],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:50:23.762121 GPU 0 125767 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 3, 715827883],"float16"), axis=0, )
[cuda error] paddle.nn.functional.log_softmax(x=Tensor([2, 3, 715827883],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:50:26.459039 GPU 0 125767 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 3, 715827883],"float16"), axis=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749459028 (unix time) try "date -d @1749459028" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1eb47) received by PID 125767 (TID 0x7f5f8f80d740) from PID 125767 ***]


2025-06-09 16:50:58.590397 GPU 0 126287 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 536870913, 4],"float16"), axis=0, )
[cuda error] paddle.nn.functional.log_softmax(x=Tensor([2, 536870913, 4],"float16"), axis=0, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 16:51:59.448500 GPU 0 126287 test begin: paddle.nn.functional.log_softmax(x=Tensor([2, 536870913, 4],"float16"), axis=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749459122 (unix time) try "date -d @1749459122" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ed4f) received by PID 126287 (TID 0x7f2dc74b2740) from PID 126287 ***]


2025-06-09 16:53:35.475970 GPU 0 127425 test begin: paddle.nn.functional.log_softmax(x=Tensor([357913942, 3, 4],"float16"), axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749459220 (unix time) try "date -d @1749459220" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f1c1) received by PID 127425 (TID 0x7f76e2fd9740) from PID 127425 ***]


2025-06-09 16:54:12.535248 GPU 0 128532 test begin: paddle.nn.functional.log_softmax(x=Tensor([357913942, 3, 4],"float16"), axis=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749459314 (unix time) try "date -d @1749459314" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1f614) received by PID 128532 (TID 0x7fb5952c6740) from PID 128532 ***]


2025-06-09 17:00:18.291873 GPU 0 129566 test begin: paddle.nn.functional.multi_margin_loss(Tensor([2147483649, 2],"float16"), Tensor([2147483649],"int64"), p=1, margin=1.0, weight=Tensor([2],"float16"), reduction="mean", name=None, )
[paddle error] paddle.nn.functional.multi_margin_loss(Tensor([2147483649, 2],"float16"), Tensor([2147483649],"int64"), p=1, margin=1.0, weight=Tensor([2],"float16"), reduction="mean", name=None, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 17:00:44.123949 GPU 0 129566 test begin: paddle.nn.functional.multi_margin_loss(Tensor([2281701379, 2],"float64"), Tensor([2281701379],"int64"), p=1, margin=1.0, weight=Tensor([2],"float64"), reduction="mean", name=None, )
[paddle error] paddle.nn.functional.multi_margin_loss(Tensor([2281701379, 2],"float64"), Tensor([2281701379],"int64"), p=1, margin=1.0, weight=Tensor([2],"float64"), reduction="mean", name=None, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 17:02:57.460872 GPU 0 129566 test begin: paddle.nn.functional.multi_margin_loss(Tensor([5, 858993460],"float16"), Tensor([5],"int64"), p=1, margin=1.0, weight=Tensor([858993460],"float16"), reduction="mean", name=None, )
W0609 17:02:58.966250 129566 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   MultiplyGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::multiply_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::ElementwiseMulGrad<phi::dtype::float16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, phi::DenseTensor*, int)
5   void phi::SumKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
6   void phi::SumRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
7   phi::DenseTensor::~DenseTensor()
8   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
9   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749459779 (unix time) try "date -d @1749459779" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1fa1e) received by PID 129566 (TID 0x7ffb87bb0740) from PID 129566 ***]


2025-06-09 17:03:32.555552 GPU 0 3644 test begin: paddle.nn.functional.multi_margin_loss(input=Tensor([2147483649, 2],"float16"), label=Tensor([2147483649],"int64"), p=1, margin=1.0, weight=Tensor([2],"float16"), reduction="mean", )
[paddle error] paddle.nn.functional.multi_margin_loss(input=Tensor([2147483649, 2],"float16"), label=Tensor([2147483649],"int64"), p=1, margin=1.0, weight=Tensor([2],"float16"), reduction="mean", ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 17:05:01.283168 GPU 0 3644 test begin: paddle.nn.functional.multi_margin_loss(input=Tensor([2281701379, 2],"float64"), label=Tensor([2281701379],"int64"), p=1, margin=1.0, weight=Tensor([2],"float64"), reduction="mean", )
[paddle error] paddle.nn.functional.multi_margin_loss(input=Tensor([2281701379, 2],"float64"), label=Tensor([2281701379],"int64"), p=1, margin=1.0, weight=Tensor([2],"float64"), reduction="mean", ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 17:07:07.481550 GPU 0 3644 test begin: paddle.nn.functional.multi_margin_loss(input=Tensor([5, 858993460],"float16"), label=Tensor([5],"int64"), p=1, margin=1.0, weight=Tensor([858993460],"float16"), reduction="mean", )
W0609 17:07:09.009554  3644 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   MultiplyGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::multiply_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, int, paddle::Tensor*, paddle::Tensor*)
4   void phi::ElementwiseMulGrad<phi::dtype::float16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, phi::DenseTensor*, int)
5   void phi::SumKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
6   void phi::SumRawKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
7   phi::DenseTensor::~DenseTensor()
8   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
9   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749460029 (unix time) try "date -d @1749460029" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe3c) received by PID 3644 (TID 0x7ff36e16b740) from PID 3644 ***]


2025-06-09 17:19:59.956416 GPU 0 6136 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 1114113, 64],"float32"), Tensor([2, 1, 1114113, 64],"int64"), axis=1, )
/host_home/wanghuan29/PaddleAPITest-lhy/tester/paddle_only.py:42: VisibleDeprecationWarning: [93m
Warning:
API "paddle.nn.functional.loss.softmax_with_cross_entropy" is deprecated since 2.0.0, and will be removed in future versions. Please use "paddle.nn.functional.cross_entropy" instead.
    Reason: Please notice that behavior of "paddle.nn.functional.softmax_with_cross_entropy" and "paddle.nn.functional.cross_entropy" is different. [0m
  paddle_output = self.paddle_api(*tuple(self.paddle_args), **self.paddle_kwargs)
[paddle error] paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 1114113, 64],"float32"), Tensor([2, 1, 1114113, 64],"int64"), axis=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_helper.h:243)


2025-06-09 17:20:02.206607 GPU 1 10075 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 2228225],"float32"), Tensor([2, 1, 32, 2228225],"int64"), axis=1, )
[paddle error] paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 16, 32, 2228225],"float32"), Tensor([2, 1, 32, 2228225],"int64"), axis=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_helper.h:243)


2025-06-09 17:20:31.211437 GPU 0 6136 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 557057, 32, 64],"float32"), Tensor([2, 1, 32, 64],"int64"), axis=1, )
[paddle error] paddle.nn.functional.softmax_with_cross_entropy(Tensor([2, 557057, 32, 64],"float32"), Tensor([2, 1, 32, 64],"int64"), axis=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_helper.h:243)


2025-06-09 17:20:34.608616 GPU 0 6136 test begin: paddle.nn.functional.softmax_with_cross_entropy(Tensor([69633, 16, 32, 64],"float32"), Tensor([69633, 1, 32, 64],"int64"), axis=1, )
[paddle error] paddle.nn.functional.softmax_with_cross_entropy(Tensor([69633, 16, 32, 64],"float32"), Tensor([69633, 1, 32, 64],"int64"), axis=1, ) 
 (External) CUDNN error(9), CUDNN_STATUS_NOT_SUPPORTED. 
  [Hint: 'CUDNN_STATUS_NOT_SUPPORTED'.  The functionality requested is not presently supported by cuDNN.  ] (at ../paddle/phi/backends/gpu/cuda/cudnn_helper.h:243)


2025-06-09 17:20:47.119840 GPU 0 6136 test begin: paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 190141782, 3],"float32"), seg_num=2, )
[cuda error] paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 190141782, 3],"float32"), seg_num=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 17:20:51.855908 GPU 0 6136 test begin: paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 4, 142606337],"float32"), seg_num=2, )
[cuda error] paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 4, 142606337],"float32"), seg_num=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 17:20:54.735519 GPU 0 6136 test begin: paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 4, 268435457],"float16"), seg_num=2, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749460856 (unix time) try "date -d @1749460856" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x17f8) received by PID 6136 (TID 0x7f5730b6b740) from PID 6136 ***]


2025-06-09 17:21:08.657108 GPU 1 10075 test begin: paddle.nn.functional.temporal_shift(x=Tensor([2, 95070891, 4, 3],"float32"), seg_num=2, )
[cuda error] paddle.nn.functional.temporal_shift(x=Tensor([2, 95070891, 4, 3],"float32"), seg_num=2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 17:21:13.778412 GPU 1 10075 test begin: paddle.nn.functional.temporal_shift(x=Tensor([6, 4, 2, 47535446],"float32"), seg_num=2, shift_ratio=0.2, )
[cuda error] paddle.nn.functional.temporal_shift(x=Tensor([6, 4, 2, 47535446],"float32"), seg_num=2, shift_ratio=0.2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 17:21:17.672046 GPU 1 10075 test begin: paddle.nn.functional.temporal_shift(x=Tensor([6, 4, 47535446, 2],"float32"), seg_num=2, shift_ratio=0.2, )
[cuda error] paddle.nn.functional.temporal_shift(x=Tensor([6, 4, 47535446, 2],"float32"), seg_num=2, shift_ratio=0.2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 17:21:21.228487 GPU 1 10075 test begin: paddle.nn.functional.temporal_shift(x=Tensor([6, 95070891, 2, 2],"float32"), seg_num=2, shift_ratio=0.2, )
[cuda error] paddle.nn.functional.temporal_shift(x=Tensor([6, 95070891, 2, 2],"float32"), seg_num=2, shift_ratio=0.2, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at ../paddle/fluid/pybind/eager_functions.cc:1384)


2025-06-09 17:49:02.716211 GPU 2 31120 test begin: paddle.nn.functional.upsample(Tensor([24, 96, 16, 61896],"float32"), size=list[31,31,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749462614 (unix time) try "date -d @1749462614" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7990) received by PID 31120 (TID 0x7fe732e88740) from PID 31120 ***]


2025-06-09 17:49:04.948302 GPU 3 30822 test begin: paddle.nn.functional.upsample(Tensor([24, 96, 16235, 61],"float32"), size=list[122,122,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749462617 (unix time) try "date -d @1749462617" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7866) received by PID 30822 (TID 0x7fd7953eb740) from PID 30822 ***]


2025-06-09 17:49:43.852327 GPU 1 32036 test begin: paddle.nn.functional.upsample(Tensor([24, 96, 31, 31946],"float32"), size=list[61,61,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749462658 (unix time) try "date -d @1749462658" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7d24) received by PID 32036 (TID 0x7f359d64d740) from PID 32036 ***]


2025-06-09 17:50:15.606904 GPU 0 32194 test begin: paddle.nn.functional.upsample(Tensor([24, 96, 31946, 31],"float32"), size=list[61,61,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749462687 (unix time) try "date -d @1749462687" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7dc2) received by PID 32194 (TID 0x7ff057980740) from PID 32194 ***]


2025-06-09 17:50:21.878296 GPU 3 32254 test begin: paddle.nn.functional.upsample(Tensor([24, 96, 61, 16235],"float32"), size=list[122,122,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749462697 (unix time) try "date -d @1749462697" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7dfe) received by PID 32254 (TID 0x7f59a56c8740) from PID 32254 ***]


2025-06-09 17:50:46.696604 GPU 2 32382 test begin: paddle.nn.functional.upsample(Tensor([24, 96, 61896, 16],"float32"), size=list[31,31,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749462718 (unix time) try "date -d @1749462718" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x7e7e) received by PID 32382 (TID 0x7fa502ce9740) from PID 32382 ***]


2025-06-09 17:57:56.187680 GPU 0 36352 test begin: paddle.nn.functional.upsample(Tensor([4, 48, 297097, 40],"float32"), size=list[80,80,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749463146 (unix time) try "date -d @1749463146" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8e00) received by PID 36352 (TID 0x7f80f7ca1740) from PID 36352 ***]


2025-06-09 17:58:17.455075 GPU 2 34871 test begin: paddle.nn.functional.upsample(Tensor([4, 48, 40, 297097],"float32"), size=list[80,80,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749463166 (unix time) try "date -d @1749463166" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x8837) received by PID 34871 (TID 0x7f8753abe740) from PID 34871 ***]


2025-06-09 18:24:14.935633 GPU 1 53551 test begin: paddle.nn.functional.upsample(Tensor([64, 96, 11460, 61],"float16"), size=list[122,122,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749464762 (unix time) try "date -d @1749464762" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd12f) received by PID 53551 (TID 0x7fc637c13740) from PID 53551 ***]


2025-06-09 18:24:30.519470 GPU 0 52120 test begin: paddle.nn.functional.upsample(Tensor([64, 96, 16, 43691],"float16"), size=list[31,31,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749464778 (unix time) try "date -d @1749464778" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcb98) received by PID 52120 (TID 0x7fd18a8b6740) from PID 52120 ***]


2025-06-09 18:24:34.683652 GPU 3 47191 test begin: paddle.nn.functional.upsample(Tensor([64, 96, 22551, 31],"float16"), size=list[61,61,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749464780 (unix time) try "date -d @1749464780" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb857) received by PID 47191 (TID 0x7f029dd9e740) from PID 47191 ***]


2025-06-09 18:24:38.513128 GPU 2 53673 test begin: paddle.nn.functional.upsample(Tensor([64, 96, 31, 22551],"float16"), size=list[61,61,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749464802 (unix time) try "date -d @1749464802" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd1a9) received by PID 53673 (TID 0x7f2d1410c740) from PID 53673 ***]


2025-06-09 18:26:21.748214 GPU 0 54828 test begin: paddle.nn.functional.upsample(Tensor([64, 96, 43691, 16],"float16"), size=list[31,31,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749464901 (unix time) try "date -d @1749464901" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd62c) received by PID 54828 (TID 0x7f7641a51740) from PID 54828 ***]


2025-06-09 18:26:24.027634 GPU 3 54856 test begin: paddle.nn.functional.upsample(Tensor([64, 96, 61, 11460],"float16"), size=list[122,122,], mode="nearest", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749464921 (unix time) try "date -d @1749464921" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd648) received by PID 54856 (TID 0x7fc1ecae8740) from PID 54856 ***]


2025-06-09 18:43:52.095738 GPU 3 63584 test begin: paddle.nn.functional.upsample(x=Tensor([1, 1073741825, 2, 2, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749465877 (unix time) try "date -d @1749465877" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf860) received by PID 63584 (TID 0x7fbfc5d13740) from PID 63584 ***]


2025-06-09 18:44:32.542700 GPU 2 65994 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 1073741825, 2, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749465917 (unix time) try "date -d @1749465917" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x101ca) received by PID 65994 (TID 0x7f38b3833740) from PID 65994 ***]


2025-06-09 18:45:09.473416 GPU 3 66404 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 2, 1073741825, 1],"float16"), size=Tensor([3],"float16"), scale_factor=None, mode="trilinear", align_corners=True, align_mode=1, data_format="NDHWC", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749465958 (unix time) try "date -d @1749465958" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10364) received by PID 66404 (TID 0x7f5648d7c740) from PID 66404 ***]


2025-06-09 18:48:37.800134 GPU 0 67435 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 2147483649, 1],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="bicubic", align_corners=False, align_mode=0, data_format="NHWC", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749466162 (unix time) try "date -d @1749466162" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1076b) received by PID 67435 (TID 0x7f5c2150c740) from PID 67435 ***]


2025-06-09 18:49:25.907708 GPU 0 69675 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 2147483649, 1],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="bilinear", align_corners=True, align_mode=1, data_format="NHWC", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749466215 (unix time) try "date -d @1749466215" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1102b) received by PID 69675 (TID 0x7f25ff6cc740) from PID 69675 ***]


2025-06-09 18:49:36.144357 GPU 2 69746 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2, 2147483649],"float16"), size=Tensor([1],"float16"), scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", )
[paddle error] paddle.nn.functional.upsample(x=Tensor([1, 2, 2147483649],"float16"), size=Tensor([1],"float16"), scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:50:46.752156 GPU 0 70059 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2147483649, 2, 1],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="bicubic", align_corners=False, align_mode=0, data_format="NHWC", )
W0609 18:52:31.276347 70059 backward.cc:441] While running Node (BicubicInterpGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.upsample(x=Tensor([1, 2147483649, 2, 1],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="bicubic", align_corners=False, align_mode=0, data_format="NHWC", ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:50:48.284728 GPU 1 66339 test begin: paddle.nn.functional.upsample(x=Tensor([1, 2147483649, 2, 1],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="bilinear", align_corners=True, align_mode=1, data_format="NHWC", )
W0609 18:52:34.280339 66339 backward.cc:441] While running Node (BilinearInterpGradNode) raises an EnforceNotMet exception
[paddle error] paddle.nn.functional.upsample(x=Tensor([1, 2147483649, 2, 1],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="bilinear", align_corners=True, align_mode=1, data_format="NHWC", ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:53:36.747262 GPU 0 70059 test begin: paddle.nn.functional.upsample(x=Tensor([2, 1, 285212673, 4],"float32"), size=Tensor([2],"float32"), scale_factor=None, mode="nearest", align_corners=False, align_mode=0, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749466436 (unix time) try "date -d @1749466436" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x111ab) received by PID 70059 (TID 0x7f98b2cb8740) from PID 70059 ***]


2025-06-09 18:53:37.351165 GPU 2 69746 test begin: paddle.nn.functional.upsample(x=Tensor([2, 1, 4, 285212673],"float32"), size=Tensor([2],"float32"), scale_factor=None, mode="nearest", align_corners=False, align_mode=0, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749466438 (unix time) try "date -d @1749466438" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11072) received by PID 69746 (TID 0x7f0bba27d740) from PID 69746 ***]


2025-06-09 18:54:24.520491 GPU 2 72281 test begin: paddle.nn.functional.upsample(x=Tensor([2, 1, 4, 536870913],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="nearest", align_corners=False, align_mode=0, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749466509 (unix time) try "date -d @1749466509" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11a59) received by PID 72281 (TID 0x7fca4f2bf740) from PID 72281 ***]


2025-06-09 18:54:27.665732 GPU 0 72420 test begin: paddle.nn.functional.upsample(x=Tensor([2, 1, 536870913, 4],"float16"), size=Tensor([2],"float16"), scale_factor=None, mode="nearest", align_corners=False, align_mode=0, data_format="NCHW", )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749466515 (unix time) try "date -d @1749466515" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11ae4) received by PID 72420 (TID 0x7feb87cf5740) from PID 72420 ***]


2025-06-09 18:55:18.915541 GPU 0 73383 test begin: paddle.nn.functional.upsample(x=Tensor([2147483649, 2, 1],"float16"), size=Tensor([1],"float16"), scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", )
[paddle error] paddle.nn.functional.upsample(x=Tensor([2147483649, 2, 1],"float16"), size=Tensor([1],"float16"), scale_factor=None, mode="linear", align_corners=False, align_mode=0, data_format="NWC", ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:57:03.075170 GPU 3 73667 test begin: paddle.outer(Tensor([22817014, 10, 10],"int32"), Tensor([2, 10],"int32"), )
[paddle error] paddle.outer(Tensor([22817014, 10, 10],"int32"), Tensor([2, 10],"int32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:57:30.363429 GPU 2 73508 test begin: paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([2, 1140850690],"int32"), )
[paddle error] paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([2, 1140850690],"int32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:57:39.183290 GPU 3 73667 test begin: paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([228170138, 10],"int32"), )
[paddle error] paddle.outer(Tensor([5, 10, 10],"int32"), Tensor([228170138, 10],"int32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:57:40.545018 GPU 3 73667 test begin: paddle.outer(Tensor([5, 10, 45634028],"int32"), Tensor([2, 10],"int32"), )
[paddle error] paddle.outer(Tensor([5, 10, 45634028],"int32"), Tensor([2, 10],"int32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 18:57:41.912118 GPU 3 73667 test begin: paddle.outer(Tensor([5, 45634028, 10],"int32"), Tensor([2, 10],"int32"), )
[paddle error] paddle.outer(Tensor([5, 45634028, 10],"int32"), Tensor([2, 10],"int32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:113)


2025-06-09 19:02:44.660074 GPU 1 66339 test begin: paddle.tensordot(Tensor([142606337, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), list[Tensor([2],"int64"),Tensor([2],"int64"),], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_matmul(_object*, _object*, _object*)
1   matmul_ad_func(paddle::Tensor const&, paddle::Tensor const&, bool, bool)
2   paddle::experimental::matmul(paddle::Tensor const&, paddle::Tensor const&, bool, bool)
3   void phi::MatmulKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, bool, bool, phi::DenseTensor*)
4   void phi::MatMulFunctionImplWithBlas<phi::GPUContext, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*, bool, bool, bool, phi::funcs::MatmulPlanner*)
5   phi::GPUContext::CublasCall(std::function<void (cublasContext*)> const&) const
6   std::once_flag::_Prepare_execution::_Prepare_execution<std::call_once<phi::GPUContext::Impl::CublasCall(std::function<void (cublasContext*)> const&)::{lambda()#1}>(std::once_flag&, phi::GPUContext::Impl::CublasCall(std::function<void (cublasContext*)> const&)::{lambda()#1}&&)::{lambda()#1}>(std::once_flag&)::{lambda()#1}::_FUN()
7   phi::InitBlasHandle(cublasContext**, CUstream_st*)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749466966 (unix time) try "date -d @1749466966" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x570) received by PID 66339 (TID 0x7f57b1064740) from PID 1392 ***]


2025-06-09 19:33:53.495370 GPU 0 79859 test begin: paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), list[Tensor([2],"int64"),Tensor([2281701379],"int64"),], )
[paddle error] paddle.tensordot(Tensor([3, 4, 4],"float32"), Tensor([4, 4, 5],"float32"), list[Tensor([2],"int64"),Tensor([2281701379],"int64"),], ) 
 index 2 is out of bounds for axis 0 with size 2

2025-06-09 19:33:56.684764 GPU 3 79497 test begin: paddle.topk(Tensor([1, 101, 22591103],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749469067 (unix time) try "date -d @1749469067" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13689) received by PID 79497 (TID 0x7efc3b8d9740) from PID 79497 ***]


2025-06-09 19:35:04.408497 GPU 0 79859 test begin: paddle.topk(Tensor([1, 102, 22369622],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749469132 (unix time) try "date -d @1749469132" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x137f3) received by PID 79859 (TID 0x7f12f43d0740) from PID 79859 ***]


2025-06-09 19:38:22.398758 GPU 3 80472 test begin: paddle.topk(Tensor([1, 105, 21730490],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749469403 (unix time) try "date -d @1749469403" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13a58) received by PID 80472 (TID 0x7f5a8d515740) from PID 80472 ***]


2025-06-09 19:39:26.759494 GPU 0 80778 test begin: paddle.topk(Tensor([1, 107, 21324312],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749469434 (unix time) try "date -d @1749469434" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13b8a) received by PID 80778 (TID 0x7f66554fb740) from PID 80778 ***]


2025-06-09 19:43:57.816063 GPU 3 81392 test begin: paddle.topk(Tensor([1, 14, 162978670],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   std::unique_ptr<egr::GradTensorHolder, std::default_delete<egr::GradTensorHolder> >::~unique_ptr()
3   phi::DenseTensor::~DenseTensor()
4   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
5   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749469726 (unix time) try "date -d @1749469726" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13df0) received by PID 81392 (TID 0x7f304199a740) from PID 81392 ***]


2025-06-09 19:44:28.817720 GPU 0 81426 test begin: paddle.topk(Tensor([1, 30182, 75600],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749469731 (unix time) try "date -d @1749469731" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x13e12) received by PID 81426 (TID 0x7f5197830740) from PID 81426 ***]


2025-06-09 19:48:56.456353 GPU 0 82040 test begin: paddle.topk(Tensor([1, 323371, 7056],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470007 (unix time) try "date -d @1749470007" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14078) received by PID 82040 (TID 0x7f78f26e8740) from PID 82040 ***]


2025-06-09 19:49:20.824610 GPU 3 82338 test begin: paddle.topk(Tensor([1, 34647, 65856],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470024 (unix time) try "date -d @1749470024" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x141a2) received by PID 82338 (TID 0x7f13206bf740) from PID 82338 ***]


2025-06-09 19:53:49.741861 GPU 3 82952 test begin: paddle.topk(Tensor([1, 56123, 40656],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470296 (unix time) try "date -d @1749470296" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14408) received by PID 82952 (TID 0x7fb6e820c740) from PID 82952 ***]


2025-06-09 19:54:01.072179 GPU 0 82982 test begin: paddle.topk(Tensor([1, 61595, 37044],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470329 (unix time) try "date -d @1749470329" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14426) received by PID 82982 (TID 0x7f78c5120740) from PID 82982 ***]


2025-06-09 19:58:49.245072 GPU 3 83605 test begin: paddle.topk(Tensor([1, 93991, 24276],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470600 (unix time) try "date -d @1749470600" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14695) received by PID 83605 (TID 0x7f6759558740) from PID 83605 ***]


2025-06-09 19:59:24.471527 GPU 0 83905 test begin: paddle.topk(Tensor([1022, 2232585],"float32"), 10, axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_topk(_object*, _object*, _object*)
1   topk_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, int, bool, bool)
2   paddle::experimental::topk(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, int, bool, bool)
3   void phi::TopkKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470539 (unix time) try "date -d @1749470539" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x147c1) received by PID 83905 (TID 0x7f749f656740) from PID 83905 ***]


2025-06-09 20:02:51.862906 GPU 0 84241 test begin: paddle.topk(Tensor([10612565, 215],"float32"), 10, axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_topk(_object*, _object*, _object*)
1   topk_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, int, bool, bool)
2   paddle::experimental::topk(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, int, bool, bool)
3   void phi::TopkKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470759 (unix time) try "date -d @1749470759" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14911) received by PID 84241 (TID 0x7f23930bd740) from PID 84241 ***]


2025-06-09 20:03:12.503849 GPU 2 84544 test begin: paddle.topk(Tensor([10737419, 400],"float16"), k=5, )
[paddle error] paddle.topk(Tensor([10737419, 400],"float16"), k=5, ) 
 Cannot generate 4294967600 unique items of type float16 within the range.

2025-06-09 20:03:15.072736 GPU 1 84567 test begin: paddle.topk(Tensor([12906, 176794],"float32"), 10, axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_topk(_object*, _object*, _object*)
1   topk_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, int, bool, bool)
2   paddle::experimental::topk(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, int, bool, bool)
3   void phi::TopkKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470783 (unix time) try "date -d @1749470783" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14a57) received by PID 84567 (TID 0x7fe7070f4740) from PID 84567 ***]


2025-06-09 20:03:15.570239 GPU 2 84544 test begin: paddle.topk(Tensor([1302, 1752459],"float32"), 10, axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_topk(_object*, _object*, _object*)
1   topk_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, int, bool, bool)
2   paddle::experimental::topk(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, int, bool, bool)
3   void phi::TopkKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470785 (unix time) try "date -d @1749470785" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14a40) received by PID 84544 (TID 0x7f5626861740) from PID 84544 ***]


2025-06-09 20:03:55.193518 GPU 3 84611 test begin: paddle.topk(Tensor([14, 306783379],"float16"), k=5, )
[paddle error] paddle.topk(Tensor([14, 306783379],"float16"), k=5, ) 
 Cannot generate 4294967306 unique items of type float16 within the range.

2025-06-09 20:03:58.277718 GPU 3 84611 test begin: paddle.topk(Tensor([14877, 153372],"float32"), 10, axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_topk(_object*, _object*, _object*)
1   topk_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, int, bool, bool)
2   paddle::experimental::topk(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, int, bool, bool)
3   void phi::TopkKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470821 (unix time) try "date -d @1749470821" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14a83) received by PID 84611 (TID 0x7f6f35079740) from PID 84611 ***]


2025-06-09 20:06:27.501523 GPU 1 84937 test begin: paddle.topk(Tensor([1490, 1531344],"float32"), 10, axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_topk(_object*, _object*, _object*)
1   topk_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, int, bool, bool)
2   paddle::experimental::topk(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, int, bool, bool)
3   void phi::TopkKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749470979 (unix time) try "date -d @1749470979" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14bc9) received by PID 84937 (TID 0x7fdb60a52740) from PID 84937 ***]


2025-06-09 20:06:29.092791 GPU 2 84958 test begin: paddle.topk(Tensor([15548, 146753],"float32"), k=3, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471073 (unix time) try "date -d @1749471073" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14bde) received by PID 84958 (TID 0x7f8dbcf79740) from PID 84958 ***]


2025-06-09 20:06:32.774359 GPU 0 84994 test begin: paddle.topk(Tensor([16, 10, 14260634],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471077 (unix time) try "date -d @1749471077" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14c02) received by PID 84994 (TID 0x7f4b44370740) from PID 84994 ***]


2025-06-09 20:07:35.327774 GPU 3 85300 test begin: paddle.topk(Tensor([16, 13, 10969719],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471129 (unix time) try "date -d @1749471129" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14d34) received by PID 85300 (TID 0x7fcb80de9740) from PID 85300 ***]


2025-06-09 20:10:13.316528 GPU 1 85627 test begin: paddle.topk(Tensor([16, 14, 10186167],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471297 (unix time) try "date -d @1749471297" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14e7b) received by PID 85627 (TID 0x7fcd1c604740) from PID 85627 ***]


2025-06-09 20:11:23.456837 GPU 0 85968 test begin: paddle.topk(Tensor([16, 15474, 9216],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471390 (unix time) try "date -d @1749471390" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14fd0) received by PID 85968 (TID 0x7fd70e774740) from PID 85968 ***]


2025-06-09 20:11:48.664926 GPU 2 86001 test begin: paddle.topk(Tensor([16, 24690, 5776],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471392 (unix time) try "date -d @1749471392" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x14ff1) received by PID 86001 (TID 0x7faf99a52740) from PID 86001 ***]


2025-06-09 20:12:44.933181 GPU 3 86041 test begin: paddle.topk(Tensor([16, 268435457],"float16"), k=5, )
[paddle error] paddle.topk(Tensor([16, 268435457],"float16"), k=5, ) 
 Cannot generate 4294967312 unique items of type float16 within the range.

2025-06-09 20:12:47.826880 GPU 3 86041 test begin: paddle.topk(Tensor([16, 39613, 3600],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471463 (unix time) try "date -d @1749471463" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15019) received by PID 86041 (TID 0x7fc156e8a740) from PID 86041 ***]


2025-06-09 20:15:32.158392 GPU 1 86641 test begin: paddle.topk(Tensor([16, 73661, 1936],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471609 (unix time) try "date -d @1749471609" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15271) received by PID 86641 (TID 0x7fe1648c8740) from PID 86641 ***]


2025-06-09 20:17:05.154582 GPU 0 86716 test begin: paddle.topk(Tensor([1680193, 1358],"float32"), k=3, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471706 (unix time) try "date -d @1749471706" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x152bc) received by PID 86716 (TID 0x7f476b9d2740) from PID 86716 ***]


2025-06-09 20:18:17.644370 GPU 3 87023 test begin: paddle.topk(Tensor([23098, 14, 7056],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471780 (unix time) try "date -d @1749471780" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x153ef) received by PID 87023 (TID 0x7fdd1fd33740) from PID 87023 ***]


2025-06-09 20:20:44.043224 GPU 1 87348 test begin: paddle.topk(Tensor([24759, 10, 9216],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471918 (unix time) try "date -d @1749471918" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15534) received by PID 87348 (TID 0x7f8ef7ba9740) from PID 87348 ***]


2025-06-09 20:21:21.620606 GPU 2 86682 test begin: paddle.topk(Tensor([26736, 85342],"float32"), k=3, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749471876 (unix time) try "date -d @1749471876" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1529a) received by PID 86682 (TID 0x7f9b2f5f9740) from PID 86682 ***]


2025-06-09 20:22:22.228571 GPU 0 87662 test begin: paddle.topk(Tensor([28217, 14, 5776],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472050 (unix time) try "date -d @1749472050" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1566e) received by PID 87662 (TID 0x7f6b22d0d740) from PID 87662 ***]


2025-06-09 20:23:34.948454 GPU 3 87970 test begin: paddle.topk(Tensor([288, 105, 75600],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472105 (unix time) try "date -d @1749472105" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x157a2) received by PID 87970 (TID 0x7f866dd6f740) from PID 87970 ***]


2025-06-09 20:25:11.022177 GPU 2 88283 test begin: paddle.topk(Tensor([32, 134217729],"float16"), k=5, )
[paddle error] paddle.topk(Tensor([32, 134217729],"float16"), k=5, ) 
 Cannot generate 4294967328 unique items of type float16 within the range.

2025-06-09 20:25:53.117546 GPU 1 88321 test begin: paddle.topk(Tensor([340, 102, 65856],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472232 (unix time) try "date -d @1749472232" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15901) received by PID 88321 (TID 0x7fe567153740) from PID 88321 ***]


2025-06-09 20:28:05.350760 GPU 0 88642 test begin: paddle.topk(Tensor([48755, 13, 3600],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472368 (unix time) try "date -d @1749472368" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15a42) received by PID 88642 (TID 0x7fb58d586740) from PID 88642 ***]


2025-06-09 20:29:00.899932 GPU 3 88682 test begin: paddle.topk(Tensor([5432623, 420],"float32"), 10, axis=0, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_topk(_object*, _object*, _object*)
1   topk_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, int, bool, bool)
2   paddle::experimental::topk(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, int, bool, bool)
3   void phi::TopkKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472352 (unix time) try "date -d @1749472352" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15a6a) received by PID 88682 (TID 0x7f5875b20740) from PID 88682 ***]


2025-06-09 20:30:15.021351 GPU 2 88283 test begin: paddle.topk(Tensor([556, 101, 40656],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472416 (unix time) try "date -d @1749472416" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x158db) received by PID 88283 (TID 0x7f676a11e740) from PID 88283 ***]


2025-06-09 20:31:08.264766 GPU 1 89000 test begin: paddle.topk(Tensor([604, 102, 37044],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472552 (unix time) try "date -d @1749472552" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15ba8) received by PID 89000 (TID 0x7ff24cee9740) from PID 89000 ***]


2025-06-09 20:32:53.861771 GPU 0 89316 test begin: paddle.topk(Tensor([6684, 341368],"float32"), k=3, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472662 (unix time) try "date -d @1749472662" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15ce4) received by PID 89316 (TID 0x7f6600697740) from PID 89316 ***]


2025-06-09 20:33:04.196371 GPU 3 89346 test begin: paddle.topk(Tensor([753286, 3029],"float32"), k=3, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472670 (unix time) try "date -d @1749472670" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15d02) received by PID 89346 (TID 0x7f1116489740) from PID 89346 ***]


2025-06-09 20:34:11.655749 GPU 2 89666 test begin: paddle.topk(Tensor([84184, 14, 1936],"float32"), 9, axis=-1, largest=False, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472723 (unix time) try "date -d @1749472723" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15e42) received by PID 89666 (TID 0x7fc098e27740) from PID 89666 ***]


2025-06-09 20:36:25.680908 GPU 1 89988 test begin: paddle.topk(Tensor([879, 107, 24276],"float32"), 13, axis=-1, largest=True, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   phi::DenseTensor::~DenseTensor()
1   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
2   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472863 (unix time) try "date -d @1749472863" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x15f84) received by PID 89988 (TID 0x7fb94b94b740) from PID 89988 ***]


2025-06-09 20:39:18.177606 GPU 2 90642 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([1014090, 5, 5, 5],"float32"), offset=Tensor([1014090, 90, 5, 5],"float32"), mask=Tensor([1014090, 45, 5, 5],"float32"), weight=Tensor([5, 5, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=5, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472875 (unix time) try "date -d @1749472875" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16212) received by PID 90642 (TID 0x7f0e97e6a740) from PID 90642 ***]


2025-06-09 20:39:31.676522 GPU 0 90334 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([14084577, 2, 5, 5],"float32"), offset=Tensor([14084577, 18, 3, 3],"float32"), mask=Tensor([14084577, 9, 3, 3],"float32"), weight=Tensor([5, 2, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[0,0,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473662 (unix time) try "date -d @1749473662" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x160de) received by PID 90334 (TID 0x7f24fb207740) from PID 90334 ***]


2025-06-09 20:39:49.560774 GPU 3 90302 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([14084577, 3, 5, 5],"float32"), offset=Tensor([14084577, 18, 3, 3],"float32"), mask=Tensor([14084577, 9, 3, 3],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473599 (unix time) try "date -d @1749473599" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x160be) received by PID 90302 (TID 0x7fc67d617740) from PID 90302 ***]


2025-06-09 20:42:21.367697 GPU 2 90962 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([18253612, 5, 5, 5],"float32"), offset=Tensor([4, 18, 5, 5],"float32"), mask=Tensor([4, 9, 5, 5],"float32"), weight=Tensor([5, 1, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=5, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472952 (unix time) try "date -d @1749472952" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16352) received by PID 90962 (TID 0x7fe13af15740) from PID 90962 ***]


2025-06-09 20:42:29.520883 GPU 1 90994 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([18253612, 5, 5, 5],"float32"), offset=Tensor([4, 90, 5, 5],"float32"), mask=Tensor([4, 45, 5, 5],"float32"), weight=Tensor([5, 5, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=5, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749472952 (unix time) try "date -d @1749472952" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16372) received by PID 90994 (TID 0x7fcb3e500740) from PID 90994 ***]


2025-06-09 20:43:54.010602 GPU 1 91036 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([2586964, 3, 5, 5],"float32"), offset=Tensor([2586964, 18, 7, 7],"float32"), mask=Tensor([2586964, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473193 (unix time) try "date -d @1749473193" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1639c) received by PID 91036 (TID 0x7fe5a219d740) from PID 91036 ***]


2025-06-09 20:44:09.079153 GPU 2 91070 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([2586964, 3, 5, 5],"float32"), offset=Tensor([2586964, 18, 7, 7],"float32"), mask=Tensor([2586964, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473211 (unix time) try "date -d @1749473211" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x163be) received by PID 91070 (TID 0x7f9612779740) from PID 91070 ***]


2025-06-09 20:47:47.711426 GPU 2 91676 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([30422686, 3, 5, 5],"float32"), offset=Tensor([30422686, 18, 1, 1],"float32"), mask=Tensor([30422686, 9, 1, 1],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[3,3,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749474587 (unix time) try "date -d @1749474587" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1661c) received by PID 91676 (TID 0x7f88b0659740) from PID 91676 ***]


2025-06-09 20:48:08.172385 GPU 1 91706 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([30422686, 3, 5, 5],"float32"), offset=Tensor([4, 18, 1, 1],"float32"), mask=Tensor([4, 9, 1, 1],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[3,3,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473374 (unix time) try "date -d @1749473374" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1663a) received by PID 91706 (TID 0x7fe2fdfb3740) from PID 91706 ***]


2025-06-09 20:50:05.555131 GPU 1 92302 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([30422686, 3, 5, 5],"float32"), offset=Tensor([4, 18, 3, 3],"float32"), mask=Tensor([4, 9, 3, 3],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[2,2,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473495 (unix time) try "date -d @1749473495" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1688e) received by PID 92302 (TID 0x7fcb7c42b740) from PID 92302 ***]


2025-06-09 20:52:08.079519 GPU 1 92620 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([30422686, 3, 5, 5],"float32"), offset=Tensor([4, 18, 5, 7],"float32"), mask=Tensor([4, 9, 5, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473584 (unix time) try "date -d @1749473584" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x169cc) received by PID 92620 (TID 0x7f99f586c740) from PID 92620 ***]


2025-06-09 20:53:22.963897 GPU 3 92929 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([30422686, 3, 5, 5],"float32"), offset=Tensor([4, 18, 7, 7],"float32"), mask=Tensor([4, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473659 (unix time) try "date -d @1749473659" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16b01) received by PID 92929 (TID 0x7f99c8f78740) from PID 92929 ***]


2025-06-09 20:53:35.886990 GPU 1 92960 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([30422686, 3, 5, 5],"float32"), offset=Tensor([4, 18, 7, 7],"float32"), mask=Tensor([4, 9, 7, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[2,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473684 (unix time) try "date -d @1749473684" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16b20) received by PID 92960 (TID 0x7f076bdba740) from PID 92960 ***]


2025-06-09 20:54:29.463914 GPU 0 92999 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([3621749, 3, 5, 5],"float32"), offset=Tensor([3621749, 18, 5, 7],"float32"), mask=Tensor([3621749, 9, 5, 7],"float32"), weight=Tensor([5, 3, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,2,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473965 (unix time) try "date -d @1749473965" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16b47) received by PID 92999 (TID 0x7f2e3e8ed740) from PID 92999 ***]


2025-06-09 20:55:58.433755 GPU 3 93062 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([4, 22817014, 5, 5],"float32"), offset=Tensor([4, 18, 3, 3],"float32"), mask=Tensor([4, 9, 3, 3],"float32"), weight=Tensor([5, 22817014, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[0,0,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473760 (unix time) try "date -d @1749473760" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16b86) received by PID 93062 (TID 0x7f95f89cf740) from PID 93062 ***]


2025-06-09 20:58:03.733862 GPU 3 93378 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([45634028, 2, 5, 5],"float32"), offset=Tensor([4, 18, 3, 3],"float32"), mask=Tensor([4, 9, 3, 3],"float32"), weight=Tensor([5, 2, 3, 3],"float32"), bias=None, stride=list[1,1,], padding=list[0,0,], dilation=list[1,1,], deformable_groups=1, groups=1, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_deformable_conv(_object*, _object*, _object*)
1   deformable_conv_ad_func(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, int, int, int)
2   paddle::experimental::deformable_conv(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int)
3   void phi::DeformableConvKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*)
4   phi::DenseTensor::~DenseTensor()
5   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
6   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749473911 (unix time) try "date -d @1749473911" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16cc2) received by PID 93378 (TID 0x7f510050e740) from PID 93378 ***]


2025-06-09 20:58:04.404059 GPU 1 93033 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([5070448, 5, 5, 5],"float32"), offset=Tensor([5070448, 18, 5, 5],"float32"), mask=Tensor([5070448, 9, 5, 5],"float32"), weight=Tensor([5, 1, 3, 3],"float32"), bias=Tensor([5],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=5, )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749474406 (unix time) try "date -d @1749474406" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16b69) received by PID 93033 (TID 0x7f1a53881740) from PID 93033 ***]


2025-06-09 20:59:59.654836 GPU 3 93702 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([863, 64, 152, 272],"float32"), offset=Tensor([20, 18, 152, 272],"float32"), weight=Tensor([64, 64, 3, 3],"float32"), bias=Tensor([64],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([20, 9, 152, 272],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749474003 (unix time) try "date -d @1749474003" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16e06) received by PID 93702 (TID 0x7f9a69d85740) from PID 93702 ***]


2025-06-09 21:00:34.653702 GPU 3 94043 test begin: paddle.vision.ops.deform_conv2d(x=Tensor([863, 64, 152, 272],"float32"), offset=Tensor([863, 18, 152, 272],"float32"), weight=Tensor([64, 64, 3, 3],"float32"), bias=Tensor([64],"float32"), stride=list[1,1,], padding=list[1,1,], dilation=list[1,1,], deformable_groups=1, groups=1, mask=Tensor([863, 9, 152, 272],"float32"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   DeformableConvGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::deformable_conv_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::optional<paddle::Tensor> const&, paddle::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*, paddle::Tensor*)
4   void phi::DeformableConvGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, paddle::optional<phi::DenseTensor> const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, int, int, int, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DenseTensor::~DenseTensor()
6   std::_Sp_counted_deleter<phi::Allocation*, std::function<void (phi::Allocation*)>, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
7   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1749474103 (unix time) try "date -d @1749474103" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x16f5b) received by PID 94043 (TID 0x7f8b8c93f740) from PID 94043 ***]


