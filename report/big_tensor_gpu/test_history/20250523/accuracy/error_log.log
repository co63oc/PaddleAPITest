[Worker 3] Processing Task 151: paddle.bmm(x=Tensor([2, 380283564, 3],"float32"), y=Tensor([2, 3, 2],"float32"), )
[accuracy error] backward  paddle.bmm(x=Tensor([2, 380283564, 3],"float32"), y=Tensor([2, 3, 2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 12 / 12 (100.0%)
Greatest absolute difference: 2318.46826171875 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.24659264087677 at index (1, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 2]), dtype=torch.float32)
All elements: tensor([ 1827.5634,    16.2143,  2015.5171,  -399.0278,  -786.0734,   -57.1531,
         -547.2297,  1786.6112,  -399.4922,   303.9944,  1050.1431, -2192.8596])
DESIRED: (shape=torch.Size([2, 3, 2]), dtype=torch.float32)
All elements: tensor([ 4146.0317,   844.8246,  4028.9153,  -692.1207, -2507.9585,  -359.3054,
         -243.5821,  3473.0830, -2452.3967,  1383.2056,  2332.8250, -3996.1948])
[Worker 3] Completed Task 151

[Worker 3] Processing Task 189: paddle.conj(Tensor([2, 20, 35791395, 3],"float32"), )
W0522 15:55:15.497982 42881 backward.cc:441] While running Node (ConjGradNode) raises a std::exception: paddle::memory::allocation::BadAlloc
[paddle error] paddle.conj(Tensor([2, 20, 35791395, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   ConjGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::conj(paddle::Tensor const&)
4   void phi::ConjKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.012695GB memory has been allocated and available memory is only 13.172180GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 189

[Worker 3] Processing Task 194: paddle.cumsum(Tensor([1, 2281701379],"float32"), axis=-1, )
[accuracy error] paddle.cumsum(Tensor([1, 2281701379],"float32"), axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 524160 / 2281701379 (0.0%)
Greatest absolute difference: 0.08074522018432617 at index (0, 2082238020) (up to 0.01 allowed)
Greatest relative difference: 73370.875 at index (0, 1264702708) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 0.4754,  0.8021,  1.0703,  0.7898,  0.9567,  1.2769,  1.7405,  1.6630,
         1.6348,  1.3342,  1.4839,  1.0757,  0.5921,  0.2263,  0.5250,  0.4458,
         0.7628,  0.4014,  0.4077,  0.6876,  0.5260,  0.1703,  0.4027,  0.2401,
         0.0364,  0.0519, -0.3756, -0.5048, -0.5550, -0.5126, -0.9805, -1.3724,
        -1.3155, -1.6199, -1.7521, -1.8266, -1.3461, -1.6110, -1.9358, -1.8828,
        -1.9564, -2.3084, -2.2998, -1.8821, -1.5018, -1.9781, -2.4278, -2.3035,
        -1.9111, -2.1068, -1.6388, -1.9804, -2.2351, -2.6316, -2.7072, -2.6665,
        -2.8311, -2.7608, -2.5419, -2.5425, -2.2405, -2.6806, -2.7779, -2.3434,
        -2.6514, -2.5331, -2.6804, -3.0305, -3.4300, -3.6928, -3.6145, -4.0064,
        -4.4035, -4.1682, -3.8057, -3.3246, -3.6823, -3.4429, -3.7595, -3.5186,
        -3.9722, -4.0520, -4.3135, -3.8428, -4.0276, -3.9352, -3.8931, -4.0678,
        -3.7837, -3.8590, -3.9445, -4.2279, -3.7747, -3.9230, -3.5679, -3.4004,
        -3.0890, -2.8909, -2.6452, -2.4406])
DESIRED: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 0.4754,  0.8021,  1.0703,  0.7898,  0.9567,  1.2769,  1.7405,  1.6630,
         1.6348,  1.3342,  1.4839,  1.0757,  0.5921,  0.2263,  0.5250,  0.4458,
         0.7628,  0.4014,  0.4077,  0.6876,  0.5260,  0.1703,  0.4027,  0.2401,
         0.0364,  0.0519, -0.3756, -0.5048, -0.5550, -0.5126, -0.9805, -1.3724,
        -1.3155, -1.6199, -1.7521, -1.8266, -1.3461, -1.6110, -1.9358, -1.8828,
        -1.9564, -2.3084, -2.2998, -1.8821, -1.5018, -1.9781, -2.4278, -2.3035,
        -1.9111, -2.1068, -1.6388, -1.9804, -2.2351, -2.6316, -2.7072, -2.6665,
        -2.8311, -2.7608, -2.5419, -2.5425, -2.2405, -2.6806, -2.7779, -2.3434,
        -2.6514, -2.5331, -2.6804, -3.0305, -3.4300, -3.6928, -3.6145, -4.0064,
        -4.4035, -4.1682, -3.8057, -3.3246, -3.6823, -3.4429, -3.7595, -3.5186,
        -3.9722, -4.0520, -4.3135, -3.8428, -4.0276, -3.9352, -3.8931, -4.0678,
        -3.7837, -3.8590, -3.9445, -4.2279, -3.7747, -3.9230, -3.5679, -3.4004,
        -3.0890, -2.8909, -2.6452, -2.4406])
[Worker 3] Completed Task 194

[Worker 3] Processing Task 195: paddle.cumsum(Tensor([2281701379],"float32"), axis=0, )
[accuracy error] paddle.cumsum(Tensor([2281701379],"float32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 13607 / 2281701379 (0.0%)
Greatest absolute difference: 0.016071557998657227 at index (2053659143,) (up to 0.01 allowed)
Greatest relative difference: 465.3633117675781 at index (2053632914,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 0.4754,  0.8021,  1.0703,  0.7898,  0.9567,  1.2769,  1.7405,  1.6630,
         1.6348,  1.3342,  1.4839,  1.0757,  0.5921,  0.2263,  0.5250,  0.4458,
         0.7628,  0.4014,  0.4077,  0.6876,  0.5260,  0.1703,  0.4027,  0.2401,
         0.0364,  0.0519, -0.3756, -0.5048, -0.5550, -0.5126, -0.9805, -1.3724,
        -1.3155, -1.6199, -1.7521, -1.8266, -1.3461, -1.6110, -1.9358, -1.8828,
        -1.9564, -2.3084, -2.2998, -1.8821, -1.5018, -1.9781, -2.4278, -2.3035,
        -1.9111, -2.1068, -1.6388, -1.9804, -2.2351, -2.6316, -2.7072, -2.6665,
        -2.8311, -2.7608, -2.5419, -2.5425, -2.2405, -2.6806, -2.7779, -2.3434,
        -2.6514, -2.5331, -2.6804, -3.0305, -3.4300, -3.6928, -3.6145, -4.0064,
        -4.4035, -4.1682, -3.8057, -3.3246, -3.6823, -3.4429, -3.7595, -3.5186,
        -3.9722, -4.0520, -4.3135, -3.8428, -4.0276, -3.9352, -3.8931, -4.0678,
        -3.7837, -3.8590, -3.9445, -4.2279, -3.7747, -3.9230, -3.5679, -3.4004,
        -3.0890, -2.8909, -2.6452, -2.4406])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 0.4754,  0.8021,  1.0703,  0.7898,  0.9567,  1.2769,  1.7405,  1.6630,
         1.6348,  1.3342,  1.4839,  1.0757,  0.5921,  0.2263,  0.5250,  0.4458,
         0.7628,  0.4014,  0.4077,  0.6876,  0.5260,  0.1703,  0.4027,  0.2401,
         0.0364,  0.0519, -0.3756, -0.5048, -0.5550, -0.5126, -0.9805, -1.3724,
        -1.3155, -1.6199, -1.7521, -1.8266, -1.3461, -1.6110, -1.9358, -1.8828,
        -1.9564, -2.3084, -2.2998, -1.8821, -1.5018, -1.9781, -2.4278, -2.3035,
        -1.9111, -2.1068, -1.6388, -1.9804, -2.2351, -2.6316, -2.7072, -2.6665,
        -2.8311, -2.7608, -2.5419, -2.5425, -2.2405, -2.6806, -2.7779, -2.3434,
        -2.6514, -2.5331, -2.6804, -3.0305, -3.4300, -3.6928, -3.6145, -4.0064,
        -4.4035, -4.1682, -3.8057, -3.3246, -3.6823, -3.4429, -3.7595, -3.5186,
        -3.9722, -4.0520, -4.3135, -3.8428, -4.0276, -3.9352, -3.8931, -4.0678,
        -3.7837, -3.8590, -3.9445, -4.2279, -3.7747, -3.9230, -3.5679, -3.4004,
        -3.0890, -2.8909, -2.6452, -2.4406])
[Worker 3] Completed Task 195

[Worker 3] Processing Task 200: paddle.diff(Tensor([2, 1140850690],"float32"), n=2, axis=0, prepend=Tensor([2, 1140850690],"float32"), append=None, )
[accuracy error] paddle.diff(Tensor([2, 1140850690],"float32"), n=2, axis=0, prepend=Tensor([2, 1140850690],"float32"), append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258710904 / 2281701380 (99.0%)
Greatest absolute difference: 1.9999357461929321 at index (0, 791934076) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([ 5.1477e-01,  1.3119e+00,  4.2671e-01, -1.3204e+00, -1.9798e-01,
         3.0366e-01,  4.8954e-01, -3.8868e-01,  3.9310e-01, -1.4530e-01,
         8.9739e-01, -5.3229e-02, -9.0807e-02, -1.6804e+00,  3.7512e-01,
         6.2116e-01,  1.5543e+00, -6.5610e-01, -4.8552e-01, -2.9047e-01,
        -8.8030e-01, -8.2230e-01,  1.2434e+00, -4.4622e-01, -1.1586e+00,
         6.6087e-01, -1.2492e+00,  1.7980e-01,  5.6211e-01, -1.3373e-01,
        -4.0487e-01,  1.4454e-01,  4.0533e-01, -1.1281e+00, -9.5656e-01,
         7.6438e-01,  6.5780e-01,  2.3197e-02, -5.7522e-01,  1.0928e+00,
        -9.3879e-01, -2.4586e-01, -2.5415e-01,  1.6899e+00, -1.1618e-02,
        -6.1016e-01, -1.7320e+00,  1.2770e-01,  1.6232e+00, -3.0493e-01,
         1.4659e+00,  6.0424e-02,  4.8442e-01, -7.6002e-01, -8.9348e-02,
        -1.2151e-01, -2.8831e-01,  2.6240e-01,  1.1992e+00, -5.2103e-01,
         9.7173e-01,  2.4753e-02,  6.5571e-01,  1.0046e+00, -1.4034e+00,
         1.1817e+00, -9.3974e-01, -1.0182e+00, -4.7606e-01, -7.1871e-01,
         4.8809e-01, -3.9809e-01,  5.3751e-02,  3.2735e-01,  9.8070e-01,
         3.2496e-01, -1.2938e+00,  3.0577e-05, -1.1897e+00,  1.2505e+00,
        -1.6622e+00, -1.0222e+00, -1.5937e-01,  5.9521e-01,  5.1108e-01,
        -1.9762e-01, -8.6426e-01, -7.4356e-01,  1.2743e-01,  3.1323e-01,
        -1.0115e+00, -4.8087e-01,  6.5969e-01, -4.8942e-01,  4.2149e-02,
        -1.9981e-01,  2.4136e-01,  8.2870e-01,  2.8256e-02,  8.1142e-01])
[Worker 3] Completed Task 200

[Worker 3] Processing Task 202: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([570425345, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([570425345, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235846205 / 2281701392 (98.0%)
Greatest absolute difference: 0.9999727606773376 at index (241375351, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425348, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425348, 4]), dtype=torch.float32)
First 100 elements: tensor([-0.3085, -0.0065,  0.1955,  0.2029,  0.3085,  0.0065, -0.1955, -0.2029,
        -0.3085, -0.0065,  0.1955,  0.2029,  0.3085,  0.0065, -0.1955, -0.2029,
        -0.3085, -0.0065,  0.1955,  0.2029, -0.1950, -0.6208, -0.3139, -0.3307,
        -0.4555, -0.0651,  0.1490,  0.3291,  0.8006,  0.0044, -0.2924,  0.3591,
        -0.4786,  0.0058,  0.2261, -0.4426, -0.0421,  0.3712, -0.6599,  0.0334,
         0.1535,  0.0269, -0.0404, -0.2627,  0.1071, -0.3469,  0.3357,  0.3174,
         0.4237,  0.0395, -0.1927,  0.1275, -0.5541, -0.0871,  0.3334,  0.3647,
         0.4538, -0.1243, -0.4582, -0.2935,  0.0121,  0.2805,  0.9178, -0.4659,
        -0.6471, -0.2008, -0.5437,  0.3823,  0.0901,  0.4668,  0.2945, -0.0413,
         0.4666, -0.5104, -0.3162,  0.4351, -0.6099,  0.5584, -0.0500, -0.7846,
        -0.0915, -0.3811,  0.2256, -0.0418,  0.0024,  0.4982,  0.2842,  0.8729,
         0.0394,  0.0041, -0.6792, -0.2401, -0.0959, -0.3192,  0.0551,  0.2298,
         0.2687,  0.1723,  0.3036, -0.6454])
[Worker 3] Completed Task 202

[Worker 3] Processing Task 206: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([570425345, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([570425345, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258649110 / 2281701388 (99.0%)
Greatest absolute difference: 1.99796462059021 at index (460321192, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([ 6.1705e-01,  1.2998e-02, -3.9091e-01, -4.0585e-01, -6.1705e-01,
        -1.2998e-02,  3.9091e-01,  4.0585e-01,  6.1705e-01,  1.2998e-02,
        -3.9091e-01, -4.0585e-01, -6.1705e-01, -1.2998e-02,  3.9091e-01,
         4.0585e-01,  1.1350e-01, -6.1433e-01, -5.0936e-01, -5.3361e-01,
        -2.6043e-01,  5.5568e-01,  4.6286e-01,  6.5981e-01,  1.2560e+00,
         6.9515e-02, -4.4140e-01,  3.0012e-02, -1.2792e+00,  1.3993e-03,
         5.1853e-01, -8.0169e-01,  4.3654e-01,  3.6547e-01, -8.8596e-01,
         4.7593e-01,  1.9561e-01, -3.4433e-01,  6.1948e-01, -2.9607e-01,
        -4.6425e-02, -3.7379e-01,  3.7614e-01,  5.8011e-01,  3.1658e-01,
         3.8641e-01, -5.2842e-01, -1.8987e-01, -9.7775e-01, -1.2662e-01,
         5.2606e-01,  2.3719e-01,  1.0079e+00, -3.7172e-02, -7.9164e-01,
        -6.5819e-01, -4.4169e-01,  4.0480e-01,  1.3760e+00, -1.7240e-01,
        -6.5925e-01, -4.8131e-01, -1.4614e+00,  8.4821e-01,  7.3729e-01,
         6.6752e-01,  8.3816e-01, -4.2366e-01,  3.7647e-01, -9.7711e-01,
        -6.1073e-01,  4.7638e-01, -1.0765e+00,  1.0687e+00,  2.6625e-01,
        -1.2196e+00,  5.1837e-01, -9.3947e-01,  2.7557e-01,  7.4279e-01,
         9.3927e-02,  8.7927e-01,  5.8653e-02,  9.1472e-01,  3.7049e-02,
        -4.9409e-01, -9.6342e-01, -1.1130e+00, -1.3534e-01, -3.2328e-01,
         7.3431e-01,  4.6988e-01,  3.6461e-01,  4.9151e-01,  2.4847e-01,
        -8.7521e-01,  2.0028e-01, -3.4007e-01, -4.3120e-01,  5.3669e-01])
[Worker 3] Completed Task 206

[Worker 3] Processing Task 210: paddle.diff(Tensor([2281701379],"float32"), n=1, axis=-1, prepend=None, append=None, )
[accuracy error] paddle.diff(Tensor([2281701379],"float32"), n=1, axis=-1, prepend=None, append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235830450 / 2281701378 (98.0%)
Greatest absolute difference: 0.9999680519104004 at index (944879172,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([-0.1488, -0.0585, -0.5487,  0.4474,  0.1533,  0.1435, -0.5412,  0.0495,
        -0.2725,  0.4504, -0.5580, -0.0753,  0.1178,  0.6645, -0.3779,  0.3961,
        -0.6784,  0.3677,  0.2737, -0.4416, -0.1940,  0.5880, -0.3949, -0.0412,
         0.2193, -0.4431,  0.2983,  0.0790,  0.0927, -0.5104,  0.0760,  0.4488,
        -0.3613,  0.1722,  0.0577,  0.5550, -0.7454, -0.0599,  0.3779, -0.1266,
        -0.2784,  0.3605,  0.4092, -0.0375, -0.8565,  0.0266,  0.5740,  0.2681,
        -0.5881,  0.6638, -0.8097,  0.0868, -0.1417,  0.3209,  0.1163, -0.2054,
         0.2349,  0.1486, -0.2195,  0.3025, -0.7421,  0.3428,  0.5318, -0.7424,
         0.4262, -0.2656, -0.2028, -0.0494,  0.1366,  0.3411, -0.4702, -0.0052,
         0.6324,  0.1272,  0.1185, -0.8387,  0.5970, -0.5560,  0.5576, -0.6945,
         0.3737, -0.1817,  0.7322, -0.6556,  0.2773, -0.0504, -0.2168,  0.4589,
        -0.3594, -0.0102, -0.1979,  0.7366, -0.6015,  0.5034, -0.1876,  0.1439,
        -0.1133,  0.0476, -0.0412, -0.4177])
[Worker 3] Completed Task 210

[Worker 3] Processing Task 214: paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4471692390 / 4563402756 (98.0%)
Greatest absolute difference: 0.9999727606773376 at index (241375347, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1140850689, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([1140850689, 4]), dtype=torch.float32)
First 100 elements: tensor([-0.3085, -0.0065,  0.1955,  0.2029, -0.1950, -0.6208, -0.3139, -0.3307,
        -0.4555, -0.0651,  0.1490,  0.3291,  0.8006,  0.0044, -0.2924,  0.3591,
        -0.4786,  0.0058,  0.2261, -0.4426, -0.0421,  0.3712, -0.6599,  0.0334,
         0.1535,  0.0269, -0.0404, -0.2627,  0.1071, -0.3469,  0.3357,  0.3174,
         0.4237,  0.0395, -0.1927,  0.1275, -0.5541, -0.0871,  0.3334,  0.3647,
         0.4538, -0.1243, -0.4582, -0.2935,  0.0121,  0.2805,  0.9178, -0.4659,
        -0.6471, -0.2008, -0.5437,  0.3823,  0.0901,  0.4668,  0.2945, -0.0413,
         0.4666, -0.5104, -0.3162,  0.4351, -0.6099,  0.5584, -0.0500, -0.7846,
        -0.0915, -0.3811,  0.2256, -0.0418,  0.0024,  0.4982,  0.2842,  0.8729,
         0.0394,  0.0041, -0.6792, -0.2401, -0.0959, -0.3192,  0.0551,  0.2298,
         0.2687,  0.1723,  0.3036, -0.6454,  0.4690, -0.1678, -0.1276, -0.1087,
         0.1691, -0.0730,  0.4406,  0.4509, -0.1418,  0.3463, -0.1094,  0.0371,
        -0.5246,  0.0092,  0.2150,  0.0376])
[Worker 3] Completed Task 214

[Worker 3] Processing Task 222: paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258649110 / 2281701388 (99.0%)
Greatest absolute difference: 1.99796462059021 at index (460321190, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([ 6.1705e-01,  1.2998e-02, -3.9091e-01, -4.0585e-01, -6.1705e-01,
        -1.2998e-02,  3.9091e-01,  4.0585e-01,  1.1350e-01, -6.1433e-01,
        -5.0936e-01, -5.3361e-01, -2.6043e-01,  5.5568e-01,  4.6286e-01,
         6.5981e-01,  1.2560e+00,  6.9515e-02, -4.4140e-01,  3.0012e-02,
        -1.2792e+00,  1.3993e-03,  5.1853e-01, -8.0169e-01,  4.3654e-01,
         3.6547e-01, -8.8596e-01,  4.7593e-01,  1.9561e-01, -3.4433e-01,
         6.1948e-01, -2.9607e-01, -4.6425e-02, -3.7379e-01,  3.7614e-01,
         5.8011e-01,  3.1658e-01,  3.8641e-01, -5.2842e-01, -1.8987e-01,
        -9.7775e-01, -1.2662e-01,  5.2606e-01,  2.3719e-01,  1.0079e+00,
        -3.7172e-02, -7.9164e-01, -6.5819e-01, -4.4169e-01,  4.0480e-01,
         1.3760e+00, -1.7240e-01, -6.5925e-01, -4.8131e-01, -1.4614e+00,
         8.4821e-01,  7.3729e-01,  6.6752e-01,  8.3816e-01, -4.2366e-01,
         3.7647e-01, -9.7711e-01, -6.1073e-01,  4.7638e-01, -1.0765e+00,
         1.0687e+00,  2.6625e-01, -1.2196e+00,  5.1837e-01, -9.3947e-01,
         2.7557e-01,  7.4279e-01,  9.3927e-02,  8.7927e-01,  5.8653e-02,
         9.1472e-01,  3.7049e-02, -4.9409e-01, -9.6342e-01, -1.1130e+00,
        -1.3534e-01, -3.2328e-01,  7.3431e-01,  4.6988e-01,  3.6461e-01,
         4.9151e-01,  2.4847e-01, -8.7521e-01,  2.0028e-01, -3.4007e-01,
        -4.3120e-01,  5.3669e-01, -2.9993e-01,  9.4814e-02,  5.6822e-01,
         5.5969e-01, -3.1085e-01,  4.1929e-01, -5.5002e-01, -4.1388e-01])
[Worker 3] Completed Task 222

[Worker 3] Processing Task 227: paddle.diff(x=Tensor([10],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4294967297],"float16"), )
[accuracy error] paddle.diff(x=Tensor([10],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208571778 / 4294967310 (98.0%)
Greatest absolute difference: 1.0 at index (8138002,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([-0.1338,  0.0667, -0.6855,  0.7529, -0.1338,  0.0667, -0.6855, -0.0071,
        -0.0522,  0.4521,  0.1733, -0.0076, -0.2333,  0.4277, -0.1338,  0.0667,
        -0.6855, -0.0071, -0.0522,  0.4521,  0.1733, -0.0076, -0.2333,  0.2969,
        -0.5859, -0.0071,  0.4819, -0.1654, -0.2534,  0.3823,  0.3013, -0.0916,
        -0.4407, -0.3218, -0.0029,  0.7891, -0.4536,  0.0749,  0.4424, -0.2246,
        -0.3896,  0.3716, -0.1521,  0.3074, -0.7617,  0.0383,  0.6152,  0.2363,
        -0.8174,  0.0439, -0.1980,  0.3169, -0.0140,  0.2292,  0.4290, -0.9141,
         0.6538, -0.0287,  0.1622, -0.8428,  0.1721,  0.2571,  0.2690, -0.3604,
        -0.3423,  0.8926, -0.5596,  0.1763, -0.4236,  0.1765,  0.2085,  0.0673,
         0.2932,  0.0408, -0.1106, -0.1425, -0.0502,  0.4185, -0.1360, -0.7646,
         0.2097,  0.2563, -0.0515,  0.1094, -0.5327,  0.6123, -0.2456,  0.4614,
        -0.3262,  0.2203, -0.3357, -0.3491,  0.1395,  0.4294, -0.0441, -0.6455,
         0.8379, -0.4507, -0.3516,  0.9028], dtype=torch.float16)
[Worker 3] Completed Task 227

[Worker 3] Processing Task 230: paddle.diff(x=Tensor([1073741825, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([4, 4],"float16"), )
[accuracy error] paddle.diff(x=Tensor([1073741825, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([4, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208553621 / 4294967328 (98.0%)
Greatest absolute difference: 1.0 at index (1318329, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741832, 4]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741832, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.7598, -0.6787, -0.2930,  0.5659,  0.5654,  0.3845,  0.2294, -0.5303,
        -0.5298,  0.1854, -0.2769,  0.0559,  0.7241,  0.1085,  0.3406, -0.0918,
        -0.7598, -0.6787, -0.2930,  0.5659,  0.5654,  0.3845,  0.2294, -0.5303,
        -0.5298,  0.1854, -0.2769,  0.0559,  0.4453,  0.2646,  0.3386,  0.1514,
        -0.5527, -0.8569,  0.0237,  0.0107,  0.4075,  0.8525, -0.1609, -0.0969,
         0.1997, -0.3948,  0.1372, -0.2347, -0.5679,  0.1992,  0.1282,  0.0720,
         0.0776, -0.7354, -0.6548,  0.1488,  0.3342,  0.9609, -0.2700,  0.3979,
         0.1399, -0.1270, -0.0554, -0.5371, -0.2512, -0.1444,  0.3381, -0.1763,
         0.4590, -0.3699,  0.1666,  0.0854, -0.6304,  0.1378,  0.0287,  0.7451,
         0.6094,  0.2905,  0.0808, -0.2625,  0.1152,  0.0898, -0.5322, -0.2725,
        -0.4346, -0.3499,  0.5239, -0.2185,  0.1377, -0.0565,  0.2954,  0.5020,
         0.1099,  0.0197, -0.7910, -0.3250, -0.1158,  0.1759, -0.1204,  0.5781,
        -0.3022, -0.6094,  0.9385, -0.7842], dtype=torch.float16)
[Worker 3] Completed Task 230

[Worker 3] Processing Task 234: paddle.diff(x=Tensor([4294967297],"float16"), )
[accuracy error] paddle.diff(x=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208571766 / 4294967296 (98.0%)
Greatest absolute difference: 1.0 at index (8137988,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967296]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967296]), dtype=torch.float16)
First 100 elements: tensor([-0.1338,  0.0667, -0.6855, -0.0071, -0.0522,  0.4521,  0.1733, -0.0076,
        -0.2333,  0.2969, -0.5859, -0.0071,  0.4819, -0.1654, -0.2534,  0.3823,
         0.3013, -0.0916, -0.4407, -0.3218, -0.0029,  0.7891, -0.4536,  0.0749,
         0.4424, -0.2246, -0.3896,  0.3716, -0.1521,  0.3074, -0.7617,  0.0383,
         0.6152,  0.2363, -0.8174,  0.0439, -0.1980,  0.3169, -0.0140,  0.2292,
         0.4290, -0.9141,  0.6538, -0.0287,  0.1622, -0.8428,  0.1721,  0.2571,
         0.2690, -0.3604, -0.3423,  0.8926, -0.5596,  0.1763, -0.4236,  0.1765,
         0.2085,  0.0673,  0.2932,  0.0408, -0.1106, -0.1425, -0.0502,  0.4185,
        -0.1360, -0.7646,  0.2097,  0.2563, -0.0515,  0.1094, -0.5327,  0.6123,
        -0.2456,  0.4614, -0.3262,  0.2203, -0.3357, -0.3491,  0.1395,  0.4294,
        -0.0441, -0.6455,  0.8379, -0.4507, -0.3516,  0.9028, -0.8848,  0.0850,
         0.3699, -0.1477, -0.3477,  0.1599,  0.7051, -0.0376,  0.0415, -0.2588,
        -0.2837,  0.0982, -0.2410, -0.1628], dtype=torch.float16)
[Worker 3] Completed Task 234

[Worker 3] Processing Task 239: paddle.digamma(Tensor([10, 10, 21474837, 2],"float16"), )
[accuracy error] paddle.digamma(Tensor([10, 10, 21474837, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 255 / 4294967400 (0.0%)
Greatest absolute difference: nan at index (0, 0, 6232437, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 6232437, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10, 21474837, 2]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([10, 10, 21474837, 2]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
[Worker 3] Completed Task 239

[Worker 3] Processing Task 243: paddle.digamma(Tensor([1398102, 3, 32, 32],"float16"), )
[accuracy error] paddle.digamma(Tensor([1398102, 3, 32, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 255 / 4294969344 (0.0%)
Greatest absolute difference: nan at index (4057, 1, 23, 10) (up to 0.01 allowed)
Greatest relative difference: nan at index (4057, 1, 23, 10) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1398102, 3, 32, 32]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1398102, 3, 32, 32]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
[Worker 3] Completed Task 243

[Worker 3] Processing Task 247: paddle.digamma(Tensor([4294967297],"float16"), )
[accuracy error] paddle.digamma(Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 255 / 4294967297 (0.0%)
Greatest absolute difference: nan at index (12464874,) (up to 0.01 allowed)
Greatest relative difference: nan at index (12464874,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
[Worker 3] Completed Task 247

[Worker 3] Processing Task 251: paddle.digamma(Tensor([8, 3, 5592406, 32],"float16"), )
[accuracy error] paddle.digamma(Tensor([8, 3, 5592406, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 255 / 4294967808 (0.0%)
Greatest absolute difference: nan at index (0, 0, 389527, 10) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 389527, 10) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8, 3, 5592406, 32]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([8, 3, 5592406, 32]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
[Worker 3] Completed Task 251

[Worker 3] Processing Task 255: paddle.digamma(x=Tensor([19884108, 6, 6, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([19884108, 6, 6, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 255 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (57707, 4, 3, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (57707, 4, 3, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([19884108, 6, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([19884108, 6, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
[Worker 3] Completed Task 255

[Worker 3] Processing Task 259: paddle.digamma(x=Tensor([3, 6, 6628036, 6, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([3, 6, 6628036, 6, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 255 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 0, 346246, 3, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 346246, 3, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 6, 6628036, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 6, 6628036, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
[Worker 3] Completed Task 259

[Worker 3] Processing Task 263: paddle.digamma(x=Tensor([6, 19884108, 6, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([6, 19884108, 6, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 255 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 346246, 3, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 346246, 3, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([6, 19884108, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([6, 19884108, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-2.3203e+00, -3.4785e+00, -2.8066e+00,  1.8838e+00,  1.7939e+00,
         1.1982e+00, -1.3695e+01, -4.2461e+00, -4.3828e+00, -1.2388e+02,
        -3.4434e+00,  2.3867e+00,  2.2812e+00, -5.4648e+00, -3.6219e+01,
         3.4121e+00, -6.7109e+00, -2.1855e+00, -2.8223e+00,  1.2820e+01,
         1.0020e+00,  9.7266e-01, -2.6328e+00,  1.5141e+01, -8.5750e+01,
        -2.2090e+00, -4.6094e+00,  5.3711e+00, -5.0039e+00, -1.7328e+01,
        -2.8223e+00,  1.0117e+00,  1.4141e+00, -4.0859e+00, -1.9893e+00,
         1.8125e+00,  2.4258e+00,  2.4390e-01,  5.3789e+00,  4.8438e+00,
        -1.8547e+01, -2.0430e+00,  6.7188e-01, -4.7266e+00, -5.4180e+00,
        -2.9043e+00,  1.6736e-01,  1.9346e+00,  1.7172e+01, -4.9688e+00,
         5.9414e+00,  1.3025e-01, -2.5410e+00,  5.5039e+00, -5.2000e+01,
         9.1943e-01,  3.3652e+00,  5.1781e+01, -2.1250e+01, -3.0527e+00,
        -2.6973e+00, -3.8848e+00, -8.1328e+00, -1.3133e+01, -1.9766e+00,
        -2.8691e+00,  9.2676e-01,  4.2148e+00, -1.6406e+01, -8.8562e+01,
        -8.6797e+00,  8.4131e-01, -5.2773e+00,  2.1500e+01, -2.4473e+00,
        -1.1555e+01, -3.3809e+00,  3.8656e+01,  1.2188e+00,  3.2070e+00,
        -5.4375e+00, -7.0039e+00,  8.2275e-02, -3.0371e+00,  8.5156e+00,
         4.0234e-01, -2.2715e+00,  5.6494e-01,  1.4141e+00, -7.4688e+01,
         6.6328e+00,  2.0020e-01,  1.8242e+00, -2.6895e+00, -3.0137e+00,
        -2.6582e+00, -8.1953e+00,  5.5625e+00,  1.6766e+01,  2.1367e+00],
       dtype=torch.float16)
[Worker 3] Completed Task 263

[Worker 3] Processing Task 267: paddle.dist(Tensor([190141782, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[accuracy error] paddle.dist(Tensor([190141782, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 22314.349609375 but got 0.0.
Absolute difference: 22314.349609375 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([22314.3496])
[Worker 3] Completed Task 267

[Worker 3] Processing Task 270: paddle.dist(Tensor([2, 190141782, 3, 2],"float32"), Tensor([1, 190141782, 3, 1],"float32"), 2, )
[accuracy error] paddle.dist(Tensor([2, 190141782, 3, 2],"float32"), Tensor([1, 190141782, 3, 1],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 19500.578125 but got 0.0.
Absolute difference: 19500.578125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([19500.5781])
[Worker 3] Completed Task 270

[Worker 3] Processing Task 272: paddle.dist(Tensor([2, 2, 3, 190141782],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[accuracy error] paddle.dist(Tensor([2, 2, 3, 190141782],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 22314.298828125 but got 0.0.
Absolute difference: 22314.298828125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([22314.2988])
[Worker 3] Completed Task 272

[Worker 3] Processing Task 284: paddle.fft.ifftshift(x=Tensor([53687092, 5, 4, 4],"float16"), )
[accuracy error] paddle.fft.ifftshift(x=Tensor([53687092, 5, 4, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 78 / 4294967360 (0.0%)
Greatest absolute difference: 0.494140625 at index (53687091, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (53687091, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([53687092, 5, 4, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.0948, -0.3357, -0.3313, -0.0982,  0.0316, -0.0768, -0.1722,  0.1118,
         0.1747, -0.0738, -0.0850,  0.4778,  0.4531, -0.1987,  0.0705,  0.3975,
         0.4531, -0.1879, -0.3047, -0.0230, -0.2192, -0.0178, -0.2747,  0.2096,
        -0.3098, -0.2646, -0.4080,  0.4958,  0.2993, -0.4978, -0.2986, -0.1735,
         0.2174,  0.4768,  0.1140, -0.1797, -0.4719,  0.2278,  0.0938, -0.3975,
         0.3184, -0.1519,  0.3682,  0.2021,  0.4036,  0.1869,  0.0748, -0.1365,
        -0.1166,  0.4414, -0.3809,  0.2399, -0.1262,  0.2622, -0.4832,  0.4158,
         0.1362,  0.0028, -0.2939, -0.0296, -0.0972, -0.1440, -0.1388, -0.0961,
         0.1204, -0.0909, -0.3608,  0.2396,  0.1793,  0.2078,  0.2456, -0.4187,
        -0.0734, -0.4963, -0.2323,  0.1166, -0.2700,  0.0234, -0.4961,  0.3250,
         0.3032,  0.2024, -0.2930, -0.3484,  0.2347,  0.1979, -0.4612, -0.0931,
        -0.1195,  0.1508, -0.0549,  0.1033,  0.2147, -0.1414, -0.3142, -0.1918,
         0.1182, -0.2764,  0.1182,  0.1449], dtype=torch.float16)
DESIRED: (shape=torch.Size([53687092, 5, 4, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.0948, -0.3357, -0.3313, -0.0982,  0.0316, -0.0768, -0.1722,  0.1118,
         0.1747, -0.0738, -0.0850,  0.4778,  0.4531, -0.1987,  0.0705,  0.3975,
         0.4531, -0.1879, -0.3047, -0.0230, -0.2192, -0.0178, -0.2747,  0.2096,
        -0.3098, -0.2646, -0.4080,  0.4958,  0.2993, -0.4978, -0.2986, -0.1735,
         0.2174,  0.4768,  0.1140, -0.1797, -0.4719,  0.2278,  0.0938, -0.3975,
         0.3184, -0.1519,  0.3682,  0.2021,  0.4036,  0.1869,  0.0748, -0.1365,
        -0.1166,  0.4414, -0.3809,  0.2399, -0.1262,  0.2622, -0.4832,  0.4158,
         0.1362,  0.0028, -0.2939, -0.0296, -0.0972, -0.1440, -0.1388, -0.0961,
         0.1204, -0.0909, -0.3608,  0.2396,  0.1793,  0.2078,  0.2456, -0.4187,
        -0.0734, -0.4963, -0.2323,  0.1166, -0.2700,  0.0234, -0.4961,  0.3250,
         0.3032,  0.2024, -0.2930, -0.3484,  0.2347,  0.1979, -0.4612, -0.0931,
        -0.1195,  0.1508, -0.0549,  0.1033,  0.2147, -0.1414, -0.3142, -0.1918,
         0.1182, -0.2764,  0.1182,  0.1449], dtype=torch.float16)
[Worker 3] Completed Task 284

[Worker 3] Processing Task 378: paddle.full_like(Tensor([2, 1140850690],"int64"), 2, )
[accuracy error] paddle.full_like(Tensor([2, 1140850690],"int64"), 2, ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[2, 2, 2,  ..., 2, 2, 2],
        [2, 2, 2,  ..., 2, 2, 2]]),
    expected=tensor([[2, 2, 2,  ..., 2, 2, 2],
        [2, 2, 2,  ..., 2, 2, 2]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 3] Completed Task 378

[Worker 3] Processing Task 540: paddle.isreal(Tensor([2, 2147483648],"bfloat16"), )
[accuracy error] paddle.isreal(Tensor([2, 2147483648],"bfloat16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    expected=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 3] Completed Task 540

[Worker 3] Processing Task 548: paddle.isreal(Tensor([64, 67108864],"bfloat16"), )
[accuracy error] paddle.isreal(Tensor([64, 67108864],"bfloat16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    expected=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 3] Completed Task 548

[Worker 3] Processing Task 553: paddle.isreal(Tensor([64, 67108864],"int32"), )
[accuracy error] paddle.isreal(Tensor([64, 67108864],"int32"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    expected=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 3] Completed Task 553

[Worker 3] Processing Task 565: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([35651585, 8, 8],"float32"), 0.3, )
[accuracy error] backward  paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([35651585, 8, 8],"float32"), 0.3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 7592.0146484375 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([7592.0146])
[Worker 3] Completed Task 565

[Worker 3] Processing Task 569: paddle.lerp(Tensor([1, 3, 4],"float16"), Tensor([357913942, 3, 4],"float16"), Tensor([1, 3, 4],"float16"), )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43898 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 569: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43898 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 569: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43898 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 571: paddle.lerp(Tensor([1, 8, 8],"float32"), Tensor([35651585, 8, 8],"float32"), 1.1, )
W0522 16:45:12.718350 43428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:45:12.719281 43428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.lerp(Tensor([1, 8, 8],"float32"), Tensor([35651585, 8, 8],"float32"), 1.1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 64 / 64 (100.0%)
Greatest absolute difference: 357.5798645019531 at index (0, 6, 4) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 8, 8]), dtype=torch.float32)
All elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
DESIRED: (shape=torch.Size([1, 8, 8]), dtype=torch.float32)
All elements: tensor([ -53.6186, -251.3440,   44.2487, -108.7778, -165.1540,  146.9714,
          30.9149,   18.9404,  163.0445,  -62.6223,  -40.4919,  -51.2215,
         241.7252,  -55.6451,   22.2755,   57.9179, -103.9285,  310.3943,
        -132.5089, -250.3595,   76.0518, -153.1492,    9.1144,  317.4518,
         -67.3593, -172.2172,  -89.5665,  224.8926,  181.4648, -208.7106,
        -203.4342,  -33.8791, -109.3506, -159.7032, -218.5398,   21.4857,
         181.2763, -341.6209,  -82.4172,  149.3199,  212.2366,   11.8982,
          -7.5649,  214.5959,  204.3975,  172.6026,  -66.1692,  174.5535,
         120.0234,   19.5907,   72.8903,   44.3903, -357.5799,  -28.7146,
         247.2480,  215.3667,  266.1791,  109.0341,  129.7243,   18.9806,
          81.8539,  -16.8319,  -41.2818,   38.0841])
[Worker 3] Completed Task 571

[Worker 3] Processing Task 577: paddle.lerp(Tensor([2, 1, 8, 8],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 1.1, )
[accuracy error] backward  paddle.lerp(Tensor([2, 1, 8, 8],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 1.1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 128 / 128 (100.0%)
Greatest absolute difference: 307.8075866699219 at index (0, 0, 4, 5) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1, 8, 8]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2, 1, 8, 8]), dtype=torch.float32)
First 100 elements: tensor([ 102.2787, -175.3024,  -13.0281,  -66.1872,  -22.3090,  110.2804,
        -103.8493,   -3.4586,  112.6867,  -20.2441,  -66.4149,   29.1379,
          95.3467, -139.3260, -107.7552,   65.2173,  -86.4756,  175.0948,
         -94.4754, -193.3859,  -36.7585,  -18.9853,  -33.6067,  127.4421,
          52.8648, -161.8385,  -26.3521,  230.5359,  186.1862, -160.4282,
         -21.7687,    2.8558,  -70.7354,   40.8476, -134.0284,   69.1710,
         -25.7516, -307.8076,   19.6975,  -16.6547,  221.5997,    6.9369,
         -30.5229,    5.0285,  170.8141,   54.3889,  -33.0637,   -9.8229,
         198.7195,   55.1049,   63.0307,  102.1589, -172.1996,  -53.9750,
          54.4245,    5.9366,   -8.1511,  -36.2297,   69.5361,   -7.5980,
         -95.3700,   -7.0438,  -42.3900, -121.0366, -155.9464,  -76.0824,
          57.2379,  -42.6066, -142.8714,   36.6925,  134.8100,   22.3837,
          50.3180,  -42.4226,   25.9561,  -80.4086,  146.4206,   83.6595,
         130.0797,   -7.2499,  -17.5007,  135.3382,  -37.9938,  -56.9822,
         112.8365, -134.2113,   42.6918,  190.0058, -120.2152,  -10.4239,
         -63.2072,   -5.6655,   -4.7068,  -48.2660, -181.6537,  -36.7200,
         -38.5742, -200.5895,  -84.4884,  -47.6952])
[Worker 3] Completed Task 577

[Worker 3] Processing Task 580: paddle.linalg.cholesky_solve(x=Tensor([4, 570425345],"float32"), y=Tensor([4, 4],"float32"), )
[accuracy error] backward  paddle.linalg.cholesky_solve(x=Tensor([4, 570425345],"float32"), y=Tensor([4, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 6 / 16 (37.5%)
Greatest absolute difference: 14055282.0 at index (0, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 4]), dtype=torch.float32)
All elements: tensor([ 1783105.0000,        0.0000,        0.0000,        0.0000,
         -123482.0000,   -92055.9375,        0.0000,        0.0000,
         -680057.0000,  1531904.6250, -4876962.5000,        0.0000,
         -348641.2500,   470831.9688, -7727014.0000, -4831338.5000])
DESIRED: (shape=torch.Size([4, 4]), dtype=torch.float32)
All elements: tensor([ 1785444.2500, -3720715.2500, 14055282.0000,  8864536.0000,
         -122902.5938,   -92086.1719, -7081830.0000, -4484314.0000,
         -677775.3750,  1532503.0000, -4873945.0000, -3093404.7500,
         -346410.6875,   470934.1875, -7726330.0000, -4832268.0000])
[Worker 3] Completed Task 580

[Worker 3] Processing Task 583: paddle.linalg.matrix_norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=False, )
[accuracy error] paddle.linalg.matrix_norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 3] Completed Task 583

[Worker 3] Processing Task 596: paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=3.0, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=3.0, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 2.7190704345703125 at index (2, 7) (up to 0.01 allowed)
Greatest relative difference: 0.024650299921631813 at index (2, 7) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([107.5950, 107.6062, 107.5913, 107.5803, 107.6047, 107.5934, 107.5940,
        107.5960, 107.6025, 107.5980, 107.5992, 107.5947, 107.5947, 107.5901,
        107.5916, 107.5863, 107.5769, 107.5850, 107.6038, 107.6053, 107.6019,
        107.5959, 107.5916, 107.5894, 107.5974, 107.5928, 107.5909, 107.5867,
        107.5960, 107.5939, 107.5957, 107.6001, 107.6062, 107.6009, 107.5962,
        107.5865, 107.5889, 107.5976, 107.5913, 107.5971, 107.5986, 107.6012,
        107.6035, 107.5879, 107.5848, 107.5998, 107.5982, 107.5968, 107.5959,
        107.5989, 107.5984, 107.5834, 107.6013, 107.5858, 107.5981, 107.5807,
        107.5822, 107.5991, 107.6051, 107.5880, 107.5919, 107.5906, 107.5906,
        107.5910, 107.5900, 107.5973, 107.5947, 107.6138, 107.5953, 107.6031,
        107.6039, 107.5982, 107.5943, 107.5876, 107.5941, 107.5955, 107.5988,
        107.6043, 107.5777, 107.5989, 107.6095, 107.5941, 107.5877, 107.5995,
        107.5967, 107.5968, 107.5951, 107.6011, 107.5923, 107.5960, 107.5897,
        107.5970, 107.5970, 107.5837, 107.5989, 107.6000, 107.5931, 107.5974,
        107.6064, 107.5960])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([110.3052, 110.3203, 110.3051, 110.2956, 110.3159, 110.3041, 110.3024,
        110.3090, 110.3133, 110.3096, 110.3086, 110.3075, 110.3071, 110.3035,
        110.3007, 110.3016, 110.2911, 110.2935, 110.3176, 110.3142, 110.3101,
        110.3067, 110.3030, 110.3023, 110.3081, 110.3062, 110.3028, 110.3058,
        110.3113, 110.3090, 110.3052, 110.3095, 110.3195, 110.3081, 110.3097,
        110.3034, 110.2999, 110.3119, 110.3086, 110.3097, 110.3119, 110.3122,
        110.3159, 110.3029, 110.2998, 110.3076, 110.3069, 110.3087, 110.3099,
        110.3070, 110.3075, 110.2973, 110.3112, 110.3018, 110.3123, 110.2931,
        110.2919, 110.3078, 110.3122, 110.3034, 110.3018, 110.3024, 110.3016,
        110.3083, 110.2998, 110.3100, 110.3060, 110.3280, 110.3068, 110.3136,
        110.3071, 110.3089, 110.3022, 110.3016, 110.3069, 110.3063, 110.3083,
        110.3152, 110.2925, 110.3068, 110.3180, 110.3035, 110.3049, 110.3099,
        110.3091, 110.3050, 110.3065, 110.3135, 110.3092, 110.3074, 110.3016,
        110.3093, 110.3068, 110.2970, 110.3103, 110.3103, 110.3062, 110.3070,
        110.3162, 110.3086])
[Worker 3] Completed Task 596

[Worker 3] Processing Task 599: paddle.linalg.norm(Tensor([2, 107374183, 4, 5],"float16"), 2.0, 1, False, )
[accuracy error] paddle.linalg.norm(Tensor([2, 107374183, 4, 5],"float16"), 2.0, 1, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 40 / 40 (100.0%)
Greatest absolute difference: 2970.0 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.99267578125 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 4, 5]), dtype=torch.float16)
All elements: tensor([22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 4, 5]), dtype=torch.float16)
All elements: tensor([2992., 2992., 2992., 2992., 2990., 2992., 2992., 2992., 2992., 2992.,
        2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992.,
        2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992.,
        2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992., 2992.],
       dtype=torch.float16)
[Worker 3] Completed Task 599

[Worker 3] Processing Task 609: paddle.linalg.norm(Tensor([3, 20, 71582789],"float32"), 2.0, -1, False, )
[accuracy error] paddle.linalg.norm(Tensor([3, 20, 71582789],"float32"), 2.0, -1, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 60 / 60 (100.0%)
Greatest absolute difference: 394.8671875 at index (2, 0) (up to 0.01 allowed)
Greatest relative difference: 0.16164086759090424 at index (2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 20]), dtype=torch.float32)
All elements: tensor([2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048.,
        2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048.,
        2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048.,
        2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048.,
        2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048.,
        2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048.])
DESIRED: (shape=torch.Size([3, 20]), dtype=torch.float32)
All elements: tensor([2442.5876, 2442.2664, 2442.3618, 2442.1741, 2442.4583, 2442.5190,
        2442.4180, 2442.4185, 2442.1970, 2442.2019, 2442.0962, 2442.5833,
        2442.4341, 2442.3491, 2442.3010, 2442.2683, 2442.4382, 2442.4978,
        2442.3772, 2442.5256, 2442.5308, 2442.2622, 2442.4229, 2442.5010,
        2442.5505, 2442.4822, 2442.2532, 2442.3813, 2442.5234, 2442.3132,
        2442.2666, 2442.3535, 2442.4409, 2441.9202, 2442.4536, 2442.2991,
        2442.2805, 2442.2649, 2442.2175, 2442.3528, 2442.8672, 2442.4067,
        2442.3965, 2442.2642, 2442.3406, 2442.4106, 2442.4697, 2442.1870,
        2442.4458, 2442.5107, 2442.4446, 2442.3735, 2442.6345, 2442.3025,
        2442.3196, 2442.3022, 2442.4055, 2442.3982, 2442.4846, 2442.4717])
[Worker 3] Completed Task 609

[Worker 3] Processing Task 614: paddle.linalg.norm(Tensor([380283564, 6],"float32"), p=1, axis=list[0,1,], )
[accuracy error] paddle.linalg.norm(Tensor([380283564, 6],"float32"), p=1, axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 95076408.0 but got 8388607.5.
Absolute difference: 86687800.5 (up to 0.01 allowed)
Relative difference: 0.9117698314812229 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([8388607.5000])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([95076408.])
[Worker 3] Completed Task 614

[Worker 3] Processing Task 622: paddle.linalg.norm(Tensor([4294967295],"float32"), 2.0, )
[accuracy error] paddle.linalg.norm(Tensor([4294967295],"float32"), 2.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18918.6171875 but got 0.0.
Absolute difference: 18918.6171875 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([18918.6172])
[Worker 3] Completed Task 622

[Worker 3] Processing Task 624: paddle.linalg.norm(Tensor([4294967295],"float32"), p=1, axis=0, )
[accuracy error] paddle.linalg.norm(Tensor([4294967295],"float32"), p=1, axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 1073746944.0 but got 0.0.
Absolute difference: 1073746944.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([1.0737e+09])
[Worker 3] Completed Task 624

[Worker 3] Processing Task 627: paddle.linalg.norm(Tensor([715827883, 6],"float32"), p=1, axis=list[0,1,], )
[accuracy error] paddle.linalg.norm(Tensor([715827883, 6],"float32"), p=1, axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 178964192.0 but got 8388607.5.
Absolute difference: 170575584.5 (up to 0.01 allowed)
Relative difference: 0.95312689423368 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([8388607.5000])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([1.7896e+08])
[Worker 3] Completed Task 627

[Worker 3] Processing Task 645: paddle.linalg.norm(x=Tensor([2, 536870912, 4],"float32"), p=math.inf, axis=0, keepdim=False, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.00 GiB is free. Process 88940 has 70.18 GiB memory in use. Of the allocated memory 52.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 645: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.00 GiB is free. Process 88940 has 70.18 GiB memory in use. Of the allocated memory 52.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 645: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.00 GiB is free. Process 88940 has 70.18 GiB memory in use. Of the allocated memory 52.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 646: paddle.linalg.norm(x=Tensor([2, 536870912, 4],"float32"), p=math.inf, axis=0, keepdim=True, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 84182 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 646: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 84182 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 646: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 84182 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 648: paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=math.inf, axis=list[0,1,], keepdim=False, )
W0522 17:08:14.078562 44853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 17:08:14.079421 44853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=math.inf, axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 3] Completed Task 648

[Worker 3] Processing Task 654: paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=0, axis=1, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=0, axis=1, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: inf at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1]), dtype=torch.float16)
All elements: tensor([2048., 2048., 2048.], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1]), dtype=torch.float16)
All elements: tensor([inf, inf, inf], dtype=torch.float16)
[Worker 3] Completed Task 654

[Worker 3] Processing Task 656: paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=1, axis=1, keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=1, axis=1, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: inf at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1]), dtype=torch.float16)
All elements: tensor([inf, inf, inf], dtype=torch.float16)
[Worker 3] Completed Task 656

[Worker 3] Processing Task 660: paddle.linalg.norm(x=Tensor([3, 3, 477218589],"float16"), axis=None, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 3, 477218589],"float16"), axis=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.60546875.
Absolute difference: 18911.39453125 (up to 0.01 allowed)
Relative difference: 0.9999679849434222 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.6055], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 3] Completed Task 660

[Worker 3] Processing Task 661: paddle.linalg.norm(x=Tensor([3, 477218589, 3],"float16"), axis=1, p=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.linalg.norm(x=Tensor([3, 477218589, 3],"float16"), axis=1, p=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 9 / 9 (100.0%)
Greatest absolute difference: inf at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3]), dtype=torch.float16)
All elements: tensor([2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048., 2048.],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 3]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf, inf, inf, inf, inf, inf], dtype=torch.float16)
[Worker 3] Completed Task 661

[Worker 3] Processing Task 663: paddle.linalg.norm(x=Tensor([3, 477218589, 3],"float16"), axis=None, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 477218589, 3],"float16"), axis=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.60546875.
Absolute difference: 18911.39453125 (up to 0.01 allowed)
Relative difference: 0.9999679849434222 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.6055], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 3] Completed Task 663

[Worker 3] Processing Task 664: paddle.linalg.norm(x=Tensor([357913942, 3, 4],"float16"), )
[accuracy error] paddle.linalg.norm(x=Tensor([357913942, 3, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.74658203125.
Absolute difference: 18911.25341796875 (up to 0.01 allowed)
Relative difference: 0.999960523369752 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.7466], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 3] Completed Task 664

[Worker 3] Processing Task 665: paddle.linalg.norm(x=Tensor([357913942, 3, 4],"float16"), p=1, axis=list[0,1,], keepdim=False, )
[accuracy error] paddle.linalg.norm(x=Tensor([357913942, 3, 4],"float16"), p=1, axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 3] Completed Task 665

[Worker 3] Processing Task 668: paddle.linalg.norm(x=Tensor([477218589, 3, 3],"float16"), axis=None, )
[accuracy error] paddle.linalg.norm(x=Tensor([477218589, 3, 3],"float16"), axis=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.60546875.
Absolute difference: 18911.39453125 (up to 0.01 allowed)
Relative difference: 0.9999679849434222 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.6055], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 3] Completed Task 668

[Worker 3] Processing Task 670: paddle.linalg.vector_norm(x=Tensor([2, 3, 715827883],"float32"), p=math.inf, axis=0, keepdim=False, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 94656 has 77.62 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 670: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 94656 has 77.62 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 670: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 94656 has 77.62 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 675: paddle.linalg.vector_norm(x=Tensor([2, 536870912, 4],"float32"), p=math.inf, axis=0, keepdim=True, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 72093 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 675: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 72093 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 675: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 72093 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 678: paddle.linalg.vector_norm(x=Tensor([3, 715827883],"float64"), p=0, axis=None, keepdim=False, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
W0522 17:30:26.027799 45421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 17:30:26.028729 45421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.vector_norm(x=Tensor([3, 715827883],"float64"), p=0, axis=None, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 2147483649.0 but got 0.0.
Absolute difference: 2147483649.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
All elements: tensor([0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
All elements: tensor([2.1475e+09], dtype=torch.float64)
[Worker 3] Completed Task 678

[Worker 3] Processing Task 682: paddle.linalg.vector_norm(x=Tensor([536870913, 4],"float64"), p=0, axis=None, keepdim=False, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.linalg.vector_norm(x=Tensor([536870913, 4],"float64"), p=0, axis=None, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 2147483652.0 but got 0.0.
Absolute difference: 2147483652.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float64)
All elements: tensor([0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([]), dtype=torch.float64)
All elements: tensor([2.1475e+09], dtype=torch.float64)
[Worker 3] Completed Task 682

[Worker 3] Processing Task 683: paddle.linalg.vector_norm(x=Tensor([536870913, 4],"float64"), p=0, axis=None, keepdim=True, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.linalg.vector_norm(x=Tensor([536870913, 4],"float64"), p=0, axis=None, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 2147483652.0 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1]), dtype=torch.float64)
All elements: tensor([0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1]), dtype=torch.float64)
All elements: tensor([2.1475e+09], dtype=torch.float64)
[Worker 3] Completed Task 683

[Worker 3] Processing Task 983: paddle.nn.functional.grid_sample(Tensor([67395, 1, 184, 184],"float32"), Tensor([67395, 1, 12544, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([67395, 1, 184, 184],"float32"), Tensor([67395, 1, 12544, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747909230 (unix time) try "date -d @1747909230" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb16d) received by PID 45421 (TID 0x7f2766dac740) from PID 45421 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 985: paddle.nn.functional.hardshrink(x=Tensor([2281701379],"float32"), )
W0522 18:21:51.056727 45974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:21:51.057723 45974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.hardshrink(x=Tensor([2281701379],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 62 / 2281701379 (0.0%)
Greatest absolute difference: 0.5 at index (3389993,) (up to 0.01 allowed)
Greatest relative difference: inf at index (3389993,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
[Worker 3] Completed Task 985

[Worker 3] Processing Task 990: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([760567127, 3],"float32"), )
[accuracy error] backward  paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([760567127, 3],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2037 / 2281701381 (0.0%)
Greatest absolute difference: 0.10060137510299683 at index (396777563, 1) (up to 0.01 allowed)
Greatest relative difference: 30.7716007232666 at index (346897461, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([760567127, 3]), dtype=torch.float32)
First 100 elements: tensor([ 1.8814e-01,  6.9835e-01, -8.8649e-01,  5.9324e-03, -9.5387e-03,
         3.6063e-03, -1.0435e-01,  5.2888e-01, -4.2453e-01, -9.8163e-03,
        -8.3525e-01,  8.4507e-01,  1.1404e+00, -2.5830e-02, -1.1146e+00,
         3.7001e-01,  5.0649e-01, -8.7649e-01, -2.9371e-01, -1.0047e-01,
         3.9418e-01,  4.9071e-01, -1.4421e-01, -3.4650e-01,  1.8293e-03,
         3.7745e+00, -3.7764e+00,  7.6127e-01, -3.6641e-01, -3.9486e-01,
         9.9679e-01, -1.1727e+00,  1.7595e-01,  5.9323e-02, -4.3921e-01,
         3.7989e-01, -7.0435e-01,  9.2212e-01, -2.1777e-01, -3.2770e-01,
         2.9164e-01,  3.6057e-02,  7.7680e-02,  1.9412e-01, -2.7181e-01,
         6.2588e-01, -2.0918e+00,  1.4659e+00,  6.6045e-02, -5.8382e-02,
        -7.6631e-03, -1.7263e+00, -8.5551e-01,  2.5818e+00, -5.5006e-01,
         1.2070e-01,  4.2936e-01, -5.3149e-03, -2.0741e-01,  2.1272e-01,
        -1.8504e-01,  1.5769e+00, -1.3919e+00, -1.2003e+00,  3.0702e-01,
         8.9329e-01,  8.1361e-01,  1.4541e+00, -2.2677e+00,  2.3456e+00,
        -4.4708e-01, -1.8985e+00, -7.5106e-01, -1.0446e+00,  1.7957e+00,
        -2.6630e-01, -8.1290e-02,  3.4759e-01,  2.2518e-01,  1.1456e+00,
        -1.3707e+00, -1.1811e+00,  1.3984e-02,  1.1671e+00,  6.7546e-02,
        -1.4597e+00,  1.3921e+00, -4.9498e-01, -3.0224e-01,  7.9722e-01,
        -1.0849e-01, -2.5881e-03,  1.1108e-01,  5.2272e-01, -2.0324e-01,
        -3.1948e-01,  7.8696e-01, -5.1083e-01, -2.7614e-01, -9.6595e-01])
DESIRED: (shape=torch.Size([760567127, 3]), dtype=torch.float32)
First 100 elements: tensor([ 1.8814e-01,  6.9835e-01, -8.8649e-01,  5.9324e-03, -9.5386e-03,
         3.6064e-03, -1.0435e-01,  5.2888e-01, -4.2453e-01, -9.8163e-03,
        -8.3525e-01,  8.4507e-01,  1.1404e+00, -2.5830e-02, -1.1146e+00,
         3.7001e-01,  5.0649e-01, -8.7649e-01, -2.9371e-01, -1.0047e-01,
         3.9418e-01,  4.9071e-01, -1.4421e-01, -3.4650e-01,  1.8296e-03,
         3.7745e+00, -3.7764e+00,  7.6127e-01, -3.6642e-01, -3.9486e-01,
         9.9679e-01, -1.1727e+00,  1.7595e-01,  5.9323e-02, -4.3921e-01,
         3.7989e-01, -7.0435e-01,  9.2212e-01, -2.1777e-01, -3.2770e-01,
         2.9164e-01,  3.6057e-02,  7.7680e-02,  1.9412e-01, -2.7181e-01,
         6.2588e-01, -2.0918e+00,  1.4659e+00,  6.6045e-02, -5.8382e-02,
        -7.6631e-03, -1.7262e+00, -8.5561e-01,  2.5818e+00, -5.5006e-01,
         1.2070e-01,  4.2936e-01, -5.3146e-03, -2.0741e-01,  2.1272e-01,
        -1.8504e-01,  1.5769e+00, -1.3919e+00, -1.2003e+00,  3.0702e-01,
         8.9329e-01,  8.1361e-01,  1.4541e+00, -2.2677e+00,  2.3456e+00,
        -4.4708e-01, -1.8985e+00, -7.5106e-01, -1.0446e+00,  1.7957e+00,
        -2.6630e-01, -8.1290e-02,  3.4759e-01,  2.2518e-01,  1.1456e+00,
        -1.3707e+00, -1.1811e+00,  1.3984e-02,  1.1671e+00,  6.7546e-02,
        -1.4597e+00,  1.3921e+00, -4.9498e-01, -3.0224e-01,  7.9722e-01,
        -1.0849e-01, -2.5882e-03,  1.1108e-01,  5.2273e-01, -2.0324e-01,
        -3.1948e-01,  7.8696e-01, -5.1083e-01, -2.7614e-01, -9.6595e-01])
[Worker 3] Completed Task 990

[Worker 3] Processing Task 991: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([760567127, 3],"float32"), epsilon=1e-05, )
[accuracy error] backward  paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([760567127, 3],"float32"), epsilon=1e-05, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2037 / 2281701381 (0.0%)
Greatest absolute difference: 0.10060137510299683 at index (396777563, 1) (up to 0.01 allowed)
Greatest relative difference: 30.7716007232666 at index (346897461, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([760567127, 3]), dtype=torch.float32)
First 100 elements: tensor([ 1.8814e-01,  6.9835e-01, -8.8649e-01,  5.9324e-03, -9.5387e-03,
         3.6063e-03, -1.0435e-01,  5.2888e-01, -4.2453e-01, -9.8163e-03,
        -8.3525e-01,  8.4507e-01,  1.1404e+00, -2.5830e-02, -1.1146e+00,
         3.7001e-01,  5.0649e-01, -8.7649e-01, -2.9371e-01, -1.0047e-01,
         3.9418e-01,  4.9071e-01, -1.4421e-01, -3.4650e-01,  1.8293e-03,
         3.7745e+00, -3.7764e+00,  7.6127e-01, -3.6641e-01, -3.9486e-01,
         9.9679e-01, -1.1727e+00,  1.7595e-01,  5.9323e-02, -4.3921e-01,
         3.7989e-01, -7.0435e-01,  9.2212e-01, -2.1777e-01, -3.2770e-01,
         2.9164e-01,  3.6057e-02,  7.7680e-02,  1.9412e-01, -2.7181e-01,
         6.2588e-01, -2.0918e+00,  1.4659e+00,  6.6045e-02, -5.8382e-02,
        -7.6631e-03, -1.7263e+00, -8.5551e-01,  2.5818e+00, -5.5006e-01,
         1.2070e-01,  4.2936e-01, -5.3149e-03, -2.0741e-01,  2.1272e-01,
        -1.8504e-01,  1.5769e+00, -1.3919e+00, -1.2003e+00,  3.0702e-01,
         8.9329e-01,  8.1361e-01,  1.4541e+00, -2.2677e+00,  2.3456e+00,
        -4.4708e-01, -1.8985e+00, -7.5106e-01, -1.0446e+00,  1.7957e+00,
        -2.6630e-01, -8.1290e-02,  3.4759e-01,  2.2518e-01,  1.1456e+00,
        -1.3707e+00, -1.1811e+00,  1.3984e-02,  1.1671e+00,  6.7546e-02,
        -1.4597e+00,  1.3921e+00, -4.9498e-01, -3.0224e-01,  7.9722e-01,
        -1.0849e-01, -2.5881e-03,  1.1108e-01,  5.2272e-01, -2.0324e-01,
        -3.1948e-01,  7.8696e-01, -5.1083e-01, -2.7614e-01, -9.6595e-01])
DESIRED: (shape=torch.Size([760567127, 3]), dtype=torch.float32)
First 100 elements: tensor([ 1.8814e-01,  6.9835e-01, -8.8649e-01,  5.9324e-03, -9.5386e-03,
         3.6064e-03, -1.0435e-01,  5.2888e-01, -4.2453e-01, -9.8163e-03,
        -8.3525e-01,  8.4507e-01,  1.1404e+00, -2.5830e-02, -1.1146e+00,
         3.7001e-01,  5.0649e-01, -8.7649e-01, -2.9371e-01, -1.0047e-01,
         3.9418e-01,  4.9071e-01, -1.4421e-01, -3.4650e-01,  1.8296e-03,
         3.7745e+00, -3.7764e+00,  7.6127e-01, -3.6642e-01, -3.9486e-01,
         9.9679e-01, -1.1727e+00,  1.7595e-01,  5.9323e-02, -4.3921e-01,
         3.7989e-01, -7.0435e-01,  9.2212e-01, -2.1777e-01, -3.2770e-01,
         2.9164e-01,  3.6057e-02,  7.7680e-02,  1.9412e-01, -2.7181e-01,
         6.2588e-01, -2.0918e+00,  1.4659e+00,  6.6045e-02, -5.8382e-02,
        -7.6631e-03, -1.7262e+00, -8.5561e-01,  2.5818e+00, -5.5006e-01,
         1.2070e-01,  4.2936e-01, -5.3146e-03, -2.0741e-01,  2.1272e-01,
        -1.8504e-01,  1.5769e+00, -1.3919e+00, -1.2003e+00,  3.0702e-01,
         8.9329e-01,  8.1361e-01,  1.4541e+00, -2.2677e+00,  2.3456e+00,
        -4.4708e-01, -1.8985e+00, -7.5106e-01, -1.0446e+00,  1.7957e+00,
        -2.6630e-01, -8.1290e-02,  3.4759e-01,  2.2518e-01,  1.1456e+00,
        -1.3707e+00, -1.1811e+00,  1.3984e-02,  1.1671e+00,  6.7546e-02,
        -1.4597e+00,  1.3921e+00, -4.9498e-01, -3.0224e-01,  7.9722e-01,
        -1.0849e-01, -2.5882e-03,  1.1108e-01,  5.2273e-01, -2.0324e-01,
        -3.1948e-01,  7.8696e-01, -5.1083e-01, -2.7614e-01, -9.6595e-01])
[Worker 3] Completed Task 991

[Worker 3] Processing Task 997: paddle.nn.functional.normalize(x=Tensor([4, 25565282, 6, 7],"float16"), )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.40 GiB is free. Process 55340 has 72.79 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 997: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.40 GiB is free. Process 55340 has 72.79 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 997: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.40 GiB is free. Process 55340 has 72.79 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 1000: paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), p=4, )
W0522 18:26:59.838018 46620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:26:59.839115 46620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), p=4, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 353 / 4294967320 (0.0%)
Greatest absolute difference: inf at index (0, 0, 969196, 2) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 969196, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 5, 30678338, 7]), dtype=torch.float16)
First 100 elements: tensor([ 0.9214, -0.6685,  0.2126,  0.7793,  0.7495, -0.2499, -0.6382, -0.6602,
        -0.2303,  0.5493, -0.1980, -0.5366, -0.6655,  0.4424,  0.2983,  0.6553,
         0.0583,  0.3098,  0.6758,  0.5356,  0.0687, -0.7373, -0.3906,  0.1964,
         0.2930, -0.0174, -0.0542, -0.6401, -0.8794, -0.9653, -0.6572,  0.2111,
         0.6880,  0.4792, -0.6797, -0.7451,  0.0590,  0.6865,  0.6152,  0.6021,
         0.7373, -0.9736, -0.1906, -0.8613,  0.0117,  0.5586,  0.5337, -0.8516,
        -0.5156, -0.4329, -0.4866,  0.3108, -0.5557,  0.5200,  0.7236,  0.0571,
         0.4321,  0.5444,  0.7603, -0.6382, -0.7358, -0.7803,  0.4819, -0.8628,
         0.3430,  0.3953, -0.9238,  0.6406, -0.2018,  0.6367,  0.6074, -0.5801,
        -0.2827,  0.5605,  0.7124, -0.7266,  0.4150, -0.4072,  0.1711, -0.8101,
        -0.3655, -0.8066, -0.6846, -0.7056,  0.0902, -0.2532, -0.5293,  0.7046,
        -0.8643, -0.7983, -0.0583, -0.0789, -0.7212,  0.3430, -0.2637, -0.9502,
        -0.3376, -0.2737,  0.7593, -0.3936], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 5, 30678338, 7]), dtype=torch.float16)
First 100 elements: tensor([ 0.9214, -0.6685,  0.2125,  0.7793,  0.7500, -0.2499, -0.6387, -0.6602,
        -0.2303,  0.5493, -0.1980, -0.5366, -0.6655,  0.4424,  0.2983,  0.6553,
         0.0583,  0.3098,  0.6758,  0.5356,  0.0687, -0.7373, -0.3906,  0.1962,
         0.2930, -0.0174, -0.0542, -0.6401, -0.8794, -0.9653, -0.6572,  0.2111,
         0.6880,  0.4792, -0.6797, -0.7446,  0.0590,  0.6865,  0.6152,  0.6021,
         0.7373, -0.9736, -0.1906, -0.8613,  0.0117,  0.5586,  0.5337, -0.8525,
        -0.5156, -0.4329, -0.4866,  0.3108, -0.5557,  0.5200,  0.7236,  0.0571,
         0.4321,  0.5444,  0.7607, -0.6382, -0.7358, -0.7803,  0.4819, -0.8628,
         0.3430,  0.3953, -0.9238,  0.6406, -0.2018,  0.6367,  0.6074, -0.5801,
        -0.2827,  0.5601,  0.7124, -0.7266,  0.4150, -0.4072,  0.1710, -0.8101,
        -0.3655, -0.8066, -0.6846, -0.7056,  0.0902, -0.2532, -0.5298,  0.7041,
        -0.8643, -0.7983, -0.0582, -0.0789, -0.7207,  0.3430, -0.2637, -0.9502,
        -0.3376, -0.2737,  0.7593, -0.3936], dtype=torch.float16)
[Worker 3] Completed Task 1000

[Worker 3] Processing Task 1004: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 0, 1e-06, False, None, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 0, 1e-06, False, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 6039798.0 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 0.2647058963775635 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([100]), dtype=torch.float32)
All elements: tensor([16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216.])
DESIRED: (shape=torch.Size([100]), dtype=torch.float32)
All elements: tensor([22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014.])
[Worker 3] Completed Task 1004

[Worker 3] Processing Task 1008: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 0, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 0, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 115774 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 1008

[Worker 3] Processing Task 1010: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 1, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 1, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 115774 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 1010

[Worker 3] Processing Task 1012: paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 0, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 0, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 115774 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 1012

[Worker 3] Processing Task 1014: paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 2, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 2, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 115774 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 1014

[Worker 3] Processing Task 1016: paddle.nn.functional.pairwise_distance(x=Tensor([100, 22817014],"float32"), y=Tensor([100, 1],"float32"), p=2.0, epsilon=1e-06, keepdim=False, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 115774 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 11.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 1016: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 115774 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 11.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 1016: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 115774 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 11.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 1019: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 95070891],"float32"), 0.3, 0.300000009, training=True, )
W0522 18:30:19.800729 46775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:30:19.801795 46775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 95070891],"float32"), 0.3, 0.300000009, training=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2182819413 / 2281701384 (95.7%)
Greatest absolute difference: 0.5 at index (0, 0, 0, 32525410) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 4, 95070891]), dtype=torch.float32)
First 100 elements: tensor([-0.0324, -0.0526, -0.0937,  0.4906,  0.3344,  0.2126, -0.0379,  0.4814,
         0.2271, -0.0648, -0.0340,  0.4446, -0.0794,  0.1273,  0.3187, -0.0272,
        -0.0816, -0.0564, -0.0633, -0.0395,  0.1074,  0.3701,  0.0420,  0.4611,
         0.3298,  0.3557,  0.0553, -0.0185, -0.0197,  0.4077, -0.0732, -0.1394,
        -0.0063,  0.4726,  0.2483, -0.0870,  0.0320, -0.0590, -0.0965, -0.0238,
         0.3147, -0.1209,  0.4378, -0.1133,  0.2854, -0.0615,  0.4684,  0.4762,
        -0.1044,  0.0456, -0.0385, -0.0450,  0.3914, -0.0325,  0.2207, -0.1380,
         0.2156,  0.1607, -0.0314, -0.0047, -0.0447, -0.1350, -0.1380, -0.0483,
        -0.0851,  0.1500, -0.0534, -0.0400, -0.0891, -0.0132,  0.1405,  0.2656,
         0.4923, -0.0697, -0.1178, -0.1041,  0.1964,  0.0553,  0.1429,  0.4084,
         0.3214, -0.0935,  0.0994, -0.0742, -0.1208,  0.1445, -0.0119, -0.1440,
        -0.1352,  0.3716, -0.1059,  0.3832, -0.0945, -0.0502,  0.3481, -0.0525,
         0.2364,  0.4674, -0.0678,  0.4405])
DESIRED: (shape=torch.Size([2, 3, 4, 95070891]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
[Worker 3] Completed Task 1019

[Worker 3] Processing Task 1147: paddle.roll(Tensor([1, 114131, 7, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 114131, 7, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 10257 / 4294977792 (0.0%)
Greatest absolute difference: 0.5 at index (0, 114130, 5, 0, 427) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 114130, 5, 0, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 114131, 7, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4595,  0.3237,  0.4285,  0.0616,  0.2476, -0.0512, -0.2435,  0.4380,
        -0.0165,  0.4622, -0.2430, -0.4456, -0.2944,  0.0485,  0.4248,  0.4980,
         0.2404, -0.1692,  0.3799, -0.2306,  0.1407, -0.3123,  0.3037, -0.4973,
        -0.1743,  0.3989, -0.2761,  0.4854,  0.4968,  0.4370, -0.4268,  0.2988,
        -0.2061,  0.1692,  0.0277,  0.3049, -0.3235, -0.3855,  0.4724,  0.0510,
        -0.2595,  0.3328,  0.4419,  0.2913,  0.3264, -0.1483, -0.1339, -0.3557,
         0.1573,  0.0182, -0.1564,  0.3213,  0.4800,  0.4712,  0.2715,  0.4292,
        -0.1631, -0.4104, -0.1418,  0.4448,  0.2515, -0.3083,  0.0800, -0.4761,
        -0.3875, -0.0145, -0.2651,  0.4106,  0.1631,  0.1444,  0.4541,  0.4065,
        -0.2739,  0.3191,  0.0018, -0.0579, -0.2839, -0.4478, -0.2136,  0.4539,
         0.0645, -0.3843, -0.2915, -0.1908,  0.4729, -0.1326,  0.0266, -0.3020,
        -0.4304,  0.2209,  0.2483, -0.2484, -0.1748, -0.2097, -0.1479,  0.0097,
        -0.4226,  0.3772, -0.0254, -0.2627], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 114131, 7, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4595,  0.3237,  0.4285,  0.0616,  0.2476, -0.0512, -0.2435,  0.4380,
        -0.0165,  0.4622, -0.2430, -0.4456, -0.2944,  0.0485,  0.4248,  0.4980,
         0.2404, -0.1692,  0.3799, -0.2306,  0.1407, -0.3123,  0.3037, -0.4973,
        -0.1743,  0.3989, -0.2761,  0.4854,  0.4968,  0.4370, -0.4268,  0.2988,
        -0.2061,  0.1692,  0.0277,  0.3049, -0.3235, -0.3855,  0.4724,  0.0510,
        -0.2595,  0.3328,  0.4419,  0.2913,  0.3264, -0.1483, -0.1339, -0.3557,
         0.1573,  0.0182, -0.1564,  0.3213,  0.4800,  0.4712,  0.2715,  0.4292,
        -0.1631, -0.4104, -0.1418,  0.4448,  0.2515, -0.3083,  0.0800, -0.4761,
        -0.3875, -0.0145, -0.2651,  0.4106,  0.1631,  0.1444,  0.4541,  0.4065,
        -0.2739,  0.3191,  0.0018, -0.0579, -0.2839, -0.4478, -0.2136,  0.4539,
         0.0645, -0.3843, -0.2915, -0.1908,  0.4729, -0.1326,  0.0266, -0.3020,
        -0.4304,  0.2209,  0.2483, -0.2484, -0.1748, -0.2097, -0.1479,  0.0097,
        -0.4226,  0.3772, -0.0254, -0.2627], dtype=torch.float16)
[Worker 3] Completed Task 1147

[Worker 3] Processing Task 1151: paddle.roll(Tensor([1, 16, 14, 21, 913046],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 21, 913046],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3209 / 4294968384 (0.0%)
Greatest absolute difference: 0.499755859375 at index (0, 15, 10, 17, 911986) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 10, 17, 911958) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 21, 913046]), dtype=torch.float16)
First 100 elements: tensor([-0.0532,  0.1270,  0.3765, -0.1669,  0.4124,  0.2507, -0.4846, -0.0329,
         0.1477,  0.2908,  0.0626, -0.1289, -0.2732,  0.2242, -0.2488,  0.3577,
         0.4648, -0.0552,  0.4543, -0.1750, -0.1350, -0.2668,  0.1554,  0.3779,
         0.0275,  0.2087,  0.1550, -0.0864, -0.0078, -0.1943,  0.3525,  0.3635,
        -0.1671, -0.0221,  0.1237,  0.3552,  0.1968,  0.4658,  0.2023,  0.1147,
        -0.3262,  0.0337, -0.1301, -0.4941, -0.1995,  0.2705,  0.3142, -0.2325,
         0.4292, -0.3989,  0.3484,  0.4985,  0.2134, -0.2922, -0.2866, -0.3940,
         0.2361, -0.2295, -0.3582, -0.2440,  0.3816,  0.0316,  0.3896, -0.3586,
         0.2505,  0.0035, -0.2208, -0.2367,  0.4209, -0.2035, -0.0720, -0.4482,
         0.2025, -0.2175,  0.2866,  0.2410,  0.0103, -0.0028, -0.2246,  0.1467,
        -0.3340,  0.4478, -0.0139,  0.1060, -0.4084,  0.4160, -0.4824, -0.1087,
         0.3127, -0.0183,  0.0111, -0.4910, -0.4048,  0.0760, -0.2537, -0.1198,
         0.3074,  0.3459,  0.3379,  0.2124], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 21, 913046]), dtype=torch.float16)
First 100 elements: tensor([-0.0532,  0.1270,  0.3765, -0.1669,  0.4124,  0.2507, -0.4846, -0.0329,
         0.1477,  0.2908,  0.0626, -0.1289, -0.2732,  0.2242, -0.2488,  0.3577,
         0.4648, -0.0552,  0.4543, -0.1750, -0.1350, -0.2668,  0.1554,  0.3779,
         0.0275,  0.2087,  0.1550, -0.0864, -0.0078, -0.1943,  0.3525,  0.3635,
        -0.1671, -0.0221,  0.1237,  0.3552,  0.1968,  0.4658,  0.2023,  0.1147,
        -0.3262,  0.0337, -0.1301, -0.4941, -0.1995,  0.2705,  0.3142, -0.2325,
         0.4292, -0.3989,  0.3484,  0.4985,  0.2134, -0.2922, -0.2866, -0.3940,
         0.2361, -0.2295, -0.3582, -0.2440,  0.3816,  0.0316,  0.3896, -0.3586,
         0.2505,  0.0035, -0.2208, -0.2367,  0.4209, -0.2035, -0.0720, -0.4482,
         0.2025, -0.2175,  0.2866,  0.2410,  0.0103, -0.0028, -0.2246,  0.1467,
        -0.3340,  0.4478, -0.0139,  0.1060, -0.4084,  0.4160, -0.4824, -0.1087,
         0.3127, -0.0183,  0.0111, -0.4910, -0.4048,  0.0760, -0.2537, -0.1198,
         0.3074,  0.3459,  0.3379,  0.2124], dtype=torch.float16)
[Worker 3] Completed Task 1151

[Worker 3] Processing Task 1155: paddle.roll(Tensor([1, 16, 14, 49933, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 49933, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 137660 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 10, 49749, 74) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 10, 49748, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 49933, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.4583, -0.3047,  0.4648, -0.2402, -0.3542,  0.2194, -0.0044, -0.2340,
        -0.3638,  0.2041, -0.2783,  0.2137, -0.4556,  0.3572,  0.2632, -0.4851,
         0.4231, -0.0325,  0.1238,  0.1066, -0.1022, -0.1300, -0.4016,  0.2240,
         0.4082, -0.4470, -0.0100, -0.3850,  0.3376,  0.3564, -0.1030,  0.1005,
        -0.2487, -0.3003,  0.2352,  0.0572, -0.2732, -0.4590,  0.2773, -0.1129,
        -0.3032,  0.3105, -0.0670, -0.4595, -0.0837,  0.1416,  0.0829, -0.3096,
        -0.3083,  0.0438,  0.4529,  0.3066, -0.4680,  0.2922,  0.4802, -0.3638,
        -0.3386, -0.1320,  0.1133,  0.2737,  0.0015, -0.4692,  0.1277, -0.2664,
         0.1532, -0.2401,  0.1096,  0.4092, -0.3191,  0.2412, -0.1512, -0.0692,
        -0.2717,  0.0014, -0.4302, -0.2957, -0.3770, -0.1008, -0.0034,  0.0623,
        -0.3071,  0.2332,  0.4456, -0.1871, -0.1119,  0.0639, -0.0997,  0.3750,
         0.1132,  0.1743,  0.2369,  0.3018, -0.3696,  0.2783,  0.3093, -0.2507,
        -0.0388, -0.4036, -0.0923, -0.1279], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 49933, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.4583, -0.3047,  0.4648, -0.2402, -0.3542,  0.2194, -0.0044, -0.2340,
        -0.3638,  0.2041, -0.2783,  0.2137, -0.4556,  0.3572,  0.2632, -0.4851,
         0.4231, -0.0325,  0.1238,  0.1066, -0.1022, -0.1300, -0.4016,  0.2240,
         0.4082, -0.4470, -0.0100, -0.3850,  0.3376,  0.3564, -0.1030,  0.1005,
        -0.2487, -0.3003,  0.2352,  0.0572, -0.2732, -0.4590,  0.2773, -0.1129,
        -0.3032,  0.3105, -0.0670, -0.4595, -0.0837,  0.1416,  0.0829, -0.3096,
        -0.3083,  0.0438,  0.4529,  0.3066, -0.4680,  0.2922,  0.4802, -0.3638,
        -0.3386, -0.1320,  0.1133,  0.2737,  0.0015, -0.4692,  0.1277, -0.2664,
         0.1532, -0.2401,  0.1096,  0.4092, -0.3191,  0.2412, -0.1512, -0.0692,
        -0.2717,  0.0014, -0.4302, -0.2957, -0.3770, -0.1008, -0.0034,  0.0623,
        -0.3071,  0.2332,  0.4456, -0.1871, -0.1119,  0.0639, -0.0997,  0.3750,
         0.1132,  0.1743,  0.2369,  0.3018, -0.3696,  0.2783,  0.3093, -0.2507,
        -0.0388, -0.4036, -0.0923, -0.1279], dtype=torch.float16)
[Worker 3] Completed Task 1155

[Worker 3] Processing Task 1159: paddle.roll(Tensor([1, 16, 21, 14, 913046],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 21, 14, 913046],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3204 / 4294968384 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 20, 10, 912049) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 17, 10, 911958) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 21, 14, 913046]), dtype=torch.float16)
First 100 elements: tensor([-0.3745, -0.3628, -0.4548, -0.3992, -0.2727, -0.1504, -0.1104,  0.4695,
         0.0304, -0.2469,  0.3469,  0.3591, -0.0553,  0.0428,  0.1487,  0.2886,
         0.1877, -0.2954,  0.4026, -0.4426, -0.1293, -0.0209, -0.3003, -0.4932,
        -0.3062, -0.4639, -0.1935, -0.4048,  0.2563,  0.0173, -0.2067, -0.4343,
         0.4456,  0.4795,  0.2869,  0.0557,  0.2119,  0.3843, -0.4043,  0.0567,
         0.0104,  0.0875,  0.0645,  0.0625,  0.2000,  0.4978, -0.1973, -0.2158,
        -0.3586,  0.2834,  0.1340,  0.0570,  0.4492, -0.4531, -0.3098, -0.3147,
         0.4197,  0.1877, -0.0565, -0.4092,  0.2428,  0.3052, -0.3923, -0.3752,
         0.0058,  0.0875, -0.3909,  0.3643,  0.3672,  0.0226,  0.4153,  0.3472,
        -0.4272, -0.2783,  0.3926,  0.0071, -0.4409, -0.2268,  0.4465, -0.4714,
         0.3000, -0.1279, -0.4966, -0.3020, -0.4102, -0.4155, -0.2839,  0.3020,
        -0.2981, -0.1055, -0.5000,  0.1109, -0.4556,  0.0344,  0.2400, -0.0173,
         0.1267, -0.0403,  0.1744,  0.0398], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 21, 14, 913046]), dtype=torch.float16)
First 100 elements: tensor([-0.3745, -0.3628, -0.4548, -0.3992, -0.2727, -0.1504, -0.1104,  0.4695,
         0.0304, -0.2469,  0.3469,  0.3591, -0.0553,  0.0428,  0.1487,  0.2886,
         0.1877, -0.2954,  0.4026, -0.4426, -0.1293, -0.0209, -0.3003, -0.4932,
        -0.3062, -0.4639, -0.1935, -0.4048,  0.2563,  0.0173, -0.2067, -0.4343,
         0.4456,  0.4795,  0.2869,  0.0557,  0.2119,  0.3843, -0.4043,  0.0567,
         0.0104,  0.0875,  0.0645,  0.0625,  0.2000,  0.4978, -0.1973, -0.2158,
        -0.3586,  0.2834,  0.1340,  0.0570,  0.4492, -0.4531, -0.3098, -0.3147,
         0.4197,  0.1877, -0.0565, -0.4092,  0.2428,  0.3052, -0.3923, -0.3752,
         0.0058,  0.0875, -0.3909,  0.3643,  0.3672,  0.0226,  0.4153,  0.3472,
        -0.4272, -0.2783,  0.3926,  0.0071, -0.4409, -0.2268,  0.4465, -0.4714,
         0.3000, -0.1279, -0.4966, -0.3020, -0.4102, -0.4155, -0.2839,  0.3020,
        -0.2981, -0.1055, -0.5000,  0.1109, -0.4556,  0.0344,  0.2400, -0.0173,
         0.1267, -0.0403,  0.1744,  0.0398], dtype=torch.float16)
[Worker 3] Completed Task 1159

[Worker 3] Processing Task 1163: paddle.roll(Tensor([1, 16, 24967, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 24967, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 154843 / 4295122944 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 24952, 10, 9) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 24952, 4, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 24967, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.0566,  0.4614, -0.4756,  0.2529,  0.0629,  0.1979,  0.3108, -0.1285,
         0.1967, -0.2925, -0.4231,  0.3511,  0.3428,  0.4568,  0.3320,  0.0667,
         0.4067,  0.4602, -0.3318, -0.2216, -0.0902,  0.2386,  0.0129,  0.2869,
        -0.2039,  0.1735, -0.2615, -0.0540,  0.1672,  0.0418, -0.4438, -0.3296,
         0.0471,  0.1179, -0.1740,  0.2815, -0.3479, -0.3276, -0.3220,  0.2507,
        -0.4495, -0.2050,  0.2430,  0.3359, -0.0352,  0.2203, -0.1365, -0.1592,
         0.2070, -0.2993,  0.0092, -0.3542,  0.4329, -0.3083,  0.1586,  0.2837,
         0.4175,  0.3711, -0.0801,  0.0283,  0.1249, -0.1869,  0.3809, -0.1768,
        -0.4114, -0.0567, -0.4138,  0.2274, -0.3428,  0.3662,  0.1338,  0.3047,
        -0.3232, -0.4744,  0.2959,  0.0863, -0.2264, -0.3247,  0.3088,  0.2861,
        -0.0381, -0.2286,  0.3301,  0.3005,  0.0139,  0.1921, -0.4028, -0.3682,
        -0.0496,  0.3677, -0.0357, -0.4150,  0.2729,  0.0435, -0.3333,  0.2566,
        -0.4600, -0.3528,  0.3010, -0.3613], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 24967, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.0566,  0.4614, -0.4756,  0.2529,  0.0629,  0.1979,  0.3108, -0.1285,
         0.1967, -0.2925, -0.4231,  0.3511,  0.3428,  0.4568,  0.3320,  0.0667,
         0.4067,  0.4602, -0.3318, -0.2216, -0.0902,  0.2386,  0.0129,  0.2869,
        -0.2039,  0.1735, -0.2615, -0.0540,  0.1672,  0.0418, -0.4438, -0.3296,
         0.0471,  0.1179, -0.1740,  0.2815, -0.3479, -0.3276, -0.3220,  0.2507,
        -0.4495, -0.2050,  0.2430,  0.3359, -0.0352,  0.2203, -0.1365, -0.1592,
         0.2070, -0.2993,  0.0092, -0.3542,  0.4329, -0.3083,  0.1586,  0.2837,
         0.4175,  0.3711, -0.0801,  0.0283,  0.1249, -0.1869,  0.3809, -0.1768,
        -0.4114, -0.0567, -0.4138,  0.2274, -0.3428,  0.3662,  0.1338,  0.3047,
        -0.3232, -0.4744,  0.2959,  0.0863, -0.2264, -0.3247,  0.3088,  0.2861,
        -0.0381, -0.2286,  0.3301,  0.3005,  0.0139,  0.1921, -0.4028, -0.3682,
        -0.0496,  0.3677, -0.0357, -0.4150,  0.2729,  0.0435, -0.3333,  0.2566,
        -0.4600, -0.3528,  0.3010, -0.3613], dtype=torch.float16)
[Worker 3] Completed Task 1163

[Worker 3] Processing Task 1167: paddle.roll(Tensor([1, 16, 49933, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 49933, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 84067 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 49917, 12, 74) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 49917, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 49933, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.0754, -0.4836,  0.2612,  0.3965,  0.2167,  0.3286, -0.0809, -0.2368,
         0.3191,  0.0601,  0.1462, -0.4429, -0.4329, -0.4995,  0.1584,  0.2690,
        -0.4375, -0.3132,  0.4412, -0.2896, -0.0212,  0.3035, -0.3911,  0.1836,
         0.0380,  0.0168,  0.3860, -0.1887, -0.1969,  0.1123, -0.4253, -0.3408,
        -0.3718,  0.2632,  0.4011,  0.2310, -0.4189,  0.4553, -0.4663,  0.2573,
        -0.4287,  0.1103, -0.0565,  0.3066, -0.4077,  0.1406, -0.0714, -0.1086,
        -0.0557, -0.4399,  0.2947,  0.4390, -0.4048,  0.3374, -0.1484, -0.0984,
         0.0036, -0.3677, -0.3015,  0.1614, -0.0420, -0.3726, -0.2026, -0.4941,
         0.2620,  0.3406, -0.4377,  0.1144, -0.2546,  0.1605,  0.4219, -0.1461,
        -0.0100, -0.1365,  0.2223,  0.3872,  0.4321, -0.1554, -0.2032, -0.4314,
        -0.4102,  0.3005,  0.2734,  0.0763,  0.4883,  0.2209, -0.0037,  0.2749,
        -0.0253,  0.3298, -0.0899,  0.0411, -0.2761,  0.1339,  0.2035, -0.3169,
         0.3701,  0.4036,  0.1373, -0.4578], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 49933, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.0754, -0.4836,  0.2612,  0.3965,  0.2167,  0.3286, -0.0809, -0.2368,
         0.3191,  0.0601,  0.1462, -0.4429, -0.4329, -0.4995,  0.1584,  0.2690,
        -0.4375, -0.3132,  0.4412, -0.2896, -0.0212,  0.3035, -0.3911,  0.1836,
         0.0380,  0.0168,  0.3860, -0.1887, -0.1969,  0.1123, -0.4253, -0.3408,
        -0.3718,  0.2632,  0.4011,  0.2310, -0.4189,  0.4553, -0.4663,  0.2573,
        -0.4287,  0.1103, -0.0565,  0.3066, -0.4077,  0.1406, -0.0714, -0.1086,
        -0.0557, -0.4399,  0.2947,  0.4390, -0.4048,  0.3374, -0.1484, -0.0984,
         0.0036, -0.3677, -0.3015,  0.1614, -0.0420, -0.3726, -0.2026, -0.4941,
         0.2620,  0.3406, -0.4377,  0.1144, -0.2546,  0.1605,  0.4219, -0.1461,
        -0.0100, -0.1365,  0.2223,  0.3872,  0.4321, -0.1554, -0.2032, -0.4314,
        -0.4102,  0.3005,  0.2734,  0.0763,  0.4883,  0.2209, -0.0037,  0.2749,
        -0.0253,  0.3298, -0.0899,  0.0411, -0.2761,  0.1339,  0.2035, -0.3169,
         0.3701,  0.4036,  0.1373, -0.4578], dtype=torch.float16)
[Worker 3] Completed Task 1167

[Worker 3] Processing Task 1171: paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 84067 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 49917, 0, 458) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 49917, 0, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.2020, -0.4541, -0.4543, -0.2161, -0.4614,  0.2434,  0.4336,  0.0889,
         0.1454, -0.4856, -0.0876, -0.2162,  0.4814,  0.4749,  0.1534, -0.0437,
         0.3413, -0.0008, -0.4641,  0.1621,  0.2522,  0.2126, -0.2703, -0.0284,
         0.3748, -0.3088,  0.2469, -0.3127,  0.0781, -0.3066, -0.2356, -0.0035,
        -0.3198, -0.2771,  0.3228, -0.2498, -0.1499, -0.0707, -0.1127,  0.3784,
        -0.0195,  0.4438, -0.0900,  0.4441, -0.3022, -0.2644,  0.4888, -0.3767,
         0.0478,  0.4661,  0.0770, -0.0213, -0.2964,  0.3499, -0.3464,  0.2367,
        -0.0048,  0.3362,  0.4832,  0.3335,  0.2937,  0.4375,  0.1211, -0.3687,
         0.4751,  0.4414,  0.1144, -0.1522,  0.0892,  0.3164,  0.0062, -0.4856,
        -0.4370,  0.2935,  0.3687,  0.3879, -0.4832,  0.0482,  0.3196,  0.3174,
         0.1772,  0.4355,  0.1820, -0.3066, -0.4995,  0.3289,  0.1340, -0.3669,
         0.0942, -0.3181, -0.0890, -0.3799,  0.1354,  0.1106,  0.2363, -0.3323,
        -0.1239,  0.0799, -0.1377,  0.1171], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.2020, -0.4541, -0.4543, -0.2161, -0.4614,  0.2434,  0.4336,  0.0889,
         0.1454, -0.4856, -0.0876, -0.2162,  0.4814,  0.4749,  0.1534, -0.0437,
         0.3413, -0.0008, -0.4641,  0.1621,  0.2522,  0.2126, -0.2703, -0.0284,
         0.3748, -0.3088,  0.2469, -0.3127,  0.0781, -0.3066, -0.2356, -0.0035,
        -0.3198, -0.2771,  0.3228, -0.2498, -0.1499, -0.0707, -0.1127,  0.3784,
        -0.0195,  0.4438, -0.0900,  0.4441, -0.3022, -0.2644,  0.4888, -0.3767,
         0.0478,  0.4661,  0.0770, -0.0213, -0.2964,  0.3499, -0.3464,  0.2367,
        -0.0048,  0.3362,  0.4832,  0.3335,  0.2937,  0.4375,  0.1211, -0.3687,
         0.4751,  0.4414,  0.1144, -0.1522,  0.0892,  0.3164,  0.0062, -0.4856,
        -0.4370,  0.2935,  0.3687,  0.3879, -0.4832,  0.0482,  0.3196,  0.3174,
         0.1772,  0.4355,  0.1820, -0.3066, -0.4995,  0.3289,  0.1340, -0.3669,
         0.0942, -0.3181, -0.0890, -0.3799,  0.1354,  0.1106,  0.2363, -0.3323,
        -0.1239,  0.0799, -0.1377,  0.1171], dtype=torch.float16)
[Worker 3] Completed Task 1171

[Worker 3] Processing Task 1175: paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 68275 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 6, 49842, 458) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 49842, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.1201, -0.0442,  0.0701,  0.1620, -0.2625,  0.1708,  0.2815, -0.4211,
         0.4290,  0.4834, -0.0088,  0.3408, -0.3694, -0.4578, -0.1543, -0.4873,
         0.1786,  0.0672, -0.1952, -0.0442,  0.4258,  0.3833, -0.2172, -0.1135,
         0.2325,  0.2195, -0.3999, -0.4292, -0.2216, -0.3132,  0.0543, -0.4402,
        -0.2903,  0.3777, -0.1854, -0.2866,  0.1772, -0.3477,  0.3384,  0.2029,
         0.0711, -0.3909, -0.1118, -0.1036,  0.0251, -0.0186, -0.4878, -0.2469,
         0.2245,  0.4517,  0.2205, -0.1133,  0.0723, -0.2539,  0.3882, -0.0716,
        -0.1406, -0.4148,  0.2415,  0.4854,  0.4705, -0.2761, -0.0302, -0.4285,
        -0.0457,  0.2957,  0.2888, -0.1323, -0.0555, -0.2764,  0.0382, -0.1954,
         0.3674, -0.2065,  0.3545,  0.0855,  0.2817, -0.2180,  0.2600,  0.2340,
         0.0720,  0.1829, -0.0272, -0.3950, -0.1036, -0.1953, -0.2544, -0.4839,
        -0.0773,  0.4443, -0.4414, -0.3013, -0.0763,  0.3127,  0.1101, -0.2222,
         0.0853, -0.4944,  0.0746,  0.0966], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.1201, -0.0442,  0.0701,  0.1620, -0.2625,  0.1708,  0.2815, -0.4211,
         0.4290,  0.4834, -0.0088,  0.3408, -0.3694, -0.4578, -0.1543, -0.4873,
         0.1786,  0.0672, -0.1952, -0.0442,  0.4258,  0.3833, -0.2172, -0.1135,
         0.2325,  0.2195, -0.3999, -0.4292, -0.2216, -0.3132,  0.0543, -0.4402,
        -0.2903,  0.3777, -0.1854, -0.2866,  0.1772, -0.3477,  0.3384,  0.2029,
         0.0711, -0.3909, -0.1118, -0.1036,  0.0251, -0.0186, -0.4878, -0.2469,
         0.2245,  0.4517,  0.2205, -0.1133,  0.0723, -0.2539,  0.3882, -0.0716,
        -0.1406, -0.4148,  0.2415,  0.4854,  0.4705, -0.2761, -0.0302, -0.4285,
        -0.0457,  0.2957,  0.2888, -0.1323, -0.0555, -0.2764,  0.0382, -0.1954,
         0.3674, -0.2065,  0.3545,  0.0855,  0.2817, -0.2180,  0.2600,  0.2340,
         0.0720,  0.1829, -0.0272, -0.3950, -0.1036, -0.1953, -0.2544, -0.4839,
        -0.0773,  0.4443, -0.4414, -0.3013, -0.0763,  0.3127,  0.1101, -0.2222,
         0.0853, -0.4944,  0.0746,  0.0966], dtype=torch.float16)
[Worker 3] Completed Task 1175

[Worker 3] Processing Task 1179: paddle.roll(Tensor([1, 16, 7, 7, 5478275],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 7, 5478275],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 297 / 4294967600 (0.0%)
Greatest absolute difference: 0.499755859375 at index (0, 15, 6, 6, 5478255) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 6, 5477971) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 7, 5478275]), dtype=torch.float16)
First 100 elements: tensor([-0.0714, -0.3953,  0.3293, -0.3728, -0.1135, -0.2773,  0.4609, -0.0478,
         0.3901, -0.0333, -0.1510,  0.4136, -0.0933,  0.4438, -0.0210,  0.3452,
         0.1897,  0.4331,  0.3975, -0.4551, -0.3750,  0.1975, -0.3364, -0.0012,
        -0.1466, -0.3279,  0.4036,  0.0290, -0.3406, -0.3088, -0.3645,  0.1589,
         0.0593,  0.3894, -0.2429,  0.3750,  0.0646, -0.2913, -0.2422,  0.0770,
        -0.0102,  0.2976,  0.3201, -0.1495, -0.2634,  0.2327, -0.4646,  0.4028,
        -0.4207,  0.2942, -0.3909,  0.3293, -0.2430,  0.0557,  0.4370,  0.0373,
        -0.1826, -0.2405,  0.1941, -0.1307, -0.4680,  0.3938, -0.1417, -0.1836,
         0.1447,  0.4773,  0.3789,  0.0156, -0.4988, -0.3809, -0.2961,  0.4763,
         0.1865,  0.3528,  0.1127, -0.3171,  0.3938, -0.2281, -0.2590, -0.4519,
        -0.3987, -0.1953, -0.3586, -0.3298, -0.2411, -0.3230,  0.1428, -0.0112,
        -0.3962, -0.0300, -0.2091,  0.3162,  0.4976, -0.4111, -0.3601, -0.2761,
        -0.3875,  0.2216, -0.1981, -0.1088], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 7, 5478275]), dtype=torch.float16)
First 100 elements: tensor([-0.0714, -0.3953,  0.3293, -0.3728, -0.1135, -0.2773,  0.4609, -0.0478,
         0.3901, -0.0333, -0.1510,  0.4136, -0.0933,  0.4438, -0.0210,  0.3452,
         0.1897,  0.4331,  0.3975, -0.4551, -0.3750,  0.1975, -0.3364, -0.0012,
        -0.1466, -0.3279,  0.4036,  0.0290, -0.3406, -0.3088, -0.3645,  0.1589,
         0.0593,  0.3894, -0.2429,  0.3750,  0.0646, -0.2913, -0.2422,  0.0770,
        -0.0102,  0.2976,  0.3201, -0.1495, -0.2634,  0.2327, -0.4646,  0.4028,
        -0.4207,  0.2942, -0.3909,  0.3293, -0.2430,  0.0557,  0.4370,  0.0373,
        -0.1826, -0.2405,  0.1941, -0.1307, -0.4680,  0.3938, -0.1417, -0.1836,
         0.1447,  0.4773,  0.3789,  0.0156, -0.4988, -0.3809, -0.2961,  0.4763,
         0.1865,  0.3528,  0.1127, -0.3171,  0.3938, -0.2281, -0.2590, -0.4519,
        -0.3987, -0.1953, -0.3586, -0.3298, -0.2411, -0.3230,  0.1428, -0.0112,
        -0.3962, -0.0300, -0.2091,  0.3162,  0.4976, -0.4111, -0.3601, -0.2761,
        -0.3875,  0.2216, -0.1981, -0.1088], dtype=torch.float16)
[Worker 3] Completed Task 1179

[Worker 3] Processing Task 1183: paddle.roll(Tensor([1, 38044, 21, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 38044, 21, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 62901 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 38043, 10, 12, 117) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 38043, 9, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 38044, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3926, -0.3127,  0.4485, -0.4602,  0.4390, -0.0618,  0.0744,  0.3127,
        -0.2471, -0.1906, -0.3230,  0.4219, -0.4741, -0.2432,  0.3877,  0.1949,
         0.3657, -0.0735,  0.4038, -0.3586, -0.0801,  0.3354,  0.0358, -0.1016,
         0.2068,  0.0762, -0.1129, -0.2832,  0.1984, -0.0374,  0.4851, -0.4724,
        -0.1067, -0.0355, -0.0317, -0.0056,  0.3154, -0.4968,  0.4209,  0.0512,
         0.1659,  0.0069,  0.2639,  0.4878, -0.0661, -0.3838, -0.3171,  0.0212,
         0.3535, -0.4058, -0.2240,  0.1725, -0.1833, -0.2123,  0.4541, -0.2705,
         0.0967,  0.2957, -0.0908,  0.4045,  0.3069,  0.4695, -0.1387, -0.3091,
        -0.3989, -0.1437, -0.2700, -0.3901, -0.1666, -0.2384,  0.1509, -0.4268,
         0.2019,  0.2014, -0.3289,  0.1722, -0.3074, -0.1769,  0.1687, -0.4744,
         0.0326,  0.0109,  0.3293, -0.4653, -0.0568, -0.1298, -0.0609, -0.3430,
        -0.1581, -0.3501,  0.3025, -0.0092, -0.0158,  0.0269, -0.1932, -0.1975,
         0.4673, -0.1068, -0.1927,  0.3730], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 38044, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3926, -0.3127,  0.4485, -0.4602,  0.4390, -0.0618,  0.0744,  0.3127,
        -0.2471, -0.1906, -0.3230,  0.4219, -0.4741, -0.2432,  0.3877,  0.1949,
         0.3657, -0.0735,  0.4038, -0.3586, -0.0801,  0.3354,  0.0358, -0.1016,
         0.2068,  0.0762, -0.1129, -0.2832,  0.1984, -0.0374,  0.4851, -0.4724,
        -0.1067, -0.0355, -0.0317, -0.0056,  0.3154, -0.4968,  0.4209,  0.0512,
         0.1659,  0.0069,  0.2639,  0.4878, -0.0661, -0.3838, -0.3171,  0.0212,
         0.3535, -0.4058, -0.2240,  0.1725, -0.1833, -0.2123,  0.4541, -0.2705,
         0.0967,  0.2957, -0.0908,  0.4045,  0.3069,  0.4695, -0.1387, -0.3091,
        -0.3989, -0.1437, -0.2700, -0.3901, -0.1666, -0.2384,  0.1509, -0.4268,
         0.2019,  0.2014, -0.3289,  0.1722, -0.3074, -0.1769,  0.1687, -0.4744,
         0.0326,  0.0109,  0.3293, -0.4653, -0.0568, -0.1298, -0.0609, -0.3430,
        -0.1581, -0.3501,  0.3025, -0.0092, -0.0158,  0.0269, -0.1932, -0.1975,
         0.4673, -0.1068, -0.1927,  0.3730], dtype=torch.float16)
[Worker 3] Completed Task 1183

[Worker 3] Processing Task 1187: paddle.roll(Tensor([1, 57066, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 57066, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 62978 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 57065, 3, 0, 125) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 57065, 2, 0, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 57066, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.0125, -0.1095, -0.3396, -0.4990,  0.4827,  0.4065, -0.4458,  0.2384,
         0.4626,  0.1044, -0.1230, -0.3616,  0.1899,  0.2128, -0.3645,  0.0711,
         0.1287,  0.4500,  0.2622,  0.1573,  0.4712, -0.4111, -0.2561,  0.4121,
        -0.2949, -0.4436, -0.4272, -0.0419,  0.4749,  0.3823,  0.3247,  0.0721,
         0.3899, -0.2200,  0.2605,  0.3401, -0.1036, -0.4094,  0.0377, -0.3479,
        -0.1915,  0.0205,  0.4172,  0.2076, -0.1583, -0.0375,  0.3674,  0.3230,
         0.2925,  0.3369,  0.0425, -0.1774,  0.0180, -0.4058,  0.0642, -0.2725,
         0.3577,  0.4595,  0.1849, -0.4568,  0.1882,  0.0402,  0.1138,  0.3274,
         0.0028, -0.0948, -0.1053,  0.0345, -0.4001, -0.1488,  0.1917,  0.4756,
        -0.0643,  0.3047, -0.4802,  0.1350,  0.1887,  0.1037, -0.1487, -0.4822,
        -0.3271, -0.0759,  0.4272,  0.2578, -0.2925, -0.2340, -0.1805, -0.2448,
         0.1499, -0.1302,  0.4685, -0.2173,  0.3057,  0.4119, -0.4558,  0.0478,
        -0.4346, -0.2162, -0.2393, -0.3274], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 57066, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.0125, -0.1095, -0.3396, -0.4990,  0.4827,  0.4065, -0.4458,  0.2384,
         0.4626,  0.1044, -0.1230, -0.3616,  0.1899,  0.2128, -0.3645,  0.0711,
         0.1287,  0.4500,  0.2622,  0.1573,  0.4712, -0.4111, -0.2561,  0.4121,
        -0.2949, -0.4436, -0.4272, -0.0419,  0.4749,  0.3823,  0.3247,  0.0721,
         0.3899, -0.2200,  0.2605,  0.3401, -0.1036, -0.4094,  0.0377, -0.3479,
        -0.1915,  0.0205,  0.4172,  0.2076, -0.1583, -0.0375,  0.3674,  0.3230,
         0.2925,  0.3369,  0.0425, -0.1774,  0.0180, -0.4058,  0.0642, -0.2725,
         0.3577,  0.4595,  0.1849, -0.4568,  0.1882,  0.0402,  0.1138,  0.3274,
         0.0028, -0.0948, -0.1053,  0.0345, -0.4001, -0.1488,  0.1917,  0.4756,
        -0.0643,  0.3047, -0.4802,  0.1350,  0.1887,  0.1037, -0.1487, -0.4822,
        -0.3271, -0.0759,  0.4272,  0.2578, -0.2925, -0.2340, -0.1805, -0.2448,
         0.1499, -0.1302,  0.4685, -0.2173,  0.3057,  0.4119, -0.4558,  0.0478,
        -0.4346, -0.2162, -0.2393, -0.3274], dtype=torch.float16)
[Worker 3] Completed Task 1187

[Worker 3] Processing Task 1191: paddle.roll(Tensor([1431655766, 3],"float16"), shifts=1, axis=0, )
[accuracy error] paddle.roll(Tensor([1431655766, 3],"float16"), shifts=1, axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 4294967298 (0.0%)
Greatest absolute difference: 0.1669921875 at index (1431655765, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1431655765, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.3528, -0.4688, -0.1833,  0.1671, -0.1775,  0.3176,  0.0399,  0.4336,
         0.2861, -0.0923, -0.0914, -0.0741,  0.2389, -0.3960,  0.4971, -0.3767,
         0.4597,  0.4797,  0.3303, -0.2310, -0.2041,  0.2288, -0.4736,  0.1851,
         0.1378,  0.1187, -0.1456,  0.2172, -0.2251,  0.0446, -0.4028,  0.3975,
         0.4851, -0.1332,  0.0858, -0.1346, -0.0154, -0.1313, -0.2524,  0.4741,
         0.1566,  0.1310,  0.3433,  0.4717, -0.1525,  0.4753,  0.1338,  0.4299,
        -0.1700,  0.1460,  0.0190, -0.4512, -0.2549,  0.0294,  0.1056, -0.2411,
        -0.1962, -0.3604, -0.1985,  0.3555, -0.4365, -0.0744,  0.0794,  0.3481,
         0.0372,  0.4917, -0.0367,  0.4021, -0.2461, -0.4990, -0.4331,  0.3777,
        -0.0318,  0.2135,  0.4951, -0.2925, -0.2585,  0.2551, -0.0589,  0.3884,
         0.0175,  0.0267, -0.2759, -0.3599,  0.0884, -0.1842,  0.1891,  0.4128,
        -0.2581,  0.0948,  0.0334, -0.1412, -0.2771, -0.4785,  0.0282, -0.3525,
        -0.3840, -0.3162,  0.1299,  0.1322], dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.3528, -0.4688, -0.1833,  0.1671, -0.1775,  0.3176,  0.0399,  0.4336,
         0.2861, -0.0923, -0.0914, -0.0741,  0.2389, -0.3960,  0.4971, -0.3767,
         0.4597,  0.4797,  0.3303, -0.2310, -0.2041,  0.2288, -0.4736,  0.1851,
         0.1378,  0.1187, -0.1456,  0.2172, -0.2251,  0.0446, -0.4028,  0.3975,
         0.4851, -0.1332,  0.0858, -0.1346, -0.0154, -0.1313, -0.2524,  0.4741,
         0.1566,  0.1310,  0.3433,  0.4717, -0.1525,  0.4753,  0.1338,  0.4299,
        -0.1700,  0.1460,  0.0190, -0.4512, -0.2549,  0.0294,  0.1056, -0.2411,
        -0.1962, -0.3604, -0.1985,  0.3555, -0.4365, -0.0744,  0.0794,  0.3481,
         0.0372,  0.4917, -0.0367,  0.4021, -0.2461, -0.4990, -0.4331,  0.3777,
        -0.0318,  0.2135,  0.4951, -0.2925, -0.2585,  0.2551, -0.0589,  0.3884,
         0.0175,  0.0267, -0.2759, -0.3599,  0.0884, -0.1842,  0.1891,  0.4128,
        -0.2581,  0.0948,  0.0334, -0.1412, -0.2771, -0.4785,  0.0282, -0.3525,
        -0.3840, -0.3162,  0.1299,  0.1322], dtype=torch.float16)
[Worker 3] Completed Task 1191

[Worker 3] Processing Task 1195: paddle.roll(Tensor([2378, 16, 21, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([2378, 16, 21, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 505645 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (2377, 11, 9, 4, 245) (up to 0.01 allowed)
Greatest relative difference: inf at index (2377, 11, 9, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2378, 16, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3926, -0.3127,  0.4485, -0.4602,  0.4390, -0.0618,  0.0744,  0.3127,
        -0.2471, -0.1906, -0.3230,  0.4219, -0.4741, -0.2432,  0.3877,  0.1949,
         0.3657, -0.0735,  0.4038, -0.3586, -0.0801,  0.3354,  0.0358, -0.1016,
         0.2068,  0.0762, -0.1129, -0.2832,  0.1984, -0.0374,  0.4851, -0.4724,
        -0.1067, -0.0355, -0.0317, -0.0056,  0.3154, -0.4968,  0.4209,  0.0512,
         0.1659,  0.0069,  0.2639,  0.4878, -0.0661, -0.3838, -0.3171,  0.0212,
         0.3535, -0.4058, -0.2240,  0.1725, -0.1833, -0.2123,  0.4541, -0.2705,
         0.0967,  0.2957, -0.0908,  0.4045,  0.3069,  0.4695, -0.1387, -0.3091,
        -0.3989, -0.1437, -0.2700, -0.3901, -0.1666, -0.2384,  0.1509, -0.4268,
         0.2019,  0.2014, -0.3289,  0.1722, -0.3074, -0.1769,  0.1687, -0.4744,
         0.0326,  0.0109,  0.3293, -0.4653, -0.0568, -0.1298, -0.0609, -0.3430,
        -0.1581, -0.3501,  0.3025, -0.0092, -0.0158,  0.0269, -0.1932, -0.1975,
         0.4673, -0.1068, -0.1927,  0.3730], dtype=torch.float16)
DESIRED: (shape=torch.Size([2378, 16, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3926, -0.3127,  0.4485, -0.4602,  0.4390, -0.0618,  0.0744,  0.3127,
        -0.2471, -0.1906, -0.3230,  0.4219, -0.4741, -0.2432,  0.3877,  0.1949,
         0.3657, -0.0735,  0.4038, -0.3586, -0.0801,  0.3354,  0.0358, -0.1016,
         0.2068,  0.0762, -0.1129, -0.2832,  0.1984, -0.0374,  0.4851, -0.4724,
        -0.1067, -0.0355, -0.0317, -0.0056,  0.3154, -0.4968,  0.4209,  0.0512,
         0.1659,  0.0069,  0.2639,  0.4878, -0.0661, -0.3838, -0.3171,  0.0212,
         0.3535, -0.4058, -0.2240,  0.1725, -0.1833, -0.2123,  0.4541, -0.2705,
         0.0967,  0.2957, -0.0908,  0.4045,  0.3069,  0.4695, -0.1387, -0.3091,
        -0.3989, -0.1437, -0.2700, -0.3901, -0.1666, -0.2384,  0.1509, -0.4268,
         0.2019,  0.2014, -0.3289,  0.1722, -0.3074, -0.1769,  0.1687, -0.4744,
         0.0326,  0.0109,  0.3293, -0.4653, -0.0568, -0.1298, -0.0609, -0.3430,
        -0.1581, -0.3501,  0.3025, -0.0092, -0.0158,  0.0269, -0.1932, -0.1975,
         0.4673, -0.1068, -0.1927,  0.3730], dtype=torch.float16)
[Worker 3] Completed Task 1195

[Worker 3] Processing Task 1199: paddle.roll(Tensor([3567, 16, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([3567, 16, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 505698 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (3566, 9, 3, 12, 235) (up to 0.01 allowed)
Greatest relative difference: inf at index (3566, 9, 2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3567, 16, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3665, -0.0929,  0.4973, -0.1755,  0.4094, -0.0450,  0.3628,  0.0213,
         0.1608,  0.4602,  0.2122, -0.2032,  0.2815,  0.2175,  0.2866,  0.0955,
         0.3369,  0.1030, -0.1965, -0.0218,  0.4551, -0.4802, -0.4360,  0.0093,
        -0.0228,  0.3899,  0.3076, -0.1081,  0.3311,  0.0440, -0.3721,  0.3076,
         0.0560, -0.4316, -0.0550,  0.2418, -0.4419, -0.2974,  0.4858, -0.1492,
        -0.3755, -0.4922, -0.2206, -0.1418,  0.3318, -0.2771, -0.4280,  0.4900,
        -0.0151, -0.3669, -0.1432, -0.2544, -0.1604, -0.4751,  0.2930,  0.1021,
        -0.4272, -0.1161,  0.0682,  0.3738,  0.4360,  0.1891, -0.4458,  0.4451,
        -0.1003, -0.4014,  0.4587, -0.0920,  0.0784, -0.0378, -0.1317,  0.4553,
         0.4436,  0.4812, -0.4385,  0.3198, -0.1237,  0.2998, -0.3572,  0.1650,
         0.4148, -0.0571,  0.3579,  0.2117, -0.0988,  0.1711,  0.3787,  0.0051,
         0.2345, -0.4626, -0.4226, -0.3977, -0.4170,  0.2340, -0.4277,  0.4023,
        -0.4719, -0.2228, -0.0219,  0.2812], dtype=torch.float16)
DESIRED: (shape=torch.Size([3567, 16, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3665, -0.0929,  0.4973, -0.1755,  0.4094, -0.0450,  0.3628,  0.0213,
         0.1608,  0.4602,  0.2122, -0.2032,  0.2815,  0.2175,  0.2866,  0.0955,
         0.3369,  0.1030, -0.1965, -0.0218,  0.4551, -0.4802, -0.4360,  0.0093,
        -0.0228,  0.3899,  0.3076, -0.1081,  0.3311,  0.0440, -0.3721,  0.3076,
         0.0560, -0.4316, -0.0550,  0.2418, -0.4419, -0.2974,  0.4858, -0.1492,
        -0.3755, -0.4922, -0.2206, -0.1418,  0.3318, -0.2771, -0.4280,  0.4900,
        -0.0151, -0.3669, -0.1432, -0.2544, -0.1604, -0.4751,  0.2930,  0.1021,
        -0.4272, -0.1161,  0.0682,  0.3738,  0.4360,  0.1891, -0.4458,  0.4451,
        -0.1003, -0.4014,  0.4587, -0.0920,  0.0784, -0.0378, -0.1317,  0.4553,
         0.4436,  0.4812, -0.4385,  0.3198, -0.1237,  0.2998, -0.3572,  0.1650,
         0.4148, -0.0571,  0.3579,  0.2117, -0.0988,  0.1711,  0.3787,  0.0051,
         0.2345, -0.4626, -0.4226, -0.3977, -0.4170,  0.2340, -0.4277,  0.4023,
        -0.4719, -0.2228, -0.0219,  0.2812], dtype=torch.float16)
[Worker 3] Completed Task 1199

[Worker 3] Processing Task 1203: paddle.roll(Tensor([3567, 16, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([3567, 16, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 492129 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (3566, 9, 2, 11, 60) (up to 0.01 allowed)
Greatest relative difference: inf at index (3566, 9, 2, 4, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3567, 16, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4626, -0.3669, -0.3286,  0.4075, -0.2234, -0.2954,  0.3853, -0.0806,
         0.3140,  0.2030, -0.3271,  0.4104, -0.4316,  0.2844,  0.4910, -0.1782,
        -0.1508,  0.0461, -0.0551, -0.3286,  0.2489, -0.0223,  0.3879, -0.3296,
         0.3552, -0.2883, -0.3477,  0.2749, -0.0479, -0.4756, -0.3157, -0.3247,
        -0.2642, -0.0760, -0.4202,  0.1176,  0.1249, -0.2837, -0.3984,  0.3337,
        -0.1119, -0.4998,  0.4971, -0.4487, -0.0466,  0.0052, -0.1869,  0.3931,
        -0.1287, -0.3699,  0.3472,  0.2058, -0.4338,  0.2491, -0.2223,  0.0307,
         0.0623, -0.0977,  0.1313,  0.0703,  0.1210, -0.3879,  0.2048,  0.2866,
        -0.1671, -0.1160,  0.1450,  0.3701,  0.1405, -0.4304,  0.4548, -0.3135,
         0.1954,  0.0245, -0.0252,  0.4236,  0.3645, -0.4788,  0.2825, -0.3474,
        -0.0214,  0.1254,  0.0856,  0.4509, -0.3926, -0.3027, -0.3804, -0.3726,
         0.0333, -0.2634,  0.0652, -0.0553,  0.1821,  0.2981, -0.3708,  0.0830,
         0.4717,  0.4294, -0.2432,  0.2268], dtype=torch.float16)
DESIRED: (shape=torch.Size([3567, 16, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4626, -0.3669, -0.3286,  0.4075, -0.2234, -0.2954,  0.3853, -0.0806,
         0.3140,  0.2030, -0.3271,  0.4104, -0.4316,  0.2844,  0.4910, -0.1782,
        -0.1508,  0.0461, -0.0551, -0.3286,  0.2489, -0.0223,  0.3879, -0.3296,
         0.3552, -0.2883, -0.3477,  0.2749, -0.0479, -0.4756, -0.3157, -0.3247,
        -0.2642, -0.0760, -0.4202,  0.1176,  0.1249, -0.2837, -0.3984,  0.3337,
        -0.1119, -0.4998,  0.4971, -0.4487, -0.0466,  0.0052, -0.1869,  0.3931,
        -0.1287, -0.3699,  0.3472,  0.2058, -0.4338,  0.2491, -0.2223,  0.0307,
         0.0623, -0.0977,  0.1313,  0.0703,  0.1210, -0.3879,  0.2048,  0.2866,
        -0.1671, -0.1160,  0.1450,  0.3701,  0.1405, -0.4304,  0.4548, -0.3135,
         0.1954,  0.0245, -0.0252,  0.4236,  0.3645, -0.4788,  0.2825, -0.3474,
        -0.0214,  0.1254,  0.0856,  0.4509, -0.3926, -0.3027, -0.3804, -0.3726,
         0.0333, -0.2634,  0.0652, -0.0553,  0.1821,  0.2981, -0.3708,  0.0830,
         0.4717,  0.4294, -0.2432,  0.2268], dtype=torch.float16)
[Worker 3] Completed Task 1203

[Worker 3] Processing Task 1207: paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=-1, axis=0, )
[accuracy error] paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=-1, axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 4294967298 (0.0%)
Greatest absolute difference: 0.15283203125 at index (2, 1431655765) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1431655764) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.3752, -0.3481,  0.2461,  0.0664,  0.2646,  0.2228, -0.1534,  0.1586,
        -0.0184, -0.3574,  0.1127, -0.4360, -0.2668, -0.2629,  0.1176, -0.1214,
        -0.4744,  0.3350, -0.2368, -0.0467, -0.1891, -0.0634,  0.2849,  0.4497,
        -0.0592, -0.4976,  0.1796,  0.4697,  0.0799, -0.4395, -0.3013,  0.2397,
        -0.2172,  0.0238,  0.2742, -0.0724,  0.4385,  0.4648,  0.4619, -0.0047,
        -0.4341,  0.1289, -0.1179, -0.1219,  0.4434,  0.0057, -0.4026, -0.3435,
        -0.2108,  0.1302,  0.1737,  0.1335, -0.4214,  0.2126,  0.2546,  0.2256,
        -0.2162, -0.0484, -0.1973, -0.4194,  0.3992, -0.2700,  0.4905, -0.3074,
        -0.0550,  0.0748, -0.0340, -0.0272, -0.1797,  0.4922, -0.4993, -0.2472,
        -0.2844, -0.0389,  0.4973,  0.1387,  0.2090, -0.4270,  0.3081,  0.2302,
         0.1243,  0.3716, -0.1631,  0.2739,  0.3315, -0.0652,  0.3535, -0.2883,
         0.2874,  0.1354, -0.1497,  0.3818, -0.2137, -0.2559, -0.4734, -0.3870,
         0.3130, -0.1271,  0.3782, -0.3247], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.3752, -0.3481,  0.2461,  0.0664,  0.2646,  0.2228, -0.1534,  0.1586,
        -0.0184, -0.3574,  0.1127, -0.4360, -0.2668, -0.2629,  0.1176, -0.1214,
        -0.4744,  0.3350, -0.2368, -0.0467, -0.1891, -0.0634,  0.2849,  0.4497,
        -0.0592, -0.4976,  0.1796,  0.4697,  0.0799, -0.4395, -0.3013,  0.2397,
        -0.2172,  0.0238,  0.2742, -0.0724,  0.4385,  0.4648,  0.4619, -0.0047,
        -0.4341,  0.1289, -0.1179, -0.1219,  0.4434,  0.0057, -0.4026, -0.3435,
        -0.2108,  0.1302,  0.1737,  0.1335, -0.4214,  0.2126,  0.2546,  0.2256,
        -0.2162, -0.0484, -0.1973, -0.4194,  0.3992, -0.2700,  0.4905, -0.3074,
        -0.0550,  0.0748, -0.0340, -0.0272, -0.1797,  0.4922, -0.4993, -0.2472,
        -0.2844, -0.0389,  0.4973,  0.1387,  0.2090, -0.4270,  0.3081,  0.2302,
         0.1243,  0.3716, -0.1631,  0.2739,  0.3315, -0.0652,  0.3535, -0.2883,
         0.2874,  0.1354, -0.1497,  0.3818, -0.2137, -0.2559, -0.4734, -0.3870,
         0.3130, -0.1271,  0.3782, -0.3247], dtype=torch.float16)
[Worker 3] Completed Task 1207

[Worker 3] Processing Task 1210: paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=tuple(-1,1,), axis=tuple(0,1,), )
[accuracy error] paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=tuple(-1,1,), axis=tuple(0,1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 4294967298 (0.0%)
Greatest absolute difference: 0.2490234375 at index (2, 1431655764) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([ 0.0899, -0.3752, -0.3481,  0.2461,  0.0664,  0.2646,  0.2228, -0.1534,
         0.1586, -0.0184, -0.3574,  0.1127, -0.4360, -0.2668, -0.2629,  0.1176,
        -0.1214, -0.4744,  0.3350, -0.2368, -0.0467, -0.1891, -0.0634,  0.2849,
         0.4497, -0.0592, -0.4976,  0.1796,  0.4697,  0.0799, -0.4395, -0.3013,
         0.2397, -0.2172,  0.0238,  0.2742, -0.0724,  0.4385,  0.4648,  0.4619,
        -0.0047, -0.4341,  0.1289, -0.1179, -0.1219,  0.4434,  0.0057, -0.4026,
        -0.3435, -0.2108,  0.1302,  0.1737,  0.1335, -0.4214,  0.2126,  0.2546,
         0.2256, -0.2162, -0.0484, -0.1973, -0.4194,  0.3992, -0.2700,  0.4905,
        -0.3074, -0.0550,  0.0748, -0.0340, -0.0272, -0.1797,  0.4922, -0.4993,
        -0.2472, -0.2844, -0.0389,  0.4973,  0.1387,  0.2090, -0.4270,  0.3081,
         0.2302,  0.1243,  0.3716, -0.1631,  0.2739,  0.3315, -0.0652,  0.3535,
        -0.2883,  0.2874,  0.1354, -0.1497,  0.3818, -0.2137, -0.2559, -0.4734,
        -0.3870,  0.3130, -0.1271,  0.3782], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([ 0.0899, -0.3752, -0.3481,  0.2461,  0.0664,  0.2646,  0.2228, -0.1534,
         0.1586, -0.0184, -0.3574,  0.1127, -0.4360, -0.2668, -0.2629,  0.1176,
        -0.1214, -0.4744,  0.3350, -0.2368, -0.0467, -0.1891, -0.0634,  0.2849,
         0.4497, -0.0592, -0.4976,  0.1796,  0.4697,  0.0799, -0.4395, -0.3013,
         0.2397, -0.2172,  0.0238,  0.2742, -0.0724,  0.4385,  0.4648,  0.4619,
        -0.0047, -0.4341,  0.1289, -0.1179, -0.1219,  0.4434,  0.0057, -0.4026,
        -0.3435, -0.2108,  0.1302,  0.1737,  0.1335, -0.4214,  0.2126,  0.2546,
         0.2256, -0.2162, -0.0484, -0.1973, -0.4194,  0.3992, -0.2700,  0.4905,
        -0.3074, -0.0550,  0.0748, -0.0340, -0.0272, -0.1797,  0.4922, -0.4993,
        -0.2472, -0.2844, -0.0389,  0.4973,  0.1387,  0.2090, -0.4270,  0.3081,
         0.2302,  0.1243,  0.3716, -0.1631,  0.2739,  0.3315, -0.0652,  0.3535,
        -0.2883,  0.2874,  0.1354, -0.1497,  0.3818, -0.2137, -0.2559, -0.4734,
        -0.3870,  0.3130, -0.1271,  0.3782], dtype=torch.float16)
[Worker 3] Completed Task 1210

[Worker 3] Processing Task 1214: paddle.rsqrt(x=Tensor([477218589, 3, 3],"float16"), )
[accuracy error] backward  paddle.rsqrt(x=Tensor([477218589, 3, 3],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2010421 / 4294967301 (0.0%)
Greatest absolute difference: nan at index (167065481, 2, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (203, 2, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([477218589, 3, 3]), dtype=torch.float16)
First 100 elements: tensor([  0.2681,      nan,   0.5396, -22.9375,   0.1228,   0.7407,      nan,
             nan,      nan,   0.3447,      nan,  -0.6064,      nan,  -0.4956,
          0.1086,  -0.1389,      nan,      nan,   1.2871,      nan,   0.1318,
          2.6289,  -4.6289,      nan,   1.1074,      nan, -18.4844,      nan,
         -0.3103,  -0.5142,      nan,   4.0430,      nan,      nan,      nan,
             nan,  -0.1385,   0.7500,   1.1104,   0.6006,  -0.1642,      nan,
         -0.3420,  -2.0410,  -0.2539,      nan,  -2.8906,  20.1250,      nan,
             nan,  35.8438,   0.2267,      nan,      nan,      nan,      nan,
          1.0068,      nan,      nan,   9.2891,  -0.5977,  31.8125,  -0.4780,
             nan,  -0.4387,      nan,      nan,      nan,   0.6865,      nan,
          1.9990,  -0.2241,      nan,      nan,   1.1240,      nan,  -0.6899,
         93.1875,   4.4297,      nan,      nan,  -7.1016,      nan,   2.4434,
         -0.2898,      nan,  -8.4062, -37.1250,      nan,      nan,      nan,
         -7.3750,      nan,      nan,      nan,  -2.6582,   0.6089,   0.2615,
         -0.1233,   1.0625], dtype=torch.float16)
DESIRED: (shape=torch.Size([477218589, 3, 3]), dtype=torch.float16)
First 100 elements: tensor([  0.2681,      nan,   0.5396, -22.9375,   0.1228,   0.7407,      nan,
             nan,      nan,   0.3447,      nan,  -0.6064,      nan,  -0.4954,
          0.1087,  -0.1389,      nan,      nan,   1.2861,      nan,   0.1318,
          2.6270,  -4.6250,      nan,   1.1064,      nan, -18.4844,      nan,
         -0.3105,  -0.5142,      nan,   4.0430,      nan,      nan,      nan,
             nan,  -0.1385,   0.7495,   1.1104,   0.6006,  -0.1642,      nan,
         -0.3423,  -2.0410,  -0.2539,      nan,  -2.8926,  20.1250,      nan,
             nan,  35.8125,   0.2268,      nan,      nan,      nan,      nan,
          1.0068,      nan,      nan,   9.2891,  -0.5977,  31.7969,  -0.4780,
             nan,  -0.4387,      nan,      nan,      nan,   0.6860,      nan,
          1.9990,  -0.2241,      nan,      nan,   1.1230,      nan,  -0.6895,
         93.1875,   4.4258,      nan,      nan,  -7.1055,      nan,   2.4434,
         -0.2900,      nan,  -8.3984, -37.0938,      nan,      nan,      nan,
         -7.3750,      nan,      nan,      nan,  -2.6582,   0.6089,   0.2612,
         -0.1232,   1.0625], dtype=torch.float16)
[Worker 3] Completed Task 1214

[Worker 3] Processing Task 1312: paddle.Tensor.bmm(Tensor([7012, 108472, 3],"float32"), Tensor([7012, 3, 2],"float32"), )
[accuracy error] backward  paddle.Tensor.bmm(Tensor([7012, 108472, 3],"float32"), Tensor([7012, 3, 2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 114 / 42072 (0.3%)
Greatest absolute difference: 0.0323714017868042 at index (6745, 2, 1) (up to 0.01 allowed)
Greatest relative difference: 1.9871398210525513 at index (3541, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([7012, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([ -8.6472,  14.1194, -57.6700, -23.2556,  15.4439, -14.8330,   7.3508,
         -7.1006,  -8.8053, -58.8534, -25.0036, -66.1511,  11.5381,  -2.0239,
          8.8581,  88.4912, -33.0763, -39.2343,  -4.2553, -40.1737, -14.4327,
         -2.5733,   6.8252,  26.2605, -13.4395,  38.6012,   1.5601,  17.9300,
          3.7084, -22.7401,  20.3778,  -5.1516,  -6.6674,  42.6544, -32.8112,
         42.7991, -23.7839, -12.1468,  32.2531, -34.2732,  47.4944,  13.1094,
         24.9586,  33.2072, -33.1309,  -3.8879,  -7.8410,  51.0231,  13.3750,
         58.6401,   3.6335,   7.7610,  -5.0649,  -2.8419,  -0.4884,  17.3193,
        -32.3912,  20.0175, -62.2127,  -4.2870,  37.5197, -11.4945,   9.9903,
        -12.4600,   7.5295, -11.7154, -16.1101,   1.0450,  -5.1509,  29.0062,
         25.4916, -20.8560, -46.9719, -54.9776,   2.7167, -19.4242, -62.0745,
        -22.2254, -12.2417, -27.3316,  25.3232,  32.7551,  -2.0427,   4.1410,
        -19.5525,  19.6274,  -6.8665,  -5.5269, -34.1885, -43.4071,  -7.0254,
        -50.0070, -40.0499, -35.0804,   1.8617, -28.2996, -16.2498,  23.3745,
        -54.6533,  13.5893])
DESIRED: (shape=torch.Size([7012, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([ -8.6380,  14.1219, -57.6822, -23.2671,  15.4504, -14.8376,   7.3541,
         -7.1054,  -8.8098, -58.8692, -25.0055, -66.1762,  11.5425,  -2.0219,
          8.8640,  88.4949, -33.0869, -39.2422,  -4.2560, -40.1999, -14.4386,
         -2.5811,   6.8295,  26.2705, -13.4440,  38.6167,   1.5746,  17.9362,
          3.7073, -22.7544,  20.3860,  -5.1532,  -6.6548,  42.6776, -32.8243,
         42.8126, -23.8055, -12.1502,  32.2593, -34.2780,  47.5084,  13.1163,
         24.9527,  33.2196, -33.1467,  -3.8902,  -7.8615,  51.0281,  13.3693,
         58.6512,   3.6299,   7.7769,  -5.0619,  -2.8311,  -0.4706,  17.3254,
        -32.3972,  20.0222, -62.2177,  -4.2918,  37.5380, -11.5060,   9.9979,
        -12.4704,   7.5191, -11.7177, -16.1167,   1.0388,  -5.1566,  29.0108,
         25.4939, -20.8480, -46.9988, -54.9922,   2.7181, -19.4217, -62.0844,
        -22.2215, -12.2381, -27.3373,  25.3254,  32.7564,  -2.0523,   4.1452,
        -19.5664,  19.6311,  -6.8539,  -5.5336, -34.2053, -43.4140,  -7.0347,
        -50.0163, -40.0674, -35.0899,   1.8621, -28.2910, -16.2552,  23.3730,
        -54.6621,  13.5899])
[Worker 3] Completed Task 1312

[Worker 3] Processing Task 1320: paddle.Tensor.cumsum(Tensor([1, 10, 228170138],"float32"), 2, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 10, 228170138],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 626558 / 2281701380 (0.0%)
Greatest absolute difference: 0.2515830993652344 at index (0, 3, 215212490) (up to 0.01 allowed)
Greatest relative difference: 6068.18896484375 at index (0, 0, 221440610) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 10, 228170138]), dtype=torch.float32)
First 100 elements: tensor([-0.1081, -0.2834, -0.5956, -0.1050,  0.2295,  0.4421,  0.3158,  0.7972,
         1.0243,  0.8082,  0.6948,  1.1394,  0.8747,  1.0020,  1.3207,  1.2301,
         0.9583,  0.7704,  0.5595,  0.4278,  0.5351,  0.9053,  0.9472,  1.4084,
         1.7381,  2.0938,  2.1492,  2.0876,  2.0220,  2.4297,  2.1858,  1.7210,
         1.7001,  2.1727,  2.4209,  2.1311,  2.1631,  1.9663,  1.6447,  1.5656,
         1.8803,  1.4774,  1.9152,  1.5374,  1.8228,  1.6179,  2.0863,  2.5625,
         2.2145,  2.2601,  2.1319,  1.9818,  2.3732,  2.2648,  2.4854,  2.0253,
         2.2409,  2.4015,  2.2970,  2.2812,  2.1324,  1.6824,  1.2224,  1.0612,
         0.7777,  0.9277,  0.7497,  0.6164,  0.3194,  0.2755,  0.4160,  0.6816,
         1.1739,  0.9414,  0.5486,  0.2015,  0.3979,  0.4531,  0.5960,  1.0044,
         1.3258,  1.0142,  1.1136,  0.8662,  0.4634,  0.6080,  0.5683,  0.0883,
        -0.3625,  0.0092, -0.3437,  0.0395, -0.2756, -0.4430, -0.0949, -0.2701,
        -0.0337,  0.4337,  0.2076,  0.6481])
DESIRED: (shape=torch.Size([1, 10, 228170138]), dtype=torch.float32)
First 100 elements: tensor([-0.1081, -0.2834, -0.5956, -0.1050,  0.2295,  0.4421,  0.3158,  0.7972,
         1.0243,  0.8082,  0.6948,  1.1394,  0.8747,  1.0020,  1.3207,  1.2301,
         0.9583,  0.7704,  0.5595,  0.4278,  0.5351,  0.9053,  0.9472,  1.4084,
         1.7381,  2.0938,  2.1492,  2.0876,  2.0220,  2.4297,  2.1858,  1.7210,
         1.7001,  2.1727,  2.4209,  2.1311,  2.1631,  1.9663,  1.6447,  1.5656,
         1.8803,  1.4774,  1.9152,  1.5374,  1.8228,  1.6179,  2.0863,  2.5625,
         2.2145,  2.2601,  2.1319,  1.9818,  2.3732,  2.2648,  2.4854,  2.0253,
         2.2409,  2.4015,  2.2970,  2.2812,  2.1324,  1.6824,  1.2224,  1.0612,
         0.7777,  0.9277,  0.7497,  0.6164,  0.3194,  0.2755,  0.4160,  0.6816,
         1.1739,  0.9414,  0.5486,  0.2015,  0.3979,  0.4531,  0.5960,  1.0044,
         1.3258,  1.0142,  1.1136,  0.8662,  0.4634,  0.6080,  0.5683,  0.0883,
        -0.3625,  0.0092, -0.3437,  0.0395, -0.2756, -0.4430, -0.0949, -0.2701,
        -0.0337,  0.4337,  0.2076,  0.6481])
[Worker 3] Completed Task 1320

[Worker 3] Processing Task 1324: paddle.Tensor.cumsum(Tensor([228170138, 10],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.cumsum(Tensor([228170138, 10],"int64"), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 70.012695GB memory has been allocated and available memory is only 9.172180GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 1324

[Worker 3] Processing Task 1329: paddle.Tensor.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([1073741825, 4],"float16"), append=Tensor([4, 4],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([1073741825, 4],"float16"), append=Tensor([4, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208560186 / 4294967352 (98.0%)
Greatest absolute difference: 1.0 at index (307530, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([ 0.2666,  0.4636, -0.4099, -0.1312, -0.5078, -0.0472, -0.3037,  0.5884,
        -0.3027,  0.2208,  0.8760, -0.1667,  0.1458, -0.6641, -0.2510, -0.8037,
         0.4160,  0.3418, -0.1100,  0.3281,  0.0321, -0.3628, -0.0741, -0.2573,
         0.1803,  0.7100, -0.1777,  0.4888, -0.5322, -0.5005,  0.0018, -0.3384,
         0.6089,  0.1720,  0.2622,  0.5957, -0.0024, -0.3091,  0.3442, -0.2095,
        -0.0417, -0.0176, -0.3293, -0.1147, -0.8809, -0.0848, -0.1166,  0.0865,
         0.2101,  0.0587, -0.3896, -0.3042,  0.5967, -0.2404,  0.2859,  0.2778,
        -0.0073,  0.4736,  0.5659, -0.1161,  0.0540, -0.2832, -0.9907, -0.3965,
        -0.0244,  0.2144,  0.7124,  0.9282, -0.6699, -0.2268,  0.0416, -0.5542,
         0.6807,  0.2761, -0.2285, -0.2170, -0.7480,  0.0709, -0.2109,  0.4648,
         0.7725, -0.3464,  0.2791, -0.1558, -0.5542, -0.0190, -0.5732, -0.0052,
        -0.2113, -0.1069,  0.1624,  0.1017,  0.4849,  0.6719,  0.5620,  0.1907,
        -0.1110, -0.3469, -0.4524, -0.3999], dtype=torch.float16)
[Worker 3] Completed Task 1329

[Worker 3] Processing Task 1332: paddle.Tensor.diff(x=Tensor([10],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4294967297],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([10],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208551124 / 4294967310 (98.0%)
Greatest absolute difference: 1.0 at index (18306595,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([-0.3447,  0.4951, -0.2778,  0.1272, -0.3447,  0.4951, -0.2778,  0.3938,
        -0.1475, -0.3784,  0.0010,  0.0173,  0.3130, -0.0718, -0.3447,  0.4951,
        -0.2778,  0.3938, -0.1475, -0.3784,  0.0010,  0.0173,  0.3130, -0.6348,
         0.8931, -0.8740,  0.8364,  0.0200, -0.1494, -0.5615,  0.0269,  0.4329,
        -0.7021,  0.6587, -0.0472, -0.0191, -0.2644,  0.3628, -0.4424,  0.2698,
        -0.4475,  0.8003,  0.0876, -0.6182,  0.2190, -0.2205,  0.1193, -0.1160,
        -0.1211,  0.7266, -0.3174, -0.0256,  0.2123,  0.1284, -0.6240,  0.6279,
        -0.3416,  0.2961, -0.6001,  0.3159, -0.1270, -0.4702,  0.1963,  0.2842,
         0.0762, -0.3467,  0.0449, -0.1642,  0.1619,  0.5537, -0.7920,  0.3621,
         0.1538,  0.2688, -0.3110,  0.4546, -0.5283,  0.4387, -0.6484, -0.2529,
         0.0659,  0.8105, -0.4094,  0.2454,  0.2817, -0.7876,  0.0339,  0.5137,
        -0.3140,  0.4473, -0.3708,  0.0092, -0.3025, -0.0840,  0.4482, -0.2725,
         0.3733,  0.2238, -0.6709,  0.3528], dtype=torch.float16)
[Worker 3] Completed Task 1332

[Worker 3] Processing Task 1336: paddle.Tensor.diff(x=Tensor([2281701379],"float32"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([2281701379],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235839635 / 2281701378 (98.0%)
Greatest absolute difference: 0.999997079372406 at index (1101195135,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([-0.0672, -0.1369,  0.8028, -0.1561, -0.1218, -0.3390,  0.6078, -0.2543,
        -0.4431,  0.1026,  0.5581, -0.7093,  0.3920,  0.1914, -0.4093, -0.1812,
         0.0840, -0.0230,  0.0791,  0.2391,  0.2628, -0.3282,  0.4191, -0.1313,
         0.0259, -0.3004, -0.1170, -0.0039,  0.4733, -0.6516, -0.2209,  0.4439,
         0.4935, -0.2243, -0.5381,  0.3218, -0.2287, -0.1248,  0.2424,  0.3939,
        -0.7176,  0.8406, -0.8156,  0.6632, -0.4904,  0.6733,  0.0079, -0.8242,
         0.3936, -0.1738, -0.0219,  0.5415, -0.4998,  0.3290, -0.6808,  0.6757,
        -0.0549, -0.2652,  0.0887, -0.1331, -0.3011, -0.0100,  0.2989, -0.1224,
         0.4336, -0.3280,  0.0446, -0.1637,  0.2531,  0.1844,  0.1251,  0.2266,
        -0.7247, -0.1604,  0.0457,  0.5435, -0.1411,  0.0876,  0.2656, -0.0870,
        -0.6331,  0.4111, -0.3468, -0.1553,  0.5473, -0.1842, -0.4403,  0.0291,
         0.8224, -0.7245,  0.7361, -0.6983,  0.1478,  0.5154, -0.5232,  0.4116,
         0.2310, -0.6935,  0.6667, -0.6285])
[Worker 3] Completed Task 1336

[Worker 3] Processing Task 1339: paddle.Tensor.diff(x=Tensor([4294967297],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208551111 / 4294967296 (98.0%)
Greatest absolute difference: 1.0 at index (18306581,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967296]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967296]), dtype=torch.float16)
First 100 elements: tensor([-0.3447,  0.4951, -0.2778,  0.3938, -0.1475, -0.3784,  0.0010,  0.0173,
         0.3130, -0.6348,  0.8931, -0.8740,  0.8364,  0.0200, -0.1494, -0.5615,
         0.0269,  0.4329, -0.7021,  0.6587, -0.0472, -0.0191, -0.2644,  0.3628,
        -0.4424,  0.2698, -0.4475,  0.8003,  0.0876, -0.6182,  0.2190, -0.2205,
         0.1193, -0.1160, -0.1211,  0.7266, -0.3174, -0.0256,  0.2123,  0.1284,
        -0.6240,  0.6279, -0.3416,  0.2961, -0.6001,  0.3159, -0.1270, -0.4702,
         0.1963,  0.2842,  0.0762, -0.3467,  0.0449, -0.1642,  0.1619,  0.5537,
        -0.7920,  0.3621,  0.1538,  0.2688, -0.3110,  0.4546, -0.5283,  0.4387,
        -0.6484, -0.2529,  0.0659,  0.8105, -0.4094,  0.2454,  0.2817, -0.7876,
         0.0339,  0.5137, -0.3140,  0.4473, -0.3708,  0.0092, -0.3025, -0.0840,
         0.4482, -0.2725,  0.3733,  0.2238, -0.6709,  0.3528, -0.0614, -0.1746,
        -0.1359, -0.2014,  0.5068, -0.3806, -0.0315,  0.0679,  0.4460,  0.0023,
         0.1554, -0.0416,  0.0746, -0.2993], dtype=torch.float16)
[Worker 3] Completed Task 1339

[Worker 3] Processing Task 1342: paddle.Tensor.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4294967297],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 8417102223 / 8589934593 (98.0%)
Greatest absolute difference: 1.0 at index (18306581,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8589934593]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([8589934593]), dtype=torch.float16)
First 100 elements: tensor([-0.3447,  0.4951, -0.2778,  0.3938, -0.1475, -0.3784,  0.0010,  0.0173,
         0.3130, -0.6348,  0.8931, -0.8740,  0.8364,  0.0200, -0.1494, -0.5615,
         0.0269,  0.4329, -0.7021,  0.6587, -0.0472, -0.0191, -0.2644,  0.3628,
        -0.4424,  0.2698, -0.4475,  0.8003,  0.0876, -0.6182,  0.2190, -0.2205,
         0.1193, -0.1160, -0.1211,  0.7266, -0.3174, -0.0256,  0.2123,  0.1284,
        -0.6240,  0.6279, -0.3416,  0.2961, -0.6001,  0.3159, -0.1270, -0.4702,
         0.1963,  0.2842,  0.0762, -0.3467,  0.0449, -0.1642,  0.1619,  0.5537,
        -0.7920,  0.3621,  0.1538,  0.2688, -0.3110,  0.4546, -0.5283,  0.4387,
        -0.6484, -0.2529,  0.0659,  0.8105, -0.4094,  0.2454,  0.2817, -0.7876,
         0.0339,  0.5137, -0.3140,  0.4473, -0.3708,  0.0092, -0.3025, -0.0840,
         0.4482, -0.2725,  0.3733,  0.2238, -0.6709,  0.3528, -0.0614, -0.1746,
        -0.1359, -0.2014,  0.5068, -0.3806, -0.0315,  0.0679,  0.4460,  0.0023,
         0.1554, -0.0416,  0.0746, -0.2993], dtype=torch.float16)
[Worker 3] Completed Task 1342

[Worker 3] Processing Task 1351: paddle.Tensor.lerp(x=Tensor([4, 268435457, 4],"float16"), y=Tensor([4, 268435457, 4],"float16"), weight=0.5, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.66 GiB is free. Process 20593 has 74.52 GiB memory in use. Of the allocated memory 40.02 GiB is allocated by PyTorch, and 13.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 1351: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.66 GiB is free. Process 20593 has 74.52 GiB memory in use. Of the allocated memory 40.02 GiB is allocated by PyTorch, and 13.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 1351: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.66 GiB is free. Process 20593 has 74.52 GiB memory in use. Of the allocated memory 40.02 GiB is allocated by PyTorch, and 13.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 1354: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 53687092],"float16"), y=Tensor([4, 5, 4, 53687092],"float16"), weight=0.5, )
W0522 19:25:50.222699 47002 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:25:50.223688 47002 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 5, 4, 53687092],"float16"), y=Tensor([4, 5, 4, 53687092],"float16"), weight=0.5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4121366058 / 4294967360 (96.0%)
Greatest absolute difference: 0.25 at index (0, 0, 0, 4169) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 64) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 5, 4, 53687092]), dtype=torch.float16)
First 100 elements: tensor([ 0.2008, -0.1897,  0.2284,  0.1449,  0.0948,  0.1665,  0.1130,  0.0132,
         0.0578,  0.1471,  0.1282, -0.0775,  0.2363,  0.1996, -0.0526,  0.1694,
        -0.1039,  0.0408, -0.0113, -0.0765,  0.1459, -0.2329,  0.1821,  0.0609,
         0.1168,  0.0956,  0.1946, -0.1126,  0.0300, -0.2201, -0.1899,  0.1401,
         0.0137, -0.2378, -0.0188,  0.0603,  0.1913,  0.1105,  0.0928, -0.1338,
         0.0008,  0.0602, -0.2375,  0.1261, -0.0148,  0.1576,  0.0869, -0.1875,
        -0.0947,  0.2280, -0.0261,  0.2469, -0.1268, -0.0446, -0.1902, -0.0433,
         0.0352,  0.1757, -0.1482, -0.2162,  0.0556, -0.0649, -0.0980,  0.1638,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 5, 4, 53687092]), dtype=torch.float16)
First 100 elements: tensor([ 0.2008, -0.1897,  0.2284,  0.1449,  0.0948,  0.1665,  0.1130,  0.0132,
         0.0578,  0.1471,  0.1282, -0.0775,  0.2363,  0.1996, -0.0526,  0.1694,
        -0.1039,  0.0408, -0.0113, -0.0765,  0.1459, -0.2329,  0.1821,  0.0609,
         0.1168,  0.0956,  0.1946, -0.1126,  0.0300, -0.2201, -0.1899,  0.1401,
         0.0137, -0.2378, -0.0188,  0.0603,  0.1913,  0.1105,  0.0928, -0.1338,
         0.0008,  0.0602, -0.2375,  0.1261, -0.0148,  0.1576,  0.0869, -0.1875,
        -0.0947,  0.2280, -0.0261,  0.2469, -0.1268, -0.0446, -0.1902, -0.0433,
         0.0352,  0.1757, -0.1482, -0.2162,  0.0556, -0.0649, -0.0980,  0.1638,
        -0.1892, -0.2451, -0.2228, -0.1309,  0.1978, -0.2299,  0.0656,  0.1410,
        -0.2433, -0.1342, -0.0315, -0.0670,  0.2318, -0.0692, -0.2318, -0.1663,
        -0.0529,  0.2058, -0.1086, -0.1299, -0.0533,  0.2186, -0.2220,  0.1345,
        -0.0075,  0.0861,  0.0173, -0.1674, -0.1259, -0.2097,  0.0588,  0.0443,
         0.1324,  0.1646, -0.0483,  0.1926], dtype=torch.float16)
[Worker 3] Completed Task 1354

[Worker 3] Processing Task 1360: paddle.Tensor.lerp(x=Tensor([4, 89478486, 4, 3],"float16"), y=Tensor([4, 89478486, 4, 3],"float16"), weight=0.5, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 17510 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 1360: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 17510 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 1360: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 17510 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 1361: paddle.Tensor.lerp(x=Tensor([4, 89478486, 4, 3],"float16"), y=Tensor([4, 89478486, 4, 3],"float16"), weight=1.0, )
W0522 19:28:20.649420 47420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:28:20.650473 47420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 89478486, 4, 3],"float16"), y=Tensor([4, 89478486, 4, 3],"float16"), weight=1.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208172734 / 4294967328 (98.0%)
Greatest absolute difference: 0.5 at index (0, 497, 1, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 2, 2, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 89478486, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.1385, -0.3918,  0.3508, -0.2251,  0.3687,  0.4675,  0.1710,  0.1016,
         0.0312, -0.0364,  0.3667,  0.1769,  0.2378, -0.3162, -0.3845,  0.2271,
        -0.2729, -0.0323,  0.0266, -0.3594,  0.3313, -0.0542, -0.0988,  0.3264,
        -0.0140,  0.4641,  0.0320,  0.3591, -0.1823, -0.2632,  0.4316, -0.3003,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 89478486, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.1385, -0.3918,  0.3508, -0.2251,  0.3687,  0.4675,  0.1710,  0.1016,
         0.0312, -0.0364,  0.3667,  0.1769,  0.2378, -0.3162, -0.3845,  0.2271,
        -0.2729, -0.0323,  0.0266, -0.3594,  0.3313, -0.0542, -0.0988,  0.3264,
        -0.0140,  0.4641,  0.0320,  0.3591, -0.1823, -0.2632,  0.4316, -0.3003,
         0.4092,  0.1809, -0.4460, -0.3347,  0.0970,  0.1548, -0.2419, -0.4460,
        -0.4260,  0.2273,  0.2866, -0.3298,  0.0179, -0.3955, -0.4973, -0.3960,
         0.1144, -0.3308, -0.4724,  0.4177, -0.0657,  0.0028, -0.0705, -0.1293,
         0.2478,  0.1633,  0.3694, -0.3022,  0.2727,  0.1630,  0.0097, -0.1731,
        -0.3733, -0.3992,  0.0626, -0.4153, -0.2404, -0.1711, -0.0041,  0.2500,
        -0.4116, -0.0016, -0.2544,  0.2076, -0.4036,  0.4346,  0.1396,  0.1256,
        -0.2078,  0.4167,  0.1772,  0.1776,  0.0172,  0.0638, -0.3267,  0.2090,
        -0.0070,  0.4402,  0.3396,  0.4690,  0.1536, -0.4592,  0.4978, -0.2534,
         0.2150, -0.2456, -0.0144,  0.3450], dtype=torch.float16)
[Worker 3] Completed Task 1361

[Worker 3] Processing Task 1369: paddle.Tensor.logit(x=Tensor([2147483649, 2],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([2147483649, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147437408 / 4294967298 (50.0%)
Greatest absolute difference: nan at index (0, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2147483649, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.5176e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -4.0117e+00,  0.0000e+00,  0.0000e+00, -1.1729e+00, -2.6734e+01,
        -1.7705e+00,  0.0000e+00,  1.1689e+00, -2.1621e+00,  1.4270e-01,
        -1.7197e+00, -2.2734e+00, -2.3301e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -5.8936e-01,  1.3084e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0031e+01,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -8.1016e+00,
         0.0000e+00,  3.8428e-01,  0.0000e+00, -3.0938e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -2.3652e+00,  0.0000e+00,  0.0000e+00,
         9.1504e-01, -1.6689e+00,  3.7871e+00,  0.0000e+00,  0.0000e+00,
        -8.4668e-01,  0.0000e+00,  0.0000e+00,  1.2906e+01,  7.6904e-02,
         2.7319e-01,  0.0000e+00,  1.8945e+00, -4.3762e-02,  1.7979e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3691e+00,
         0.0000e+00,  8.6426e-01, -1.0244e+00,  0.0000e+00,  0.0000e+00,
        -1.1094e+00,  0.0000e+00, -2.7271e-01, -9.8203e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.3416e-02,
        -7.2363e-01, -1.7510e+00,  0.0000e+00,  7.3438e-01, -3.9629e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8457e-01,  0.0000e+00,
         0.0000e+00,  1.2117e+01, -2.1191e+00,  0.0000e+00,  0.0000e+00,
        -1.7391e+01,  0.0000e+00,  0.0000e+00,  2.5537e-01,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2147483649, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.5176e+00,         nan,         nan,         nan,         nan,
        -4.0117e+00,         nan,         nan, -1.1729e+00, -2.6734e+01,
        -1.7705e+00,         nan,  1.1689e+00, -2.1621e+00,  1.4270e-01,
        -1.7197e+00, -2.2734e+00, -2.3301e+00,         nan,         nan,
                nan,         nan, -5.8936e-01,  1.3084e-02,         nan,
                nan,         nan,         nan,  1.0031e+01,         nan,
                nan,         nan,         nan,         nan, -8.1016e+00,
                nan,  3.8428e-01,         nan, -3.0938e+00,         nan,
                nan,         nan, -2.3652e+00,         nan,         nan,
         9.1504e-01, -1.6689e+00,  3.7871e+00,         nan,         nan,
        -8.4668e-01,         nan,         nan,  1.2906e+01,  7.6904e-02,
         2.7319e-01,         nan,  1.8945e+00, -4.3762e-02,  1.7979e+00,
                nan,         nan,         nan,         nan,  3.3691e+00,
                nan,  8.6426e-01, -1.0244e+00,         nan,         nan,
        -1.1094e+00,         nan, -2.7271e-01, -9.8203e+00,         nan,
                nan,         nan,         nan,         nan,  6.3416e-02,
        -7.2363e-01, -1.7510e+00,         nan,  7.3438e-01, -3.9629e+00,
                nan,         nan,         nan,  6.8457e-01,         nan,
                nan,  1.2117e+01, -2.1191e+00,         nan,         nan,
        -1.7391e+01,         nan,         nan,  2.5537e-01,         nan],
       dtype=torch.float16)
[Worker 3] Completed Task 1369

[Worker 3] Processing Task 1371: paddle.Tensor.logit(x=Tensor([4, 1073741825],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([4, 1073741825],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147437408 / 4294967300 (50.0%)
Greatest absolute difference: nan at index (0, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 1073741825]), dtype=torch.float16)
First 100 elements: tensor([-1.0625e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.1680e+00,  0.0000e+00,  0.0000e+00,  4.7046e-01,  9.2812e+00,
        -1.0059e+00,  0.0000e+00, -1.7373e+00,  1.4902e+00,  2.2832e+00,
        -1.4336e+00,  8.1909e-02, -2.3281e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -4.2383e+00,  1.9824e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.7266e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1106e-01,
         0.0000e+00, -2.2930e+00,  0.0000e+00,  8.0518e-01,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -2.3392e-02,  0.0000e+00,  0.0000e+00,
        -7.1869e-03, -1.0518e+00,  1.8096e+00,  0.0000e+00,  0.0000e+00,
         5.6885e-01,  0.0000e+00,  0.0000e+00,  3.0281e+01,  7.9199e-01,
         7.5977e-01,  0.0000e+00,  5.7910e-01, -2.0430e+00,  8.5400e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0391e+00,
         0.0000e+00,  2.0020e+00, -1.0566e+00,  0.0000e+00,  0.0000e+00,
        -5.7800e-02,  0.0000e+00, -1.1074e+00, -8.3984e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.7595e-02,
         1.8115e+00,  1.2256e-01,  0.0000e+00, -7.6904e-01, -5.7188e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1191e+00,  0.0000e+00,
         0.0000e+00, -1.2047e+01, -4.2383e+00,  0.0000e+00,  0.0000e+00,
        -2.1312e+01,  0.0000e+00,  0.0000e+00, -1.8652e-01,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 1073741825]), dtype=torch.float16)
First 100 elements: tensor([-1.0625e+00,         nan,         nan,         nan,         nan,
         2.1680e+00,         nan,         nan,  4.7046e-01,  9.2812e+00,
        -1.0059e+00,         nan, -1.7373e+00,  1.4902e+00,  2.2832e+00,
        -1.4336e+00,  8.1909e-02, -2.3281e+00,         nan,         nan,
                nan,         nan, -4.2383e+00,  1.9824e+00,         nan,
                nan,         nan,         nan,  6.7266e+00,         nan,
                nan,         nan,         nan,         nan,  2.1106e-01,
                nan, -2.2930e+00,         nan,  8.0518e-01,         nan,
                nan,         nan, -2.3392e-02,         nan,         nan,
        -7.1869e-03, -1.0518e+00,  1.8096e+00,         nan,         nan,
         5.6885e-01,         nan,         nan,  3.0281e+01,  7.9199e-01,
         7.5977e-01,         nan,  5.7910e-01, -2.0430e+00,  8.5400e-01,
                nan,         nan,         nan,         nan,  1.0391e+00,
                nan,  2.0020e+00, -1.0566e+00,         nan,         nan,
        -5.7800e-02,         nan, -1.1074e+00, -8.3984e+00,         nan,
                nan,         nan,         nan,         nan, -9.7595e-02,
         1.8115e+00,  1.2256e-01,         nan, -7.6904e-01, -5.7188e+00,
                nan,         nan,         nan,  2.1191e+00,         nan,
                nan, -1.2047e+01, -4.2383e+00,         nan,         nan,
        -2.1312e+01,         nan,         nan, -1.8652e-01,         nan],
       dtype=torch.float16)
[Worker 3] Completed Task 1371

[Worker 3] Processing Task 1374: paddle.Tensor.logit(x=Tensor([4, 3, 357913942],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([4, 3, 357913942],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147437412 / 4294967304 (50.0%)
Greatest absolute difference: nan at index (0, 0, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 3, 357913942]), dtype=torch.float16)
First 100 elements: tensor([-8.1421e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -3.1543e+00,  0.0000e+00,  0.0000e+00,  1.9834e+00,  1.0844e+01,
        -1.8545e+00,  0.0000e+00,  3.9575e-01,  1.0146e+00, -1.9268e+00,
        -1.9395e+00, -1.9482e+00,  1.3379e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -4.4609e+00, -1.8799e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.7832e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.0156e+00,
         0.0000e+00,  1.6748e+00,  0.0000e+00,  1.2524e-01,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  3.5962e-01,  0.0000e+00,  0.0000e+00,
        -7.5439e-01, -1.6830e-02,  2.1797e+00,  0.0000e+00,  0.0000e+00,
        -1.0361e+00,  0.0000e+00,  0.0000e+00,  3.1578e+01,  6.2402e-01,
         5.3711e-01,  0.0000e+00,  3.7793e+00,  1.1084e+00,  7.2559e-01,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7363e-02,
         0.0000e+00,  1.3652e+00,  1.9551e+00,  0.0000e+00,  0.0000e+00,
         2.0000e+00,  0.0000e+00,  8.6182e-01, -7.1680e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.7295e+00,
         3.4106e-01,  4.0039e+00,  0.0000e+00, -8.2825e-02,  6.2148e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4375e+00,  0.0000e+00,
         0.0000e+00, -1.7783e+00,  2.5977e+00,  0.0000e+00,  0.0000e+00,
        -2.0312e+01,  0.0000e+00,  0.0000e+00, -4.3867e+00,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 3, 357913942]), dtype=torch.float16)
First 100 elements: tensor([-8.1421e-02,         nan,         nan,         nan,         nan,
        -3.1543e+00,         nan,         nan,  1.9834e+00,  1.0844e+01,
        -1.8545e+00,         nan,  3.9575e-01,  1.0146e+00, -1.9268e+00,
        -1.9395e+00, -1.9482e+00,  1.3379e+00,         nan,         nan,
                nan,         nan, -4.4609e+00, -1.8799e+00,         nan,
                nan,         nan,         nan, -1.7832e+00,         nan,
                nan,         nan,         nan,         nan,  8.0156e+00,
                nan,  1.6748e+00,         nan,  1.2524e-01,         nan,
                nan,         nan,  3.5962e-01,         nan,         nan,
        -7.5439e-01, -1.6830e-02,  2.1797e+00,         nan,         nan,
        -1.0361e+00,         nan,         nan,  3.1578e+01,  6.2402e-01,
         5.3711e-01,         nan,  3.7793e+00,  1.1084e+00,  7.2559e-01,
                nan,         nan,         nan,         nan, -4.7363e-02,
                nan,  1.3652e+00,  1.9551e+00,         nan,         nan,
         2.0000e+00,         nan,  8.6182e-01, -7.1680e+00,         nan,
                nan,         nan,         nan,         nan, -1.7295e+00,
         3.4106e-01,  4.0039e+00,         nan, -8.2825e-02,  6.2148e+00,
                nan,         nan,         nan, -2.4375e+00,         nan,
                nan, -1.7783e+00,  2.5977e+00,         nan,         nan,
        -2.0312e+01,         nan,         nan, -4.3867e+00,         nan],
       dtype=torch.float16)
[Worker 3] Completed Task 1374

[Worker 3] Processing Task 1378: paddle.Tensor.logit(x=Tensor([715827883, 3, 2],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([715827883, 3, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147437408 / 4294967298 (50.0%)
Greatest absolute difference: nan at index (0, 0, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([715827883, 3, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.5176e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -4.0117e+00,  0.0000e+00,  0.0000e+00, -1.1729e+00, -2.6734e+01,
        -1.7705e+00,  0.0000e+00,  1.1689e+00, -2.1621e+00,  1.4270e-01,
        -1.7197e+00, -2.2734e+00, -2.3301e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -5.8936e-01,  1.3084e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0031e+01,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -8.1016e+00,
         0.0000e+00,  3.8428e-01,  0.0000e+00, -3.0938e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -2.3652e+00,  0.0000e+00,  0.0000e+00,
         9.1504e-01, -1.6689e+00,  3.7871e+00,  0.0000e+00,  0.0000e+00,
        -8.4668e-01,  0.0000e+00,  0.0000e+00,  1.2906e+01,  7.6904e-02,
         2.7319e-01,  0.0000e+00,  1.8945e+00, -4.3762e-02,  1.7979e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3691e+00,
         0.0000e+00,  8.6426e-01, -1.0244e+00,  0.0000e+00,  0.0000e+00,
        -1.1094e+00,  0.0000e+00, -2.7271e-01, -9.8203e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.3416e-02,
        -7.2363e-01, -1.7510e+00,  0.0000e+00,  7.3438e-01, -3.9629e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8457e-01,  0.0000e+00,
         0.0000e+00,  1.2117e+01, -2.1191e+00,  0.0000e+00,  0.0000e+00,
        -1.7391e+01,  0.0000e+00,  0.0000e+00,  2.5537e-01,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([715827883, 3, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.5176e+00,         nan,         nan,         nan,         nan,
        -4.0117e+00,         nan,         nan, -1.1729e+00, -2.6734e+01,
        -1.7705e+00,         nan,  1.1689e+00, -2.1621e+00,  1.4270e-01,
        -1.7197e+00, -2.2734e+00, -2.3301e+00,         nan,         nan,
                nan,         nan, -5.8936e-01,  1.3084e-02,         nan,
                nan,         nan,         nan,  1.0031e+01,         nan,
                nan,         nan,         nan,         nan, -8.1016e+00,
                nan,  3.8428e-01,         nan, -3.0938e+00,         nan,
                nan,         nan, -2.3652e+00,         nan,         nan,
         9.1504e-01, -1.6689e+00,  3.7871e+00,         nan,         nan,
        -8.4668e-01,         nan,         nan,  1.2906e+01,  7.6904e-02,
         2.7319e-01,         nan,  1.8945e+00, -4.3762e-02,  1.7979e+00,
                nan,         nan,         nan,         nan,  3.3691e+00,
                nan,  8.6426e-01, -1.0244e+00,         nan,         nan,
        -1.1094e+00,         nan, -2.7271e-01, -9.8203e+00,         nan,
                nan,         nan,         nan,         nan,  6.3416e-02,
        -7.2363e-01, -1.7510e+00,         nan,  7.3438e-01, -3.9629e+00,
                nan,         nan,         nan,  6.8457e-01,         nan,
                nan,  1.2117e+01, -2.1191e+00,         nan,         nan,
        -1.7391e+01,         nan,         nan,  2.5537e-01,         nan],
       dtype=torch.float16)
[Worker 3] Completed Task 1378

[Worker 3] Processing Task 1382: paddle.Tensor.repeat_interleave(Tensor([228170138, 10],"int64"), 2, axis=0, )
cannot reshape array of size 4300000000 into shape (456340276,10)
[accuracy error] paddle.Tensor.repeat_interleave(Tensor([228170138, 10],"int64"), 2, axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 268433394 / 4563402760 (5.9%)
Greatest absolute difference: 65535 at index (429503208, 7) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (429496729, 6) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([456340276, 10]), dtype=torch.int64)
First 100 elements: tensor([ 19608, -22197, -41354, -43334, -19791, -27300, -35121,  17551, -45171,
         -8900,  19608, -22197, -41354, -43334, -19791, -27300, -35121,  17551,
        -45171,  -8900, -30073,   3065, -46568,  14249, -22685, -20014,   9841,
         61777, -35996,  -1054, -30073,   3065, -46568,  14249, -22685, -20014,
          9841,  61777, -35996,  -1054, -40229, -52016, -55120, -11801,  20835,
         -8763, -64679,  30578,   7262,  36177, -40229, -52016, -55120, -11801,
         20835,  -8763, -64679,  30578,   7262,  36177,  12099,  52686,  13930,
        -44964, -51238,  28507,  48701, -26753,  51847, -25255,  12099,  52686,
         13930, -44964, -51238,  28507,  48701, -26753,  51847, -25255, -36825,
         41108,  35354,  23555, -46943,  36275,  22902, -54481,  46995,  32401,
        -36825,  41108,  35354,  23555, -46943,  36275,  22902, -54481,  46995,
         32401])
DESIRED: (shape=torch.Size([456340276, 10]), dtype=torch.int64)
First 100 elements: tensor([ 19608, -22197, -41354, -43334, -19791, -27300, -35121,  17551, -45171,
         -8900,  19608, -22197, -41354, -43334, -19791, -27300, -35121,  17551,
        -45171,  -8900, -30073,   3065, -46568,  14249, -22685, -20014,   9841,
         61777, -35996,  -1054, -30073,   3065, -46568,  14249, -22685, -20014,
          9841,  61777, -35996,  -1054, -40229, -52016, -55120, -11801,  20835,
         -8763, -64679,  30578,   7262,  36177, -40229, -52016, -55120, -11801,
         20835,  -8763, -64679,  30578,   7262,  36177,  12099,  52686,  13930,
        -44964, -51238,  28507,  48701, -26753,  51847, -25255,  12099,  52686,
         13930, -44964, -51238,  28507,  48701, -26753,  51847, -25255, -36825,
         41108,  35354,  23555, -46943,  36275,  22902, -54481,  46995,  32401,
        -36825,  41108,  35354,  23555, -46943,  36275,  22902, -54481,  46995,
         32401])
[Worker 3] Completed Task 1382

[Worker 3] Processing Task 1394: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,3,0,],list[3,0,2,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,3,0,],list[3,0,2,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48064 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 1394

[Worker 3] Processing Task 1474: paddle.tensordot(Tensor([1, 1, 1, 5],"float16"), Tensor([1, 5, 858993460, 1],"float16"), list[list[0,1,3,],list[0,3,1,],], )
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 1, 5],"float16"), Tensor([1, 5, 858993460, 1],"float16"), list[list[0,1,3,],list[0,3,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4294967300 (0.0%)
Greatest absolute difference: 0.1461181640625 at index (0, 4, 858993458, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 4, 858993456, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 5, 858993460, 1]), dtype=torch.float16)
First 100 elements: tensor([-0.0843, -0.0583,  0.0067,  0.0537, -0.0280, -0.0439,  0.0511,  0.0878,
        -0.0050, -0.0735, -0.0093,  0.0620,  0.0877, -0.0187, -0.0826, -0.0809,
         0.0477, -0.0298, -0.0622, -0.0628,  0.0557,  0.1022,  0.0649, -0.0947,
         0.1073,  0.0078,  0.0840, -0.0909, -0.0032,  0.1003,  0.0202, -0.0830,
        -0.0385, -0.0948, -0.0395,  0.0035, -0.0566,  0.0638,  0.0381,  0.0160,
        -0.0277,  0.0659, -0.0055, -0.0468,  0.0128, -0.0839, -0.0533,  0.0928,
         0.0451,  0.0367, -0.0785,  0.0539, -0.0507,  0.0735, -0.0269, -0.0191,
        -0.0767, -0.0732,  0.1002,  0.0678, -0.0635,  0.0192, -0.0396, -0.0643,
         0.0907, -0.0459,  0.0222,  0.0222, -0.0449,  0.0237,  0.0751, -0.0387,
         0.0082,  0.0906,  0.0167, -0.0754, -0.0430, -0.0382, -0.0389,  0.0811,
        -0.0598,  0.0278, -0.0839,  0.0802, -0.0822, -0.0571, -0.0239, -0.0526,
        -0.0647,  0.0435,  0.1082, -0.0298, -0.0983, -0.0522, -0.1039, -0.0901,
         0.0292, -0.0839,  0.1079,  0.0428], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 5, 858993460, 1]), dtype=torch.float16)
First 100 elements: tensor([-0.0843, -0.0583,  0.0067,  0.0537, -0.0280, -0.0439,  0.0511,  0.0878,
        -0.0050, -0.0735, -0.0093,  0.0620,  0.0877, -0.0187, -0.0826, -0.0809,
         0.0477, -0.0298, -0.0622, -0.0628,  0.0557,  0.1022,  0.0649, -0.0947,
         0.1073,  0.0078,  0.0840, -0.0909, -0.0032,  0.1003,  0.0202, -0.0830,
        -0.0385, -0.0948, -0.0395,  0.0035, -0.0566,  0.0638,  0.0381,  0.0160,
        -0.0277,  0.0659, -0.0055, -0.0468,  0.0128, -0.0839, -0.0533,  0.0928,
         0.0451,  0.0367, -0.0785,  0.0539, -0.0507,  0.0735, -0.0269, -0.0191,
        -0.0767, -0.0732,  0.1002,  0.0678, -0.0635,  0.0192, -0.0396, -0.0643,
         0.0907, -0.0459,  0.0222,  0.0222, -0.0449,  0.0237,  0.0751, -0.0387,
         0.0082,  0.0906,  0.0167, -0.0754, -0.0430, -0.0382, -0.0389,  0.0811,
        -0.0598,  0.0278, -0.0839,  0.0802, -0.0822, -0.0571, -0.0239, -0.0526,
        -0.0647,  0.0435,  0.1082, -0.0298, -0.0983, -0.0522, -0.1039, -0.0901,
         0.0292, -0.0839,  0.1079,  0.0428], dtype=torch.float16)
[Worker 3] Completed Task 1474

[Worker 3] Processing Task 1529: paddle.tensordot(Tensor([1, 1, 1, 5],"float16"), Tensor([858993460, 5, 1, 1],"float16"), list[list[3,1,2,],list[1,2,3,],], )
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 1672: paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([171798692, 5, 1, 5],"float16"), list[list[3,2,0,],list[2,1,0,],], )
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 1765: paddle.tensordot(Tensor([5, 171798692, 5, 1],"float16"), Tensor([5, 171798692, 1, 5],"float16"), list[list[2,3,0,],list[3,1,0,],], )
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 1908: paddle.tensordot(Tensor([5, 5, 5, 1],"float16"), Tensor([171798692, 5, 1, 5],"float16"), list[list[3,1,2,],list[2,3,1,],], )
[accuracy error] paddle.tensordot(Tensor([5, 5, 5, 1],"float16"), Tensor([171798692, 5, 1, 5],"float16"), list[list[3,1,2,],list[2,3,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 20 / 858993460 (0.0%)
Greatest absolute difference: 0.16748046875 at index (3, 171798688) (up to 0.01 allowed)
Greatest relative difference: 44.5 at index (4, 171798690) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 171798692]), dtype=torch.float16)
First 100 elements: tensor([ 1.2764e+00,  2.1045e-01, -6.6113e-01, -2.6099e-01,  7.9150e-01,
        -9.4824e-01,  7.7100e-01,  2.1997e-01,  8.1152e-01,  7.9150e-01,
         2.6245e-01, -7.4890e-02, -3.1055e-01, -3.7329e-01, -6.1865e-01,
        -3.9844e-01, -2.2864e-01,  3.0688e-01, -9.4580e-01, -4.5483e-01,
         5.1904e-01, -1.0004e-01,  6.9580e-01,  5.5225e-01, -5.3564e-01,
        -2.6953e-01, -1.2684e-03,  5.2783e-01,  4.4897e-01,  1.0020e+00,
         5.7812e-01,  8.5388e-02, -5.9912e-01, -3.5889e-02,  4.2877e-02,
         5.9082e-01, -1.5100e-01,  1.0248e-01,  8.4668e-01, -4.9365e-01,
         2.9810e-01, -7.5134e-02, -2.0020e-01, -2.4524e-01, -1.1670e-01,
         2.5293e-01, -6.0400e-01, -7.7026e-02, -3.8177e-02,  3.5205e-01,
         5.8301e-01,  1.0957e+00,  4.8486e-01, -4.4189e-01, -6.8555e-01,
         5.3516e-01,  6.1084e-01, -1.0293e+00,  9.2627e-01, -3.7964e-01,
        -4.0747e-01,  2.7856e-01,  3.0957e-01,  4.1235e-01,  3.7329e-01,
        -2.2327e-01,  5.8655e-02,  2.9980e-01, -4.6216e-01,  9.4531e-01,
        -5.3027e-01,  5.7666e-01,  7.0435e-02, -7.8369e-02, -7.2656e-01,
         3.5254e-01, -8.5352e-01,  4.4281e-02, -4.5557e-01, -7.1875e-01,
        -2.7710e-01,  3.9795e-01,  3.7720e-01,  9.2969e-01,  1.3135e-01,
        -1.8286e-01, -3.8116e-02, -6.3538e-02, -6.7505e-02,  1.0674e+00,
        -2.3254e-01,  1.1143e+00,  1.3269e-01, -4.4946e-01, -1.4336e-02,
         9.3384e-02, -1.0391e+00,  1.4270e-01, -3.8672e-01,  8.0444e-02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 171798692]), dtype=torch.float16)
First 100 elements: tensor([ 1.2764e+00,  2.1045e-01, -6.6113e-01, -2.6099e-01,  7.9150e-01,
        -9.4824e-01,  7.7100e-01,  2.1997e-01,  8.1152e-01,  7.9150e-01,
         2.6245e-01, -7.4890e-02, -3.1055e-01, -3.7329e-01, -6.1865e-01,
        -3.9844e-01, -2.2864e-01,  3.0688e-01, -9.4580e-01, -4.5483e-01,
         5.1904e-01, -1.0004e-01,  6.9580e-01,  5.5225e-01, -5.3564e-01,
        -2.6953e-01, -1.2684e-03,  5.2783e-01,  4.4897e-01,  1.0020e+00,
         5.7812e-01,  8.5388e-02, -5.9912e-01, -3.5889e-02,  4.2877e-02,
         5.9082e-01, -1.5100e-01,  1.0248e-01,  8.4668e-01, -4.9365e-01,
         2.9810e-01, -7.5134e-02, -2.0020e-01, -2.4524e-01, -1.1670e-01,
         2.5293e-01, -6.0400e-01, -7.7026e-02, -3.8177e-02,  3.5205e-01,
         5.8301e-01,  1.0957e+00,  4.8486e-01, -4.4189e-01, -6.8555e-01,
         5.3516e-01,  6.1084e-01, -1.0293e+00,  9.2627e-01, -3.7964e-01,
        -4.0747e-01,  2.7856e-01,  3.0957e-01,  4.1235e-01,  3.7329e-01,
        -2.2327e-01,  5.8655e-02,  2.9980e-01, -4.6216e-01,  9.4531e-01,
        -5.3027e-01,  5.7666e-01,  7.0435e-02, -7.8369e-02, -7.2656e-01,
         3.5254e-01, -8.5352e-01,  4.4281e-02, -4.5557e-01, -7.1875e-01,
        -2.7710e-01,  3.9795e-01,  3.7720e-01,  9.2969e-01,  1.3135e-01,
        -1.8286e-01, -3.8116e-02, -6.3538e-02, -6.7505e-02,  1.0674e+00,
        -2.3254e-01,  1.1143e+00,  1.3269e-01, -4.4946e-01, -1.4336e-02,
         9.3384e-02, -1.0391e+00,  1.4270e-01, -3.8672e-01,  8.0444e-02],
       dtype=torch.float16)
[Worker 3] Completed Task 1908

[Worker 3] Processing Task 1949: paddle.tensordot(Tensor([5, 5, 5, 1],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[0,1,3,],list[0,3,1,],], )
[accuracy error] backward  paddle.tensordot(Tensor([5, 5, 5, 1],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[0,1,3,],list[0,3,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 125 (0.8%)
Greatest absolute difference: 0.1640625 at index (1, 4, 2, 0) (up to 0.01 allowed)
Greatest relative difference: 0.01073455810546875 at index (1, 4, 2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5, 5, 1]), dtype=torch.float16)
First 100 elements: tensor([ -870.5000, -1033.0000, -1088.0000,    99.2500,   -25.9688,  -507.0000,
         -566.5000, -1165.0000,   196.3750,  -578.5000,   130.1250,  -663.0000,
          610.0000,   517.5000,   617.0000,   806.0000,  -810.0000,  -395.7500,
         -365.2500,   455.2500,  -599.5000,  1457.0000,  1112.0000, -1458.0000,
         1189.0000,  -826.0000,   743.0000,  -759.0000,   141.5000,  -604.0000,
          409.7500, -2056.0000, -2214.0000,  -454.0000, -1143.0000, -1075.0000,
        -1259.0000,  1389.0000,  -583.0000,  -148.5000,  -108.5000,  -809.0000,
        -1502.0000,  -977.5000,   217.6250,   302.0000, -1492.0000,    15.4453,
        -1012.5000,   352.0000,   -88.3750, -1696.0000,  -298.2500, -2504.0000,
         -632.5000, -1751.0000,  -132.8750,  -128.2500, -1788.0000,  -574.0000,
        -1729.0000,   271.0000,  2400.0000,  -589.5000,  -378.0000,  1031.0000,
        -1151.0000,   409.0000,   -34.6250,   963.5000,  -375.5000,  -998.5000,
          248.3750,   297.5000,   557.5000,  -297.7500,  -380.2500,  2182.0000,
          461.0000,   426.7500,  -946.5000,  -660.0000,   853.0000,   222.1250,
         -572.0000,   -70.3750,  -157.5000,  -430.7500,  -781.5000,  1322.0000,
          595.5000,  -643.0000,   241.2500,  -230.1250,   607.5000, -1202.0000,
         1614.0000,  -675.0000, -1468.0000,  1790.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 5, 5, 1]), dtype=torch.float16)
First 100 elements: tensor([ -870.5000, -1032.0000, -1088.0000,    99.0625,   -26.0781,  -507.0000,
         -566.5000, -1164.0000,   196.3750,  -578.0000,   130.0000,  -663.0000,
          610.0000,   517.5000,   617.0000,   805.5000,  -809.5000,  -395.7500,
         -365.2500,   455.5000,  -600.0000,  1457.0000,  1112.0000, -1458.0000,
         1189.0000,  -826.0000,   743.5000,  -759.0000,   141.5000,  -604.0000,
          409.7500, -2056.0000, -2214.0000,  -454.0000, -1143.0000, -1075.0000,
        -1259.0000,  1389.0000,  -583.0000,  -148.6250,  -108.5625,  -809.0000,
        -1502.0000,  -977.5000,   217.6250,   301.7500, -1492.0000,    15.2812,
        -1012.0000,   352.0000,   -88.5625, -1696.0000,  -298.2500, -2504.0000,
         -633.0000, -1751.0000,  -132.7500,  -128.1250, -1787.0000,  -574.0000,
        -1729.0000,   271.0000,  2400.0000,  -589.5000,  -377.7500,  1031.0000,
        -1151.0000,   409.2500,   -34.7812,   963.5000,  -375.5000,  -998.5000,
          248.2500,   297.5000,   557.5000,  -298.0000,  -380.0000,  2182.0000,
          461.0000,   426.7500,  -946.5000,  -660.0000,   853.0000,   222.3750,
         -572.0000,   -70.4375,  -157.5000,  -430.7500,  -781.5000,  1322.0000,
          595.5000,  -643.0000,   241.3750,  -229.8750,   607.5000, -1202.0000,
         1614.0000,  -675.0000, -1468.0000,  1790.0000], dtype=torch.float16)
[Worker 3] Completed Task 1949

[Worker 3] Processing Task 2091: paddle.tensordot(Tensor([858993460, 1, 1, 5],"float16"), Tensor([858993460, 5, 1, 1],"float16"), list[list[3,2,0,],list[3,2,0,],], )
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2228: paddle.argmin(Tensor([3, 17674763, 3, 3, 3, 3],"float16"), axis=0, )
[cuda error] paddle.argmin(Tensor([3, 17674763, 3, 3, 3, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928006 (unix time) try "date -d @1747928006" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc759) received by PID 51033 (TID 0x7f2766dac740) from PID 51033 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2231: paddle.argmin(Tensor([3, 3, 3, 3, 17674763, 3],"float16"), axis=0, )
W0522 23:34:56.001384 51317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:34:56.002193 51317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmin(Tensor([3, 3, 3, 3, 17674763, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928097 (unix time) try "date -d @1747928097" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc875) received by PID 51317 (TID 0x7f2766dac740) from PID 51317 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2236: paddle.argmin(Tensor([4, 4, 16777217, 4, 4],"float16"), axis=0, )
W0522 23:36:14.596160 51599 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:36:14.596937 51599 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmin(Tensor([4, 4, 16777217, 4, 4],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928176 (unix time) try "date -d @1747928176" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc98f) received by PID 51599 (TID 0x7f2766dac740) from PID 51599 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2247: paddle.bmm(x=Tensor([2, 715827883, 3],"float16"), y=Tensor([2, 3, 2],"float16"), )
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[cuda error] paddle.bmm(x=Tensor([2, 715827883, 3],"float16"), y=Tensor([2, 3, 2],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928322 (unix time) try "date -d @1747928322" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcbc0) received by PID 52160 (TID 0x7f2766dac740) from PID 52160 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2249: paddle.broadcast_to(Tensor([8, 1, 219, 1302341],"bool"), list[8,8,219,113,], )
[torch error] paddle.broadcast_to(Tensor([8, 1, 219, 1302341],"bool"), list[8,8,219,113,], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: The expanded size of the tensor (113) must match the existing size (1302341) at non-singleton dimension 3.  Target sizes: [8, 8, 219, 113].  Tensor sizes: [8, 1, 219, 1302341]
W0522 23:39:40.269093 52277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:39:40.269851 52277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Completed Task 2249

[Worker 3] Processing Task 2253: paddle.copysign(Tensor([10, 429496730],"float16"), Tensor([10, 429496730],"float16"), )
[cuda error] paddle.copysign(Tensor([10, 429496730],"float16"), Tensor([10, 429496730],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928478 (unix time) try "date -d @1747928478" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcc35) received by PID 52277 (TID 0x7f2766dac740) from PID 52277 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2257: paddle.copysign(Tensor([12, 20, 17895698],"float16"), Tensor([12, 20, 17895698],"float16"), )
W0522 23:42:48.438660 52732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:42:48.439726 52732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([12, 20, 17895698],"float16"), Tensor([12, 20, 17895698],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928588 (unix time) try "date -d @1747928588" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcdfc) received by PID 52732 (TID 0x7f2766dac740) from PID 52732 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2262: paddle.copysign(Tensor([2, 3, 143165577, 5],"float16"), Tensor([2, 3, 143165577, 5],"float16"), )
W0522 23:45:19.200965 53264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:45:19.202622 53264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([2, 3, 143165577, 5],"float16"), Tensor([2, 3, 143165577, 5],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928738 (unix time) try "date -d @1747928738" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd010) received by PID 53264 (TID 0x7f2766dac740) from PID 53264 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2267: paddle.copysign(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), )
W0522 23:47:36.510910 53851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:47:36.511932 53851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928872 (unix time) try "date -d @1747928872" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd25b) received by PID 53851 (TID 0x7f2766dac740) from PID 53851 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2270: paddle.copysign(Tensor([57042535, 20, 2],"float32"), Tensor([57042535, 20, 2],"float32"), )
W0522 23:49:15.511965 54193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:49:15.513025 54193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([57042535, 20, 2],"float32"), Tensor([57042535, 20, 2],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928970 (unix time) try "date -d @1747928970" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd3b1) received by PID 54193 (TID 0x7f2766dac740) from PID 54193 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2273: paddle.copysign(Tensor([8, 17, 5, 902305, 7],"float16"), Tensor([8, 17, 5, 902305, 7],"float16"), )
W0522 23:50:59.395052 54537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:50:59.396106 54537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([8, 17, 5, 902305, 7],"float16"), Tensor([8, 17, 5, 902305, 7],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747929078 (unix time) try "date -d @1747929078" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd509) received by PID 54537 (TID 0x7f2766dac740) from PID 54537 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2297: paddle.cumsum(Tensor([120, 19014179],"int32"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.cumsum(Tensor([120, 19014179],"int32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01

ACTUAL: (shape=torch.Size([120, 19014179]), dtype=torch.int32)
First 100 elements: tensor([ 43871, -58277,    388,  -6131,  57942,  18000,  59169, -55159,  37199,
          4717,  39852,  18178, -51417,  60831, -13434,   9778,  24766,  59801,
        -31055, -39188, -33957, -14347, -51851,  29704, -46369,  42905, -33532,
         -3451, -23518, -48945,  -5406, -63320,  44209, -23566,  19658,  12577,
         29824,  13351, -42942,  49336,  22887,  65055,  48175,  30435, -32926,
         27251, -49357,  -4223, -13463,  40216, -60556,  17699,   8033,  33439,
        -31004,  32408, -18167, -50525,  40907, -42142,  27480,  56508, -46682,
        -59547,  42979, -26339, -27262,  33176, -52378, -64207,  10559,  26955,
        -20538, -29389,    510,  56283,     58,  27375, -35593, -58310, -15638,
        -35453, -41437,  42762,   2244, -17318,  19803, -50768,  42218,  52768,
         57886, -34673,  -6945,  -2707,   7424,  37963,  59965, -61379, -54639,
         63547], dtype=torch.int32)
DESIRED: (shape=torch.Size([120, 19014179]), dtype=torch.int64)
First 100 elements: tensor([ 43871, -58277,    388,  -6131,  57942,  18000,  59169, -55159,  37199,
          4717,  39852,  18178, -51417,  60831, -13434,   9778,  24766,  59801,
        -31055, -39188, -33957, -14347, -51851,  29704, -46369,  42905, -33532,
         -3451, -23518, -48945,  -5406, -63320,  44209, -23566,  19658,  12577,
         29824,  13351, -42942,  49336,  22887,  65055,  48175,  30435, -32926,
         27251, -49357,  -4223, -13463,  40216, -60556,  17699,   8033,  33439,
        -31004,  32408, -18167, -50525,  40907, -42142,  27480,  56508, -46682,
        -59547,  42979, -26339, -27262,  33176, -52378, -64207,  10559,  26955,
        -20538, -29389,    510,  56283,     58,  27375, -35593, -58310, -15638,
        -35453, -41437,  42762,   2244, -17318,  19803, -50768,  42218,  52768,
         57886, -34673,  -6945,  -2707,   7424,  37963,  59965, -61379, -54639,
         63547])
[Worker 3] Completed Task 2297

[Worker 3] Processing Task 2304: paddle.cumsum(Tensor([22817014, 100],"int64"), 1, )
[torch error] paddle.cumsum(Tensor([22817014, 100],"int64"), 1, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 57367 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 2304

[Worker 3] Processing Task 2307: paddle.cumsum(Tensor([3, 190141782, 4],"float32"), axis=1, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 57367 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 2307: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 57367 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 2307: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 57367 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2313: paddle.cumsum(Tensor([49602204, 46],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
W0523 00:02:56.734511 55562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:02:56.735445 55562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[paddle error] paddle.cumsum(Tensor([49602204, 46],"int64"), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 2313

[Worker 3] Processing Task 2326: paddle.cumsum(x=Tensor([715827883, 2, 1, 3],"float16"), axis=-4, )
[accuracy error] paddle.cumsum(x=Tensor([715827883, 2, 1, 3],"float16"), axis=-4, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4290014087 / 4294967298 (99.9%)
Greatest absolute difference: 13680.0 at index (710642502, 1, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (421584, 1, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([715827883, 2, 1, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.1587,  0.1155, -0.0648, -0.1959, -0.2983, -0.1079,  0.3154,  0.5649,
        -0.2319, -0.3232, -0.2769, -0.0834,  0.5347,  0.5903,  0.1709, -0.5059,
         0.0873, -0.1242,  0.5708,  0.6230,  0.3623, -0.6084, -0.1653,  0.1241,
         0.7529,  0.2654,  0.3862, -0.1130,  0.1833, -0.1357,  0.9194, -0.2332,
         0.7817, -0.4631, -0.0723, -0.2996,  1.1660,  0.2571,  1.0068, -0.1633,
        -0.4551, -0.1746,  1.2588,  0.1294,  0.6304, -0.1608, -0.3230, -0.3491,
         1.1826, -0.3333,  0.5112,  0.1378, -0.3696, -0.8091,  1.4277, -0.6953,
         0.7402, -0.0682, -0.0527, -1.1172,  1.3193, -0.2065,  1.2246, -0.5273,
        -0.0062, -1.1963,  1.4473,  0.0363,  1.5791, -0.6650, -0.1376, -1.2520,
         1.4951,  0.0945,  1.6279, -0.1671, -0.4050, -1.5986,  1.5137, -0.1409,
         1.7520,  0.2632, -0.7446, -1.9072,  1.0186,  0.1208,  1.9971, -0.0946,
        -0.8428, -2.2129,  1.2109,  0.2479,  1.6992, -0.0981, -1.1182, -1.9043,
         1.6162,  0.3464,  1.8281, -0.0350], dtype=torch.float16)
DESIRED: (shape=torch.Size([715827883, 2, 1, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.1587,  0.1155, -0.0648, -0.1959, -0.2983, -0.1079,  0.3154,  0.5649,
        -0.2319, -0.3232, -0.2769, -0.0834,  0.5347,  0.5903,  0.1709, -0.5059,
         0.0874, -0.1241,  0.5708,  0.6230,  0.3623, -0.6084, -0.1653,  0.1241,
         0.7529,  0.2654,  0.3862, -0.1128,  0.1833, -0.1356,  0.9189, -0.2332,
         0.7822, -0.4629, -0.0723, -0.2993,  1.1650,  0.2571,  1.0068, -0.1631,
        -0.4551, -0.1743,  1.2578,  0.1294,  0.6309, -0.1605, -0.3230, -0.3491,
         1.1816, -0.3333,  0.5117,  0.1381, -0.3696, -0.8091,  1.4268, -0.6953,
         0.7407, -0.0680, -0.0527, -1.1172,  1.3184, -0.2065,  1.2246, -0.5269,
        -0.0062, -1.1963,  1.4463,  0.0364,  1.5801, -0.6650, -0.1376, -1.2520,
         1.4941,  0.0945,  1.6289, -0.1670, -0.4048, -1.5986,  1.5127, -0.1409,
         1.7529,  0.2634, -0.7441, -1.9072,  1.0176,  0.1208,  1.9980, -0.0945,
        -0.8423, -2.2129,  1.2100,  0.2479,  1.6992, -0.0980, -1.1182, -1.9043,
         1.6152,  0.3464,  1.8281, -0.0349], dtype=torch.float16)
[Worker 3] Completed Task 2326

[Worker 3] Processing Task 2342: paddle.dist(x=Tensor([1073741825, 4],"float16"), y=Tensor([1073741825, 4],"float16"), )
[cuda error] paddle.dist(x=Tensor([1073741825, 4],"float16"), y=Tensor([1073741825, 4],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930213 (unix time) try "date -d @1747930213" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd90a) received by PID 55562 (TID 0x7f2766dac740) from PID 55562 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2347: paddle.dist(x=Tensor([4, 1073741825],"float16"), y=Tensor([4, 1073741825],"float16"), p=1, )
W0523 00:12:05.064079 56318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:12:05.065060 56318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.dist(x=Tensor([4, 1073741825],"float16"), y=Tensor([4, 1073741825],"float16"), p=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930330 (unix time) try "date -d @1747930330" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdbfe) received by PID 56318 (TID 0x7f2766dac740) from PID 56318 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2352: paddle.frac(Tensor([10, 228170138, 1],"float32"), )
W0523 00:13:54.673843 56795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:13:54.674836 56795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.frac(Tensor([10, 228170138, 1],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930451 (unix time) try "date -d @1747930451" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdddb) received by PID 56795 (TID 0x7f2766dac740) from PID 56795 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2494: paddle.isnan(Tensor([858993459, 5],"float32"), )
[accuracy error] paddle.isnan(Tensor([858993459, 5],"float32"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False, False],
        ...,
        [False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False, False]]),
    expected=tensor([[False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False, False],
        ...,
        [False, False, False, False, False],
        [False, False, False, False, False],
        [False, False, False, False, False]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 3] Completed Task 2494

[Worker 3] Processing Task 2509: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), None, )
[torch error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Error on Task 2509: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] OOM on Task 2509: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2513: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), None, )
[torch error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Error on Task 2513: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] OOM on Task 2513: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2518: paddle.linalg.matrix_rank(Tensor([114085069, 4, 5],"float32"), tol=0.1, )
[torch error] paddle.linalg.matrix_rank(Tensor([114085069, 4, 5],"float32"), tol=0.1, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Error on Task 2518: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] OOM on Task 2518: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2526: paddle.linalg.solve(Tensor([10, 10],"float32"), Tensor([10, 228170138],"float32"), )
[paddle error] paddle.linalg.solve(Tensor([10, 10],"float32"), Tensor([10, 228170138],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/backends/gpu/cuda/cuda_info.cc:286)

[Worker 3] Error on Task 2526: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/backends/gpu/cuda/cuda_info.cc:286)

[Worker 3] OOM on Task 2526: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/backends/gpu/cuda/cuda_info.cc:286)

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2627: paddle.nansum(Tensor([1431655765, 3],"float32"), axis=None, keepdim=False, name=None, )
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2631: paddle.nansum(Tensor([3, 1431655765],"float32"), axis=None, keepdim=True, name=None, )
W0523 01:26:13.595981 59328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:26:13.597265 59328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2635: paddle.nansum(Tensor([858993459, 5],"float32"), axis=None, keepdim=True, name=None, )
W0523 01:56:24.176236 59708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:56:24.177246 59708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2639: paddle.nn.functional.adaptive_max_pool2d(Tensor([29217465, 3, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 3] Error on Task 2639: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 3] OOM on Task 2639: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2644: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([29217465, 3, 7, 7],"float32"), return_mask=False, output_size=list[3,3,], )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 3] Error on Task 2644: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 3] OOM on Task 2644: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2647: paddle.nn.functional.grid_sample(Tensor([56, 3, 848848, 16],"float32"), Tensor([56, 16, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
W0523 02:28:41.866667 60756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:28:41.867662 60756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 848848, 16],"float32"), Tensor([56, 16, 16, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938522 (unix time) try "date -d @1747938522" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xed54) received by PID 60756 (TID 0x7f2766dac740) from PID 60756 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2649: paddle.nn.functional.grid_sample(Tensor([56, 39790, 32, 32],"float32"), Tensor([56, 32, 32, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
W0523 02:29:52.402747 61060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:29:52.404096 61060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 39790, 32, 32],"float32"), Tensor([56, 32, 32, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938608 (unix time) try "date -d @1747938608" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xee84) received by PID 61060 (TID 0x7f2766dac740) from PID 61060 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2653: paddle.nn.functional.grid_sample(Tensor([5821, 4, 280, 350],"float32"), Tensor([5821, 368, 416, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
W0523 02:31:54.999568 61534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:31:55.000587 61534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([5821, 4, 280, 350],"float32"), Tensor([5821, 368, 416, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938738 (unix time) try "date -d @1747938738" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf05e) received by PID 61534 (TID 0x7f2766dac740) from PID 61534 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2658: paddle.nn.functional.grid_sample(x=Tensor([16, 64, 80, 94, 311],"float32"), grid=Tensor([16, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
W0523 02:34:09.223536 62083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:34:09.224566 62083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(x=Tensor([16, 64, 80, 94, 311],"float32"), grid=Tensor([16, 280, 376, 25, 3],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938850 (unix time) try "date -d @1747938850" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf283) received by PID 62083 (TID 0x7f2766dac740) from PID 62083 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2661: paddle.nn.functional.normalize(Tensor([1, 128, 32, 557057],"float32"), axis=1, )
W0523 02:35:24.096822 62406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:35:24.097965 62406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 128, 32, 557057],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938937 (unix time) try "date -d @1747938937" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf3c6) received by PID 62406 (TID 0x7f2766dac740) from PID 62406 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2664: paddle.nn.functional.normalize(Tensor([1, 256, 16, 557057],"float32"), axis=1, )
W0523 02:36:50.099521 62750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:36:50.100713 62750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 256, 16, 557057],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939023 (unix time) try "date -d @1747939023" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf51e) received by PID 62750 (TID 0x7f2766dac740) from PID 62750 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2667: paddle.nn.functional.normalize(Tensor([1, 64, 557057, 64],"float32"), axis=1, )
W0523 02:38:19.180904 63111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:38:19.181922 63111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 64, 557057, 64],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939112 (unix time) try "date -d @1747939112" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf687) received by PID 63111 (TID 0x7f2766dac740) from PID 63111 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2672: paddle.nn.functional.normalize(Tensor([10, 228170138],"float32"), p=1.5, )
W0523 02:40:13.325647 63660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:40:13.326829 63660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([10, 228170138],"float32"), p=1.5, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939345 (unix time) try "date -d @1747939345" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf8ac) received by PID 63660 (TID 0x7f2766dac740) from PID 63660 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2678: paddle.nn.functional.normalize(Tensor([2, 8, 14260634, 10],"float32"), axis=1, )
W0523 02:43:39.034665 64323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:43:39.035928 64323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([2, 8, 14260634, 10],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939435 (unix time) try "date -d @1747939435" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfb43) received by PID 64323 (TID 0x7f2766dac740) from PID 64323 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2681: paddle.nn.functional.normalize(Tensor([228170138, 10],"float32"), )
W0523 02:45:40.453383 64667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:45:40.454363 64667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([228170138, 10],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939555 (unix time) try "date -d @1747939555" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfc9b) received by PID 64667 (TID 0x7f2766dac740) from PID 64667 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2685: paddle.nn.functional.normalize(Tensor([2970966, 768],"float32"), axis=-1, )
W0523 02:47:19.543381 65029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:47:19.547482 65029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([2970966, 768],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939658 (unix time) try "date -d @1747939658" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfe05) received by PID 65029 (TID 0x7f2766dac740) from PID 65029 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2687: paddle.nn.functional.normalize(Tensor([325957340, 7],"float32"), axis=1, )
W0523 02:48:58.687559 65280 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:48:58.688755 65280 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([325957340, 7],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939758 (unix time) try "date -d @1747939758" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xff00) received by PID 65280 (TID 0x7f2766dac740) from PID 65280 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2689: paddle.nn.functional.normalize(Tensor([35651585, 64],"float32"), axis=1, )
W0523 02:50:30.684895 65602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:50:30.685914 65602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([35651585, 64],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939843 (unix time) try "date -d @1747939843" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10042) received by PID 65602 (TID 0x7f2766dac740) from PID 65602 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2693: paddle.nn.functional.normalize(Tensor([4194305, 1024],"float16"), p=2, axis=-1, )
W0523 02:52:35.851495 66036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:52:35.852552 66036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([4194305, 1024],"float16"), p=2, axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939971 (unix time) try "date -d @1747939971" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x101f4) received by PID 66036 (TID 0x7f2766dac740) from PID 66036 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2697: paddle.nn.functional.normalize(Tensor([570425345, 4],"float32"), axis=0, )
W0523 02:54:08.559298 66397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:54:08.560345 66397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([570425345, 4],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940320 (unix time) try "date -d @1747940320" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1035d) received by PID 66397 (TID 0x7f2766dac740) from PID 66397 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2703: paddle.nn.functional.normalize(x=Tensor([1073741825, 4],"float16"), )
W0523 03:00:31.901005 67176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:00:31.902139 67176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([1073741825, 4],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940448 (unix time) try "date -d @1747940448" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10668) received by PID 67176 (TID 0x7f2766dac740) from PID 67176 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2707: paddle.nn.functional.normalize(x=Tensor([20452226, 5, 6, 7],"float16"), p=1, )
W0523 03:02:40.922829 67631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:02:40.923902 67631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([20452226, 5, 6, 7],"float16"), p=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940577 (unix time) try "date -d @1747940577" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1082f) received by PID 67631 (TID 0x7f2766dac740) from PID 67631 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2709: paddle.nn.functional.normalize(x=Tensor([2970966, 768],"float32"), axis=-1, )
W0523 03:04:10.449496 67880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:04:10.450449 67880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([2970966, 768],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940664 (unix time) try "date -d @1747940664" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10928) received by PID 67880 (TID 0x7f2766dac740) from PID 67880 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2711: paddle.nn.functional.normalize(x=Tensor([4, 25565282, 6, 7],"float16"), p=1, )
W0523 03:05:44.964824 68110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:05:44.965801 68110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 25565282, 6, 7],"float16"), p=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940780 (unix time) try "date -d @1747940780" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10a0e) received by PID 68110 (TID 0x7f2766dac740) from PID 68110 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2713: paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), )
W0523 03:08:07.289604 68338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:08:07.290596 68338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940904 (unix time) try "date -d @1747940904" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10af2) received by PID 68338 (TID 0x7f2766dac740) from PID 68338 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2715: paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), p=4, axis=3, )
W0523 03:09:44.025564 68566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:09:44.026620 68566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), p=4, axis=3, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941001 (unix time) try "date -d @1747941001" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10bd6) received by PID 68566 (TID 0x7f2766dac740) from PID 68566 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2717: paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), p=1, )
W0523 03:11:25.304919 68794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:11:25.305956 68794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), p=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941102 (unix time) try "date -d @1747941102" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10cba) received by PID 68794 (TID 0x7f2766dac740) from PID 68794 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2722: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 2, 1e-06, True, None, )
W0523 03:13:35.109782 69341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:13:35.110713 69341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 2, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941229 (unix time) try "date -d @1747941229" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10edd) received by PID 69341 (TID 0x7f2766dac740) from PID 69341 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2726: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), math.inf, 1e-06, True, None, )
W0523 03:15:37.420465 69721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:15:37.421464 69721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941341 (unix time) try "date -d @1747941341" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11059) received by PID 69721 (TID 0x7f2766dac740) from PID 69721 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2731: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 2, 1e-06, True, None, )
W0523 03:17:33.770042 70196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:17:33.771018 70196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 2, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941490 (unix time) try "date -d @1747941490" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11234) received by PID 70196 (TID 0x7f2766dac740) from PID 70196 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2735: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -math.inf, 1e-06, True, None, )
W0523 03:19:32.027746 70482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:19:32.028801 70482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941580 (unix time) try "date -d @1747941580" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11352) received by PID 70482 (TID 0x7f2766dac740) from PID 70482 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2737: paddle.nn.functional.pairwise_distance(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), 2, 1e-06, False, None, )
W0523 03:21:02.071264 70768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:21:02.072281 70768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), 2, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941672 (unix time) try "date -d @1747941672" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11470) received by PID 70768 (TID 0x7f2766dac740) from PID 70768 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2743: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -1, 1e-06, False, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941770 (unix time) try "date -d @1747941770" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x115b4) received by PID 71092 (TID 0x7f2766dac740) from PID 71092 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2744: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 1, 1e-06, True, None, )
W0523 03:24:03.765657 71414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:24:03.766680 71414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 1, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941846 (unix time) try "date -d @1747941846" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x116f6) received by PID 71414 (TID 0x7f2766dac740) from PID 71414 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2748: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), math.inf, 1e-06, False, None, )
W0523 03:25:20.955579 71735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:25:20.956624 71735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941923 (unix time) try "date -d @1747941923" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11837) received by PID 71735 (TID 0x7f2766dac740) from PID 71735 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2753: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -1, 1e-06, False, None, )
W0523 03:27:21.522643 72284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:27:21.523721 72284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942047 (unix time) try "date -d @1747942047" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11a5c) received by PID 72284 (TID 0x7f2766dac740) from PID 72284 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2756: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 2, 1e-06, False, None, )
W0523 03:28:48.215432 72648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:28:48.216398 72648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 2, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942133 (unix time) try "date -d @1747942133" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11bc8) received by PID 72648 (TID 0x7f2766dac740) from PID 72648 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2761: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -math.inf, 1e-06, True, None, )
W0523 03:30:52.342830 73198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:30:52.343842 73198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942257 (unix time) try "date -d @1747942257" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11dee) received by PID 73198 (TID 0x7f2766dac740) from PID 73198 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2765: paddle.nn.functional.pairwise_distance(x=Tensor([100, 22817014],"float32"), y=Tensor([100, 22817014],"float32"), p=2.0, epsilon=1e-06, keepdim=False, )
W0523 03:32:46.160219 73655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:32:46.161211 73655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(x=Tensor([100, 22817014],"float32"), y=Tensor([100, 22817014],"float32"), p=2.0, epsilon=1e-06, keepdim=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942380 (unix time) try "date -d @1747942380" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11fb7) received by PID 73655 (TID 0x7f2766dac740) from PID 73655 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2771: paddle.nn.functional.rrelu(Tensor([38028357, 3, 4, 5],"float32"), 0.1, 0.3, training=False, )
W0523 03:34:40.128037 74131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:34:40.129185 74131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.rrelu(Tensor([38028357, 3, 4, 5],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1384)

[Worker 3] Completed Task 2771

[Worker 3] Processing Task 2775: paddle.std(Tensor([1, 3, 4, 357913942],"float16"), 2, True, False, )
W0523 03:36:19.287815 74131 dygraph_functions.cc:85403] got different data type, run type promotion automatically, this may cause data type been changed.
W0523 03:36:19.288103 74131 dygraph_functions.cc:87437] got different data type, run type promotion automatically, this may cause data type been changed.
W0523 03:36:19.290741 74131 dygraph_functions.cc:82752] got different data type, run type promotion automatically, this may cause data type been changed.
[accuracy error] backward  paddle.std(Tensor([1, 3, 4, 357913942],"float16"), 2, True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 52 / 4294967304 (0.0%)
Greatest absolute difference: 0.0784912109375 at index (0, 2, 1, 168768463) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 8489191) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 3, 4, 357913942]), dtype=torch.float16)
First 100 elements: tensor([ 8.7204e-03, -2.8824e-02,  7.6256e-03, -7.3730e-02, -5.0842e-02,
        -6.0501e-03,  1.9348e-02,  1.7175e-01, -6.6284e-02,  1.1963e-01,
         1.6138e-01,  7.1350e-02, -4.4479e-03, -3.6652e-02, -2.1667e-02,
         3.7201e-02, -4.0680e-02, -2.6062e-02, -1.0938e-01, -1.0461e-01,
        -3.0106e-02, -1.4481e-02, -2.9480e-02, -1.0431e-01,  5.8228e-02,
        -4.3411e-03,  7.7148e-02,  5.8228e-02, -3.8422e-02,  3.4821e-02,
         1.6663e-02,  4.5662e-03, -1.3513e-01,  1.7532e-02,  2.8168e-02,
         1.7853e-02, -1.0925e-02, -3.9612e-02,  7.9298e-04,  3.3997e-02,
         4.9255e-02,  1.8539e-02, -9.4360e-02,  2.9800e-02,  1.8234e-02,
         5.1300e-02, -1.1084e-01, -6.3904e-02,  9.9609e-02,  8.9783e-02,
        -5.7739e-02, -4.9530e-02, -2.3483e-02, -6.1951e-02,  2.1637e-02,
         3.5583e-02, -1.6602e-02, -1.6431e-01,  1.6537e-03,  9.5276e-02,
         5.3009e-02,  3.2074e-02,  2.9545e-03, -1.0352e-01,  1.4905e-01,
        -3.0334e-02,  1.0779e-01, -3.2288e-02,  2.2125e-02, -4.1847e-03,
        -2.7191e-02,  1.9867e-02, -2.3911e-02,  2.2125e-02, -9.9373e-04,
        -1.7166e-02, -1.0811e-02, -1.0321e-01, -1.0796e-02,  1.3696e-01,
        -1.2268e-01,  1.5903e-04,  1.0400e-01, -3.1555e-02,  1.4830e-04,
         8.6609e-02,  1.4847e-02, -5.7251e-02, -5.3955e-02, -5.3101e-02,
         4.4067e-02, -1.5396e-02,  3.1799e-02,  2.7283e-02,  3.3531e-03,
         7.8201e-03,  2.0218e-02,  4.3549e-02, -3.3684e-03, -3.2410e-02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 3, 4, 357913942]), dtype=torch.float16)
First 100 elements: tensor([ 8.7204e-03, -2.8824e-02,  7.6103e-03, -7.3730e-02, -5.0842e-02,
        -6.0539e-03,  1.9348e-02,  1.7175e-01, -6.6406e-02,  1.1963e-01,
         1.6138e-01,  7.1350e-02, -4.4479e-03, -3.6621e-02, -2.1683e-02,
         3.7170e-02, -4.0588e-02, -2.6031e-02, -1.0931e-01, -1.0461e-01,
        -3.0106e-02, -1.4473e-02, -2.9480e-02, -1.0449e-01,  5.8228e-02,
        -4.3411e-03,  7.7209e-02,  5.8228e-02, -3.8422e-02,  3.4821e-02,
         1.6663e-02,  4.5662e-03, -1.3501e-01,  1.7532e-02,  2.8168e-02,
         1.7853e-02, -1.0948e-02, -3.9612e-02,  7.9393e-04,  3.3936e-02,
         4.9255e-02,  1.8539e-02, -9.4421e-02,  2.9800e-02,  1.8234e-02,
         5.1300e-02, -1.1084e-01, -6.3904e-02,  9.9609e-02,  8.9844e-02,
        -5.7739e-02, -4.9530e-02, -2.3468e-02, -6.2134e-02,  2.1637e-02,
         3.5583e-02, -1.6617e-02, -1.6431e-01,  1.6527e-03,  9.5398e-02,
         5.3009e-02,  3.2074e-02,  2.9926e-03, -1.0352e-01,  1.4905e-01,
        -3.0334e-02,  1.0779e-01, -3.2288e-02,  2.2141e-02, -4.1809e-03,
        -2.7191e-02,  1.9867e-02, -2.3911e-02,  2.2125e-02, -9.9564e-04,
        -1.7181e-02, -1.0818e-02, -1.0315e-01, -1.0796e-02,  1.3696e-01,
        -1.2280e-01,  1.5914e-04,  1.0394e-01, -3.1555e-02,  1.4818e-04,
         8.6609e-02,  1.4862e-02, -5.7281e-02, -5.3955e-02, -5.3070e-02,
         4.4098e-02, -1.5396e-02,  3.1799e-02,  2.7298e-02,  3.3531e-03,
         7.8278e-03,  2.0218e-02,  4.3549e-02, -3.3016e-03, -3.2410e-02],
       dtype=torch.float16)
[Worker 3] Completed Task 2775

[Worker 3] Processing Task 2835: paddle.Tensor.argmax(Tensor([83837, 1, 27216],"float32"), axis=-2, )
[cuda error] paddle.Tensor.argmax(Tensor([83837, 1, 27216],"float32"), axis=-2, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943204 (unix time) try "date -d @1747943204" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12193) received by PID 74131 (TID 0x7f2766dac740) from PID 74131 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2838: paddle.Tensor.cumsum(Tensor([1, 11408507, 200],"float32"), 1, )
W0523 03:48:38.765302 74848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:48:38.766333 74848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 11408507, 200],"float32"), 1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1417714 / 2281701400 (0.1%)
Greatest absolute difference: 0.08777618408203125 at index (0, 10995631, 96) (up to 0.01 allowed)
Greatest relative difference: 30742.76171875 at index (0, 9551080, 11) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 11408507, 200]), dtype=torch.float32)
First 100 elements: tensor([ 0.2703, -0.4374, -0.3747, -0.3575, -0.0916, -0.4828, -0.2601,  0.3855,
         0.4600,  0.1346,  0.1362,  0.4685, -0.1427,  0.3866, -0.0933, -0.1249,
         0.4461,  0.2849,  0.3277, -0.0827,  0.1418, -0.4865, -0.1133,  0.0296,
         0.0014, -0.2066,  0.0410,  0.4815,  0.2916, -0.4147, -0.2368,  0.0942,
        -0.1105, -0.3125, -0.1920, -0.3808,  0.4370, -0.3483,  0.0250,  0.3304,
         0.3701, -0.3382,  0.1921,  0.1498, -0.3260,  0.1002, -0.1544, -0.0278,
        -0.0794, -0.0470,  0.2958,  0.3243,  0.1330, -0.4889,  0.3586,  0.1414,
         0.0743, -0.1173, -0.0639, -0.4495,  0.4031,  0.4701,  0.1530,  0.1084,
        -0.4007,  0.1362, -0.2938,  0.3034, -0.1948, -0.0878, -0.3438, -0.3704,
         0.2669,  0.3298,  0.2361, -0.2876,  0.2149,  0.1125, -0.1964,  0.0808,
         0.3904, -0.0411,  0.2985,  0.2123,  0.1702,  0.3584, -0.1348, -0.3626,
         0.3515, -0.3613,  0.1846,  0.0952,  0.4019,  0.3796,  0.4914, -0.3115,
         0.1373, -0.2306,  0.4435,  0.1262])
DESIRED: (shape=torch.Size([1, 11408507, 200]), dtype=torch.float32)
First 100 elements: tensor([ 0.2703, -0.4374, -0.3747, -0.3575, -0.0916, -0.4828, -0.2601,  0.3855,
         0.4600,  0.1346,  0.1362,  0.4685, -0.1427,  0.3866, -0.0933, -0.1249,
         0.4461,  0.2849,  0.3277, -0.0827,  0.1418, -0.4865, -0.1133,  0.0296,
         0.0014, -0.2066,  0.0410,  0.4815,  0.2916, -0.4147, -0.2368,  0.0942,
        -0.1105, -0.3125, -0.1920, -0.3808,  0.4370, -0.3483,  0.0250,  0.3304,
         0.3701, -0.3382,  0.1921,  0.1498, -0.3260,  0.1002, -0.1544, -0.0278,
        -0.0794, -0.0470,  0.2958,  0.3243,  0.1330, -0.4889,  0.3586,  0.1414,
         0.0743, -0.1173, -0.0639, -0.4495,  0.4031,  0.4701,  0.1530,  0.1084,
        -0.4007,  0.1362, -0.2938,  0.3034, -0.1948, -0.0878, -0.3438, -0.3704,
         0.2669,  0.3298,  0.2361, -0.2876,  0.2149,  0.1125, -0.1964,  0.0808,
         0.3904, -0.0411,  0.2985,  0.2123,  0.1702,  0.3584, -0.1348, -0.3626,
         0.3515, -0.3613,  0.1846,  0.0952,  0.4019,  0.3796,  0.4914, -0.3115,
         0.1373, -0.2306,  0.4435,  0.1262])
[Worker 3] Completed Task 2838

[Worker 3] Processing Task 2842: paddle.Tensor.cumsum(Tensor([1, 144, 15845149],"float32"), 2, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 144, 15845149],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 594 / 2281701456 (0.0%)
Greatest absolute difference: 0.013223651796579361 at index (0, 49, 15122688) (up to 0.01 allowed)
Greatest relative difference: 14.19429874420166 at index (0, 49, 15120729) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 144, 15845149]), dtype=torch.float32)
First 100 elements: tensor([ 2.7026e-01, -1.6713e-01, -5.4183e-01, -8.9928e-01, -9.9084e-01,
        -1.4736e+00, -1.7337e+00, -1.3483e+00, -8.8825e-01, -7.5368e-01,
        -6.1748e-01, -1.4897e-01, -2.9166e-01,  9.4926e-02,  1.6299e-03,
        -1.2328e-01,  3.2281e-01,  6.0772e-01,  9.3541e-01,  8.5272e-01,
         9.9450e-01,  5.0804e-01,  3.9473e-01,  4.2434e-01,  4.2574e-01,
         2.1917e-01,  2.6019e-01,  7.4171e-01,  1.0333e+00,  6.1858e-01,
         3.8175e-01,  4.7594e-01,  3.6546e-01,  5.2966e-02, -1.3908e-01,
        -5.1989e-01, -8.2919e-02, -4.3118e-01, -4.0623e-01, -7.5792e-02,
         2.9434e-01, -4.3819e-02,  1.4830e-01,  2.9809e-01, -2.7958e-02,
         7.2220e-02, -8.2218e-02, -1.1007e-01, -1.8950e-01, -2.3653e-01,
         5.9285e-02,  3.8363e-01,  5.1662e-01,  2.7757e-02,  3.8638e-01,
         5.2777e-01,  6.0206e-01,  4.8480e-01,  4.2093e-01, -2.8580e-02,
         3.7449e-01,  8.4461e-01,  9.9757e-01,  1.1060e+00,  7.0526e-01,
         8.4146e-01,  5.4769e-01,  8.5110e-01,  6.5630e-01,  5.6849e-01,
         2.2473e-01, -1.4566e-01,  1.2128e-01,  4.5110e-01,  6.8718e-01,
         3.9957e-01,  6.1443e-01,  7.2694e-01,  5.3050e-01,  6.1126e-01,
         1.0016e+00,  9.6057e-01,  1.2590e+00,  1.4714e+00,  1.6415e+00,
         2.0000e+00,  1.8651e+00,  1.5025e+00,  1.8541e+00,  1.4927e+00,
         1.6773e+00,  1.7725e+00,  2.1744e+00,  2.5539e+00,  3.0454e+00,
         2.7339e+00,  2.8711e+00,  2.6406e+00,  3.0840e+00,  3.2102e+00])
DESIRED: (shape=torch.Size([1, 144, 15845149]), dtype=torch.float32)
First 100 elements: tensor([ 2.7026e-01, -1.6713e-01, -5.4183e-01, -8.9928e-01, -9.9084e-01,
        -1.4736e+00, -1.7337e+00, -1.3483e+00, -8.8825e-01, -7.5368e-01,
        -6.1748e-01, -1.4897e-01, -2.9166e-01,  9.4926e-02,  1.6299e-03,
        -1.2328e-01,  3.2281e-01,  6.0772e-01,  9.3541e-01,  8.5272e-01,
         9.9450e-01,  5.0804e-01,  3.9473e-01,  4.2434e-01,  4.2574e-01,
         2.1917e-01,  2.6019e-01,  7.4171e-01,  1.0333e+00,  6.1858e-01,
         3.8175e-01,  4.7594e-01,  3.6546e-01,  5.2966e-02, -1.3908e-01,
        -5.1989e-01, -8.2919e-02, -4.3118e-01, -4.0623e-01, -7.5792e-02,
         2.9434e-01, -4.3819e-02,  1.4830e-01,  2.9809e-01, -2.7958e-02,
         7.2220e-02, -8.2218e-02, -1.1007e-01, -1.8950e-01, -2.3653e-01,
         5.9285e-02,  3.8363e-01,  5.1662e-01,  2.7757e-02,  3.8638e-01,
         5.2777e-01,  6.0206e-01,  4.8480e-01,  4.2093e-01, -2.8580e-02,
         3.7449e-01,  8.4461e-01,  9.9757e-01,  1.1060e+00,  7.0526e-01,
         8.4146e-01,  5.4769e-01,  8.5110e-01,  6.5630e-01,  5.6849e-01,
         2.2473e-01, -1.4566e-01,  1.2128e-01,  4.5110e-01,  6.8718e-01,
         3.9957e-01,  6.1443e-01,  7.2694e-01,  5.3050e-01,  6.1126e-01,
         1.0016e+00,  9.6057e-01,  1.2590e+00,  1.4714e+00,  1.6415e+00,
         2.0000e+00,  1.8651e+00,  1.5025e+00,  1.8541e+00,  1.4927e+00,
         1.6773e+00,  1.7725e+00,  2.1744e+00,  2.5539e+00,  3.0454e+00,
         2.7339e+00,  2.8711e+00,  2.6406e+00,  3.0840e+00,  3.2102e+00])
[Worker 3] Completed Task 2842

[Worker 3] Processing Task 2846: paddle.Tensor.cumsum(Tensor([1, 18, 126761188],"float32"), 2, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 18, 126761188],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 412752 / 2281701384 (0.0%)
Greatest absolute difference: 0.08599185943603516 at index (0, 12, 124669979) (up to 0.01 allowed)
Greatest relative difference: 10851.9580078125 at index (0, 17, 46619525) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 18, 126761188]), dtype=torch.float32)
First 100 elements: tensor([ 2.7026e-01, -1.6713e-01, -5.4183e-01, -8.9928e-01, -9.9084e-01,
        -1.4736e+00, -1.7337e+00, -1.3483e+00, -8.8825e-01, -7.5368e-01,
        -6.1748e-01, -1.4897e-01, -2.9166e-01,  9.4926e-02,  1.6299e-03,
        -1.2328e-01,  3.2281e-01,  6.0772e-01,  9.3541e-01,  8.5272e-01,
         9.9450e-01,  5.0804e-01,  3.9473e-01,  4.2434e-01,  4.2574e-01,
         2.1917e-01,  2.6019e-01,  7.4171e-01,  1.0333e+00,  6.1858e-01,
         3.8175e-01,  4.7594e-01,  3.6546e-01,  5.2966e-02, -1.3908e-01,
        -5.1989e-01, -8.2919e-02, -4.3118e-01, -4.0623e-01, -7.5792e-02,
         2.9434e-01, -4.3819e-02,  1.4830e-01,  2.9809e-01, -2.7958e-02,
         7.2220e-02, -8.2218e-02, -1.1007e-01, -1.8950e-01, -2.3653e-01,
         5.9285e-02,  3.8363e-01,  5.1662e-01,  2.7757e-02,  3.8638e-01,
         5.2777e-01,  6.0206e-01,  4.8480e-01,  4.2093e-01, -2.8580e-02,
         3.7449e-01,  8.4461e-01,  9.9757e-01,  1.1060e+00,  7.0526e-01,
         8.4146e-01,  5.4769e-01,  8.5110e-01,  6.5630e-01,  5.6849e-01,
         2.2473e-01, -1.4566e-01,  1.2128e-01,  4.5110e-01,  6.8718e-01,
         3.9957e-01,  6.1443e-01,  7.2694e-01,  5.3050e-01,  6.1126e-01,
         1.0016e+00,  9.6057e-01,  1.2590e+00,  1.4714e+00,  1.6415e+00,
         2.0000e+00,  1.8651e+00,  1.5025e+00,  1.8541e+00,  1.4927e+00,
         1.6773e+00,  1.7725e+00,  2.1744e+00,  2.5539e+00,  3.0454e+00,
         2.7339e+00,  2.8711e+00,  2.6406e+00,  3.0840e+00,  3.2102e+00])
DESIRED: (shape=torch.Size([1, 18, 126761188]), dtype=torch.float32)
First 100 elements: tensor([ 2.7026e-01, -1.6713e-01, -5.4183e-01, -8.9928e-01, -9.9084e-01,
        -1.4736e+00, -1.7337e+00, -1.3483e+00, -8.8825e-01, -7.5368e-01,
        -6.1748e-01, -1.4897e-01, -2.9166e-01,  9.4926e-02,  1.6299e-03,
        -1.2328e-01,  3.2281e-01,  6.0772e-01,  9.3541e-01,  8.5272e-01,
         9.9450e-01,  5.0804e-01,  3.9473e-01,  4.2434e-01,  4.2574e-01,
         2.1917e-01,  2.6019e-01,  7.4171e-01,  1.0333e+00,  6.1858e-01,
         3.8175e-01,  4.7594e-01,  3.6546e-01,  5.2966e-02, -1.3908e-01,
        -5.1989e-01, -8.2919e-02, -4.3118e-01, -4.0623e-01, -7.5792e-02,
         2.9434e-01, -4.3819e-02,  1.4830e-01,  2.9809e-01, -2.7958e-02,
         7.2220e-02, -8.2218e-02, -1.1007e-01, -1.8950e-01, -2.3653e-01,
         5.9285e-02,  3.8363e-01,  5.1662e-01,  2.7757e-02,  3.8638e-01,
         5.2777e-01,  6.0206e-01,  4.8480e-01,  4.2093e-01, -2.8580e-02,
         3.7449e-01,  8.4461e-01,  9.9757e-01,  1.1060e+00,  7.0526e-01,
         8.4146e-01,  5.4769e-01,  8.5110e-01,  6.5630e-01,  5.6849e-01,
         2.2473e-01, -1.4566e-01,  1.2128e-01,  4.5110e-01,  6.8718e-01,
         3.9957e-01,  6.1443e-01,  7.2694e-01,  5.3050e-01,  6.1126e-01,
         1.0016e+00,  9.6057e-01,  1.2590e+00,  1.4714e+00,  1.6415e+00,
         2.0000e+00,  1.8651e+00,  1.5025e+00,  1.8541e+00,  1.4927e+00,
         1.6773e+00,  1.7725e+00,  2.1744e+00,  2.5539e+00,  3.0454e+00,
         2.7339e+00,  2.8711e+00,  2.6406e+00,  3.0840e+00,  3.2102e+00])
[Worker 3] Completed Task 2846

[Worker 3] Processing Task 2861: paddle.Tensor.cumsum(Tensor([285212673, 4, 2],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.cumsum(Tensor([285212673, 4, 2],"int64"), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 2861

[Worker 3] Processing Task 2889: paddle.trapezoid(Tensor([2281701379],"float32"), dx=2.0, )
[paddle error] paddle.trapezoid(Tensor([2281701379],"float32"), dx=2.0, ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at /paddle/paddle/phi/core/dense_tensor.cc:113)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944091 (unix time) try "date -d @1747944091" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12460) received by PID 74848 (TID 0x7f2766dac740) from PID 74848 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2893: paddle.trunc(input=Tensor([3, 6, 6, 6, 6628036],"float16"), )
W0523 04:03:32.132637 75441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:03:32.133951 75441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([3, 6, 6, 6, 6628036],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944229 (unix time) try "date -d @1747944229" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x126b1) received by PID 75441 (TID 0x7f2766dac740) from PID 75441 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2895: paddle.trunc(input=Tensor([3, 6, 6628036, 6, 6],"float16"), )
W0523 04:05:10.882915 75761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:05:10.883894 75761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([3, 6, 6628036, 6, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944326 (unix time) try "date -d @1747944326" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x127f1) received by PID 75761 (TID 0x7f2766dac740) from PID 75761 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2900: paddle.trunc(input=Tensor([6, 19884108, 6, 6],"float16"), )
[cuda error] paddle.trunc(input=Tensor([6, 19884108, 6, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944515 (unix time) try "date -d @1747944515" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12947) received by PID 76103 (TID 0x7f2766dac740) from PID 76103 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2903: paddle.trunc(input=Tensor([6, 6, 19884108, 6],"float16"), )
W0523 04:09:55.617048 76465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:09:55.618072 76465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([6, 6, 19884108, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944611 (unix time) try "date -d @1747944611" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12ab1) received by PID 76465 (TID 0x7f2766dac740) from PID 76465 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2905: paddle.trunc(Tensor([10, 20, 11408507],"float32"), )
W0523 04:11:22.808900 76675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:11:22.809864 76675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(Tensor([10, 20, 11408507],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944696 (unix time) try "date -d @1747944696" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12b83) received by PID 76675 (TID 0x7f2766dac740) from PID 76675 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2908: paddle.trunc(Tensor([114085069, 20],"float32"), )
W0523 04:13:17.565654 77016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:13:17.566793 77016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(Tensor([114085069, 20],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944813 (unix time) try "date -d @1747944813" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12cd8) received by PID 77016 (TID 0x7f2766dac740) from PID 77016 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 2953: paddle.argsort(Tensor([22817014, 100],"int64"), axis=1, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([22817014, 100],"int64"), axis=1, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 2953

[Worker 3] Processing Task 2956: paddle.argsort(Tensor([3, 380283564, 2],"int64"), axis=2, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([3, 380283564, 2],"int64"), axis=2, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 2956

[Worker 3] Processing Task 2959: paddle.argsort(Tensor([35651585, 64],"int64"), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([35651585, 64],"int64"), axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 2959

[Worker 3] Processing Task 2970: paddle.chunk(Tensor([1, 1, 1, 4294967297],"float16"), 2, axis=-1, )
[paddle error] paddle.chunk(Tensor([1, 1, 1, 4294967297],"float16"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 1, 1, 4294967297], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2970

[Worker 3] Processing Task 2972: paddle.chunk(Tensor([1, 11, 207427399],"float32"), chunks=2, axis=-1, )
[paddle error] paddle.chunk(Tensor([1, 11, 207427399],"float32"), chunks=2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 11, 207427399], Attr(dim) = 2.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2972

[Worker 3] Processing Task 2974: paddle.chunk(Tensor([13, 16, 10969719],"float32"), chunks=2, axis=-1, )
[paddle error] paddle.chunk(Tensor([13, 16, 10969719],"float32"), chunks=2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [13, 16, 10969719], Attr(dim) = 2.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2974

[Worker 3] Processing Task 2977: paddle.chunk(Tensor([13, 5484860, 32],"float32"), 3, axis=1, )
[paddle error] paddle.chunk(Tensor([13, 5484860, 32],"float32"), 3, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [13, 5484860, 32], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2977

[Worker 3] Processing Task 2980: paddle.chunk(Tensor([2048, 1114113],"float32"), 2, axis=-1, )
[paddle error] paddle.chunk(Tensor([2048, 1114113],"float32"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [2048, 1114113], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2980

[Worker 3] Processing Task 2983: paddle.chunk(Tensor([52, 4, 7, 1567103],"float32"), 3, axis=-1, )
[paddle error] paddle.chunk(Tensor([52, 4, 7, 1567103],"float32"), 3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [52, 4, 7, 1567103], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2983

[Worker 3] Processing Task 2986: paddle.chunk(x=Tensor([1431655766, 3],"float16"), chunks=3, axis=0, )
[paddle error] paddle.chunk(x=Tensor([1431655766, 3],"float16"), chunks=3, axis=0, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [1431655766, 3], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2986

[Worker 3] Processing Task 2989: paddle.chunk(x=Tensor([3, 760567127],"float32"), chunks=3, axis=-1, )
[paddle error] paddle.chunk(x=Tensor([3, 760567127],"float32"), chunks=3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [3, 760567127], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2989

[Worker 3] Processing Task 2991: paddle.chunk(x=Tensor([3, 760567127],"int64"), chunks=3, axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.chunk(x=Tensor([3, 760567127],"int64"), chunks=3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [3, 760567127], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2991

[Worker 3] Processing Task 2992: paddle.chunk(x=Tensor([760567127, 3],"float32"), chunks=3, axis=0, )
[paddle error] paddle.chunk(x=Tensor([760567127, 3],"float32"), chunks=3, axis=0, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [760567127, 3], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2992

[Worker 3] Processing Task 2994: paddle.chunk(x=Tensor([760567127, 3],"int64"), chunks=3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.chunk(x=Tensor([760567127, 3],"int64"), chunks=3, axis=0, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [760567127, 3], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 2994

[Worker 3] Processing Task 3066: paddle.flatten(Tensor([214748365, 4, 5],"int32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.flatten(Tensor([214748365, 4, 5],"int32"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([ -6766, -22785, -32710,  ..., -58467,  57942, -56118],
       dtype=torch.int32),
    expected=tensor([ -6766, -22785, -32710,  ..., -58467,  57942, -56118],
       dtype=torch.int32),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 3] Completed Task 3066

[Worker 3] Processing Task 3088: paddle.frac(Tensor([1431655766, 3],"float16"), )
[cuda error] paddle.frac(Tensor([1431655766, 3],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747948053 (unix time) try "date -d @1747948053" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12e2e) received by PID 77358 (TID 0x7f2766dac740) from PID 77358 ***]

[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3105: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), -math.inf, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [2, 126761188, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), -math.inf, ) 
 (PreconditionNotMet) For batch [137436885]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 3] Completed Task 3105

[Worker 3] Processing Task 3108: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), -1, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [63380594, 4, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), -1, ) 
 (PreconditionNotMet) For batch [137436885]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 3] Completed Task 3108

[Worker 3] Processing Task 3111: paddle.linalg.det(Tensor([253522376, 3, 3],"float32"), )
W0523 05:11:48.028442 77907 backward.cc:437] While running Node (DetGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.det(Tensor([253522376, 3, 3],"float32"), ) 
 (PreconditionNotMet) For batch [137436885]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 3] Completed Task 3111

[Worker 3] Processing Task 3116: paddle.logsumexp(Tensor([4294967295],"float32"), axis=0, )
[accuracy error] backward  paddle.logsumexp(Tensor([4294967295],"float32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4252024839 / 4294967295 (99.0%)
Greatest absolute difference: 1.0 at index (32366904,) (up to 0.01 allowed)
Greatest relative difference: 16029647872.0 at index (32366904,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967295]), dtype=torch.float32)
First 100 elements: tensor([-0.3330, -0.8161, -0.0271, -0.1851, -0.3470, -0.6034, -0.1126, -0.1790,
        -0.6173, -0.5885, -0.6382, -0.5546, -0.1017, -0.3698, -0.8917, -0.7217,
        -0.1627, -0.4440, -0.5589, -0.8624, -0.3289, -0.6181, -0.7850, -0.1935,
        -0.3635, -0.1800, -0.1079, -0.6963, -0.5322, -0.1086, -0.8701, -0.5712,
        -0.4739, -0.5331, -0.0966, -0.9836, -0.5184, -0.6968, -0.9309, -0.2682,
        -0.4221, -0.8308, -0.4574, -0.9894, -0.0967, -0.3107, -0.7321, -0.3149,
        -0.3385, -0.6552, -0.2787, -0.1894, -0.7909, -0.7858, -0.1582, -0.2333,
        -0.5682, -0.2913, -0.8578, -0.9279, -0.6385, -0.7556, -0.5948, -0.2054,
        -0.4039, -0.3158, -0.9066, -0.4495, -0.5323, -0.3614, -0.3367, -0.4707,
        -0.7950, -0.4271, -0.7173, -0.2159, -0.9105, -0.1747, -0.1813, -0.6516,
        -0.0934, -0.9276, -0.2105, -0.3337, -0.5850, -0.2882, -0.5986, -0.8304,
        -0.7609, -0.9017, -0.4212, -0.1349, -0.1159, -0.4044, -0.9199, -0.5242,
        -0.5067, -0.0471, -0.1953, -0.6759])
DESIRED: (shape=torch.Size([4294967295]), dtype=torch.float32)
First 100 elements: tensor([1.2155e-10, 7.4976e-11, 1.6504e-10, 1.4092e-10, 1.1986e-10, 9.2754e-11,
        1.5152e-10, 1.4178e-10, 9.1471e-11, 9.4139e-11, 8.9575e-11, 9.7394e-11,
        1.5318e-10, 1.1716e-10, 6.9523e-11, 8.2405e-11, 1.4411e-10, 1.0878e-10,
        9.6967e-11, 7.1585e-11, 1.2205e-10, 9.1400e-11, 7.7346e-11, 1.3974e-10,
        1.1790e-10, 1.4164e-10, 1.5224e-10, 8.4519e-11, 9.9592e-11, 1.5212e-10,
        7.1035e-11, 9.5783e-11, 1.0557e-10, 9.9501e-11, 1.5396e-10, 6.3415e-11,
        1.0098e-10, 8.4481e-11, 6.6848e-11, 1.2968e-10, 1.1119e-10, 7.3884e-11,
        1.0734e-10, 6.3052e-11, 1.5395e-10, 1.2429e-10, 8.1550e-11, 1.2377e-10,
        1.2088e-10, 8.8072e-11, 1.2833e-10, 1.4032e-10, 7.6895e-11, 7.7284e-11,
        1.4477e-10, 1.3430e-10, 9.6076e-11, 1.2672e-10, 7.1921e-11, 6.7048e-11,
        8.9549e-11, 7.9659e-11, 9.3550e-11, 1.3809e-10, 1.1323e-10, 1.2365e-10,
        6.8494e-11, 1.0818e-10, 9.9589e-11, 1.1814e-10, 1.2110e-10, 1.0592e-10,
        7.6575e-11, 1.1063e-10, 8.2762e-11, 1.3664e-10, 6.8228e-11, 1.4239e-10,
        1.4146e-10, 8.8383e-11, 1.5445e-10, 6.7068e-11, 1.3739e-10, 1.2147e-10,
        9.4470e-11, 1.2712e-10, 9.3197e-11, 7.3912e-11, 7.9231e-11, 6.8830e-11,
        1.1128e-10, 1.4818e-10, 1.5102e-10, 1.1318e-10, 6.7588e-11, 1.0040e-10,
        1.0217e-10, 1.6178e-10, 1.3949e-10, 8.6263e-11])
[Worker 3] Completed Task 3116

[Worker 3] Processing Task 3122: paddle.minimum(Tensor([1],"float32"), Tensor([4294967295],"float32"), )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.12 GiB is free. Process 83633 has 66.06 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 5.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 3122: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.12 GiB is free. Process 83633 has 66.06 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 5.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 3122: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.12 GiB is free. Process 83633 has 66.06 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 5.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3123: paddle.minimum(Tensor([4294967295],"float32"), Tensor([1],"float32"), )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 6455 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 3123: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 6455 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 3123: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 6455 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3127: paddle.nanmean(Tensor([1431655765, 3],"float32"), tuple(0,1,), False, )
W0523 05:15:26.179441 78627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:15:26.180867 78627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3131: paddle.nanmean(Tensor([2, 107374183, 4, 5],"float32"), None, True, )
W0523 05:45:47.400795 79007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:45:47.402109 79007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3135: paddle.nanmean(Tensor([2, 2147483648],"float32"), None, True, )
W0523 06:16:06.828624 79387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:16:06.830432 79387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3139: paddle.nanmean(Tensor([2, 3, 143165577, 5],"float32"), list[0,1,2,3,], False, )
W0523 06:46:01.135066 79767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:46:01.136516 79767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3143: paddle.nanmean(Tensor([2, 3, 143165577, 5],"float32"), tuple(0,2,), False, )
W0523 07:16:10.923099 80146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:16:10.924427 80146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3147: paddle.nanmean(Tensor([2, 3, 4, 178956971],"float32"), None, False, )
W0523 07:46:24.700205 80527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:46:24.701329 80527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3151: paddle.nanmean(Tensor([4294967295],"float32"), axis=0, )
W0523 08:16:30.950723 80907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:16:30.951699 80907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3155: paddle.nanmean(Tensor([71582789, 3, 4, 5],"float32"), None, False, )
W0523 08:46:45.870074 81287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:46:45.871109 81287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3159: paddle.nanmean(Tensor([858993459, 5],"float32"), keepdim=True, )
W0523 09:16:56.512807 81667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:16:56.513830 81667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3163: paddle.nn.functional.normalize(Tensor([2281701379],"float32"), axis=0, )
W0523 09:47:14.740016 82047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:47:14.740988 82047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(Tensor([2281701379],"float32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281701379 / 2281701379 (100.0%)
Greatest absolute difference: 499999997952.0 at index (103981144,) (up to 0.01 allowed)
Greatest relative difference: 1.3789146048888832e+16 at index (18,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 4.6369e+11,  2.3779e+11, -3.7917e+11, -5.7053e+10, -1.3315e+11,
         1.2115e+11, -2.8693e+11,  4.9054e+11,  4.1644e+11,  4.0472e+11,
        -4.6377e+11, -3.4981e+11, -1.3885e+11, -2.2557e+11, -1.4155e+11,
        -3.3247e+11, -4.0540e+11,  3.1090e+11,  3.0509e+11,  4.7211e+11,
        -1.8640e+11,  2.8246e+11, -2.1976e+11,  3.6653e+11, -3.1032e+11,
        -3.9795e+11,  1.0691e+11,  3.1603e+11, -4.9552e+11, -3.8834e+11,
        -3.4834e+11, -1.3643e+11,  2.7133e+11, -4.4473e+11,  3.6356e+11,
         1.3532e+11, -4.7776e+11, -1.3591e+11,  3.7549e+11,  2.3843e+11,
        -1.1600e+11,  3.0270e+10,  1.5875e+11, -2.6378e+11, -5.2063e+10,
        -3.7703e+11, -1.4852e+11, -7.2182e+10,  4.3582e+11,  1.1928e+11,
        -4.7353e+11, -3.5379e+11,  4.0713e+11, -3.1319e+11,  3.1560e+11,
         4.2423e+11,  3.0013e+11,  4.2206e+11, -4.5690e+11,  1.2648e+10,
        -2.9176e+11,  2.9645e+11,  2.4851e+11, -9.2402e+10,  2.9263e+11,
         2.2843e+11, -4.8268e+11, -1.8941e+10,  7.4631e+10, -2.8592e+11,
         5.6260e+10,  5.7058e+10, -1.7583e+11,  1.9714e+11,  2.4133e+10,
         3.0082e+11,  2.2161e+11,  1.9603e+11, -4.9778e+11, -3.6544e+11,
         3.7268e+11, -2.3333e+11,  4.7347e+11, -2.9689e+11,  4.2022e+11,
        -2.3483e+10,  2.1879e+11, -3.3938e+11,  3.3505e+11,  9.3093e+09,
        -1.9443e+11, -3.6868e+11, -1.6062e+11, -4.3040e+11, -3.3097e+11,
         2.1790e+11, -3.0378e+11,  4.8148e+11, -2.6447e+11, -6.4944e+10])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 3.3627e-05,  1.7245e-05, -2.7498e-05, -4.1375e-06, -9.6561e-06,
         8.7861e-06, -2.0808e-05,  3.5574e-05,  3.0200e-05,  2.9351e-05,
        -3.3633e-05, -2.5369e-05, -1.0070e-05, -1.6358e-05, -1.0265e-05,
        -2.4111e-05, -2.9400e-05,  2.2546e-05,  2.2125e-05,  3.4238e-05,
        -1.3518e-05,  2.0484e-05, -1.5937e-05,  2.6581e-05, -2.2505e-05,
        -2.8859e-05,  7.7534e-06,  2.2919e-05, -3.5935e-05, -2.8163e-05,
        -2.5262e-05, -9.8942e-06,  1.9677e-05, -3.2252e-05,  2.6366e-05,
         9.8138e-06, -3.4648e-05, -9.8567e-06,  2.7231e-05,  1.7291e-05,
        -8.4127e-06,  2.1952e-06,  1.1513e-05, -1.9129e-05, -3.7757e-06,
        -2.7343e-05, -1.0771e-05, -5.2347e-06,  3.1606e-05,  8.6506e-06,
        -3.4341e-05, -2.5657e-05,  2.9525e-05, -2.2713e-05,  2.2888e-05,
         3.0766e-05,  2.1765e-05,  3.0608e-05, -3.3135e-05,  9.1723e-07,
        -2.1159e-05,  2.1499e-05,  1.8022e-05, -6.7011e-06,  2.1222e-05,
         1.6566e-05, -3.5004e-05, -1.3736e-06,  5.4123e-06, -2.0735e-05,
         4.0800e-06,  4.1379e-06, -1.2751e-05,  1.4297e-05,  1.7501e-06,
         2.1815e-05,  1.6071e-05,  1.4217e-05, -3.6099e-05, -2.6502e-05,
         2.7027e-05, -1.6921e-05,  3.4336e-05, -2.1531e-05,  3.0475e-05,
        -1.7030e-06,  1.5867e-05, -2.4612e-05,  2.4298e-05,  6.7512e-07,
        -1.4100e-05, -2.6737e-05, -1.1648e-05, -3.1213e-05, -2.4002e-05,
         1.5802e-05, -2.2030e-05,  3.4917e-05, -1.9180e-05, -4.7098e-06])
[Worker 3] Completed Task 3163

[Worker 3] Processing Task 3169: paddle.nn.functional.normalize(x=Tensor([1, 2281701379],"float32"), axis=-1, )
[accuracy error] paddle.nn.functional.normalize(x=Tensor([1, 2281701379],"float32"), axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281701379 / 2281701379 (100.0%)
Greatest absolute difference: 499999997952.0 at index (0, 103981144) (up to 0.01 allowed)
Greatest relative difference: 1.3789146048888832e+16 at index (0, 18) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 4.6369e+11,  2.3779e+11, -3.7917e+11, -5.7053e+10, -1.3315e+11,
         1.2115e+11, -2.8693e+11,  4.9054e+11,  4.1644e+11,  4.0472e+11,
        -4.6377e+11, -3.4981e+11, -1.3885e+11, -2.2557e+11, -1.4155e+11,
        -3.3247e+11, -4.0540e+11,  3.1090e+11,  3.0509e+11,  4.7211e+11,
        -1.8640e+11,  2.8246e+11, -2.1976e+11,  3.6653e+11, -3.1032e+11,
        -3.9795e+11,  1.0691e+11,  3.1603e+11, -4.9552e+11, -3.8834e+11,
        -3.4834e+11, -1.3643e+11,  2.7133e+11, -4.4473e+11,  3.6356e+11,
         1.3532e+11, -4.7776e+11, -1.3591e+11,  3.7549e+11,  2.3843e+11,
        -1.1600e+11,  3.0270e+10,  1.5875e+11, -2.6378e+11, -5.2063e+10,
        -3.7703e+11, -1.4852e+11, -7.2182e+10,  4.3582e+11,  1.1928e+11,
        -4.7353e+11, -3.5379e+11,  4.0713e+11, -3.1319e+11,  3.1560e+11,
         4.2423e+11,  3.0013e+11,  4.2206e+11, -4.5690e+11,  1.2648e+10,
        -2.9176e+11,  2.9645e+11,  2.4851e+11, -9.2402e+10,  2.9263e+11,
         2.2843e+11, -4.8268e+11, -1.8941e+10,  7.4631e+10, -2.8592e+11,
         5.6260e+10,  5.7058e+10, -1.7583e+11,  1.9714e+11,  2.4133e+10,
         3.0082e+11,  2.2161e+11,  1.9603e+11, -4.9778e+11, -3.6544e+11,
         3.7268e+11, -2.3333e+11,  4.7347e+11, -2.9689e+11,  4.2022e+11,
        -2.3483e+10,  2.1879e+11, -3.3938e+11,  3.3505e+11,  9.3093e+09,
        -1.9443e+11, -3.6868e+11, -1.6062e+11, -4.3040e+11, -3.3097e+11,
         2.1790e+11, -3.0378e+11,  4.8148e+11, -2.6447e+11, -6.4944e+10])
DESIRED: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 3.3627e-05,  1.7245e-05, -2.7498e-05, -4.1375e-06, -9.6561e-06,
         8.7861e-06, -2.0808e-05,  3.5574e-05,  3.0200e-05,  2.9351e-05,
        -3.3633e-05, -2.5369e-05, -1.0070e-05, -1.6358e-05, -1.0265e-05,
        -2.4111e-05, -2.9400e-05,  2.2546e-05,  2.2125e-05,  3.4238e-05,
        -1.3518e-05,  2.0484e-05, -1.5937e-05,  2.6581e-05, -2.2505e-05,
        -2.8859e-05,  7.7534e-06,  2.2919e-05, -3.5935e-05, -2.8163e-05,
        -2.5262e-05, -9.8942e-06,  1.9677e-05, -3.2252e-05,  2.6366e-05,
         9.8138e-06, -3.4648e-05, -9.8567e-06,  2.7231e-05,  1.7291e-05,
        -8.4127e-06,  2.1952e-06,  1.1513e-05, -1.9129e-05, -3.7757e-06,
        -2.7343e-05, -1.0771e-05, -5.2347e-06,  3.1606e-05,  8.6506e-06,
        -3.4341e-05, -2.5657e-05,  2.9525e-05, -2.2713e-05,  2.2888e-05,
         3.0766e-05,  2.1765e-05,  3.0608e-05, -3.3135e-05,  9.1723e-07,
        -2.1159e-05,  2.1499e-05,  1.8022e-05, -6.7011e-06,  2.1222e-05,
         1.6566e-05, -3.5004e-05, -1.3736e-06,  5.4123e-06, -2.0735e-05,
         4.0800e-06,  4.1379e-06, -1.2751e-05,  1.4297e-05,  1.7501e-06,
         2.1815e-05,  1.6071e-05,  1.4217e-05, -3.6099e-05, -2.6502e-05,
         2.7027e-05, -1.6921e-05,  3.4336e-05, -2.1531e-05,  3.0475e-05,
        -1.7030e-06,  1.5867e-05, -2.4612e-05,  2.4298e-05,  6.7512e-07,
        -1.4100e-05, -2.6737e-05, -1.1648e-05, -3.1213e-05, -2.4002e-05,
         1.5802e-05, -2.2030e-05,  3.4917e-05, -1.9180e-05, -4.7098e-06])
[Worker 3] Completed Task 3169

[Worker 3] Processing Task 3170: paddle.nn.functional.normalize(x=Tensor([2, 2147483649],"float16"), )
[accuracy error] paddle.nn.functional.normalize(x=Tensor([2, 2147483649],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4294967298 / 4294967298 (100.0%)
Greatest absolute difference: nan at index (0, 18027734) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 18027734) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 2147483649]), dtype=torch.float16)
First 100 elements: tensor([-inf, inf, inf, -inf, inf, inf, inf, -inf, inf, inf, -inf, -inf, inf, -inf, inf, inf, -inf, inf, -inf, -inf, -inf, -inf, -inf, inf,
        -inf, -inf, inf, -inf, -inf, -inf, -inf, inf, inf, inf, inf, -inf, -inf, inf, -inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, -inf, -inf,
        -inf, -inf, -inf, inf, inf, inf, inf, -inf, inf, -inf, inf, -inf, inf, -inf, inf, inf, inf, -inf, -inf, inf, inf, -inf, -inf, inf,
        inf, -inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, -inf, inf, inf, inf, inf, inf, inf, inf, -inf, inf, inf, inf, inf, inf, -inf,
        inf, inf, inf, -inf], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 2147483649]), dtype=torch.float16)
First 100 elements: tensor([-3.5763e-06,  8.3447e-06,  1.1921e-05, -2.7716e-05,  8.2850e-06,
         9.7752e-06,  1.4424e-05, -2.0862e-05,  1.5497e-06,  1.7881e-06,
        -2.0862e-06, -1.9729e-05,  5.3644e-07, -4.8876e-06,  3.2842e-05,
         6.8545e-06, -1.5318e-05,  1.6689e-06, -9.7752e-06, -3.2783e-06,
        -1.0788e-05, -3.0994e-05, -5.6624e-06,  6.0797e-06, -1.1683e-05,
        -3.5584e-05,  3.3081e-05, -2.8312e-05, -3.4094e-05, -2.4319e-05,
        -2.6226e-05,  3.4273e-05,  2.2173e-05,  8.3447e-07,  1.4842e-05,
        -1.2696e-05, -5.5432e-06,  4.6492e-06, -5.5432e-06, -6.2585e-06,
        -3.6955e-05, -1.9729e-05,  2.5272e-05, -2.5690e-05, -9.1195e-06,
        -3.6240e-05, -1.8716e-05, -7.8082e-06, -4.9472e-06, -1.7345e-05,
        -3.6716e-05,  4.7684e-06,  2.2054e-06,  2.1398e-05,  1.5497e-05,
        -3.5524e-05,  1.0788e-05, -1.0192e-05,  2.7061e-05, -2.7835e-05,
         3.4690e-05, -7.5102e-06,  2.6822e-06,  3.0339e-05,  3.7134e-05,
        -5.4240e-06, -1.9968e-05,  9.7156e-06,  3.6299e-05, -1.7047e-05,
        -3.3855e-05,  3.2008e-05,  3.3259e-05, -1.7464e-05, -3.0041e-05,
        -2.8968e-05, -3.2485e-05,  3.7014e-05, -5.0664e-06, -2.8014e-05,
        -8.3447e-07, -9.0599e-06,  2.5034e-05,  2.3663e-05,  1.7583e-05,
         3.7253e-05,  8.1658e-06,  3.0398e-05,  3.2783e-05, -3.2425e-05,
         1.2636e-05,  3.0279e-05,  1.6749e-05,  1.8597e-05,  8.3447e-06,
        -7.3314e-06,  8.0466e-06,  1.6272e-05,  2.2650e-06, -3.5346e-05],
       dtype=torch.float16)
[Worker 3] Completed Task 3170

[Worker 3] Processing Task 3176: paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), math.inf, 1e-06, False, None, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.07 GiB is free. Process 34606 has 54.12 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Error on Task 3176: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.07 GiB is free. Process 34606 has 54.12 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] OOM on Task 3176: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.07 GiB is free. Process 34606 has 54.12 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Started on GPU 3

[Worker 3] Processing Task 3179: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 0, 1e-06, False, None, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
W0523 09:51:09.755375 82714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:51:09.756402 82714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 0, 1e-06, False, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 2281701376.0 but got 0.0.
Absolute difference: 2281701376.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([2.2817e+09])
[Worker 3] Completed Task 3179

[Worker 3] Processing Task 3185: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 2, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 2, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 74252 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 3185

[Worker 3] Processing Task 3187: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), math.inf, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), math.inf, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 74252 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 3187

[Worker 3] Processing Task 3189: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), math.inf, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), math.inf, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 74252 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 3189

[Worker 3] Processing Task 3191: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 0, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 0, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 74252 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 3] Completed Task 3191

[Worker 3] Processing Task 3228: paddle.sum(Tensor([1431655765, 3],"bool"), axis=1, keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=1, keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 52.270508GB memory has been allocated and available memory is only 26.914368GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 3228

[Worker 3] Processing Task 3263: paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[0,], keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=list[0,], keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 57.602539GB memory has been allocated and available memory is only 21.582336GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 3263

[Worker 3] Processing Task 3272: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=-1, keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=-1, keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 48.008789GB memory has been allocated and available memory is only 31.176086GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 3272

[Worker 3] Processing Task 3277: paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[-1,], keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 3, 143165577, 5],"bool"), axis=list[-1,], keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 48.008789GB memory has been allocated and available memory is only 31.176086GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 3277

[Worker 3] Processing Task 3286: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[0,2,], keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[0,2,], keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.612305GB memory has been allocated and available memory is only 1.572571GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 3286

[Worker 3] Processing Task 3309: paddle.sum(Tensor([3, 4, 357913942],"int32"), axis=0, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([3, 4, 357913942],"int32"), axis=0, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<int, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 76.276367GB memory has been allocated and available memory is only 2.908508GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 3309

[Worker 3] Processing Task 3329: paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=list[-1,], keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=list[-1,], keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 48.008789GB memory has been allocated and available memory is only 31.176086GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 3] Completed Task 3329

[Worker 3] Processing Task 3347: paddle.Tensor.chunk(Tensor([1, 1, 10164, 224489],"float32"), 2, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 1, 10164, 224489],"float32"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 1, 10164, 224489], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 3347

[Worker 3] Processing Task 3351: paddle.Tensor.chunk(Tensor([1, 10, 1, 228170138],"float32"), 4, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 10, 1, 228170138],"float32"), 4, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [1, 10, 1, 228170138], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 3351

[Worker 3] Processing Task 3355: paddle.Tensor.chunk(Tensor([1, 103, 1, 22152441],"float32"), 4, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 103, 1, 22152441],"float32"), 4, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [1, 103, 1, 22152441], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 3355

[Worker 3] Processing Task 3359: paddle.Tensor.chunk(Tensor([475355, 300, 16],"float32"), 2, )
[paddle error] paddle.Tensor.chunk(Tensor([475355, 300, 16],"float32"), 2, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [475355, 300, 16], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 3] Completed Task 3359

[Worker 3] Processing Task 3364: paddle.Tensor.expand_as(Tensor([2281701379, 1],"int32"), Tensor([2281701379, 1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([2281701379, 1],"int32"), Tensor([2281701379, 1],"int64"), ) 
 (InvalidArgument) When the value in shape is negative for expand_as_v2 op, only -1 is supported, but the value received is -2013265917.
  [Hint: Expected target_shape[i] == -1, but received target_shape[i]:-2013265917 != -1:-1.] (at /paddle/paddle/phi/kernels/gpu/expand_as_kernel.cu:70)

[Worker 3] Completed Task 3364

[Worker 3] Processing Task 3441: paddle.Tensor.lu(Tensor([760567127, 3],"float32"), )
=========================================================================================
   WARNING batched routines are designed for small sizes. It might be better to use the
   Native/Hybrid classical routines if you want good performance.
=========================================================================================
CUDA runtime error: an illegal memory access was encountered (700) in magma_sgetrf_batched at /builder/magma/magma-cuda118/magma-2.6.1/src/sgetrf_batched.cpp:217
CUDA runtime error: an illegal memory access was encountered (700) in magma_sgetrf_batched at /builder/magma/magma-cuda118/magma-2.6.1/src/sgetrf_batched.cpp:218
CUDA runtime error: an illegal memory access was encountered (700) in magma_sgetrf_batched at /builder/magma/magma-cuda118/magma-2.6.1/src/sgetrf_batched.cpp:219
/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
[torch error] paddle.Tensor.lu(Tensor([760567127, 3],"float32"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py", line 898, in lu
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py", line 902, in lu
    LU, pivots, infos = torch._lu_with_info(
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Error on Task 3441: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] OOM on Task 3441: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 3] Started on GPU 3

[Worker 0] Processing Task 149: paddle.atan2(Tensor([100],"float16"), Tensor([42949673, 100],"float16"), )
[accuracy error] backward  paddle.atan2(Tensor([100],"float16"), Tensor([42949673, 100],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 100 (4.0%)
Greatest absolute difference: 0.84375 at index (3,) (up to 0.01 allowed)
Greatest relative difference: 0.84521484375 at index (99,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([100]), dtype=torch.float16)
All elements: tensor([-2.9906e+01, -2.3888e+02, -9.4850e+02,  4.1156e+01, -1.1890e+03,
        -2.6160e+03, -8.5500e+02,  1.4640e+03, -2.6350e+02,  1.3450e+03,
         1.2120e+03, -5.1550e+02, -3.1200e+02, -4.8825e+02, -6.0050e+02,
        -6.7640e+03,  4.6350e+02, -5.9406e+01,  8.7700e+02, -1.1790e+03,
         6.4750e+02,  3.9136e-01, -1.3050e+03,  1.1000e+03, -9.1750e+02,
        -1.4730e+03,  7.8250e+02, -7.0200e+02, -2.0520e+03, -1.1456e+02,
        -2.1620e+03, -1.2938e+02, -4.7550e+02,  2.5300e+03, -3.8800e+03,
         8.0300e+02,  1.9520e+03,  1.6170e+03, -4.3080e+03,  5.2450e+02,
        -6.1900e+02, -1.7450e+03,  9.5700e+02,  4.0844e+01, -2.4838e+02,
        -7.4280e+03,  2.8120e+03,  1.4720e+03, -5.4500e+01,  4.9525e+02,
         2.4560e+03, -1.7520e+03, -5.0600e+02,  5.3320e+03,  1.0980e+03,
        -6.0750e+02,  5.5550e+02,  1.3830e+03, -6.8080e+03, -2.6225e+02,
        -1.6950e+03, -1.8175e+02,  5.1450e+02, -9.4400e+03,  2.4896e+04,
        -1.3688e+02,  2.2180e+03, -4.0560e+03, -3.0050e+02, -2.4362e+02,
        -9.6650e+02,  1.6410e+03,  4.0340e+03,  9.7200e+03,  1.7240e+03,
        -1.4950e+03, -1.3960e+03, -8.2880e+03,  1.9470e+03,  3.5760e+03,
        -2.0230e+03, -9.8800e+02, -1.2444e+02, -6.5200e+02, -7.6400e+02,
        -2.0688e+02,  1.1360e+03, -1.3670e+03, -9.9500e+02,  5.7900e+02,
         7.4000e+03, -2.7340e+03,  1.6140e+03,  1.7500e+02,  2.4240e+03,
         2.0638e+02,  7.3560e+03, -4.3750e+02,  1.6960e+03, -1.4978e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([100]), dtype=torch.float16)
All elements: tensor([-2.9359e+01, -2.3850e+02, -9.4700e+02,  4.2000e+01, -1.1920e+03,
        -2.6180e+03, -8.5250e+02,  1.4640e+03, -2.6350e+02,  1.3450e+03,
         1.2090e+03, -5.1550e+02, -3.1325e+02, -4.8825e+02, -6.0100e+02,
        -6.7680e+03,  4.6350e+02, -5.9906e+01,  8.7650e+02, -1.1790e+03,
         6.4650e+02,  2.6514e-01, -1.3060e+03,  1.1010e+03, -9.1650e+02,
        -1.4760e+03,  7.8200e+02, -7.0050e+02, -2.0520e+03, -1.1450e+02,
        -2.1640e+03, -1.2912e+02, -4.7500e+02,  2.5280e+03, -3.8800e+03,
         8.0250e+02,  1.9520e+03,  1.6150e+03, -4.3080e+03,  5.2500e+02,
        -6.1900e+02, -1.7460e+03,  9.6100e+02,  4.1094e+01, -2.4788e+02,
        -7.4280e+03,  2.8120e+03,  1.4710e+03, -5.4875e+01,  4.9550e+02,
         2.4560e+03, -1.7520e+03, -5.0600e+02,  5.3280e+03,  1.1000e+03,
        -6.0750e+02,  5.5500e+02,  1.3850e+03, -6.8120e+03, -2.6100e+02,
        -1.6950e+03, -1.8225e+02,  5.1350e+02, -9.4400e+03,  2.4896e+04,
        -1.3688e+02,  2.2200e+03, -4.0560e+03, -3.0050e+02, -2.4412e+02,
        -9.6550e+02,  1.6410e+03,  4.0340e+03,  9.7200e+03,  1.7230e+03,
        -1.4950e+03, -1.3980e+03, -8.2880e+03,  1.9470e+03,  3.5740e+03,
        -2.0230e+03, -9.8800e+02, -1.2425e+02, -6.5250e+02, -7.6500e+02,
        -2.0700e+02,  1.1360e+03, -1.3670e+03, -9.9400e+02,  5.7900e+02,
         7.4080e+03, -2.7340e+03,  1.6140e+03,  1.7488e+02,  2.4260e+03,
         2.0700e+02,  7.3560e+03, -4.3750e+02,  1.6960e+03, -8.1177e-02],
       dtype=torch.float16)
[Worker 0] Completed Task 149

[Worker 0] Processing Task 187: paddle.conj(Tensor([2, 20, 2, 53687092],"float32"), )
W0522 15:55:04.998239 42878 backward.cc:441] While running Node (ConjGradNode) raises a std::exception: paddle::memory::allocation::BadAlloc
[paddle error] paddle.conj(Tensor([2, 20, 2, 53687092],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   ConjGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::conj(paddle::Tensor const&)
4   void phi::ConjKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.610352GB memory has been allocated and available memory is only 13.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 187

[Worker 0] Processing Task 196: paddle.diff(Tensor([2, 1140850690],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 1140850690],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 1140850690],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 1140850690],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235845014 / 2281701380 (98.0%)
Greatest absolute difference: 0.9999924898147583 at index (0, 999222546) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([ 0.5429,  0.5159, -0.1039, -0.0425,  0.6141,  0.1832, -0.0554, -0.6994,
        -0.5628, -0.2576, -0.3291,  0.0043, -0.6556,  0.6846, -0.6279,  0.8483,
        -0.0046, -0.0789, -0.0069,  0.0542, -0.0101,  0.0957, -0.0725,  0.2340,
         0.0213,  0.3497, -0.1983,  0.1631,  0.2567, -0.2438,  0.5919,  0.4954,
        -0.3321, -0.0789, -0.2694, -0.4842,  0.3753, -0.5445,  0.5687,  0.0757,
         0.2352,  0.2587,  0.2682, -0.5277,  0.5749, -0.3666,  0.7202,  0.5428,
        -0.1753,  0.5693, -0.5507,  0.3928, -0.1266, -0.7358,  0.2956, -0.6192,
        -0.5869, -0.2389,  0.3104, -0.0583,  0.1911,  0.2630,  0.3573, -0.5906,
         0.3607,  0.1182, -0.4327,  0.0148,  0.4362,  0.2636, -0.0143,  0.2917,
        -0.0766,  0.0202,  0.3710, -0.7475,  0.0144, -0.0313,  0.0405, -0.1748,
         0.1461,  0.1502, -0.0247, -0.0386,  0.4978,  0.3400,  0.0450, -0.3519,
         0.4186,  0.2481, -0.1210, -0.6403,  0.3805, -0.3349, -0.0474, -0.5329,
        -0.8436, -0.1485,  0.3872,  0.3235])
[Worker 0] Completed Task 196

[Worker 0] Processing Task 199: paddle.diff(Tensor([2, 1140850690],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 1140850690],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 1140850690],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 1140850690],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258716382 / 2281701380 (99.0%)
Greatest absolute difference: 1.9999849796295166 at index (0, 999222546) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([-1.0858, -1.0317,  0.2077,  0.0849, -1.2281, -0.3664,  0.1108,  1.3989,
         1.1256,  0.5152,  0.6583, -0.0086,  1.3111, -1.3692,  1.2559, -1.6966,
         0.0093,  0.1579,  0.0138, -0.1084,  0.0201, -0.1914,  0.1449, -0.4680,
        -0.0426, -0.6994,  0.3965, -0.3262, -0.5134,  0.4876, -1.1839, -0.9908,
         0.6643,  0.1578,  0.5387,  0.9684, -0.7505,  1.0889, -1.1373, -0.1515,
        -0.4703, -0.5174, -0.5364,  1.0553, -1.1498,  0.7332, -1.4404, -1.0855,
         0.3505, -1.1386,  1.1014, -0.7857,  0.2533,  1.4716, -0.5912,  1.2384,
         1.1738,  0.4778, -0.6208,  0.1165, -0.3821, -0.5261, -0.7146,  1.1811,
        -0.7213, -0.2364,  0.8655, -0.0295, -0.8724, -0.5273,  0.0286, -0.5834,
         0.1532, -0.0403, -0.7419,  1.4951, -0.0288,  0.0626, -0.0809,  0.3496,
        -0.2921, -0.3005,  0.0494,  0.0771, -0.9955, -0.6800, -0.0900,  0.7039,
        -0.8373, -0.4962,  0.2420,  1.2806, -0.7611,  0.6698,  0.0947,  1.0657,
         1.6871,  0.2970, -0.7743, -0.6471])
[Worker 0] Completed Task 199

[Worker 0] Processing Task 203: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235838282 / 2281701384 (98.0%)
Greatest absolute difference: 0.999972939491272 at index (194408396, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425346, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425346, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.0758,  0.2996, -0.0252,  0.0205,  0.2947, -0.1357,  0.2485, -0.3488,
         0.0477, -0.2124,  0.1210, -0.4236, -0.2281,  0.5748, -0.4990,  0.5820,
        -0.3562, -0.1548,  0.3835, -0.3032,  0.8425,  0.0231,  0.0070,  0.5282,
        -0.8124,  0.0984, -0.2834, -0.5389,  0.6291, -0.4031,  0.0856,  0.2832,
        -0.4557,  0.5971, -0.2012,  0.1856,  0.2114, -0.5616,  0.2360, -0.2177,
        -0.2230,  0.0557, -0.1328, -0.5277,  0.1289, -0.2207,  0.2893,  0.4585,
        -0.0232,  0.5690, -0.4742,  0.3238,  0.3016, -0.4025,  0.0236, -0.1308,
        -0.4062, -0.3094,  0.0758,  0.1458,  0.0595,  0.1478,  0.7603, -0.7501,
         0.2256,  0.1927, -0.7294,  0.0854,  0.1213,  0.2545,  0.0514,  0.7927,
        -0.1027,  0.1962, -0.1867, -0.4054, -0.4791, -0.2663,  0.6208,  0.0892,
         0.3369, -0.2465, -0.3012,  0.0861,  0.0966, -0.2654,  0.4202,  0.0855,
        -0.0969,  0.6665,  0.0548, -0.1219,  0.5260, -0.2032, -0.5125, -0.5146,
        -0.0794, -0.0316, -0.1069,  0.1881])
[Worker 0] Completed Task 203

[Worker 0] Processing Task 207: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258655688 / 2281701380 (99.0%)
Greatest absolute difference: 1.9985848665237427 at index (379088153, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([ 2.1883e-01, -4.3530e-01,  2.7377e-01, -3.6931e-01, -2.4693e-01,
        -7.6653e-02, -1.2754e-01, -7.4740e-02, -2.7587e-01,  7.8713e-01,
        -6.1998e-01,  1.0055e+00, -1.2810e-01, -7.2959e-01,  8.8246e-01,
        -8.8515e-01,  1.1987e+00,  1.7797e-01, -3.7651e-01,  8.3142e-01,
        -1.6549e+00,  7.5288e-02, -2.9036e-01, -1.0671e+00,  1.4415e+00,
        -5.0154e-01,  3.6899e-01,  8.2209e-01, -1.0848e+00,  1.0003e+00,
        -2.8679e-01, -9.7634e-02,  6.6709e-01, -1.1587e+00,  4.3717e-01,
        -4.0329e-01, -4.3434e-01,  6.1728e-01, -3.6873e-01, -3.1000e-01,
         3.5185e-01, -2.7638e-01,  4.2211e-01,  9.8617e-01, -1.5213e-01,
         7.8965e-01, -7.6355e-01, -1.3467e-01,  3.2485e-01, -9.7148e-01,
         4.9777e-01, -4.5454e-01, -7.0783e-01,  9.3118e-02,  5.2224e-02,
         2.7654e-01,  4.6572e-01,  4.5716e-01,  6.8453e-01, -8.9589e-01,
         1.6611e-01,  4.4860e-02, -1.4897e+00,  8.3551e-01, -1.0433e-01,
         6.1811e-02,  7.8079e-01,  7.0732e-01, -2.2398e-01, -5.8227e-02,
        -2.3811e-01, -1.1981e+00, -3.7638e-01, -4.6257e-01,  8.0756e-01,
         4.9460e-01,  8.1596e-01,  1.9821e-02, -9.2203e-01, -3.1267e-03,
        -2.4024e-01, -1.8848e-02,  7.2138e-01, -5.7418e-04, -1.9355e-01,
         9.3187e-01, -3.6537e-01, -2.0743e-01,  6.2295e-01, -8.6969e-01,
        -5.6736e-01, -3.9263e-01, -6.0546e-01,  1.7162e-01,  4.0567e-01,
         7.0264e-01, -2.0302e-01,  4.8017e-01,  2.2669e-01, -3.9732e-01])
[Worker 0] Completed Task 207

[Worker 0] Processing Task 211: paddle.diff(Tensor([2281701379],"float32"), n=2, axis=0, prepend=None, append=None, )
[accuracy error] paddle.diff(Tensor([2281701379],"float32"), n=2, axis=0, prepend=None, append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258649731 / 2281701377 (99.0%)
Greatest absolute difference: 1.9983524084091187 at index (1037730876,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701377]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701377]), dtype=torch.float32)
First 100 elements: tensor([ 0.0959,  0.3585, -0.9086,  0.6779, -0.4527,  0.7290, -0.6801, -0.0267,
         0.3619, -0.2526,  0.3139, -0.6833,  0.9554, -1.1305,  1.0539, -0.0759,
        -0.9213,  1.0242, -0.9652,  1.0637, -0.5844, -0.2007,  0.8670, -0.9013,
         0.2188,  0.3368, -0.9949,  1.3502, -1.0739,  0.4631,  0.4286, -0.8500,
         0.4470,  0.1720, -0.5080,  0.9418, -1.4042,  1.3572, -0.8689,  0.1430,
         0.1663,  0.1060, -0.4205,  0.4269, -0.3009, -0.1005,  0.6311, -0.5792,
         0.5587, -0.4414, -0.0197,  0.4947, -1.0767,  1.3998, -0.8399, -0.1873,
         0.0534,  0.8194, -0.9610,  0.1850,  0.3417,  0.5042, -1.1173,  0.3596,
         0.8660, -1.6188,  1.3689, -0.6491, -0.0231,  0.1181,  0.5900, -0.5518,
        -0.3594,  1.0625, -1.0468,  0.6426, -1.0413,  1.2268, -0.9018,  0.9290,
        -0.3668, -0.1920, -0.1225,  0.0980,  0.1619,  0.2499, -0.4992, -0.2746,
         1.2094, -0.7704, -0.3469,  0.6712, -0.1657, -0.3354,  0.4778, -0.7059,
         0.2542, -0.0281,  0.9149, -1.0932])
[Worker 0] Completed Task 211

[Worker 0] Processing Task 216: paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([3, 4],"float32"), append=None, )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([3, 4],"float32"), append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235838286 / 2281701388 (98.0%)
Greatest absolute difference: 0.999972939491272 at index (194408399, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.0758,  0.2996, -0.0252,  0.0205,  0.2947, -0.1357,  0.2485, -0.3488,
        -0.3705, -0.1639, -0.2233,  0.3284,  0.0758,  0.2996, -0.0252,  0.0205,
         0.2947, -0.1357,  0.2485, -0.3488,  0.0477, -0.2124,  0.1210, -0.4236,
        -0.2281,  0.5748, -0.4990,  0.5820, -0.3562, -0.1548,  0.3835, -0.3032,
         0.8425,  0.0231,  0.0070,  0.5282, -0.8124,  0.0984, -0.2834, -0.5389,
         0.6291, -0.4031,  0.0856,  0.2832, -0.4557,  0.5971, -0.2012,  0.1856,
         0.2114, -0.5616,  0.2360, -0.2177, -0.2230,  0.0557, -0.1328, -0.5277,
         0.1289, -0.2207,  0.2893,  0.4585, -0.0232,  0.5690, -0.4742,  0.3238,
         0.3016, -0.4025,  0.0236, -0.1308, -0.4062, -0.3094,  0.0758,  0.1458,
         0.0595,  0.1478,  0.7603, -0.7501,  0.2256,  0.1927, -0.7294,  0.0854,
         0.1213,  0.2545,  0.0514,  0.7927, -0.1027,  0.1962, -0.1867, -0.4054,
        -0.4791, -0.2663,  0.6208,  0.0892,  0.3369, -0.2465, -0.3012,  0.0861,
         0.0966, -0.2654,  0.4202,  0.0855])
[Worker 0] Completed Task 216

[Worker 0] Processing Task 218: paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=Tensor([570425345, 4],"float32"), )
[torch error] paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=Tensor([570425345, 4],"float32"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 25.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 43895 has 69.61 GiB memory in use. Of the allocated memory 51.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 218

[Worker 0] Processing Task 220: paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), )
[torch error] paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 43895 has 69.61 GiB memory in use. Of the allocated memory 51.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 220

[Worker 0] Processing Task 221: paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=None, )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258655688 / 2281701380 (99.0%)
Greatest absolute difference: 1.9985848665237427 at index (379088155, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([-1.5169e-01, -5.9918e-01,  5.0470e-02, -4.0937e-02,  1.5169e-01,
         5.9918e-01, -5.0470e-02,  4.0937e-02,  2.1883e-01, -4.3530e-01,
         2.7377e-01, -3.6931e-01, -2.4693e-01, -7.6653e-02, -1.2754e-01,
        -7.4740e-02, -2.7587e-01,  7.8713e-01, -6.1998e-01,  1.0055e+00,
        -1.2810e-01, -7.2959e-01,  8.8246e-01, -8.8515e-01,  1.1987e+00,
         1.7797e-01, -3.7651e-01,  8.3142e-01, -1.6549e+00,  7.5288e-02,
        -2.9036e-01, -1.0671e+00,  1.4415e+00, -5.0154e-01,  3.6899e-01,
         8.2209e-01, -1.0848e+00,  1.0003e+00, -2.8679e-01, -9.7634e-02,
         6.6709e-01, -1.1587e+00,  4.3717e-01, -4.0329e-01, -4.3434e-01,
         6.1728e-01, -3.6873e-01, -3.1000e-01,  3.5185e-01, -2.7638e-01,
         4.2211e-01,  9.8617e-01, -1.5213e-01,  7.8965e-01, -7.6355e-01,
        -1.3467e-01,  3.2485e-01, -9.7148e-01,  4.9777e-01, -4.5454e-01,
        -7.0783e-01,  9.3118e-02,  5.2224e-02,  2.7654e-01,  4.6572e-01,
         4.5716e-01,  6.8453e-01, -8.9589e-01,  1.6611e-01,  4.4860e-02,
        -1.4897e+00,  8.3551e-01, -1.0433e-01,  6.1811e-02,  7.8079e-01,
         7.0732e-01, -2.2398e-01, -5.8227e-02, -2.3811e-01, -1.1981e+00,
        -3.7638e-01, -4.6257e-01,  8.0756e-01,  4.9460e-01,  8.1596e-01,
         1.9821e-02, -9.2203e-01, -3.1267e-03, -2.4024e-01, -1.8848e-02,
         7.2138e-01, -5.7418e-04, -1.9355e-01,  9.3187e-01, -3.6537e-01,
        -2.0743e-01,  6.2295e-01, -8.6969e-01, -5.6736e-01, -3.9263e-01])
[Worker 0] Completed Task 221

[Worker 0] Processing Task 225: paddle.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([1073741825, 4],"float16"), )
[accuracy error] paddle.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([1073741825, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208571744 / 4294967352 (98.0%)
Greatest absolute difference: 1.0 at index (2127357, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.4299, -0.5479,  0.2744, -0.1128,  0.7534, -0.0034, -0.7642,  0.2454,
        -0.7100, -0.0391,  0.5693,  0.2935,  0.3867,  0.5908, -0.0796, -0.4260,
        -0.4299, -0.5479,  0.2744, -0.1128,  0.7534, -0.0034, -0.7642,  0.2454,
        -0.7100, -0.0391,  0.5693,  0.2935,  0.1936,  0.2094, -0.3013,  0.1499,
         0.3381,  0.3535, -0.0560, -0.6968, -0.6211, -0.2361,  0.4224,  0.1833,
         0.3826,  0.3145,  0.0872,  0.0122, -0.4004, -0.0801,  0.1035,  0.4600,
         0.2461, -0.3276, -0.2385,  0.1752,  0.2476,  0.3569, -0.0968, -0.7095,
        -0.4299, -0.5479,  0.2744, -0.1128,  0.7534, -0.0034, -0.7642,  0.2454,
        -0.7100, -0.0391,  0.5693,  0.2935,  0.1936,  0.2094, -0.3013,  0.1499,
         0.3381,  0.3535, -0.0560, -0.6968, -0.6211, -0.2361,  0.4224,  0.1833,
         0.3826,  0.3145,  0.0872,  0.0122, -0.4004, -0.0801,  0.1035,  0.4600,
         0.2461, -0.3276, -0.2385,  0.1752, -0.0663, -0.0952,  0.2957, -0.7920,
         0.2634,  0.0190, -0.5859,  0.3657], dtype=torch.float16)
[Worker 0] Completed Task 225

[Worker 0] Processing Task 229: paddle.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), append=Tensor([4],"float16"), )
[accuracy error] paddle.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), append=Tensor([4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208569534 / 4294967310 (98.0%)
Greatest absolute difference: 1.0 at index (169689,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([ 0.2144, -0.1949, -0.4546,  0.0054,  0.0962,  0.6279, -0.8418,  0.8716,
        -0.6606, -0.1331,  0.1675, -0.0840,  0.0105,  0.4751, -0.1083, -0.1837,
         0.0262, -0.0354,  0.3428,  0.0045,  0.0417, -0.4451, -0.2981,  0.0806,
         0.4265,  0.2134, -0.5371,  0.2798,  0.3584, -0.0139, -0.6123, -0.1328,
         0.6787,  0.1697, -0.2559, -0.3467,  0.1049,  0.2588,  0.1580, -0.5879,
         0.0760,  0.6494, -0.9297,  0.4678, -0.1683,  0.0445,  0.0220, -0.3081,
         0.8311, -0.4688, -0.2291,  0.0240,  0.4556, -0.1017, -0.2910, -0.0122,
         0.2927,  0.2048, -0.8022,  0.3555,  0.4482, -0.2444,  0.3040, -0.3936,
         0.1943, -0.1664,  0.1741,  0.0753, -0.2607,  0.4846, -0.2712, -0.3665,
        -0.2800, -0.0652,  0.4053, -0.1846,  0.0538,  0.4399, -0.1543, -0.2764,
         0.4858,  0.1179, -0.8179,  0.0071,  0.2803, -0.0420,  0.6436, -0.5430,
        -0.2764,  0.5933, -0.4380, -0.2472,  0.2820,  0.6123, -0.5703, -0.2949,
         0.7988, -0.6758,  0.5029,  0.2294], dtype=torch.float16)
[Worker 0] Completed Task 229

[Worker 0] Processing Task 233: paddle.diff(x=Tensor([2281701379],"int64"), )
[accuracy error] paddle.diff(x=Tensor([2281701379],"int64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281683797 / 2281701378 (100.0%)
Greatest absolute difference: 131062 at index (484721382,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.int64)
First 100 elements: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0])
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.int64)
First 100 elements: tensor([ -14205,   19398,   50313,  -77667,   43893,  -41776,   -8643,    7829,
          79271,  -29236,  -41158,   45892,  -32129,  -46453,  -16319,   10091,
         113498,  -57031,    8500,  -27503,  -26871,   36348,  -30714,   12221,
         -31915,   95941, -101435,   94859,     180,   22010,  -92425,   61979,
         -91152,  123991,  -40102,  -48482,   76288,  -89528,    5105,   32998,
          -7162,   13996,   -3524,    1435,   59706, -125089,   75282,  -15139,
         -41318,   32244,   48414,  -11243,    7426,  -10577,  -40929,   53477,
         -40395,   64381,  -13846,  -10598,  -96177,   13822,   75366,  -14946,
          -8588,   -1684,   47098,    8318, -103178,   44546,    4525,  -55814,
          80408,   -2998,  -82117,    7091,   46470,  -19810,   26593,    3934,
          22543,    7197,  -46123,   58331,  -64749,   73816,  -27231,  -81629,
          44863,   56041,  -16794,   28513,  -56978,   56657,  -18676,    -210,
         -83055,   29213,   23669,  -29282])
[Worker 0] Completed Task 233

[Worker 0] Processing Task 237: paddle.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4294967297],"float16"), )
[torch error] paddle.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4294967297],"float16"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 11.57 GiB is free. Process 43895 has 67.61 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 237

[Worker 0] Processing Task 238: paddle.digamma(Tensor([10, 10, 10, 4294968],"float16"), )
[accuracy error] paddle.digamma(Tensor([10, 10, 10, 4294968],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294968000 (0.0%)
Greatest absolute difference: nan at index (0, 0, 3, 725396) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 3, 725396) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10, 10, 4294968]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([10, 10, 10, 4294968]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 238

[Worker 0] Processing Task 242: paddle.digamma(Tensor([10, 42949673, 10],"float16"), )
[accuracy error] paddle.digamma(Tensor([10, 42949673, 10],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294967300 (0.0%)
Greatest absolute difference: nan at index (0, 1361030, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 1361030, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 42949673, 10]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([10, 42949673, 10]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 242

[Worker 0] Processing Task 246: paddle.digamma(Tensor([21474837, 10, 10, 2],"float16"), )
[accuracy error] paddle.digamma(Tensor([21474837, 10, 10, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294967400 (0.0%)
Greatest absolute difference: nan at index (68051, 5, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (68051, 5, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([21474837, 10, 10, 2]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([21474837, 10, 10, 2]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 246

[Worker 0] Processing Task 250: paddle.digamma(Tensor([8, 3, 32, 5592406],"float16"), )
[accuracy error] paddle.digamma(Tensor([8, 3, 32, 5592406],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294967808 (0.0%)
Greatest absolute difference: nan at index (0, 0, 2, 2425488) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 2, 2425488) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8, 3, 32, 5592406]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([8, 3, 32, 5592406]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 250

[Worker 0] Processing Task 254: paddle.digamma(x=Tensor([1431655766, 3],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([1431655766, 3],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294967298 (0.0%)
Greatest absolute difference: nan at index (4536766, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (4536766, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 254

[Worker 0] Processing Task 258: paddle.digamma(x=Tensor([3, 6, 6, 6628036, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([3, 6, 6, 6628036, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 0, 0, 2268383, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 2268383, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 6, 6, 6628036, 6]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 6, 6, 6628036, 6]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 258

[Worker 0] Processing Task 262: paddle.digamma(x=Tensor([6, 119304648, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([6, 119304648, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 2268383, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 2268383, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([6, 119304648, 6]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([6, 119304648, 6]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 262

[Worker 0] Processing Task 266: paddle.digamma(x=Tensor([6, 6, 6, 19884108],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([6, 6, 6, 19884108],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 289 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 0, 0, 13610300) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 13610300) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([6, 6, 6, 19884108]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([6, 6, 6, 19884108]), dtype=torch.float16)
First 100 elements: tensor([-1.4445e+01, -3.6836e+00, -1.1430e+01,  1.3340e+00,  1.3926e+00,
         2.6973e+00, -2.8340e+00,  2.4609e-01, -2.5977e+00,  2.6387e+00,
         9.7266e-01,  3.2871e+00,  1.9092e+00,  2.0488e+00, -6.1914e+00,
        -1.6562e+01,  7.4336e+00,  9.7422e+00,  6.8320e+00, -4.9883e+00,
        -4.8867e+00, -4.0898e+00,  4.4180e+00,  1.7175e-01,  9.1699e-01,
        -4.5438e+01, -4.4883e+00,  2.0918e+00,  4.5281e+01, -3.0996e+00,
        -3.2422e+00,  2.2656e+00,  7.4561e-01, -4.1172e+00, -2.3809e+00,
        -6.1914e+00,  4.7695e+00,  1.3359e+01, -5.6328e+00, -3.0117e+00,
         3.0605e+00,  5.1250e+00, -2.0469e+00,  5.1807e-01, -4.7906e+01,
         5.9414e+00,  8.9766e+00,  1.1672e+01,  1.0703e+00, -2.2812e+00,
         3.7062e+01,  2.8125e+00,  3.2793e+00, -4.7266e+00, -8.5781e+00,
         5.0312e+00,  4.6055e+00, -9.3438e+00, -3.3086e+00,  1.6516e-01,
         6.8633e+00, -3.2949e+00, -1.4070e+01, -2.7344e+00,  6.1219e+01,
        -5.9297e+00, -8.4625e+01, -5.6875e+00, -4.0430e+00, -2.6300e+03,
        -2.0391e+00, -4.9492e+00,  5.6914e+00,  6.4648e-01,  5.6122e-02,
         1.0070e+01,  2.4512e+00,  3.4590e+00, -4.8867e+00, -1.6547e+01,
         3.6699e+00, -3.8848e+00, -2.6406e+00,  6.8555e-01,  7.5244e-01,
         6.2500e+00,  4.5352e+00, -2.1719e+00,  1.1461e+01,  1.3926e+00,
        -4.5000e+00,  3.9551e+00,  4.8438e-01,  5.0508e+00, -2.2695e+00,
         7.1250e+00,  7.5684e-01, -2.7305e+00,  2.1465e+00, -5.1562e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 266

[Worker 0] Processing Task 274: paddle.dist(x=Tensor([10],"float16"), y=Tensor([429496730, 10],"float16"), )
[accuracy error] paddle.dist(x=Tensor([10],"float16"), y=Tensor([429496730, 10],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 28160.0 but got 0.0.
Absolute difference: 28160.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([28160.], dtype=torch.float16)
[Worker 0] Completed Task 274

[Worker 0] Processing Task 282: paddle.fft.ifftshift(x=Tensor([4294967297],"float16"), )
[accuracy error] paddle.fft.ifftshift(x=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 4294967297 (0.0%)
Greatest absolute difference: 0.259033203125 at index (4294967296,) (up to 0.01 allowed)
Greatest relative difference: inf at index (4294967296,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([ 0.1627,  0.4402, -0.2571, -0.2047,  0.4712,  0.2450,  0.0077, -0.4956,
        -0.0646,  0.3450, -0.3726, -0.4224,  0.3525, -0.2661,  0.1731, -0.1514,
         0.4050,  0.3931, -0.2517,  0.2930, -0.4727,  0.0116, -0.3550, -0.1715,
         0.4670,  0.4397,  0.3076,  0.2467, -0.4666, -0.1450,  0.4062,  0.2163,
        -0.1059,  0.1055, -0.3403, -0.4934,  0.1848,  0.0266, -0.1672, -0.0928,
        -0.3704,  0.1935, -0.1299, -0.4241,  0.2893, -0.4390, -0.2451,  0.4790,
        -0.0312,  0.0076,  0.2551,  0.1416,  0.1406,  0.2749, -0.3625,  0.1788,
        -0.0394,  0.4414,  0.1744,  0.3384, -0.3660,  0.2194,  0.0953, -0.4131,
         0.2688,  0.0394,  0.1639,  0.3809,  0.4238,  0.1439,  0.2378,  0.2019,
         0.2028, -0.1015,  0.2001, -0.0659,  0.1129, -0.0603,  0.4958,  0.0963,
         0.3496,  0.0409, -0.0100, -0.4675,  0.3987, -0.4739, -0.3337,  0.1617,
        -0.3213,  0.1135, -0.4075, -0.1043,  0.0516, -0.1765, -0.1528, -0.4290,
        -0.1473, -0.0047, -0.4573,  0.2198], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([ 0.1627,  0.4402, -0.2571, -0.2047,  0.4712,  0.2450,  0.0077, -0.4956,
        -0.0646,  0.3450, -0.3726, -0.4224,  0.3525, -0.2661,  0.1731, -0.1514,
         0.4050,  0.3931, -0.2517,  0.2930, -0.4727,  0.0116, -0.3550, -0.1715,
         0.4670,  0.4397,  0.3076,  0.2467, -0.4666, -0.1450,  0.4062,  0.2163,
        -0.1059,  0.1055, -0.3403, -0.4934,  0.1848,  0.0266, -0.1672, -0.0928,
        -0.3704,  0.1935, -0.1299, -0.4241,  0.2893, -0.4390, -0.2451,  0.4790,
        -0.0312,  0.0076,  0.2551,  0.1416,  0.1406,  0.2749, -0.3625,  0.1788,
        -0.0394,  0.4414,  0.1744,  0.3384, -0.3660,  0.2194,  0.0953, -0.4131,
         0.2688,  0.0394,  0.1639,  0.3809,  0.4238,  0.1439,  0.2378,  0.2019,
         0.2028, -0.1015,  0.2001, -0.0659,  0.1129, -0.0603,  0.4958,  0.0963,
         0.3496,  0.0409, -0.0100, -0.4675,  0.3987, -0.4739, -0.3337,  0.1617,
        -0.3213,  0.1135, -0.4075, -0.1043,  0.0516, -0.1765, -0.1528, -0.4290,
        -0.1473, -0.0047, -0.4573,  0.2198], dtype=torch.float16)
[Worker 0] Completed Task 282

[Worker 0] Processing Task 494: paddle.inner(Tensor([42949673, 10, 10],"float16"), Tensor([2, 10],"float16"), )
[accuracy error] backward  paddle.inner(Tensor([42949673, 10, 10],"float16"), Tensor([2, 10],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 5 / 20 (25.0%)
Greatest absolute difference: 6.4375 at index (1, 0) (up to 0.01 allowed)
Greatest relative difference: 0.091796875 at index (1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 10]), dtype=torch.float16)
All elements: tensor([-1360.0000,   231.5000, -1088.0000,  -885.0000,    73.8125,  -615.0000,
        -1126.0000,  -352.2500, -1231.0000,  1572.0000,    63.6875,  2164.0000,
        -2434.0000,   700.5000,  2498.0000,  -920.5000,  -444.2500,  1162.0000,
        -1291.0000,  -172.1250], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 10]), dtype=torch.float16)
All elements: tensor([-1364.0000,   225.5000, -1080.0000,  -883.0000,    71.4375,  -614.0000,
        -1124.0000,  -348.2500, -1230.0000,  1560.0000,    70.1250,  2166.0000,
        -2430.0000,   697.5000,  2490.0000,  -919.5000,  -444.5000,  1161.0000,
        -1299.0000,  -177.1250], dtype=torch.float16)
[Worker 0] Completed Task 494

[Worker 0] Processing Task 498: paddle.isclose(Tensor([429496730, 10],"float16"), Tensor([429496730, 10],"float16"), rtol=1e-05, atol=1e-08, )
[torch error] paddle.isclose(Tensor([429496730, 10],"float16"), Tensor([429496730, 10],"float16"), rtol=1e-05, atol=1e-08, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.96 GiB is free. Process 43895 has 73.22 GiB memory in use. Of the allocated memory 52.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 498

[Worker 0] Processing Task 499: paddle.isclose(x=Tensor([214748365, 4, 5],"float16"), y=Tensor([214748365, 4, 5],"float16"), )
[torch error] paddle.isclose(x=Tensor([214748365, 4, 5],"float16"), y=Tensor([214748365, 4, 5],"float16"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.96 GiB is free. Process 43895 has 73.22 GiB memory in use. Of the allocated memory 52.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 499

[Worker 0] Processing Task 500: paddle.isclose(x=Tensor([3, 286331154, 5],"float16"), y=Tensor([3, 286331154, 5],"float16"), )
[torch error] paddle.isclose(x=Tensor([3, 286331154, 5],"float16"), y=Tensor([3, 286331154, 5],"float16"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.96 GiB is free. Process 43895 has 73.22 GiB memory in use. Of the allocated memory 52.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 500

[Worker 0] Processing Task 502: paddle.isclose(x=Tensor([4294967297],"float16"), y=Tensor([4294967297],"float16"), )
[torch error] paddle.isclose(x=Tensor([4294967297],"float16"), y=Tensor([4294967297],"float16"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.96 GiB is free. Process 43895 has 73.22 GiB memory in use. Of the allocated memory 52.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 502

[Worker 0] Processing Task 512: paddle.isfinite(Tensor([8, 17, 5, 6, 1052689],"float16"), )
[accuracy error] paddle.isfinite(Tensor([8, 17, 5, 6, 1052689],"float16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        ...,



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]]]),
    expected=tensor([[[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        ...,



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]],



        [[[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         ...,


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]],


         [[[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]],

          [[True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True],
           [True, True, True,  ..., True, True, True]]]]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 0] Completed Task 512

[Worker 0] Processing Task 535: paddle.isreal(Tensor([1431655765, 3],"int16"), )
[accuracy error] paddle.isreal(Tensor([1431655765, 3],"int16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True],
        [True, True, True],
        [True, True, True],
        ...,
        [True, True, True],
        [True, True, True],
        [True, True, True]]),
    expected=tensor([[True, True, True],
        [True, True, True],
        [True, True, True],
        ...,
        [True, True, True],
        [True, True, True],
        [True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 0] Completed Task 535

[Worker 0] Processing Task 561: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 27163112, 28],"float32"), 0.36, )
[accuracy error] backward  paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 27163112, 28],"float32"), 0.36, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 20174.88671875 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([20174.8867])
[Worker 0] Completed Task 561

[Worker 0] Processing Task 563: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 8, 95070891],"float32"), 0.3, )
[accuracy error] backward  paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 8, 95070891],"float32"), 0.3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 22068.248046875 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([22068.2480])
[Worker 0] Completed Task 563

[Worker 0] Processing Task 567: paddle.lerp(Tensor([1, 3, 3],"float16"), Tensor([477218589, 3, 3],"float16"), Tensor([1, 3, 3],"float16"), )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43895 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 567: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43895 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 567: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43895 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 570: paddle.lerp(Tensor([1, 3],"float16"), Tensor([1431655766, 3],"float16"), Tensor([1, 3],"float16"), )
W0522 16:45:10.532641 43335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:45:10.536479 43335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.lerp(Tensor([1, 3],"float16"), Tensor([1431655766, 3],"float16"), Tensor([1, 3],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: 3358.0 at index (0, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 3]), dtype=torch.float16)
All elements: tensor([ 0.3613, -0.3115,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 3]), dtype=torch.float16)
All elements: tensor([  884.5000,  2196.0000, -3358.0000], dtype=torch.float16)
[Worker 0] Completed Task 570

[Worker 0] Processing Task 576: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 8, 47535446],"float32"), 0.3, )
[accuracy error] backward  paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 8, 47535446],"float32"), 0.3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 2 (100.0%)
Greatest absolute difference: 3103.0068359375 at index (0, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1, 1, 1]), dtype=torch.float32)
All elements: tensor([0., 0.])
DESIRED: (shape=torch.Size([2, 1, 1, 1]), dtype=torch.float32)
All elements: tensor([ 3103.0068, -2991.5215])
[Worker 0] Completed Task 576

[Worker 0] Processing Task 585: paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=0, axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=0, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 6039798.0 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.2647058963775635 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216.])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014.])
[Worker 0] Completed Task 585

[Worker 0] Processing Task 586: paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=1.5, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=1.5, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 706.462890625 at index (8, 6) (up to 0.01 allowed)
Greatest relative difference: 0.03234802186489105 at index (8, 6) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([21129.7285, 21134.2422, 21132.8477, 21137.2871, 21127.9102, 21132.0820,
        21133.6660, 21131.5430, 21130.3418, 21131.8438, 21131.5898, 21132.5254,
        21133.8438, 21132.4570, 21133.0645, 21132.5820, 21132.7051, 21136.2148,
        21130.8457, 21133.4922, 21130.4902, 21131.9590, 21133.4883, 21132.7383,
        21136.0410, 21127.9746, 21131.0078, 21128.7871, 21132.9941, 21132.5391,
        21128.2500, 21131.1992, 21130.0918, 21134.0625, 21135.0449, 21131.0332,
        21134.0898, 21130.5293, 21127.5977, 21128.0801, 21134.1680, 21128.1816,
        21129.2441, 21132.0215, 21133.8848, 21131.4961, 21130.3848, 21128.5625,
        21133.8184, 21127.7891, 21134.0879, 21132.1309, 21132.7949, 21134.8359,
        21133.8477, 21131.3398, 21129.1230, 21131.4668, 21135.7852, 21131.2383,
        21131.5879, 21130.2148, 21130.7266, 21129.1641, 21132.4062, 21131.1426,
        21134.5469, 21133.1172, 21132.7773, 21133.9336, 21134.7051, 21134.5918,
        21134.0254, 21132.1641, 21130.3457, 21136.0547, 21131.2559, 21133.3906,
        21134.9551, 21128.7051, 21136.1387, 21128.3496, 21133.9863, 21131.0820,
        21132.4746, 21133.0215, 21132.9824, 21128.6660, 21132.1582, 21131.4688,
        21132.6543, 21131.5918, 21129.4727, 21134.7715, 21130.6230, 21132.7578,
        21132.9941, 21130.3496, 21128.8555, 21132.5156])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([21834.0898, 21839.8223, 21837.4648, 21840.6094, 21832.2246, 21834.7988,
        21839.8965, 21836.3242, 21835.3965, 21836.2910, 21835.8574, 21836.1543,
        21838.0410, 21836.6543, 21836.2598, 21837.0879, 21836.7363, 21841.0000,
        21834.8438, 21835.9043, 21835.2305, 21836.4062, 21836.9805, 21836.4492,
        21839.3145, 21833.8496, 21835.1543, 21833.7578, 21838.8379, 21837.0508,
        21832.7969, 21835.3945, 21835.8184, 21838.6777, 21839.0605, 21836.3320,
        21838.2754, 21835.0703, 21831.7969, 21832.0703, 21839.2656, 21833.5625,
        21834.4941, 21837.0293, 21838.5488, 21836.0938, 21836.7598, 21832.1094,
        21837.6426, 21831.7129, 21838.9922, 21836.2676, 21836.9121, 21839.2656,
        21837.7930, 21836.2441, 21834.7520, 21837.1230, 21840.5859, 21834.2559,
        21834.7051, 21834.4258, 21836.2266, 21833.9297, 21835.9082, 21835.9355,
        21837.9082, 21838.4336, 21838.3320, 21838.8438, 21838.3027, 21838.9688,
        21839.3652, 21837.7051, 21835.4102, 21840.4473, 21835.0566, 21837.5176,
        21838.4570, 21834.4355, 21841.4824, 21833.4707, 21839.8691, 21835.6523,
        21837.2031, 21838.9766, 21839.4453, 21831.9121, 21836.8223, 21834.5801,
        21838.4688, 21835.7695, 21833.8438, 21838.6406, 21835.4707, 21838.2930,
        21836.7031, 21834.9980, 21834.7070, 21835.1426])
[Worker 0] Completed Task 586

[Worker 0] Processing Task 587: paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=2.0, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=2.0, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 19.681640625 at index (3, 5) (up to 0.01 allowed)
Greatest relative difference: 0.014273347333073616 at index (3, 5) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([1359.1313, 1359.5179, 1359.4531, 1359.6317, 1359.1522, 1359.3000,
        1359.4912, 1359.2646, 1359.2902, 1359.3081, 1359.3562, 1359.3234,
        1359.4698, 1359.3402, 1359.3735, 1359.3865, 1359.3446, 1359.5350,
        1359.2295, 1359.3702, 1359.2522, 1359.3230, 1359.3777, 1359.4062,
        1359.5146, 1359.1261, 1359.2521, 1359.1638, 1359.4388, 1359.3746,
        1359.1581, 1359.2286, 1359.3304, 1359.5165, 1359.4978, 1359.2269,
        1359.5095, 1359.2646, 1359.0573, 1359.1177, 1359.5035, 1359.0750,
        1359.2480, 1359.3632, 1359.4072, 1359.3013, 1359.3113, 1359.0730,
        1359.3823, 1358.9999, 1359.5312, 1359.3315, 1359.4255, 1359.5037,
        1359.4242, 1359.3411, 1359.2241, 1359.3452, 1359.5044, 1359.2815,
        1359.3064, 1359.2577, 1359.2645, 1359.1732, 1359.3147, 1359.3444,
        1359.3933, 1359.4252, 1359.3881, 1359.4669, 1359.4232, 1359.4327,
        1359.5439, 1359.3119, 1359.3490, 1359.5717, 1359.2615, 1359.4080,
        1359.5551, 1359.1639, 1359.6293, 1359.1846, 1359.5511, 1359.2603,
        1359.3070, 1359.4149, 1359.4700, 1359.0796, 1359.3540, 1359.2969,
        1359.4744, 1359.2784, 1359.2329, 1359.5226, 1359.2081, 1359.3916,
        1359.2968, 1359.2539, 1359.1493, 1359.3341])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([1378.7922, 1379.1198, 1378.9966, 1379.1438, 1378.6661, 1378.8350,
        1379.1273, 1378.8939, 1378.8555, 1378.8961, 1378.8990, 1378.8953,
        1379.0295, 1378.9445, 1378.9100, 1378.9360, 1378.9257, 1379.1608,
        1378.8364, 1378.8719, 1378.8572, 1378.9094, 1378.9730, 1378.9442,
        1379.0743, 1378.7628, 1378.8436, 1378.7780, 1379.0548, 1378.9633,
        1378.7362, 1378.8260, 1378.8992, 1379.0414, 1379.0938, 1378.9086,
        1379.0341, 1378.8506, 1378.6503, 1378.6819, 1379.0773, 1378.7296,
        1378.8138, 1378.9540, 1379.0259, 1378.8890, 1378.9479, 1378.6632,
        1378.9943, 1378.6520, 1379.0715, 1378.9028, 1378.9611, 1379.0627,
        1379.0034, 1378.9161, 1378.8497, 1378.9594, 1379.1212, 1378.7833,
        1378.8219, 1378.8245, 1378.8889, 1378.7662, 1378.8892, 1378.9021,
        1378.9927, 1379.0212, 1379.0077, 1379.0426, 1379.0120, 1379.0360,
        1379.0753, 1378.9739, 1378.8680, 1379.1346, 1378.8231, 1378.9736,
        1379.0458, 1378.7880, 1379.2188, 1378.7856, 1379.1069, 1378.8746,
        1378.9397, 1379.0714, 1379.0928, 1378.6639, 1378.9204, 1378.8135,
        1379.0585, 1378.8928, 1378.7896, 1379.0425, 1378.8452, 1379.0229,
        1378.9041, 1378.8237, 1378.7972, 1378.8407])
[Worker 0] Completed Task 587

[Worker 0] Processing Task 588: paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=2.5, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=2.5, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 3.95556640625 at index (2, 2) (up to 0.01 allowed)
Greatest relative difference: 0.0148778660222888 at index (2, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([261.8879, 261.9447, 261.9319, 261.9579, 261.8724, 261.9020, 261.9596,
        261.9105, 261.9125, 261.9073, 261.9082, 261.9185, 261.9284, 261.9272,
        261.9156, 261.9160, 261.9120, 261.9536, 261.9038, 261.9123, 261.9023,
        261.9279, 261.9136, 261.9271, 261.9428, 261.8875, 261.8968, 261.8841,
        261.9327, 261.9299, 261.8786, 261.8903, 261.9240, 261.9366, 261.9481,
        261.9164, 261.9348, 261.9059, 261.8756, 261.8808, 261.9404, 261.8806,
        261.8985, 261.9175, 261.9312, 261.9147, 261.9094, 261.8669, 261.9315,
        261.8652, 261.9433, 261.9218, 261.9294, 261.9361, 261.9365, 261.9111,
        261.8968, 261.9210, 261.9346, 261.8907, 261.8977, 261.8934, 261.9066,
        261.8915, 261.9135, 261.9184, 261.9232, 261.9429, 261.9309, 261.9366,
        261.9298, 261.9214, 261.9464, 261.9278, 261.9075, 261.9474, 261.9020,
        261.9265, 261.9294, 261.8883, 261.9726, 261.9036, 261.9469, 261.9125,
        261.9193, 261.9413, 261.9472, 261.8751, 261.9106, 261.9078, 261.9388,
        261.9226, 261.8919, 261.9357, 261.9124, 261.9257, 261.9114, 261.9033,
        261.8920, 261.9040])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([265.8354, 265.8926, 265.8725, 265.8935, 265.8099, 265.8419, 265.8945,
        265.8496, 265.8443, 265.8506, 265.8545, 265.8512, 265.8783, 265.8627,
        265.8552, 265.8562, 265.8566, 265.8964, 265.8423, 265.8454, 265.8467,
        265.8533, 265.8692, 265.8641, 265.8818, 265.8278, 265.8427, 265.8337,
        265.8806, 265.8650, 265.8280, 265.8353, 265.8553, 265.8769, 265.8906,
        265.8541, 265.8780, 265.8459, 265.8086, 265.8153, 265.8833, 265.8200,
        265.8386, 265.8624, 265.8735, 265.8494, 265.8636, 265.8108, 265.8707,
        265.8098, 265.8840, 265.8528, 265.8661, 265.8792, 265.8710, 265.8571,
        265.8485, 265.8638, 265.8861, 265.8305, 265.8387, 265.8420, 265.8495,
        265.8279, 265.8506, 265.8552, 265.8672, 265.8723, 265.8682, 265.8759,
        265.8705, 265.8734, 265.8813, 265.8639, 265.8487, 265.8921, 265.8370,
        265.8648, 265.8802, 265.8309, 265.9098, 265.8380, 265.8878, 265.8483,
        265.8573, 265.8844, 265.8867, 265.8119, 265.8540, 265.8382, 265.8843,
        265.8535, 265.8361, 265.8784, 265.8403, 265.8743, 265.8490, 265.8377,
        265.8311, 265.8427])
[Worker 0] Completed Task 588

[Worker 0] Processing Task 589: paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=3.0, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=3.0, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 1.0523452758789062 at index (2, 4) (up to 0.01 allowed)
Greatest relative difference: 0.011778369545936584 at index (2, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([88.2857, 88.3024, 88.2966, 88.3041, 88.2765, 88.2892, 88.3057, 88.2876,
        88.2906, 88.2892, 88.2954, 88.2909, 88.2997, 88.2961, 88.2913, 88.2924,
        88.2890, 88.3025, 88.2860, 88.2870, 88.2904, 88.2893, 88.2952, 88.2953,
        88.2932, 88.2836, 88.2871, 88.2827, 88.2983, 88.2963, 88.2821, 88.2858,
        88.2949, 88.2979, 88.3051, 88.2946, 88.3017, 88.2896, 88.2771, 88.2779,
        88.2996, 88.2816, 88.2875, 88.2975, 88.2944, 88.2910, 88.2958, 88.2759,
        88.2979, 88.2763, 88.3027, 88.2914, 88.2980, 88.2974, 88.2966, 88.2931,
        88.2890, 88.2955, 88.3015, 88.2853, 88.2876, 88.2882, 88.2903, 88.2847,
        88.2906, 88.2901, 88.2941, 88.2966, 88.2954, 88.2949, 88.2958, 88.2957,
        88.3008, 88.2948, 88.2898, 88.3029, 88.2837, 88.2948, 88.3026, 88.2808,
        88.3108, 88.2913, 88.3025, 88.2907, 88.2911, 88.3015, 88.3055, 88.2802,
        88.2901, 88.2871, 88.3006, 88.2921, 88.2869, 88.2996, 88.2908, 88.2965,
        88.2877, 88.2856, 88.2829, 88.2887])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([89.3322, 89.3497, 89.3438, 89.3491, 89.3234, 89.3336, 89.3505, 89.3357,
        89.3343, 89.3362, 89.3381, 89.3365, 89.3457, 89.3407, 89.3381, 89.3374,
        89.3383, 89.3500, 89.3339, 89.3341, 89.3356, 89.3370, 89.3431, 89.3415,
        89.3456, 89.3292, 89.3339, 89.3319, 89.3460, 89.3411, 89.3305, 89.3306,
        89.3386, 89.3443, 89.3497, 89.3375, 89.3453, 89.3355, 89.3235, 89.3256,
        89.3463, 89.3264, 89.3329, 89.3401, 89.3433, 89.3357, 89.3412, 89.3242,
        89.3430, 89.3240, 89.3470, 89.3371, 89.3419, 89.3447, 89.3425, 89.3388,
        89.3371, 89.3407, 89.3458, 89.3297, 89.3325, 89.3343, 89.3360, 89.3291,
        89.3363, 89.3384, 89.3410, 89.3426, 89.3407, 89.3437, 89.3420, 89.3427,
        89.3451, 89.3401, 89.3363, 89.3487, 89.3316, 89.3406, 89.3461, 89.3299,
        89.3548, 89.3340, 89.3475, 89.3356, 89.3380, 89.3473, 89.3475, 89.3246,
        89.3370, 89.3328, 89.3478, 89.3378, 89.3326, 89.3453, 89.3324, 89.3437,
        89.3347, 89.3320, 89.3294, 89.3343])
[Worker 0] Completed Task 589

[Worker 0] Processing Task 590: paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=math.inf, axis=-1, )
[accuracy error] backward  paddle.linalg.norm(Tensor([10, 10, 22817014],"float32"), p=math.inf, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 117 / 2281701400 (0.0%)
Greatest absolute difference: 0.326238751411438 at index (7, 1, 11537476) (up to 0.01 allowed)
Greatest relative difference: 3.0 at index (1, 0, 11520857) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10, 22817014]), dtype=torch.float32)
First 100 elements: tensor([0., 0., -0., -0., -0., 0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0., -0., 0., 0., -0., -0.,
        0., 0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., -0., 0., -0., -0., 0., 0., 0., 0., -0., 0., -0., 0.,
        0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0., 0., -0., -0., 0., 0., -0., 0.,
        -0., -0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0., -0., -0., 0., 0.,
        0., -0., 0., -0.])
DESIRED: (shape=torch.Size([10, 10, 22817014]), dtype=torch.float32)
First 100 elements: tensor([0., 0., -0., -0., -0., 0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0., -0., 0., 0., -0., -0.,
        0., 0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., -0., 0., -0., -0., 0., 0., 0., 0., -0., 0., -0., 0.,
        0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0., 0., -0., -0., 0., 0., -0., 0.,
        -0., -0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0., -0., -0., 0., 0.,
        0., -0., 0., -0.])
[Worker 0] Completed Task 590

[Worker 0] Processing Task 591: paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=0, axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=0, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 26172456.0 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.609375 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216.])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672., 42949672., 42949672.,
        42949672., 42949672., 42949672., 42949672.])
[Worker 0] Completed Task 591

[Worker 0] Processing Task 592: paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=1.0, axis=-1, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 88402 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 592: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 88402 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 592: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 88402 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 593: paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=1.5, axis=-1, )
W0522 16:50:47.380394 43884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:50:47.381434 43884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=1.5, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 2726.611328125 at index (0, 1) (up to 0.01 allowed)
Greatest relative difference: 0.08190466463565826 at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([30573.1953, 30563.4512, 30565.7715, 30570.8242, 30569.2266, 30568.2598,
        30571.6660, 30573.5684, 30569.0723, 30570.9688, 30568.3359, 30570.6758,
        30570.8848, 30570.5996, 30566.3008, 30567.4688, 30574.1172, 30567.6113,
        30571.5332, 30575.7441, 30568.3613, 30574.5820, 30570.0488, 30575.7695,
        30574.6680, 30566.9121, 30570.1797, 30569.0000, 30570.4062, 30565.9141,
        30570.1680, 30570.1973, 30566.5938, 30571.1660, 30563.9492, 30565.6699,
        30564.7441, 30567.5078, 30567.6270, 30565.5762, 30568.9180, 30566.9609,
        30565.2227, 30565.0371, 30567.5898, 30571.9336, 30566.5859, 30567.4238,
        30571.4941, 30570.2324, 30567.0430, 30567.7949, 30568.9453, 30567.9023,
        30566.0059, 30566.6113, 30568.6172, 30572.1484, 30565.4688, 30569.1211,
        30571.9004, 30566.8203, 30572.3633, 30568.8301, 30575.2109, 30571.9141,
        30568.7266, 30566.4766, 30564.6348, 30565.6875, 30572.2461, 30570.1875,
        30573.4492, 30574.3574, 30570.5840, 30568.5020, 30568.3203, 30569.4648,
        30570.4238, 30571.8164, 30574.8496, 30568.0684, 30569.1836, 30570.9102,
        30573.4980, 30570.3828, 30569.8301, 30567.4551, 30566.9395, 30571.9961,
        30569.8965, 30568.5000, 30568.0156, 30563.6152, 30568.1035, 30568.2305,
        30570.9551, 30569.4961, 30571.5371, 30567.8516])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([33292.2969, 33290.0625, 33288.1328, 33291.6055, 33291.6055, 33292.5039,
        33295.0977, 33293.6758, 33292.8281, 33291.6719, 33288.9219, 33288.0820,
        33287.8672, 33292.6797, 33288.8125, 33289.6406, 33293.8555, 33291.4805,
        33293.1914, 33293.3320, 33290.3359, 33294.0195, 33290.8203, 33295.3984,
        33293.1094, 33288.4414, 33292.1992, 33289.1211, 33289.8047, 33290.8984,
        33289.3594, 33291.8398, 33290.8164, 33291.5781, 33285.2188, 33286.7344,
        33284.8750, 33288.4375, 33289.8125, 33291.2734, 33288.7695, 33287.5352,
        33287.4961, 33285.8984, 33291.0977, 33289.6367, 33286.7539, 33289.8008,
        33293.8125, 33293.1523, 33290.2383, 33290.1914, 33289.7695, 33286.9688,
        33288.5117, 33288.6836, 33288.6875, 33292.7617, 33289.2539, 33288.7734,
        33291.4766, 33287.7617, 33292.0586, 33291.5508, 33293.1680, 33288.6055,
        33291.1680, 33289.4258, 33287.0977, 33286.7695, 33295.5820, 33290.1016,
        33295.0117, 33291.2734, 33292.8359, 33287.9883, 33289.7773, 33289.8555,
        33291.5820, 33290.8125, 33294.1328, 33291.5625, 33290.9336, 33290.8477,
        33289.9297, 33290.4648, 33289.1016, 33292.1641, 33289.1523, 33292.0820,
        33288.9766, 33289.2070, 33289.7773, 33288.4062, 33289.6172, 33288.8203,
        33291.0586, 33290.4258, 33292.5977, 33291.2695])
[Worker 0] Completed Task 593

[Worker 0] Processing Task 594: paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=2.0, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=2.0, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 64.2447509765625 at index (0, 1) (up to 0.01 allowed)
Greatest relative difference: 0.033959224820137024 at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([1827.9303, 1827.5756, 1827.7042, 1827.9620, 1827.9960, 1827.9639,
        1828.0969, 1828.1895, 1828.0251, 1827.8365, 1827.8254, 1827.8383,
        1827.7878, 1828.0957, 1827.6261, 1827.8319, 1828.0316, 1827.8535,
        1827.9388, 1828.0627, 1827.9502, 1827.9139, 1827.8560, 1828.1383,
        1828.0670, 1827.6033, 1827.9827, 1827.7646, 1827.8938, 1827.8419,
        1827.6649, 1827.8951, 1827.9031, 1828.0614, 1827.7501, 1827.5317,
        1827.5276, 1827.6038, 1827.8374, 1827.7094, 1827.6890, 1827.7441,
        1827.5657, 1827.6935, 1827.9071, 1827.8278, 1827.5938, 1827.7128,
        1827.9254, 1828.0775, 1827.8116, 1827.8737, 1827.7751, 1827.6229,
        1827.8541, 1827.7087, 1827.6864, 1827.8904, 1827.7552, 1827.6855,
        1827.8021, 1827.6064, 1827.8462, 1827.9210, 1827.9980, 1827.9081,
        1827.8777, 1827.8513, 1827.5956, 1827.5753, 1828.1061, 1827.8405,
        1828.0233, 1828.0157, 1828.1019, 1827.6771, 1827.7375, 1827.7683,
        1827.8589, 1827.7760, 1828.1053, 1827.8810, 1827.9161, 1827.9341,
        1827.7238, 1827.7272, 1827.8544, 1827.9875, 1827.7959, 1827.9272,
        1827.7393, 1827.5988, 1827.7333, 1827.5815, 1827.8727, 1827.6024,
        1827.8286, 1827.8137, 1827.9492, 1827.7805])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([1891.9751, 1891.8203, 1891.7720, 1891.9435, 1891.9434, 1891.9937,
        1892.1163, 1892.0361, 1891.9987, 1891.9144, 1891.8108, 1891.7572,
        1891.7351, 1891.9823, 1891.7921, 1891.8213, 1892.0453, 1891.9237,
        1892.0251, 1892.0321, 1891.8843, 1892.0452, 1891.9169, 1892.1230,
        1892.0364, 1891.7596, 1891.9513, 1891.7904, 1891.8438, 1891.8820,
        1891.7953, 1891.9352, 1891.9028, 1891.9371, 1891.6248, 1891.6694,
        1891.6101, 1891.7666, 1891.8375, 1891.9019, 1891.7810, 1891.7428,
        1891.7247, 1891.6410, 1891.9064, 1891.8159, 1891.6749, 1891.8212,
        1892.0435, 1892.0114, 1891.8533, 1891.8398, 1891.8276, 1891.7095,
        1891.7646, 1891.8129, 1891.7659, 1891.9818, 1891.8176, 1891.7870,
        1891.9073, 1891.7687, 1891.9537, 1891.9375, 1892.0071, 1891.8024,
        1891.9152, 1891.8101, 1891.6995, 1891.6788, 1892.1478, 1891.8669,
        1892.0829, 1891.9279, 1892.0090, 1891.7386, 1891.8527, 1891.8267,
        1891.9194, 1891.8798, 1892.0907, 1891.9358, 1891.8955, 1891.8718,
        1891.8308, 1891.8771, 1891.8096, 1891.9740, 1891.8160, 1891.9614,
        1891.7994, 1891.7988, 1891.8462, 1891.7762, 1891.8387, 1891.7788,
        1891.9135, 1891.8691, 1891.9982, 1891.9066])
[Worker 0] Completed Task 594

[Worker 0] Processing Task 595: paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=2.5, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([10, 10, 42949673],"float32"), p=2.5, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 13.204132080078125 at index (0, 1) (up to 0.01 allowed)
Greatest relative difference: 0.03856530785560608 at index (0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([329.2380, 329.1796, 329.2000, 329.2413, 329.2416, 329.2334, 329.2652,
        329.2578, 329.2358, 329.2276, 329.2042, 329.1987, 329.2108, 329.2517,
        329.1875, 329.2217, 329.2469, 329.2205, 329.2293, 329.2365, 329.2317,
        329.2236, 329.2241, 329.2597, 329.2481, 329.1869, 329.2445, 329.2095,
        329.2139, 329.1995, 329.2005, 329.2082, 329.2272, 329.2250, 329.1801,
        329.1763, 329.1849, 329.1938, 329.2090, 329.2123, 329.1917, 329.1951,
        329.1917, 329.1736, 329.2245, 329.2011, 329.1604, 329.1855, 329.2342,
        329.2409, 329.2103, 329.2165, 329.1892, 329.1875, 329.2024, 329.1926,
        329.1923, 329.2292, 329.2077, 329.1846, 329.2176, 329.1916, 329.2153,
        329.2264, 329.2371, 329.1977, 329.2269, 329.2132, 329.1655, 329.1748,
        329.2620, 329.1976, 329.2429, 329.2363, 329.2320, 329.1899, 329.2213,
        329.1939, 329.2095, 329.2050, 329.2424, 329.2243, 329.2146, 329.2178,
        329.1985, 329.2161, 329.1939, 329.2316, 329.2039, 329.2116, 329.2058,
        329.1898, 329.2051, 329.1836, 329.2070, 329.1954, 329.2221, 329.2126,
        329.2377, 329.2009])
DESIRED: (shape=torch.Size([10, 10]), dtype=torch.float32)
All elements: tensor([342.4141, 342.3837, 342.3820, 342.4096, 342.4091, 342.4189, 342.4373,
        342.4223, 342.4178, 342.3999, 342.3885, 342.3778, 342.3722, 342.4138,
        342.3844, 342.3864, 342.4248, 342.4045, 342.4228, 342.4240, 342.4002,
        342.4238, 342.4073, 342.4365, 342.4267, 342.3766, 342.4074, 342.3811,
        342.3924, 342.3967, 342.3807, 342.4060, 342.4024, 342.4080, 342.3580,
        342.3616, 342.3564, 342.3786, 342.3899, 342.4001, 342.3809, 342.3775,
        342.3724, 342.3581, 342.4021, 342.3849, 342.3631, 342.3858, 342.4240,
        342.4186, 342.3921, 342.3883, 342.3871, 342.3716, 342.3773, 342.3909,
        342.3763, 342.4138, 342.3880, 342.3818, 342.4000, 342.3838, 342.4093,
        342.4074, 342.4178, 342.3878, 342.4040, 342.3849, 342.3675, 342.3631,
        342.4430, 342.3973, 342.4281, 342.4067, 342.4210, 342.3730, 342.3941,
        342.3871, 342.4027, 342.3962, 342.4364, 342.4067, 342.3990, 342.3930,
        342.3881, 342.3977, 342.3872, 342.4151, 342.3889, 342.4119, 342.3848,
        342.3833, 342.3940, 342.3818, 342.3920, 342.3796, 342.4048, 342.3958,
        342.4192, 342.4009])
[Worker 0] Completed Task 595

[Worker 0] Processing Task 598: paddle.linalg.norm(Tensor([11408507, 10, 20],"float32"), p=math.inf, axis=-1, )
[accuracy error] backward  paddle.linalg.norm(Tensor([11408507, 10, 20],"float32"), p=math.inf, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 156 / 2281701400 (0.0%)
Greatest absolute difference: 0.2435346096754074 at index (6026583, 4, 6) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (39382, 8, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([11408507, 10, 20]), dtype=torch.float32)
First 100 elements: tensor([ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,
        -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0434,
         0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,
         0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0756,
         0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,
        -0.3895, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
         0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,
         0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.2024,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,
        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
        -0.2928, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        -0.0000, -0.0000,  0.0000,  0.0000])
DESIRED: (shape=torch.Size([11408507, 10, 20]), dtype=torch.float32)
First 100 elements: tensor([ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,
        -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0434,
         0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,
         0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0756,
         0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,
        -0.3895, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
         0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,
         0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.2024,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,
        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
        -0.2928, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        -0.0000, -0.0000,  0.0000,  0.0000])
[Worker 0] Completed Task 598

[Worker 0] Processing Task 603: paddle.linalg.norm(Tensor([2281701379],"float32"), p=1, axis=0, )
[accuracy error] paddle.linalg.norm(Tensor([2281701379],"float32"), p=1, axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 570430784.0 but got 0.0.
Absolute difference: 570430784.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([5.7043e+08])
[Worker 0] Completed Task 603

[Worker 0] Processing Task 606: paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), 2.0, 2, True, )
[accuracy error] paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), 2.0, 2, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 60 / 60 (100.0%)
Greatest absolute difference: 53.8929443359375 at index (1, 19, 0) (up to 0.01 allowed)
Greatest relative difference: 0.030276881530880928 at index (1, 19, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 20, 1]), dtype=torch.float32)
All elements: tensor([1726.4475, 1726.5259, 1726.4624, 1726.4810, 1726.4475, 1726.5421,
        1726.4426, 1726.5972, 1726.6993, 1726.5913, 1726.5547, 1726.5208,
        1726.2084, 1726.3694, 1726.3296, 1726.5697, 1726.3099, 1726.4486,
        1726.7339, 1726.5953, 1726.5157, 1726.5858, 1726.7439, 1726.4362,
        1726.7241, 1726.5822, 1726.6102, 1726.6161, 1726.3958, 1726.3387,
        1726.4523, 1726.3837, 1726.5941, 1726.2793, 1726.2804, 1726.5471,
        1726.5740, 1726.4056, 1726.1902, 1726.1102, 1726.4398, 1726.2802,
        1726.2544, 1726.4128, 1726.6031, 1726.2477, 1726.3188, 1726.4670,
        1726.2290, 1726.3644, 1726.3024, 1726.4814, 1726.2209, 1726.4437,
        1726.5920, 1726.5922, 1726.4246, 1726.3823, 1726.4043, 1726.2474])
DESIRED: (shape=torch.Size([3, 20, 1]), dtype=torch.float32)
All elements: tensor([1780.2051, 1780.3732, 1780.0212, 1780.2437, 1780.1782, 1780.3451,
        1780.1982, 1780.4131, 1780.3306, 1780.3621, 1780.2820, 1780.1873,
        1779.9685, 1780.1781, 1780.0011, 1780.3357, 1780.1036, 1780.1234,
        1780.3531, 1780.3218, 1780.2638, 1780.2821, 1780.3881, 1780.1464,
        1780.3009, 1780.2776, 1780.3395, 1780.3516, 1780.2761, 1780.0939,
        1780.2400, 1780.1130, 1780.2368, 1780.1200, 1780.1222, 1780.2883,
        1780.2710, 1780.1830, 1779.9576, 1780.0032, 1780.0421, 1779.9586,
        1780.0647, 1780.1581, 1780.2941, 1780.0405, 1780.0320, 1780.1775,
        1779.9498, 1780.1366, 1780.0922, 1780.1511, 1779.9965, 1780.1947,
        1780.2659, 1780.3389, 1780.2223, 1780.1774, 1780.1417, 1780.0831])
[Worker 0] Completed Task 606

[Worker 0] Processing Task 607: paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), math.inf, 2, True, )
[accuracy error] backward  paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), math.inf, 2, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 106 / 2281701420 (0.0%)
Greatest absolute difference: 0.3542698621749878 at index (1, 17, 13031241) (up to 0.01 allowed)
Greatest relative difference: 4.0 at index (1, 1, 1754079) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 20, 38028357]), dtype=torch.float32)
First 100 elements: tensor([-0., 0., 0., -0., -0., 0., -0., 0., 0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0.,
        0., -0., -0., 0., -0., 0., -0., 0., 0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0.,
        0., 0., -0., -0., -0., -0., 0., 0., -0., 0., -0., -0., 0., 0., 0., 0., -0., 0., -0., 0., -0., -0., 0., -0.,
        -0., -0., -0., -0., 0., 0., 0., -0., 0., -0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0., -0., -0.,
        0., 0., -0., -0.])
DESIRED: (shape=torch.Size([3, 20, 38028357]), dtype=torch.float32)
First 100 elements: tensor([-0., 0., 0., -0., -0., 0., -0., 0., 0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., 0., 0., -0., -0., -0.,
        0., -0., -0., 0., -0., 0., -0., 0., 0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0.,
        0., 0., -0., -0., -0., -0., 0., 0., -0., 0., -0., -0., 0., 0., 0., 0., -0., 0., -0., 0., -0., -0., 0., -0.,
        -0., -0., -0., -0., 0., 0., 0., -0., 0., -0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0., -0., -0.,
        0., 0., -0., -0.])
[Worker 0] Completed Task 607

[Worker 0] Processing Task 612: paddle.linalg.norm(Tensor([3, 253522376, 3],"float32"), -math.inf, 2, True, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 26646 has 74.58 GiB memory in use. Of the allocated memory 50.29 GiB is allocated by PyTorch, and 5.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 612: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 26646 has 74.58 GiB memory in use. Of the allocated memory 50.29 GiB is allocated by PyTorch, and 5.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 612: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 26646 has 74.58 GiB memory in use. Of the allocated memory 50.29 GiB is allocated by PyTorch, and 5.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 613: paddle.linalg.norm(Tensor([380283564, 6],"float32"), )
W0522 16:56:10.322405 44091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:56:10.323343 44091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.norm(Tensor([380283564, 6],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 13789.025390625 but got 0.0.
Absolute difference: 13789.025390625 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([13789.0254])
[Worker 0] Completed Task 613

[Worker 0] Processing Task 615: paddle.linalg.norm(Tensor([38028357, 20, 3],"float32"), math.inf, 2, True, )
[accuracy error] backward  paddle.linalg.norm(Tensor([38028357, 20, 3],"float32"), math.inf, 2, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 112 / 2281701420 (0.0%)
Greatest absolute difference: 0.24965327978134155 at index (4103561, 4, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (437976, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([38028357, 20, 3]), dtype=torch.float32)
First 100 elements: tensor([ 0.0000, -0.0000,  0.1902,  0.0000, -0.4320,  0.0000, -0.0000, -0.0000,
        -0.1413, -0.0000,  0.0000, -0.3566,  0.0000,  0.0000,  0.0162, -0.2806,
        -0.0000,  0.0000, -0.0000,  0.0410,  0.0000,  0.0000, -0.0000,  0.1179,
        -0.0000,  0.0000, -0.3780,  0.0000,  0.0000, -0.0023,  0.0428,  0.0000,
         0.0000, -0.0000, -0.0000,  0.2839,  0.0000,  0.3111, -0.0000,  0.0000,
         0.4988,  0.0000,  0.0582,  0.0000,  0.0000,  0.0000, -0.0000, -0.2330,
        -0.0000, -0.4012, -0.0000, -0.0000, -0.0000,  0.0012, -0.0000,  0.0000,
         0.2610, -0.2298, -0.0000, -0.0000, -0.0000, -0.1682, -0.0000, -0.0355,
         0.0000,  0.0000, -0.2461,  0.0000,  0.0000,  0.1314, -0.0000,  0.0000,
        -0.0000,  0.4676, -0.0000,  0.0000,  0.0000,  0.0869,  0.0824, -0.0000,
        -0.0000, -0.0000,  0.0000,  0.1830,  0.3525, -0.0000,  0.0000, -0.0000,
        -0.2558, -0.0000, -0.0000, -0.1761, -0.0000, -0.1181,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0895,  0.0000])
DESIRED: (shape=torch.Size([38028357, 20, 3]), dtype=torch.float32)
First 100 elements: tensor([ 0.0000, -0.0000,  0.1902,  0.0000, -0.4320,  0.0000, -0.0000, -0.0000,
        -0.1413, -0.0000,  0.0000, -0.3566,  0.0000,  0.0000,  0.0162, -0.2806,
        -0.0000,  0.0000, -0.0000,  0.0410,  0.0000,  0.0000, -0.0000,  0.1179,
        -0.0000,  0.0000, -0.3780,  0.0000,  0.0000, -0.0023,  0.0428,  0.0000,
         0.0000, -0.0000, -0.0000,  0.2839,  0.0000,  0.3111, -0.0000,  0.0000,
         0.4988,  0.0000,  0.0582,  0.0000,  0.0000,  0.0000, -0.0000, -0.2330,
        -0.0000, -0.4012, -0.0000, -0.0000, -0.0000,  0.0012, -0.0000,  0.0000,
         0.2610, -0.2298, -0.0000, -0.0000, -0.0000, -0.1682, -0.0000, -0.0355,
         0.0000,  0.0000, -0.2461,  0.0000,  0.0000,  0.1314, -0.0000,  0.0000,
        -0.0000,  0.4676, -0.0000,  0.0000,  0.0000,  0.0869,  0.0824, -0.0000,
        -0.0000, -0.0000,  0.0000,  0.1830,  0.3525, -0.0000,  0.0000, -0.0000,
        -0.2558, -0.0000, -0.0000, -0.1761, -0.0000, -0.1181,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0895,  0.0000])
[Worker 0] Completed Task 615

[Worker 0] Processing Task 618: paddle.linalg.norm(Tensor([4, 1073741824],"float32"), p=-math.inf, axis=list[0,1,], )
[accuracy error] paddle.linalg.norm(Tensor([4, 1073741824],"float32"), p=-math.inf, axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 268431312.0 but got 8388607.5.
Absolute difference: 260042704.5 (up to 0.01 allowed)
Relative difference: 0.9687495194301327 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([8388607.5000])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([2.6843e+08])
[Worker 0] Completed Task 618

[Worker 0] Processing Task 639: paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=1, axis=list[0,1,], keepdim=False, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=1, axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 715308375 / 715827883 (99.9%)
Greatest absolute difference: nan at index (10,) (up to 0.01 allowed)
Greatest relative difference: nan at index (10,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([715827883]), dtype=torch.float16)
First 100 elements: tensor([ 5.4836e-04,  1.0010e+00, -3.3259e-05,  1.6660e+00,  5.4200e+03,
         3.7227e+00,  1.4600e+00,  1.6260e+00,  1.8580e+03,  1.7061e+00,
                nan,  1.6855e+00,  1.6982e+00,  1.6357e+00,         nan,
        -9.0210e-02,  1.9609e+00,  1.5986e+00,  1.1540e+03,  1.7480e+00,
         1.0187e-01,  2.4040e+03,  1.7227e+00,  1.3789e+00,  1.7373e+00,
         4.8000e+04,         nan,  3.7129e+00,  8.1406e-03,  1.3838e+00,
         1.6367e+00,  6.3281e-01,  1.7412e+00,  1.6299e+00,  8.7600e+03,
         1.7158e+00,  1.6250e+00,  1.5811e+00,  2.8516e+01,  1.7432e+00,
         2.8062e-04,  1.1584e+04,  2.5475e+02,  1.6465e+00,  1.4717e+00,
         1.7158e+00,  8.1550e+02,  9.8125e+01, -8.6963e-05,  1.6836e+00,
         7.6240e+03,  1.3808e+04,  6.4250e+01,  1.5293e+00,  1.0527e+00,
         3.7329e-01,  3.3223e+00,  2.0325e-05,  1.9776e+04,  6.5039e-01,
         2.9175e+02,  1.5752e+00,  8.5680e+03,  1.7062e+02, -1.9287e-01,
         1.7188e+00,  1.6299e+00,  1.7363e+00,  7.7680e+03,  6.2969e+01,
         1.7246e+00, -1.3779e+00,  1.6436e+00, -1.7100e+00, -5.1737e-04,
         1.4277e+00,  1.8672e+01,  3.0275e+02,  2.5952e+04,  1.3389e+00,
        -1.6396e+00,  1.6885e+00,  1.6982e+00,  1.9717e+00,  1.7373e+00,
        -1.6475e+00,  1.6895e+00,  1.1846e+00,  4.0375e+02, -1.3030e-04,
         2.1900e+03,  1.7422e+00,  1.7090e+00,  3.6672e+04,  9.3765e-03,
         1.9219e+01, -1.4971e+00, -8.0811e-02,         nan, -2.1194e-02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([715827883]), dtype=torch.float16)
First 100 elements: tensor([0.8848, 0.4307, 0.8779, 0.7402, 0.7246, 0.6855, 0.6152, 0.7964, 0.7773,
        0.4404, 0.8438, 0.8711, 0.8525, 0.5996, 0.6255, 0.5615, 0.3750, 0.9438,
        0.6333, 0.4590, 0.4915, 0.4956, 0.8535, 0.6260, 0.5967, 0.5688, 0.3879,
        0.3862, 0.8896, 0.9346, 0.6973, 0.7427, 0.8545, 0.3967, 0.6631, 0.7539,
        0.6455, 0.7344, 0.5576, 0.5957, 0.5781, 0.5684, 0.6904, 0.5352, 0.6416,
        0.7285, 0.7300, 0.4827, 0.6240, 0.2302, 0.9277, 0.6738, 0.5879, 0.6777,
        0.5596, 0.8789, 0.5039, 0.4990, 0.8154, 0.2896, 0.6982, 0.7495, 0.7021,
        0.6118, 0.7754, 0.6011, 0.8809, 0.9746, 0.5625, 0.8672, 0.6943, 0.6562,
        0.7656, 0.7578, 0.9390, 0.6997, 0.5366, 0.4360, 0.3164, 0.6523, 0.5723,
        0.5483, 0.4277, 0.7051, 0.7173, 0.9570, 0.8047, 0.5332, 0.7715, 0.5361,
        0.6978, 0.7275, 0.5010, 0.6255, 0.6265, 0.7144, 0.9399, 0.7437, 0.8008,
        0.5986], dtype=torch.float16)
[Worker 0] Completed Task 639

[Worker 0] Processing Task 642: paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=2, axis=-1, keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=2, axis=-1, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: 7700.0 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.9970703125 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 1]), dtype=torch.float16)
All elements: tensor([22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 3, 1]), dtype=torch.float16)
All elements: tensor([7724., 7724., 7724., 7724., 7724., 7724.], dtype=torch.float16)
[Worker 0] Completed Task 642

[Worker 0] Processing Task 651: paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 0] Completed Task 651

[Worker 0] Processing Task 658: paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=2, axis=1, keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=2, axis=1, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: 10896.0 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.99755859375 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1]), dtype=torch.float16)
All elements: tensor([22.6250, 22.6250, 22.6250], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1]), dtype=torch.float16)
All elements: tensor([10920., 10920., 10920.], dtype=torch.float16)
[Worker 0] Completed Task 658

[Worker 0] Processing Task 666: paddle.linalg.norm(x=Tensor([357913942, 3, 4],"float16"), p=1, axis=list[0,1,], keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([357913942, 3, 4],"float16"), p=1, axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 0] Completed Task 666

[Worker 0] Processing Task 669: paddle.linalg.vector_norm(x=Tensor([1073741824, 4],"float32"), p=2, axis=None, keepdim=True, )
[accuracy error] paddle.linalg.vector_norm(x=Tensor([1073741824, 4],"float32"), p=2, axis=None, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 18918.525390625 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1, 1]), dtype=torch.float32)
All elements: tensor([18918.5254])
[Worker 0] Completed Task 669

[Worker 0] Processing Task 672: paddle.linalg.vector_norm(x=Tensor([2, 3, 715827883],"float32"), p=math.inf, axis=None, keepdim=False, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.57 GiB is free. Process 86420 has 53.61 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 672: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.57 GiB is free. Process 86420 has 53.61 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 672: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.57 GiB is free. Process 86420 has 53.61 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 673: paddle.linalg.vector_norm(x=Tensor([2, 3, 715827883],"float32"), p=math.inf, axis=None, keepdim=True, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 68877 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 673: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 68877 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 673: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 68877 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 677: paddle.linalg.vector_norm(x=Tensor([3, 1431655765],"float32"), p=2, axis=None, keepdim=True, )
W0522 17:29:54.775583 45326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 17:29:54.776575 45326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.vector_norm(x=Tensor([3, 1431655765],"float32"), p=2, axis=None, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 18918.529296875 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1, 1]), dtype=torch.float32)
All elements: tensor([18918.5293])
[Worker 0] Completed Task 677

[Worker 0] Processing Task 679: paddle.linalg.vector_norm(x=Tensor([3, 715827883],"float64"), p=0, axis=None, keepdim=True, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.linalg.vector_norm(x=Tensor([3, 715827883],"float64"), p=0, axis=None, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 2147483649.0 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1]), dtype=torch.float64)
All elements: tensor([0.], dtype=torch.float64)
DESIRED: (shape=torch.Size([1, 1]), dtype=torch.float64)
All elements: tensor([2.1475e+09], dtype=torch.float64)
[Worker 0] Completed Task 679

[Worker 0] Processing Task 980: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 67108864, 32],"float32"), 16, None, )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Error on Task 980: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] OOM on Task 980: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 981: paddle.nn.functional.adaptive_avg_pool1d(Tensor([2, 67108864, 32],"float32"), output_size=16, )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Error on Task 981: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] OOM on Task 981: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 988: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([1431655766, 3],"float16"), )
W0522 18:22:48.261197 46162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:22:48.262543 46162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([1431655766, 3],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 76536 / 4294967298 (0.0%)
Greatest absolute difference: 0.125 at index (382959251, 0) (up to 0.01 allowed)
Greatest relative difference: 3072.0 at index (472886126, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 5.9814e-02,  4.8828e-03, -6.4209e-02, -7.0312e-02, -3.5449e-01,
         4.2529e-01, -1.6235e-01,  1.3562e-01,  2.6611e-02,  1.6260e-01,
         4.7852e-02, -2.1021e-01, -1.3306e-01,  4.3018e-01, -2.9688e-01,
         7.6172e-02,  5.6055e-01, -6.3721e-01,  2.4355e+00, -2.0977e+00,
        -3.3740e-01, -7.5781e-01, -1.5586e+00,  2.3145e+00,  1.1230e-01,
        -4.6460e-01,  3.5303e-01,  1.0527e+00, -1.2256e-01, -9.2969e-01,
         4.9854e-01, -7.3926e-01,  2.4170e-01, -3.5400e-01,  3.8257e-01,
        -2.8564e-02,  6.1621e-01, -2.6367e-01, -3.5352e-01,  4.1357e-01,
        -7.3193e-01,  3.1982e-01, -1.0132e-02,  4.8828e-04,  9.3994e-03,
        -3.5889e-01, -2.5146e-01,  6.1084e-01,  1.3301e+00, -2.2559e+00,
         9.2822e-01,  1.0117e+00,  5.8643e-01, -1.5977e+00, -3.5986e-01,
         6.9922e-01, -3.3984e-01,  6.2598e-01, -1.4365e+00,  8.1152e-01,
         1.5615e+00, -5.8203e-01, -9.7949e-01,  6.9043e-01, -1.1680e+00,
         4.7803e-01, -1.4209e+00,  1.3604e+00,  6.1523e-02,  3.4590e+00,
        -1.3564e+00, -2.1016e+00, -6.9580e-03,  4.8828e-04,  6.1035e-03,
         6.5430e-02,  1.3770e-01, -2.0300e-01, -3.8398e+00,  1.3047e+00,
         2.5352e+00, -2.3770e+00,  2.2207e+00,  1.5430e-01,  9.2627e-01,
         1.1792e-01, -1.0449e+00, -5.3711e-01,  1.4844e-01,  3.9062e-01,
        -2.2620e-01,  1.0254e-02,  2.1558e-01,  1.1299e+00, -1.3086e+00,
         1.7847e-01, -9.7021e-01,  2.0195e+00, -1.0488e+00, -5.6836e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 5.9601e-02,  4.6616e-03, -6.4270e-02, -7.0557e-02, -3.5474e-01,
         4.2529e-01, -1.6260e-01,  1.3599e-01,  2.6718e-02,  1.6248e-01,
         4.7943e-02, -2.1033e-01, -1.3293e-01,  4.2993e-01, -2.9688e-01,
         7.6538e-02,  5.6055e-01, -6.3721e-01,  2.4355e+00, -2.0977e+00,
        -3.3765e-01, -7.5781e-01, -1.5586e+00,  2.3164e+00,  1.1212e-01,
        -4.6484e-01,  3.5278e-01,  1.0527e+00, -1.2292e-01, -9.2969e-01,
         4.9854e-01, -7.3975e-01,  2.4146e-01, -3.5400e-01,  3.8257e-01,
        -2.8336e-02,  6.1670e-01, -2.6221e-01, -3.5474e-01,  4.1309e-01,
        -7.3242e-01,  3.1934e-01, -1.0056e-02,  5.5790e-04,  9.4986e-03,
        -3.5938e-01, -2.5171e-01,  6.1084e-01,  1.3281e+00, -2.2559e+00,
         9.2773e-01,  1.0117e+00,  5.8643e-01, -1.5977e+00, -3.5962e-01,
         6.9922e-01, -3.3960e-01,  6.2598e-01, -1.4375e+00,  8.1152e-01,
         1.5615e+00, -5.8154e-01, -9.7949e-01,  6.8994e-01, -1.1680e+00,
         4.7778e-01, -1.4219e+00,  1.3604e+00,  6.1188e-02,  3.4590e+00,
        -1.3574e+00, -2.1016e+00, -6.8283e-03,  5.5027e-04,  6.2752e-03,
         6.5430e-02,  1.3757e-01, -2.0300e-01, -3.8379e+00,  1.3037e+00,
         2.5352e+00, -2.3750e+00,  2.2227e+00,  1.5405e-01,  9.2676e-01,
         1.1798e-01, -1.0449e+00, -5.3857e-01,  1.4771e-01,  3.9087e-01,
        -2.2620e-01,  1.0307e-02,  2.1594e-01,  1.1299e+00, -1.3086e+00,
         1.7859e-01, -9.7021e-01,  2.0176e+00, -1.0479e+00, -5.6836e-01],
       dtype=torch.float16)
[Worker 0] Completed Task 988

[Worker 0] Processing Task 995: paddle.nn.functional.normalize(x=Tensor([20452226, 5, 6, 7],"float16"), p=4, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.10 GiB is free. Process 57901 has 73.08 GiB memory in use. Of the allocated memory 35.20 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 995: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.10 GiB is free. Process 57901 has 73.08 GiB memory in use. Of the allocated memory 35.20 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 995: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.10 GiB is free. Process 57901 has 73.08 GiB memory in use. Of the allocated memory 35.20 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 996: paddle.nn.functional.normalize(x=Tensor([4, 178956971, 6],"float16"), )
W0522 18:25:24.948117 46411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:25:24.949374 46411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(x=Tensor([4, 178956971, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2338860561 / 4294967304 (54.5%)
Greatest absolute difference: 0.02197265625 at index (0, 661, 4) (up to 0.01 allowed)
Greatest relative difference: 169.875 at index (0, 2, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 178956971, 6]), dtype=torch.float16)
First 100 elements: tensor([-0.0050,  0.0178,  0.0048,  0.0056, -0.0199, -0.0013,  0.0055, -0.0027,
        -0.0137,  0.0093, -0.0004,  0.0153,  0.0105, -0.0120,  0.0162,  0.0164,
         0.0022, -0.0056, -0.0149,  0.0211, -0.0057, -0.0175, -0.0023, -0.0004,
         0.0018, -0.0164,  0.0037, -0.0002,  0.0130, -0.0106, -0.0119, -0.0095,
        -0.0147,  0.0148, -0.0082, -0.0023, -0.0194, -0.0019, -0.0100, -0.0084,
         0.0175,  0.0073,  0.0086,  0.0148,  0.0087, -0.0012,  0.0111, -0.0109,
         0.0170, -0.0166,  0.0036,  0.0045, -0.0124, -0.0173,  0.0073,  0.0185,
        -0.0049,  0.0044,  0.0048, -0.0116,  0.0039, -0.0191, -0.0061,  0.0126,
         0.0014, -0.0071, -0.0161, -0.0082, -0.0186,  0.0040, -0.0079,  0.0130,
         0.0035, -0.0170, -0.0102, -0.0192,  0.0063,  0.0096,  0.0111, -0.0067,
        -0.0031,  0.0166,  0.0220, -0.0119,  0.0201, -0.0040,  0.0204,  0.0085,
        -0.0133, -0.0131, -0.0188, -0.0181, -0.0133, -0.0183, -0.0216, -0.0146,
        -0.0018,  0.0073, -0.0014, -0.0085], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 178956971, 6]), dtype=torch.float16)
First 100 elements: tensor([-2.9445e-05,  1.0407e-04,  2.8074e-05,  3.2604e-05, -1.1665e-04,
        -7.3910e-06,  3.2187e-05, -1.5974e-05, -8.0228e-05,  5.4479e-05,
        -2.3246e-06,  8.9526e-05,  6.1631e-05, -7.0393e-05,  9.5010e-05,
         9.6202e-05,  1.2815e-05, -3.2544e-05, -8.7082e-05,  1.2374e-04,
        -3.3498e-05, -1.0240e-04, -1.3292e-05, -2.5034e-06,  1.0669e-05,
        -9.6023e-05,  2.1696e-05, -1.0729e-06,  7.6056e-05, -6.2227e-05,
        -6.9976e-05, -5.5552e-05, -8.6367e-05,  8.6725e-05, -4.8339e-05,
        -1.3351e-05, -1.1367e-04, -1.1146e-05, -5.8532e-05, -4.9353e-05,
         1.0270e-04,  4.2856e-05,  5.0247e-05,  8.6844e-05,  5.0724e-05,
        -7.2718e-06,  6.5148e-05, -6.3837e-05,  9.9480e-05, -9.7096e-05,
         2.1338e-05,  2.6345e-05, -7.2837e-05, -1.0157e-04,  4.2975e-05,
         1.0854e-04, -2.8551e-05,  2.5928e-05,  2.8372e-05, -6.7770e-05,
         2.2590e-05, -1.1170e-04, -3.5584e-05,  7.3671e-05,  8.4043e-06,
        -4.1306e-05, -9.4295e-05, -4.8220e-05, -1.0896e-04,  2.3484e-05,
        -4.6611e-05,  7.6413e-05,  2.0385e-05, -9.9480e-05, -5.9545e-05,
        -1.1230e-04,  3.7134e-05,  5.6148e-05,  6.5029e-05, -3.9160e-05,
        -1.8001e-05,  9.7454e-05,  1.2910e-04, -6.9976e-05,  1.1748e-04,
        -2.3544e-05,  1.1927e-04,  4.9829e-05, -7.7605e-05, -7.6950e-05,
        -1.1045e-04, -1.0604e-04, -7.7665e-05, -1.0723e-04, -1.2672e-04,
        -8.5711e-05, -1.0669e-05,  4.2796e-05, -8.2850e-06, -4.9591e-05],
       dtype=torch.float16)
[Worker 0] Completed Task 996

[Worker 0] Processing Task 1005: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 0, 1e-06, True, None, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 0, 1e-06, True, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 6039798.0 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.2647058963775635 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([100, 1]), dtype=torch.float32)
All elements: tensor([16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216.])
DESIRED: (shape=torch.Size([100, 1]), dtype=torch.float32)
All elements: tensor([22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014., 22817014., 22817014.,
        22817014., 22817014., 22817014., 22817014.])
[Worker 0] Completed Task 1005

[Worker 0] Processing Task 1009: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 0, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 0, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 93764 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 1009

[Worker 0] Processing Task 1011: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 1, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 1, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 93764 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 1011

[Worker 0] Processing Task 1013: paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 1, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 1, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.06 GiB is free. Process 93764 has 78.12 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 1013

[Worker 0] Processing Task 1015: paddle.nn.functional.pairwise_distance(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), 2, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), 2, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 93764 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 1015

[Worker 0] Processing Task 1017: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float16"), 0.1, 0.3, training=False, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 93764 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 1017: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 93764 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 1017: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 93764 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 1018: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float16"), 0.3, 0.300000009, training=True, )
W0522 18:30:22.067185 46774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:30:22.068239 46774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 178956971],"float16"), 0.3, 0.300000009, training=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4108774720 / 4294967304 (95.7%)
Greatest absolute difference: 0.5 at index (0, 0, 0, 9048) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 8) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 4, 178956971]), dtype=torch.float16)
First 100 elements: tensor([ 0.2216,  0.1813, -0.0117,  0.4016, -0.0897, -0.0377, -0.0765,  0.1731,
         0.0670,  0.1948,  0.3696, -0.0949,  0.3958,  0.0383, -0.1315, -0.0729,
         0.4951, -0.0755, -0.1044, -0.0829, -0.0585,  0.2327, -0.0451, -0.1144,
         0.1998, -0.0400,  0.2239,  0.2417,  0.4849, -0.0188, -0.1129, -0.0396,
        -0.0689,  0.2366,  0.1300, -0.1476, -0.0823, -0.1050, -0.0509,  0.4768,
         0.3013, -0.0522, -0.0780,  0.0765, -0.0956,  0.3328,  0.3591,  0.3091,
        -0.1173,  0.0920, -0.1368, -0.0942,  0.3818,  0.4138,  0.4224,  0.1785,
        -0.0978,  0.3174, -0.1271,  0.2981,  0.3240, -0.1343, -0.0745, -0.1076,
        -0.0945, -0.0009,  0.2111, -0.0102, -0.1152,  0.4182,  0.2761,  0.1326,
        -0.0119, -0.1075, -0.0006, -0.1130, -0.0784,  0.3726, -0.0533, -0.1252,
        -0.0578, -0.0192,  0.4346,  0.0263, -0.0660, -0.0592,  0.0268, -0.0506,
        -0.0845, -0.1309, -0.0687, -0.0156,  0.2742,  0.0304,  0.4763, -0.0554,
         0.1603,  0.0828,  0.4983,  0.1445], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 3, 4, 178956971]), dtype=torch.float16)
First 100 elements: tensor([ 0.2216,  0.1813, -0.0117,  0.4016, -0.0897, -0.0377, -0.0765,  0.1731,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
[Worker 0] Completed Task 1018

[Worker 0] Processing Task 1149: paddle.roll(Tensor([1, 16, 14, 14, 1369569],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 14, 1369569],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3208 / 4294968384 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 13, 10, 1369369) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 10, 10, 1368481) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 14, 1369569]), dtype=torch.float16)
First 100 elements: tensor([-0.4602, -0.3875, -0.2891, -0.1544,  0.0815,  0.2194, -0.0008, -0.4155,
        -0.2385, -0.0708,  0.1909,  0.3828,  0.4937,  0.3379, -0.3569,  0.0692,
        -0.2439, -0.4612,  0.2097, -0.0977, -0.3491, -0.4202,  0.4351, -0.1182,
         0.4600,  0.3408, -0.2269, -0.0491, -0.0419, -0.0273, -0.0496,  0.0299,
         0.2212, -0.4155,  0.0290,  0.1740,  0.3916,  0.2308, -0.2866, -0.1344,
         0.3750,  0.1821,  0.3491,  0.0064, -0.1810, -0.1104, -0.3076, -0.2612,
         0.4727,  0.2703, -0.2272,  0.3835,  0.2563,  0.3613, -0.3442, -0.2371,
         0.0690, -0.4475, -0.2898,  0.4045, -0.3647,  0.0522, -0.1938, -0.1604,
         0.1193, -0.4526, -0.0246,  0.3997,  0.2544, -0.1017,  0.3184,  0.0177,
        -0.1382,  0.1080,  0.2566, -0.2306, -0.1486,  0.4783,  0.1742,  0.2148,
         0.0135, -0.0589, -0.4031, -0.0009, -0.0630, -0.1683, -0.4180, -0.4329,
         0.1553, -0.3611,  0.2117, -0.3352,  0.4807, -0.4731,  0.2225, -0.0249,
        -0.4961, -0.2869,  0.3633, -0.4551], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 14, 1369569]), dtype=torch.float16)
First 100 elements: tensor([-0.4602, -0.3875, -0.2891, -0.1544,  0.0815,  0.2194, -0.0008, -0.4155,
        -0.2385, -0.0708,  0.1909,  0.3828,  0.4937,  0.3379, -0.3569,  0.0692,
        -0.2439, -0.4612,  0.2097, -0.0977, -0.3491, -0.4202,  0.4351, -0.1182,
         0.4600,  0.3408, -0.2269, -0.0491, -0.0419, -0.0273, -0.0496,  0.0299,
         0.2212, -0.4155,  0.0290,  0.1740,  0.3916,  0.2308, -0.2866, -0.1344,
         0.3750,  0.1821,  0.3491,  0.0064, -0.1810, -0.1104, -0.3076, -0.2612,
         0.4727,  0.2703, -0.2272,  0.3835,  0.2563,  0.3613, -0.3442, -0.2371,
         0.0690, -0.4475, -0.2898,  0.4045, -0.3647,  0.0522, -0.1938, -0.1604,
         0.1193, -0.4526, -0.0246,  0.3997,  0.2544, -0.1017,  0.3184,  0.0177,
        -0.1382,  0.1080,  0.2566, -0.2306, -0.1486,  0.4783,  0.1742,  0.2148,
         0.0135, -0.0589, -0.4031, -0.0009, -0.0630, -0.1683, -0.4180, -0.4329,
         0.1553, -0.3611,  0.2117, -0.3352,  0.4807, -0.4731,  0.2225, -0.0249,
        -0.4961, -0.2869,  0.3633, -0.4551], dtype=torch.float16)
[Worker 0] Completed Task 1149

[Worker 0] Processing Task 1153: paddle.roll(Tensor([1, 16, 14, 24967, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 24967, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 305012 / 4295122944 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 10, 24775, 107) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 10, 24764, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 24967, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.1372,  0.1296,  0.0365,  0.3433,  0.3499,  0.3242,  0.4897, -0.4568,
         0.4355, -0.4729,  0.1226, -0.1348,  0.1327,  0.1382,  0.3223,  0.0991,
        -0.3054,  0.4019,  0.3291, -0.0351,  0.4058, -0.2174, -0.0027,  0.0498,
         0.3833,  0.1615,  0.0539, -0.4626, -0.0883, -0.1116,  0.2878,  0.4614,
        -0.1343, -0.3752,  0.3962, -0.1888, -0.1907,  0.0565,  0.0101, -0.0658,
         0.2534, -0.1488,  0.1765, -0.2783,  0.0094, -0.4580, -0.0037,  0.3589,
         0.0059, -0.4719, -0.0604, -0.4438,  0.0587, -0.3767, -0.0062, -0.2976,
         0.4910, -0.3118,  0.2798,  0.4973, -0.4529, -0.0541,  0.3303, -0.3652,
        -0.4211, -0.2039, -0.0839,  0.3721, -0.1130, -0.3689, -0.4666,  0.4526,
         0.2903,  0.1616, -0.4939,  0.4475,  0.4729,  0.4736, -0.3118,  0.1567,
         0.3018, -0.0726, -0.1970, -0.1005,  0.4670,  0.2996,  0.1613, -0.3308,
        -0.1166,  0.3042, -0.4976, -0.4590,  0.1475,  0.2563,  0.1073,  0.2085,
        -0.2502, -0.0015, -0.2581,  0.4236], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 24967, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.1372,  0.1296,  0.0365,  0.3433,  0.3499,  0.3242,  0.4897, -0.4568,
         0.4355, -0.4729,  0.1226, -0.1348,  0.1327,  0.1382,  0.3223,  0.0991,
        -0.3054,  0.4019,  0.3291, -0.0351,  0.4058, -0.2174, -0.0027,  0.0498,
         0.3833,  0.1615,  0.0539, -0.4626, -0.0883, -0.1116,  0.2878,  0.4614,
        -0.1343, -0.3752,  0.3962, -0.1888, -0.1907,  0.0565,  0.0101, -0.0658,
         0.2534, -0.1488,  0.1765, -0.2783,  0.0094, -0.4580, -0.0037,  0.3589,
         0.0059, -0.4719, -0.0604, -0.4438,  0.0587, -0.3767, -0.0062, -0.2976,
         0.4910, -0.3118,  0.2798,  0.4973, -0.4529, -0.0541,  0.3303, -0.3652,
        -0.4211, -0.2039, -0.0839,  0.3721, -0.1130, -0.3689, -0.4666,  0.4526,
         0.2903,  0.1616, -0.4939,  0.4475,  0.4729,  0.4736, -0.3118,  0.1567,
         0.3018, -0.0726, -0.1970, -0.1005,  0.4670,  0.2996,  0.1613, -0.3308,
        -0.1166,  0.3042, -0.4976, -0.4590,  0.1475,  0.2563,  0.1073,  0.2085,
        -0.2502, -0.0015, -0.2581,  0.4236], dtype=torch.float16)
[Worker 0] Completed Task 1153

[Worker 0] Processing Task 1157: paddle.roll(Tensor([1, 16, 14, 7, 2739138],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 7, 2739138],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2139 / 4294968384 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 13, 6, 2738938) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 10, 6, 2738050) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 7, 2739138]), dtype=torch.float16)
First 100 elements: tensor([ 0.4287,  0.2098, -0.1494,  0.1753, -0.4243, -0.3066, -0.4836, -0.4141,
         0.3479,  0.3149,  0.1191,  0.2524,  0.0938, -0.3352, -0.0892, -0.4792,
         0.4954, -0.4385, -0.2467,  0.1302,  0.3171, -0.1755, -0.3789, -0.0419,
        -0.3240, -0.3840, -0.0855, -0.3782, -0.0960,  0.2473, -0.1965,  0.4768,
         0.2032,  0.4592, -0.1334,  0.2344, -0.4924, -0.1979, -0.4285,  0.2134,
         0.0705, -0.2629,  0.3147, -0.0237, -0.3657, -0.4280, -0.0709,  0.4724,
         0.0582,  0.0990,  0.1602, -0.0008, -0.1071, -0.3552,  0.1979,  0.1755,
         0.4365,  0.0185, -0.1458, -0.4651,  0.4712, -0.4749,  0.3406,  0.3999,
        -0.1338,  0.0178,  0.0484, -0.0999,  0.4119, -0.2251,  0.0815, -0.4133,
         0.1472,  0.3921, -0.4578, -0.0396,  0.3997,  0.4146, -0.0674,  0.3225,
        -0.3896, -0.1825, -0.0120,  0.3228,  0.0167, -0.4167, -0.3049,  0.4736,
        -0.0578,  0.0061,  0.1211,  0.3979,  0.4641,  0.4629,  0.1920, -0.3069,
        -0.4272,  0.0500,  0.0435,  0.0198], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 7, 2739138]), dtype=torch.float16)
First 100 elements: tensor([ 0.4287,  0.2098, -0.1494,  0.1753, -0.4243, -0.3066, -0.4836, -0.4141,
         0.3479,  0.3149,  0.1191,  0.2524,  0.0938, -0.3352, -0.0892, -0.4792,
         0.4954, -0.4385, -0.2467,  0.1302,  0.3171, -0.1755, -0.3789, -0.0419,
        -0.3240, -0.3840, -0.0855, -0.3782, -0.0960,  0.2473, -0.1965,  0.4768,
         0.2032,  0.4592, -0.1334,  0.2344, -0.4924, -0.1979, -0.4285,  0.2134,
         0.0705, -0.2629,  0.3147, -0.0237, -0.3657, -0.4280, -0.0709,  0.4724,
         0.0582,  0.0990,  0.1602, -0.0008, -0.1071, -0.3552,  0.1979,  0.1755,
         0.4365,  0.0185, -0.1458, -0.4651,  0.4712, -0.4749,  0.3406,  0.3999,
        -0.1338,  0.0178,  0.0484, -0.0999,  0.4119, -0.2251,  0.0815, -0.4133,
         0.1472,  0.3921, -0.4578, -0.0396,  0.3997,  0.4146, -0.0674,  0.3225,
        -0.3896, -0.1825, -0.0120,  0.3228,  0.0167, -0.4167, -0.3049,  0.4736,
        -0.0578,  0.0061,  0.1211,  0.3979,  0.4641,  0.4629,  0.1920, -0.3069,
        -0.4272,  0.0500,  0.0435,  0.0198], dtype=torch.float16)
[Worker 0] Completed Task 1157

[Worker 0] Processing Task 1161: paddle.roll(Tensor([1, 16, 21, 33289, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 21, 33289, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 221854 / 4295079936 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 17, 33003, 97) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 17, 32992, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 21, 33289, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.2527,  0.2886, -0.1538, -0.1416,  0.3125,  0.0957, -0.4868, -0.2966,
        -0.3535, -0.1031, -0.2573, -0.1562,  0.1578, -0.1302,  0.4385, -0.1746,
        -0.3076,  0.2477, -0.2698, -0.0251, -0.1804,  0.4036, -0.2896, -0.2417,
         0.1714, -0.2705, -0.3293, -0.1700,  0.4170, -0.1122, -0.1857, -0.0160,
        -0.0605, -0.3230,  0.1182,  0.1691,  0.2627, -0.3877,  0.2622,  0.4216,
         0.2219, -0.2214, -0.0682,  0.3867, -0.2008, -0.2439, -0.1376,  0.4788,
        -0.0201,  0.0471,  0.0721,  0.3435, -0.3013,  0.3533, -0.3083, -0.2406,
         0.3594,  0.2063,  0.4832,  0.3481, -0.4106,  0.4568, -0.3137,  0.1120,
        -0.4419, -0.1318, -0.0343,  0.0365, -0.2529, -0.0015, -0.3357, -0.0742,
         0.4221,  0.1218, -0.2249,  0.1721, -0.1770, -0.1948, -0.1688, -0.1473,
        -0.2969,  0.3000,  0.0983,  0.3486, -0.1499, -0.1255, -0.2539, -0.2279,
        -0.0947,  0.2505, -0.0204,  0.3252,  0.2302,  0.0978,  0.4084,  0.1794,
         0.3811, -0.3875, -0.0953,  0.3188], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 21, 33289, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.2527,  0.2886, -0.1538, -0.1416,  0.3125,  0.0957, -0.4868, -0.2966,
        -0.3535, -0.1031, -0.2573, -0.1562,  0.1578, -0.1302,  0.4385, -0.1746,
        -0.3076,  0.2477, -0.2698, -0.0251, -0.1804,  0.4036, -0.2896, -0.2417,
         0.1714, -0.2705, -0.3293, -0.1700,  0.4170, -0.1122, -0.1857, -0.0160,
        -0.0605, -0.3230,  0.1182,  0.1691,  0.2627, -0.3877,  0.2622,  0.4216,
         0.2219, -0.2214, -0.0682,  0.3867, -0.2008, -0.2439, -0.1376,  0.4788,
        -0.0201,  0.0471,  0.0721,  0.3435, -0.3013,  0.3533, -0.3083, -0.2406,
         0.3594,  0.2063,  0.4832,  0.3481, -0.4106,  0.4568, -0.3137,  0.1120,
        -0.4419, -0.1318, -0.0343,  0.0365, -0.2529, -0.0015, -0.3357, -0.0742,
         0.4221,  0.1218, -0.2249,  0.1721, -0.1770, -0.1948, -0.1688, -0.1473,
        -0.2969,  0.3000,  0.0983,  0.3486, -0.1499, -0.1255, -0.2539, -0.2279,
        -0.0947,  0.2505, -0.0204,  0.3252,  0.2302,  0.0978,  0.4084,  0.1794,
         0.3811, -0.3875, -0.0953,  0.3188], dtype=torch.float16)
[Worker 0] Completed Task 1161

[Worker 0] Processing Task 1165: paddle.roll(Tensor([1, 16, 33289, 21, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 33289, 21, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 134075 / 4295079936 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 33272, 8, 97) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 33272, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 33289, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0048,  0.2460, -0.0736, -0.0853, -0.2913,  0.1732, -0.4578,  0.3450,
        -0.2686, -0.1981,  0.4607, -0.0981, -0.1552, -0.4055,  0.4380,  0.4565,
        -0.0169,  0.3994, -0.0495, -0.0081, -0.2727,  0.3989,  0.4021,  0.2499,
         0.1713, -0.1953,  0.0593, -0.4487, -0.3767, -0.3384,  0.3792, -0.3706,
         0.0435,  0.4790,  0.1891, -0.3828, -0.4622, -0.1860,  0.4636,  0.2764,
         0.1954,  0.4275,  0.2372, -0.0693,  0.0300,  0.2639, -0.3928, -0.4680,
         0.4414, -0.3594,  0.4700,  0.3042,  0.2014,  0.3948,  0.0975,  0.1927,
        -0.3540, -0.4812, -0.1469, -0.4204, -0.0594, -0.2837,  0.1631, -0.1798,
         0.0838,  0.2484, -0.4810, -0.1609,  0.0162,  0.2034,  0.4504,  0.4434,
        -0.4797, -0.0161,  0.3081,  0.1453,  0.2454,  0.0547,  0.0985,  0.1400,
         0.2705,  0.1080, -0.2573,  0.2554,  0.1165,  0.2306, -0.2749,  0.0015,
        -0.4963,  0.3254,  0.0170, -0.2683, -0.1448, -0.2368,  0.4722,  0.4915,
         0.0978,  0.2747, -0.2065, -0.1158], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 33289, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0048,  0.2460, -0.0736, -0.0853, -0.2913,  0.1732, -0.4578,  0.3450,
        -0.2686, -0.1981,  0.4607, -0.0981, -0.1552, -0.4055,  0.4380,  0.4565,
        -0.0169,  0.3994, -0.0495, -0.0081, -0.2727,  0.3989,  0.4021,  0.2499,
         0.1713, -0.1953,  0.0593, -0.4487, -0.3767, -0.3384,  0.3792, -0.3706,
         0.0435,  0.4790,  0.1891, -0.3828, -0.4622, -0.1860,  0.4636,  0.2764,
         0.1954,  0.4275,  0.2372, -0.0693,  0.0300,  0.2639, -0.3928, -0.4680,
         0.4414, -0.3594,  0.4700,  0.3042,  0.2014,  0.3948,  0.0975,  0.1927,
        -0.3540, -0.4812, -0.1469, -0.4204, -0.0594, -0.2837,  0.1631, -0.1798,
         0.0838,  0.2484, -0.4810, -0.1609,  0.0162,  0.2034,  0.4504,  0.4434,
        -0.4797, -0.0161,  0.3081,  0.1453,  0.2454,  0.0547,  0.0985,  0.1400,
         0.2705,  0.1080, -0.2573,  0.2554,  0.1165,  0.2306, -0.2749,  0.0015,
        -0.4963,  0.3254,  0.0170, -0.2683, -0.1448, -0.2368,  0.4722,  0.4915,
         0.0978,  0.2747, -0.2065, -0.1158], dtype=torch.float16)
[Worker 0] Completed Task 1165

[Worker 0] Processing Task 1169: paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(-4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 68203 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 49921, 6, 726) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 49920, 0, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.3447, -0.1344, -0.1823, -0.3809, -0.2249,  0.2566,  0.0184, -0.2737,
        -0.3933, -0.4695,  0.1813, -0.3953, -0.2842,  0.0278,  0.1165,  0.3057,
        -0.1530,  0.0112, -0.1904, -0.3220, -0.3298,  0.0588, -0.0565, -0.3477,
        -0.4907,  0.1299, -0.3813,  0.1954,  0.3345,  0.4260, -0.2371, -0.0810,
         0.1807,  0.0741,  0.2007, -0.0212, -0.2908,  0.4099,  0.3127,  0.3860,
         0.4080,  0.0261,  0.4099, -0.3335,  0.3918, -0.1115,  0.0062, -0.4871,
        -0.0387, -0.0675,  0.4106,  0.0809,  0.3276, -0.1209,  0.3943,  0.4968,
        -0.1170, -0.0763,  0.1646,  0.2009,  0.1444,  0.2389,  0.3140,  0.2028,
         0.2764,  0.3281,  0.4360, -0.1222, -0.4602,  0.2130, -0.3523,  0.1254,
         0.4429, -0.1000,  0.0732,  0.2583,  0.0925,  0.2820,  0.4485, -0.4097,
        -0.3796,  0.4949, -0.4380,  0.2732,  0.2457,  0.1837,  0.3999, -0.1787,
        -0.2467,  0.3857,  0.2749,  0.2131,  0.3059, -0.0327,  0.1597,  0.2949,
        -0.2703, -0.3723,  0.4534, -0.3672], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.3447, -0.1344, -0.1823, -0.3809, -0.2249,  0.2566,  0.0184, -0.2737,
        -0.3933, -0.4695,  0.1813, -0.3953, -0.2842,  0.0278,  0.1165,  0.3057,
        -0.1530,  0.0112, -0.1904, -0.3220, -0.3298,  0.0588, -0.0565, -0.3477,
        -0.4907,  0.1299, -0.3813,  0.1954,  0.3345,  0.4260, -0.2371, -0.0810,
         0.1807,  0.0741,  0.2007, -0.0212, -0.2908,  0.4099,  0.3127,  0.3860,
         0.4080,  0.0261,  0.4099, -0.3335,  0.3918, -0.1115,  0.0062, -0.4871,
        -0.0387, -0.0675,  0.4106,  0.0809,  0.3276, -0.1209,  0.3943,  0.4968,
        -0.1170, -0.0763,  0.1646,  0.2009,  0.1444,  0.2389,  0.3140,  0.2028,
         0.2764,  0.3281,  0.4360, -0.1222, -0.4602,  0.2130, -0.3523,  0.1254,
         0.4429, -0.1000,  0.0732,  0.2583,  0.0925,  0.2820,  0.4485, -0.4097,
        -0.3796,  0.4949, -0.4380,  0.2732,  0.2457,  0.1837,  0.3999, -0.1787,
        -0.2467,  0.3857,  0.2749,  0.2131,  0.3059, -0.0327,  0.1597,  0.2949,
        -0.2703, -0.3723,  0.4534, -0.3672], dtype=torch.float16)
[Worker 0] Completed Task 1169

[Worker 0] Processing Task 1173: paddle.roll(Tensor([1, 16, 7, 14, 2739138],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 14, 2739138],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2139 / 4294968384 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 6, 13, 2738969) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 10, 2738050) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 14, 2739138]), dtype=torch.float16)
First 100 elements: tensor([-2.4231e-01,  2.2498e-01, -3.0127e-01, -3.0365e-02,  2.0544e-01,
         4.3579e-01,  4.4629e-01,  1.4320e-02, -1.9092e-01,  2.7905e-01,
        -4.3221e-03, -3.9001e-02, -4.9707e-01,  2.7271e-01, -3.2471e-01,
         4.3970e-01, -4.1382e-01, -1.2292e-01,  3.9526e-01,  5.9906e-02,
        -1.8784e-02, -1.6565e-01, -4.9805e-02, -4.2871e-01,  1.6016e-01,
        -9.2651e-02, -3.1226e-01,  1.5161e-01, -1.6333e-01,  3.1958e-01,
         3.6523e-01, -7.2754e-02,  2.6660e-01, -2.9297e-01,  4.5630e-01,
        -3.1006e-01,  9.3994e-02,  1.4661e-01,  1.0663e-01, -3.4937e-01,
        -2.2156e-01,  1.3538e-01, -1.3928e-01, -1.8762e-01, -1.0638e-01,
        -4.7754e-01,  3.1445e-01, -1.2158e-01, -1.0541e-01, -9.6252e-02,
        -3.8794e-01, -4.8926e-01,  1.6370e-01, -4.2041e-01, -1.1017e-01,
        -4.5630e-01,  2.5058e-04, -2.3608e-01, -4.1699e-01, -3.3105e-01,
         4.5581e-01, -3.1853e-03, -4.1040e-01, -3.5278e-01,  2.4463e-01,
        -3.6621e-01,  7.6538e-02,  1.9702e-01, -2.1179e-01, -3.1909e-01,
         1.4343e-01, -2.2229e-01,  2.9834e-01, -4.6533e-01, -1.4868e-03,
        -3.8647e-01, -1.3074e-01, -1.9470e-01,  2.8613e-01,  1.2952e-01,
         1.1908e-01, -9.1095e-03, -1.4636e-01, -2.9956e-01, -2.0093e-01,
        -1.2201e-01, -2.9395e-01,  1.6394e-01,  4.7778e-01, -3.7036e-01,
         2.7344e-01,  1.4908e-02,  3.4497e-01,  3.6816e-01, -8.6243e-02,
         1.6516e-01,  3.6224e-02, -2.7881e-01,  2.4866e-01, -2.8638e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 14, 2739138]), dtype=torch.float16)
First 100 elements: tensor([-2.4231e-01,  2.2498e-01, -3.0127e-01, -3.0365e-02,  2.0544e-01,
         4.3579e-01,  4.4629e-01,  1.4320e-02, -1.9092e-01,  2.7905e-01,
        -4.3221e-03, -3.9001e-02, -4.9707e-01,  2.7271e-01, -3.2471e-01,
         4.3970e-01, -4.1382e-01, -1.2292e-01,  3.9526e-01,  5.9906e-02,
        -1.8784e-02, -1.6565e-01, -4.9805e-02, -4.2871e-01,  1.6016e-01,
        -9.2651e-02, -3.1226e-01,  1.5161e-01, -1.6333e-01,  3.1958e-01,
         3.6523e-01, -7.2754e-02,  2.6660e-01, -2.9297e-01,  4.5630e-01,
        -3.1006e-01,  9.3994e-02,  1.4661e-01,  1.0663e-01, -3.4937e-01,
        -2.2156e-01,  1.3538e-01, -1.3928e-01, -1.8762e-01, -1.0638e-01,
        -4.7754e-01,  3.1445e-01, -1.2158e-01, -1.0541e-01, -9.6252e-02,
        -3.8794e-01, -4.8926e-01,  1.6370e-01, -4.2041e-01, -1.1017e-01,
        -4.5630e-01,  2.5058e-04, -2.3608e-01, -4.1699e-01, -3.3105e-01,
         4.5581e-01, -3.1853e-03, -4.1040e-01, -3.5278e-01,  2.4463e-01,
        -3.6621e-01,  7.6538e-02,  1.9702e-01, -2.1179e-01, -3.1909e-01,
         1.4343e-01, -2.2229e-01,  2.9834e-01, -4.6533e-01, -1.4868e-03,
        -3.8647e-01, -1.3074e-01, -1.9470e-01,  2.8613e-01,  1.2952e-01,
         1.1908e-01, -9.1095e-03, -1.4636e-01, -2.9956e-01, -2.0093e-01,
        -1.2201e-01, -2.9395e-01,  1.6394e-01,  4.7778e-01, -3.7036e-01,
         2.7344e-01,  1.4908e-02,  3.4497e-01,  3.6816e-01, -8.6243e-02,
         1.6516e-01,  3.6224e-02, -2.7881e-01,  2.4866e-01, -2.8638e-01],
       dtype=torch.float16)
[Worker 0] Completed Task 1173

[Worker 0] Processing Task 1177: paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 70443 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 6, 49852, 726) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 49839, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.0140,  0.4006,  0.3545, -0.4260,  0.4573, -0.0994,  0.2272,  0.3252,
        -0.2240,  0.0234, -0.0206,  0.2788,  0.2859, -0.0859,  0.0668, -0.3154,
        -0.2671,  0.3601,  0.3193, -0.1986, -0.1730, -0.0789,  0.4089, -0.4395,
         0.1963,  0.2878,  0.3621,  0.0911,  0.3525,  0.1144,  0.3010, -0.2605,
        -0.3628,  0.0667, -0.2566, -0.4824,  0.0674, -0.4802,  0.0710,  0.0401,
         0.1600,  0.2954, -0.3469,  0.0491, -0.0279,  0.4023,  0.3198, -0.3850,
        -0.4573, -0.1743,  0.0079, -0.2937,  0.2168, -0.0177, -0.3291, -0.3865,
        -0.2382, -0.0358,  0.1783, -0.3611,  0.0581, -0.1837,  0.2258,  0.4868,
        -0.3884, -0.1224,  0.2483,  0.2861,  0.2905, -0.0080,  0.1812, -0.4248,
         0.1300, -0.1378, -0.0123,  0.1582,  0.2489, -0.3540,  0.2612, -0.2249,
         0.0456, -0.3604,  0.4326, -0.4575, -0.0273,  0.1985,  0.4023,  0.1995,
        -0.3608,  0.1738, -0.4810,  0.0522,  0.2245,  0.0181, -0.3547,  0.1659,
        -0.0909,  0.2050,  0.4590, -0.4001], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.0140,  0.4006,  0.3545, -0.4260,  0.4573, -0.0994,  0.2272,  0.3252,
        -0.2240,  0.0234, -0.0206,  0.2788,  0.2859, -0.0859,  0.0668, -0.3154,
        -0.2671,  0.3601,  0.3193, -0.1986, -0.1730, -0.0789,  0.4089, -0.4395,
         0.1963,  0.2878,  0.3621,  0.0911,  0.3525,  0.1144,  0.3010, -0.2605,
        -0.3628,  0.0667, -0.2566, -0.4824,  0.0674, -0.4802,  0.0710,  0.0401,
         0.1600,  0.2954, -0.3469,  0.0491, -0.0279,  0.4023,  0.3198, -0.3850,
        -0.4573, -0.1743,  0.0079, -0.2937,  0.2168, -0.0177, -0.3291, -0.3865,
        -0.2382, -0.0358,  0.1783, -0.3611,  0.0581, -0.1837,  0.2258,  0.4868,
        -0.3884, -0.1224,  0.2483,  0.2861,  0.2905, -0.0080,  0.1812, -0.4248,
         0.1300, -0.1378, -0.0123,  0.1582,  0.2489, -0.3540,  0.2612, -0.2249,
         0.0456, -0.3604,  0.4326, -0.4575, -0.0273,  0.1985,  0.4023,  0.1995,
        -0.3608,  0.1738, -0.4810,  0.0522,  0.2245,  0.0181, -0.3547,  0.1659,
        -0.0909,  0.2050,  0.4590, -0.4001], dtype=torch.float16)
[Worker 0] Completed Task 1177

[Worker 0] Processing Task 1181: paddle.roll(Tensor([1, 38044, 14, 21, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 38044, 14, 21, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 70909 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 38043, 5, 2, 306) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 38043, 5, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 38044, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.3599,  0.0720,  0.2700, -0.3772, -0.2469, -0.2783,  0.0792,  0.2256,
        -0.4197, -0.3538, -0.2764,  0.0212,  0.1100, -0.4390,  0.2480, -0.2839,
        -0.1598, -0.1581,  0.4612,  0.4636, -0.3450, -0.2993, -0.2935, -0.0807,
        -0.2092,  0.3997, -0.2637, -0.4119,  0.0403, -0.0730,  0.1647, -0.3201,
         0.0316, -0.3264,  0.2449,  0.4368, -0.1092,  0.2578, -0.3018, -0.2158,
        -0.4565, -0.1230, -0.4341, -0.2642, -0.4705,  0.4133,  0.1554, -0.2686,
         0.0317, -0.3679, -0.1132,  0.1504,  0.3416,  0.3850, -0.1414, -0.4343,
         0.3655,  0.3079,  0.1088, -0.3699,  0.2050,  0.3992,  0.1403,  0.0022,
         0.0137, -0.4377, -0.4685, -0.1203, -0.4438,  0.4688, -0.4719, -0.0017,
         0.4656, -0.4888,  0.2805, -0.0191, -0.0150, -0.2234,  0.1787, -0.0463,
        -0.3193,  0.3550, -0.1399, -0.4155, -0.4519,  0.1106, -0.3655, -0.1229,
        -0.0208,  0.0337, -0.4277,  0.3315, -0.0801, -0.0025, -0.1528,  0.1620,
        -0.0494,  0.1528, -0.3535, -0.1492], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 38044, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.3599,  0.0720,  0.2700, -0.3772, -0.2469, -0.2783,  0.0792,  0.2256,
        -0.4197, -0.3538, -0.2764,  0.0212,  0.1100, -0.4390,  0.2480, -0.2839,
        -0.1598, -0.1581,  0.4612,  0.4636, -0.3450, -0.2993, -0.2935, -0.0807,
        -0.2092,  0.3997, -0.2637, -0.4119,  0.0403, -0.0730,  0.1647, -0.3201,
         0.0316, -0.3264,  0.2449,  0.4368, -0.1092,  0.2578, -0.3018, -0.2158,
        -0.4565, -0.1230, -0.4341, -0.2642, -0.4705,  0.4133,  0.1554, -0.2686,
         0.0317, -0.3679, -0.1132,  0.1504,  0.3416,  0.3850, -0.1414, -0.4343,
         0.3655,  0.3079,  0.1088, -0.3699,  0.2050,  0.3992,  0.1403,  0.0022,
         0.0137, -0.4377, -0.4685, -0.1203, -0.4438,  0.4688, -0.4719, -0.0017,
         0.4656, -0.4888,  0.2805, -0.0191, -0.0150, -0.2234,  0.1787, -0.0463,
        -0.3193,  0.3550, -0.1399, -0.4155, -0.4519,  0.1106, -0.3655, -0.1229,
        -0.0208,  0.0337, -0.4277,  0.3315, -0.0801, -0.0025, -0.1528,  0.1620,
        -0.0494,  0.1528, -0.3535, -0.1492], dtype=torch.float16)
[Worker 0] Completed Task 1181

[Worker 0] Processing Task 1185: paddle.roll(Tensor([1, 57066, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 57066, 14, 14, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 62957 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 57065, 2, 10, 125) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 57065, 2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 57066, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0079, -0.1135,  0.4026,  0.1461,  0.1809,  0.0981, -0.4065, -0.3315,
        -0.3137, -0.4119,  0.3938, -0.2742,  0.2522, -0.2639,  0.1768,  0.1285,
        -0.0235, -0.4114, -0.2086, -0.1477, -0.2455, -0.1885, -0.2783, -0.1047,
        -0.2993,  0.2837, -0.1976, -0.3657, -0.0193,  0.4421,  0.1501,  0.4668,
        -0.0202, -0.1046,  0.1333, -0.3552,  0.1005, -0.3972,  0.2603,  0.1677,
         0.4719,  0.0420, -0.2330,  0.3811, -0.1224,  0.2791,  0.3721, -0.0587,
        -0.2954,  0.4966, -0.4956, -0.0980, -0.0850,  0.2435, -0.1898, -0.4304,
         0.4319,  0.0430, -0.0516, -0.3213, -0.3313,  0.4023, -0.3765, -0.0876,
         0.0009,  0.3743, -0.2961,  0.3960,  0.0120,  0.4829,  0.2109, -0.4360,
         0.2720, -0.3118,  0.0666, -0.1942, -0.2029,  0.1536,  0.3831, -0.1522,
         0.4561,  0.0106, -0.3542, -0.4539, -0.1686, -0.2917,  0.4739, -0.1489,
         0.3267, -0.1133, -0.3398, -0.1646,  0.1284, -0.1450,  0.0478, -0.4209,
        -0.4077, -0.0148,  0.1857,  0.0091], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 57066, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0079, -0.1135,  0.4026,  0.1461,  0.1809,  0.0981, -0.4065, -0.3315,
        -0.3137, -0.4119,  0.3938, -0.2742,  0.2522, -0.2639,  0.1768,  0.1285,
        -0.0235, -0.4114, -0.2086, -0.1477, -0.2455, -0.1885, -0.2783, -0.1047,
        -0.2993,  0.2837, -0.1976, -0.3657, -0.0193,  0.4421,  0.1501,  0.4668,
        -0.0202, -0.1046,  0.1333, -0.3552,  0.1005, -0.3972,  0.2603,  0.1677,
         0.4719,  0.0420, -0.2330,  0.3811, -0.1224,  0.2791,  0.3721, -0.0587,
        -0.2954,  0.4966, -0.4956, -0.0980, -0.0850,  0.2435, -0.1898, -0.4304,
         0.4319,  0.0430, -0.0516, -0.3213, -0.3313,  0.4023, -0.3765, -0.0876,
         0.0009,  0.3743, -0.2961,  0.3960,  0.0120,  0.4829,  0.2109, -0.4360,
         0.2720, -0.3118,  0.0666, -0.1942, -0.2029,  0.1536,  0.3831, -0.1522,
         0.4561,  0.0106, -0.3542, -0.4539, -0.1686, -0.2917,  0.4739, -0.1489,
         0.3267, -0.1133, -0.3398, -0.1646,  0.1284, -0.1450,  0.0478, -0.4209,
        -0.4077, -0.0148,  0.1857,  0.0091], dtype=torch.float16)
[Worker 0] Completed Task 1185

[Worker 0] Processing Task 1189: paddle.roll(Tensor([1, 57066, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 57066, 7, 14, 768],"float16"), shifts=tuple(-4,0,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 49395 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 57065, 2, 10, 509) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 57065, 2, 4, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 57066, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.0900, -0.1814,  0.0812,  0.4116, -0.1716, -0.3389,  0.2202, -0.0747,
         0.0865, -0.3787, -0.4583, -0.4888,  0.2676,  0.3491, -0.2642, -0.2397,
         0.3164,  0.3828,  0.0007, -0.0786,  0.0033,  0.3276, -0.0629, -0.2349,
         0.0206, -0.3281, -0.0570, -0.1173,  0.0321, -0.4622,  0.4661,  0.0205,
        -0.2942, -0.3059, -0.3342,  0.1821, -0.1952, -0.3877, -0.4385,  0.0259,
        -0.1180,  0.0342, -0.2351, -0.3904, -0.1047, -0.4358, -0.2241, -0.3596,
        -0.1714, -0.4844,  0.1151, -0.4565,  0.1792,  0.4292, -0.1505, -0.1975,
         0.2678, -0.0081,  0.4458, -0.2642,  0.2871,  0.2196,  0.1266, -0.1405,
        -0.3015, -0.1464, -0.3687, -0.1160,  0.4629,  0.1692, -0.3220,  0.4534,
         0.2041,  0.2629, -0.3599,  0.4941, -0.2808,  0.4890,  0.1560, -0.4038,
        -0.2783,  0.2849, -0.0556, -0.4177,  0.1398,  0.3884,  0.4019, -0.2666,
        -0.1947,  0.3679, -0.3291,  0.4124, -0.3682,  0.1967,  0.0050, -0.2847,
        -0.2252, -0.1403, -0.1455, -0.2314], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 57066, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.0900, -0.1814,  0.0812,  0.4116, -0.1716, -0.3389,  0.2202, -0.0747,
         0.0865, -0.3787, -0.4583, -0.4888,  0.2676,  0.3491, -0.2642, -0.2397,
         0.3164,  0.3828,  0.0007, -0.0786,  0.0033,  0.3276, -0.0629, -0.2349,
         0.0206, -0.3281, -0.0570, -0.1173,  0.0321, -0.4622,  0.4661,  0.0205,
        -0.2942, -0.3059, -0.3342,  0.1821, -0.1952, -0.3877, -0.4385,  0.0259,
        -0.1180,  0.0342, -0.2351, -0.3904, -0.1047, -0.4358, -0.2241, -0.3596,
        -0.1714, -0.4844,  0.1151, -0.4565,  0.1792,  0.4292, -0.1505, -0.1975,
         0.2678, -0.0081,  0.4458, -0.2642,  0.2871,  0.2196,  0.1266, -0.1405,
        -0.3015, -0.1464, -0.3687, -0.1160,  0.4629,  0.1692, -0.3220,  0.4534,
         0.2041,  0.2629, -0.3599,  0.4941, -0.2808,  0.4890,  0.1560, -0.4038,
        -0.2783,  0.2849, -0.0556, -0.4177,  0.1398,  0.3884,  0.4019, -0.2666,
        -0.1947,  0.3679, -0.3291,  0.4124, -0.3682,  0.1967,  0.0050, -0.2847,
        -0.2252, -0.1403, -0.1455, -0.2314], dtype=torch.float16)
[Worker 0] Completed Task 1189

[Worker 0] Processing Task 1193: paddle.roll(Tensor([2378, 16, 14, 21, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([2378, 16, 14, 21, 384],"float16"), shifts=tuple(-4,-3,-3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 513376 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (2377, 11, 5, 8, 260) (up to 0.01 allowed)
Greatest relative difference: inf at index (2377, 11, 5, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2378, 16, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.3599,  0.0720,  0.2700, -0.3772, -0.2469, -0.2783,  0.0792,  0.2256,
        -0.4197, -0.3538, -0.2764,  0.0212,  0.1100, -0.4390,  0.2480, -0.2839,
        -0.1598, -0.1581,  0.4612,  0.4636, -0.3450, -0.2993, -0.2935, -0.0807,
        -0.2092,  0.3997, -0.2637, -0.4119,  0.0403, -0.0730,  0.1647, -0.3201,
         0.0316, -0.3264,  0.2449,  0.4368, -0.1092,  0.2578, -0.3018, -0.2158,
        -0.4565, -0.1230, -0.4341, -0.2642, -0.4705,  0.4133,  0.1554, -0.2686,
         0.0317, -0.3679, -0.1132,  0.1504,  0.3416,  0.3850, -0.1414, -0.4343,
         0.3655,  0.3079,  0.1088, -0.3699,  0.2050,  0.3992,  0.1403,  0.0022,
         0.0137, -0.4377, -0.4685, -0.1203, -0.4438,  0.4688, -0.4719, -0.0017,
         0.4656, -0.4888,  0.2805, -0.0191, -0.0150, -0.2234,  0.1787, -0.0463,
        -0.3193,  0.3550, -0.1399, -0.4155, -0.4519,  0.1106, -0.3655, -0.1229,
        -0.0208,  0.0337, -0.4277,  0.3315, -0.0801, -0.0025, -0.1528,  0.1620,
        -0.0494,  0.1528, -0.3535, -0.1492], dtype=torch.float16)
DESIRED: (shape=torch.Size([2378, 16, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.3599,  0.0720,  0.2700, -0.3772, -0.2469, -0.2783,  0.0792,  0.2256,
        -0.4197, -0.3538, -0.2764,  0.0212,  0.1100, -0.4390,  0.2480, -0.2839,
        -0.1598, -0.1581,  0.4612,  0.4636, -0.3450, -0.2993, -0.2935, -0.0807,
        -0.2092,  0.3997, -0.2637, -0.4119,  0.0403, -0.0730,  0.1647, -0.3201,
         0.0316, -0.3264,  0.2449,  0.4368, -0.1092,  0.2578, -0.3018, -0.2158,
        -0.4565, -0.1230, -0.4341, -0.2642, -0.4705,  0.4133,  0.1554, -0.2686,
         0.0317, -0.3679, -0.1132,  0.1504,  0.3416,  0.3850, -0.1414, -0.4343,
         0.3655,  0.3079,  0.1088, -0.3699,  0.2050,  0.3992,  0.1403,  0.0022,
         0.0137, -0.4377, -0.4685, -0.1203, -0.4438,  0.4688, -0.4719, -0.0017,
         0.4656, -0.4888,  0.2805, -0.0191, -0.0150, -0.2234,  0.1787, -0.0463,
        -0.3193,  0.3550, -0.1399, -0.4155, -0.4519,  0.1106, -0.3655, -0.1229,
        -0.0208,  0.0337, -0.4277,  0.3315, -0.0801, -0.0025, -0.1528,  0.1620,
        -0.0494,  0.1528, -0.3535, -0.1492], dtype=torch.float16)
[Worker 0] Completed Task 1193

[Worker 0] Processing Task 1197: paddle.roll(Tensor([3, 1431655766],"float16"), shifts=1, axis=0, )
[accuracy error] paddle.roll(Tensor([3, 1431655766],"float16"), shifts=1, axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 4294967298 (0.0%)
Greatest absolute difference: 0.38916015625 at index (2, 1431655765) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1431655764) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([ 0.2642,  0.4065,  0.3286, -0.3806, -0.0140,  0.1547,  0.4231, -0.2876,
         0.0918, -0.2722,  0.1956, -0.0211,  0.1841, -0.2367, -0.4617,  0.4951,
        -0.1393, -0.1139, -0.0915, -0.3594, -0.3491,  0.0742, -0.1967, -0.2012,
         0.0724, -0.3052,  0.4163,  0.0446,  0.1914,  0.3850,  0.3467, -0.3777,
         0.4387, -0.3513,  0.2377,  0.0391, -0.0211, -0.2031,  0.0743,  0.4277,
         0.0758,  0.0396, -0.0542,  0.0178, -0.0845,  0.1666, -0.0471, -0.3540,
        -0.3916, -0.1842, -0.4111, -0.0837,  0.4673,  0.1237,  0.1104,  0.4250,
         0.0764,  0.1832,  0.4819,  0.2766, -0.3892, -0.0983, -0.0456, -0.0014,
         0.4456,  0.4685,  0.2629, -0.0886,  0.4099, -0.1658, -0.3174,  0.4226,
        -0.2876,  0.0859,  0.1689,  0.3440,  0.0787,  0.4453,  0.3184,  0.0476,
         0.0543,  0.3306,  0.4897, -0.2571, -0.2495, -0.1511,  0.2551, -0.4336,
         0.0981, -0.4912,  0.1599,  0.3135, -0.4780, -0.1353,  0.4973,  0.2642,
         0.2883, -0.3203,  0.2279, -0.4949], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([ 0.2642,  0.4065,  0.3286, -0.3806, -0.0140,  0.1547,  0.4231, -0.2876,
         0.0918, -0.2722,  0.1956, -0.0211,  0.1841, -0.2367, -0.4617,  0.4951,
        -0.1393, -0.1139, -0.0915, -0.3594, -0.3491,  0.0742, -0.1967, -0.2012,
         0.0724, -0.3052,  0.4163,  0.0446,  0.1914,  0.3850,  0.3467, -0.3777,
         0.4387, -0.3513,  0.2377,  0.0391, -0.0211, -0.2031,  0.0743,  0.4277,
         0.0758,  0.0396, -0.0542,  0.0178, -0.0845,  0.1666, -0.0471, -0.3540,
        -0.3916, -0.1842, -0.4111, -0.0837,  0.4673,  0.1237,  0.1104,  0.4250,
         0.0764,  0.1832,  0.4819,  0.2766, -0.3892, -0.0983, -0.0456, -0.0014,
         0.4456,  0.4685,  0.2629, -0.0886,  0.4099, -0.1658, -0.3174,  0.4226,
        -0.2876,  0.0859,  0.1689,  0.3440,  0.0787,  0.4453,  0.3184,  0.0476,
         0.0543,  0.3306,  0.4897, -0.2571, -0.2495, -0.1511,  0.2551, -0.4336,
         0.0981, -0.4912,  0.1599,  0.3135, -0.4780, -0.1353,  0.4973,  0.2642,
         0.2883, -0.3203,  0.2279, -0.4949], dtype=torch.float16)
[Worker 0] Completed Task 1197

[Worker 0] Processing Task 1201: paddle.roll(Tensor([3567, 16, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([3567, 16, 14, 7, 768],"float16"), shifts=tuple(-4,-3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 505357 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (3566, 9, 2, 5, 276) (up to 0.01 allowed)
Greatest relative difference: inf at index (3566, 9, 2, 0, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3567, 16, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4456, -0.1087, -0.3633,  0.2491,  0.1290, -0.0518, -0.0930,  0.3945,
         0.0099, -0.3503,  0.0396, -0.3811, -0.3164,  0.0334, -0.2216, -0.4468,
        -0.3411,  0.0491,  0.0490,  0.0157, -0.1943,  0.2410,  0.3049, -0.1124,
        -0.0865, -0.4309, -0.4929,  0.3245,  0.3748, -0.3210,  0.2234,  0.3811,
         0.2297, -0.2450,  0.3223,  0.0917,  0.1149,  0.1437, -0.2472, -0.2021,
         0.4951,  0.2448, -0.4587,  0.3821,  0.2595, -0.4692, -0.0585, -0.0617,
         0.1421, -0.2837,  0.1606, -0.1503,  0.1181,  0.4399,  0.1499,  0.3469,
        -0.2256,  0.2861, -0.3074,  0.0651, -0.4138,  0.2717, -0.2175,  0.1296,
         0.3572, -0.1692, -0.0476, -0.3625,  0.0571,  0.2323, -0.1294, -0.3103,
        -0.4053,  0.3591,  0.1048, -0.4944, -0.1591,  0.0829,  0.1744, -0.3081,
         0.3157,  0.2368, -0.0958, -0.3372,  0.3042,  0.4172,  0.1354,  0.1312,
        -0.1202,  0.0374, -0.3196,  0.2186, -0.4590,  0.4619,  0.0646,  0.0905,
        -0.0748, -0.2512, -0.2052,  0.3774], dtype=torch.float16)
DESIRED: (shape=torch.Size([3567, 16, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4456, -0.1087, -0.3633,  0.2491,  0.1290, -0.0518, -0.0930,  0.3945,
         0.0099, -0.3503,  0.0396, -0.3811, -0.3164,  0.0334, -0.2216, -0.4468,
        -0.3411,  0.0491,  0.0490,  0.0157, -0.1943,  0.2410,  0.3049, -0.1124,
        -0.0865, -0.4309, -0.4929,  0.3245,  0.3748, -0.3210,  0.2234,  0.3811,
         0.2297, -0.2450,  0.3223,  0.0917,  0.1149,  0.1437, -0.2472, -0.2021,
         0.4951,  0.2448, -0.4587,  0.3821,  0.2595, -0.4692, -0.0585, -0.0617,
         0.1421, -0.2837,  0.1606, -0.1503,  0.1181,  0.4399,  0.1499,  0.3469,
        -0.2256,  0.2861, -0.3074,  0.0651, -0.4138,  0.2717, -0.2175,  0.1296,
         0.3572, -0.1692, -0.0476, -0.3625,  0.0571,  0.2323, -0.1294, -0.3103,
        -0.4053,  0.3591,  0.1048, -0.4944, -0.1591,  0.0829,  0.1744, -0.3081,
         0.3157,  0.2368, -0.0958, -0.3372,  0.3042,  0.4172,  0.1354,  0.1312,
        -0.1202,  0.0374, -0.3196,  0.2186, -0.4590,  0.4619,  0.0646,  0.0905,
        -0.0748, -0.2512, -0.2052,  0.3774], dtype=torch.float16)
[Worker 0] Completed Task 1201

[Worker 0] Processing Task 1205: paddle.roll(x=Tensor([1431655766, 3],"float16"), shifts=tuple(-1,1,), axis=tuple(0,1,), )
[accuracy error] paddle.roll(x=Tensor([1431655766, 3],"float16"), shifts=tuple(-1,1,), axis=tuple(0,1,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 4294967298 (0.0%)
Greatest absolute difference: 0.2215576171875 at index (1431655765, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1431655765, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.1255,  0.4016, -0.2991,  0.0670, -0.2549,  0.1731, -0.3164,  0.1948,
         0.3696, -0.4382,  0.3958,  0.0383, -0.2517, -0.2429,  0.4951, -0.1951,
        -0.3479, -0.2764, -0.3813,  0.2327, -0.1503,  0.2239,  0.1998, -0.1333,
        -0.0628,  0.2417,  0.4849, -0.2297, -0.3762, -0.1320, -0.4919,  0.2366,
         0.1300, -0.1696, -0.2744, -0.3499, -0.1740,  0.4768,  0.3013, -0.3186,
        -0.2600,  0.0765,  0.3091,  0.3328,  0.3591, -0.4561, -0.3909,  0.0920,
         0.4138, -0.3140,  0.3818, -0.3262,  0.4224,  0.1785,  0.2981,  0.3174,
        -0.4233, -0.2484,  0.3240, -0.4475, -0.0030, -0.3586, -0.3152, -0.3840,
         0.2111, -0.0340,  0.1326,  0.4182,  0.2761, -0.0019, -0.0397, -0.3584,
         0.3726, -0.3765, -0.2612, -0.1926, -0.1777, -0.4175,  0.0263, -0.0639,
         0.4346,  0.0268, -0.2198, -0.1974, -0.4363, -0.1687, -0.2815,  0.2742,
        -0.2290, -0.0521, -0.1846,  0.0304,  0.4763,  0.4983,  0.1603,  0.0828,
        -0.2144,  0.1445, -0.3506,  0.4397], dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.1255,  0.4016, -0.2991,  0.0670, -0.2549,  0.1731, -0.3164,  0.1948,
         0.3696, -0.4382,  0.3958,  0.0383, -0.2517, -0.2429,  0.4951, -0.1951,
        -0.3479, -0.2764, -0.3813,  0.2327, -0.1503,  0.2239,  0.1998, -0.1333,
        -0.0628,  0.2417,  0.4849, -0.2297, -0.3762, -0.1320, -0.4919,  0.2366,
         0.1300, -0.1696, -0.2744, -0.3499, -0.1740,  0.4768,  0.3013, -0.3186,
        -0.2600,  0.0765,  0.3091,  0.3328,  0.3591, -0.4561, -0.3909,  0.0920,
         0.4138, -0.3140,  0.3818, -0.3262,  0.4224,  0.1785,  0.2981,  0.3174,
        -0.4233, -0.2484,  0.3240, -0.4475, -0.0030, -0.3586, -0.3152, -0.3840,
         0.2111, -0.0340,  0.1326,  0.4182,  0.2761, -0.0019, -0.0397, -0.3584,
         0.3726, -0.3765, -0.2612, -0.1926, -0.1777, -0.4175,  0.0263, -0.0639,
         0.4346,  0.0268, -0.2198, -0.1974, -0.4363, -0.1687, -0.2815,  0.2742,
        -0.2290, -0.0521, -0.1846,  0.0304,  0.4763,  0.4983,  0.1603,  0.0828,
        -0.2144,  0.1445, -0.3506,  0.4397], dtype=torch.float16)
[Worker 0] Completed Task 1205

[Worker 0] Processing Task 1209: paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=list[-1,1,], axis=list[0,1,], )
[accuracy error] paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=list[-1,1,], axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 4294967298 (0.0%)
Greatest absolute difference: 0.478515625 at index (2, 1431655764) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.3892,  0.2576,  0.4329, -0.3760, -0.0931, -0.2446, -0.2062, -0.0272,
         0.2922,  0.2413, -0.2944, -0.4399,  0.3774, -0.4641, -0.3262, -0.0731,
        -0.2101,  0.0553, -0.2849, -0.2412,  0.0705,  0.0276, -0.2499, -0.2615,
        -0.2673, -0.4866,  0.1742,  0.3584,  0.1565, -0.3911,  0.0412, -0.4470,
         0.4731, -0.4204,  0.4331, -0.4700,  0.2681,  0.4543, -0.4158, -0.4624,
        -0.1377, -0.2137,  0.4973,  0.1949,  0.2612,  0.0841, -0.4519, -0.2766,
         0.2238, -0.0434,  0.3804,  0.3752,  0.1906,  0.3569,  0.4524, -0.4404,
         0.0205,  0.3008, -0.2129, -0.3381,  0.2512,  0.3489,  0.4214,  0.3486,
         0.4502,  0.0645,  0.0612, -0.4082, -0.3894,  0.0959,  0.1237,  0.0100,
         0.1521, -0.2029, -0.4626,  0.3733,  0.0265,  0.0800,  0.0078,  0.3013,
         0.0180, -0.1980,  0.3865,  0.2615, -0.3945,  0.4219,  0.0204,  0.2852,
        -0.3831,  0.0929, -0.1428, -0.3708, -0.3308, -0.4922, -0.4966, -0.3992,
        -0.4304,  0.2203, -0.4641,  0.2351], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.3892,  0.2576,  0.4329, -0.3760, -0.0931, -0.2446, -0.2062, -0.0272,
         0.2922,  0.2413, -0.2944, -0.4399,  0.3774, -0.4641, -0.3262, -0.0731,
        -0.2101,  0.0553, -0.2849, -0.2412,  0.0705,  0.0276, -0.2499, -0.2615,
        -0.2673, -0.4866,  0.1742,  0.3584,  0.1565, -0.3911,  0.0412, -0.4470,
         0.4731, -0.4204,  0.4331, -0.4700,  0.2681,  0.4543, -0.4158, -0.4624,
        -0.1377, -0.2137,  0.4973,  0.1949,  0.2612,  0.0841, -0.4519, -0.2766,
         0.2238, -0.0434,  0.3804,  0.3752,  0.1906,  0.3569,  0.4524, -0.4404,
         0.0205,  0.3008, -0.2129, -0.3381,  0.2512,  0.3489,  0.4214,  0.3486,
         0.4502,  0.0645,  0.0612, -0.4082, -0.3894,  0.0959,  0.1237,  0.0100,
         0.1521, -0.2029, -0.4626,  0.3733,  0.0265,  0.0800,  0.0078,  0.3013,
         0.0180, -0.1980,  0.3865,  0.2615, -0.3945,  0.4219,  0.0204,  0.2852,
        -0.3831,  0.0929, -0.1428, -0.3708, -0.3308, -0.4922, -0.4966, -0.3992,
        -0.4304,  0.2203, -0.4641,  0.2351], dtype=torch.float16)
[Worker 0] Completed Task 1209

[Worker 0] Processing Task 1213: paddle.rsqrt(x=Tensor([2, 715827883, 3],"float16"), )
[accuracy error] backward  paddle.rsqrt(x=Tensor([2, 715827883, 3],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2012413 / 4294967298 (0.0%)
Greatest absolute difference: inf at index (0, 634, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 634, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 715827883, 3]), dtype=torch.float16)
First 100 elements: tensor([-7.4951e-01,  3.1289e+00,         nan,  7.0117e-01,         nan,
                nan,         nan,  2.1641e+00,  3.3066e+00,  9.1162e-01,
        -3.5718e-01,         nan,  3.2007e-01,  5.4414e+00,         nan,
                nan,  1.6052e-01,         nan,         nan,         nan,
                nan, -1.9199e+00,         nan,         nan,  8.6279e-01,
                nan, -2.0488e+00, -4.7388e-01, -3.7262e-02,         nan,
                nan,         nan,         nan, -7.9736e-01, -8.1592e-01,
                nan,         nan,         nan,         nan, -1.4502e-01,
         7.9102e-01,         nan,         nan, -7.0938e+00,         nan,
         3.2153e-01, -8.5742e-01, -6.6553e-01,         nan, -3.8750e+00,
                nan,         nan,  5.1758e-01,  3.5449e-01,  2.2766e-01,
        -3.2461e+00,         nan,  1.3945e+00,         nan, -1.0977e+00,
        -9.3994e-01,         nan,         nan,         nan,         nan,
                nan,  1.6973e+00,         nan,         nan, -4.8853e-01,
        -1.5881e-01, -1.5732e+00,         nan,         nan,         nan,
                nan,         nan, -1.0117e+00,         nan,         nan,
                nan,         nan,  3.2642e-01, -8.3672e+00,         nan,
                nan, -1.8969e+01,         nan,         nan,         nan,
                nan,         nan,  1.7383e+00, -4.4219e+01, -2.1545e-01,
                nan, -6.4844e-01,  3.0312e+00, -6.7773e-01,  2.6816e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 715827883, 3]), dtype=torch.float16)
First 100 elements: tensor([-7.4951e-01,  3.1289e+00,         nan,  7.0068e-01,         nan,
                nan,         nan,  2.1641e+00,  3.3066e+00,  9.1162e-01,
        -3.5742e-01,         nan,  3.2007e-01,  5.4414e+00,         nan,
                nan,  1.6064e-01,         nan,         nan,         nan,
                nan, -1.9189e+00,         nan,         nan,  8.6230e-01,
                nan, -2.0488e+00, -4.7388e-01, -3.7292e-02,         nan,
                nan,         nan,         nan, -7.9785e-01, -8.1543e-01,
                nan,         nan,         nan,         nan, -1.4502e-01,
         7.9102e-01,         nan,         nan, -7.0938e+00,         nan,
         3.2153e-01, -8.5742e-01, -6.6553e-01,         nan, -3.8730e+00,
                nan,         nan,  5.1807e-01,  3.5474e-01,  2.2766e-01,
        -3.2461e+00,         nan,  1.3955e+00,         nan, -1.0977e+00,
        -9.3994e-01,         nan,         nan,         nan,         nan,
                nan,  1.6982e+00,         nan,         nan, -4.8853e-01,
        -1.5881e-01, -1.5742e+00,         nan,         nan,         nan,
                nan,         nan, -1.0127e+00,         nan,         nan,
                nan,         nan,  3.2666e-01, -8.3672e+00,         nan,
                nan, -1.8984e+01,         nan,         nan,         nan,
                nan,         nan,  1.7383e+00, -4.4219e+01, -2.1545e-01,
                nan, -6.4844e-01,  3.0312e+00, -6.7773e-01,  2.6797e+00],
       dtype=torch.float16)
[Worker 0] Completed Task 1213

[Worker 0] Processing Task 1309: paddle.Tensor.bmm(Tensor([5203, 146200, 3],"float32"), Tensor([5203, 3, 2],"float32"), )
[accuracy error] backward  paddle.Tensor.bmm(Tensor([5203, 146200, 3],"float32"), Tensor([5203, 3, 2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 150 / 31218 (0.5%)
Greatest absolute difference: 0.037779927253723145 at index (4296, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 28.205547332763672 at index (3099, 2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5203, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([ -5.6077, -40.4566,  17.6887, -19.3310,  52.4842, -34.9865, -11.3864,
         29.6968,  16.4271,  16.6520,  20.1989, -29.5711,  14.3057,  37.8326,
         30.2430,   6.5214,  27.4515,  18.9236, -33.8514, -15.2523,  21.8532,
        -34.4956,  14.3926,  46.0110, -45.3887,   1.8662,  56.0910, -14.4158,
        -34.8808, -52.2767,  14.1108,  15.2477,  52.1756, -27.0956,  33.0878,
         19.0182, -67.2136,  11.2654,  40.0173,  16.4768,  45.7636, -34.1446,
         43.9746, -26.2890, -35.6371,  19.2394,  31.3142,  23.4203,  -7.4010,
        -47.1376,  17.7135,  18.4497,  39.0894,   3.3164, -53.8115,  44.4951,
         26.4068, -45.8673,   6.5974,   7.6287,  67.6246, -23.1422, -28.7622,
        -63.7916,   9.5490,  10.4247, -57.1742,  32.9002, -12.3955, -23.6123,
        -15.5512,   6.9327,   7.6515,   9.8190, -14.6795,  -5.5403,  42.4706,
         18.1179, -39.1447, -22.7769, -19.0851,  -5.6067,  21.9005,  54.8941,
         24.6059,  15.3333,  14.4346,   3.1550,  16.9343,  35.7705,  17.9990,
         -0.1943,  18.8940, -43.8011, -12.9830,   1.9587, -45.4693, -15.4415,
        -49.9543,  31.6707])
DESIRED: (shape=torch.Size([5203, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([ -5.5962, -40.4756,  17.6801, -19.3548,  52.4951, -35.0039, -11.3871,
         29.7280,  16.4254,  16.6462,  20.1819, -29.5917,  14.3003,  37.8513,
         30.2588,   6.5120,  27.4696,  18.9275, -33.8744, -15.2625,  21.8658,
        -34.5033,  14.3978,  46.0409, -45.4093,   1.8666,  56.1182, -14.4019,
        -34.8920, -52.2976,  14.1306,  15.2727,  52.2114, -27.1143,  33.0881,
         19.0314, -67.2363,  11.2687,  40.0346,  16.4707,  45.7813, -34.1518,
         44.0142, -26.3089, -35.6640,  19.2607,  31.3351,  23.4241,  -7.4039,
        -47.1536,  17.7182,  18.4742,  39.1114,   3.3071, -53.8367,  44.5098,
         26.4292, -45.8801,   6.5969,   7.6104,  67.6451, -23.1605, -28.7806,
        -63.8348,   9.5657,  10.4182, -57.1862,  32.9122, -12.4078, -23.6110,
        -15.5608,   6.9326,   7.6544,   9.8294, -14.6878,  -5.5300,  42.4738,
         18.1264, -39.1523, -22.7757, -19.0609,  -5.6151,  21.8952,  54.9079,
         24.6204,  15.3495,  14.4390,   3.1610,  16.9508,  35.7818,  18.0144,
         -0.2039,  18.9135, -43.8239, -12.9807,   1.9735, -45.4857, -15.4294,
        -49.9665,  31.6779])
[Worker 0] Completed Task 1309

[Worker 0] Processing Task 1321: paddle.Tensor.cumsum(Tensor([1, 12, 190141782],"float32"), 2, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 12, 190141782],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1069295 / 2281701384 (0.0%)
Greatest absolute difference: 0.1330443024635315 at index (0, 4, 127914350) (up to 0.01 allowed)
Greatest relative difference: 10728.1865234375 at index (0, 4, 127989153) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 12, 190141782]), dtype=torch.float32)
First 100 elements: tensor([-0.4589, -0.2462, -0.6681, -0.1851, -0.2513, -0.6317, -1.1006, -0.8751,
        -0.8524, -0.9050, -0.6308, -0.2895, -0.3045, -0.1393, -0.4792, -0.4254,
        -0.0694,  0.4052,  0.0424, -0.0556,  0.3370, -0.1343, -0.2787, -0.2342,
        -0.5062, -0.3863, -0.7464, -1.1864, -1.6300, -1.6949, -2.1117, -2.0106,
        -1.8432, -1.6034, -2.0317, -2.3320, -2.1361, -1.9291, -1.4852, -1.8764,
        -1.4811, -1.8514, -1.9527, -2.1313, -1.9454, -1.6433, -1.1508, -0.7592,
        -0.8964, -1.0375, -1.4984, -1.4724, -1.8429, -1.6399, -1.8164, -2.1719,
        -2.2262, -1.7638, -1.2724, -1.1706, -1.4035, -1.8790, -1.3882, -1.6496,
        -1.3155, -1.0198, -1.4230, -1.3276, -0.8853, -1.1644, -1.4762, -1.3428,
        -1.2475, -1.5237, -1.6037, -1.3140, -1.2811, -1.4143, -1.6583, -1.7813,
        -2.2415, -2.5892, -2.7918, -2.6340, -2.8167, -2.7168, -2.4892, -2.5322,
        -2.5098, -2.3980, -2.6220, -2.7368, -2.8772, -2.5450, -2.9231, -2.7528,
        -2.6155, -2.3263, -2.2101, -2.1735])
DESIRED: (shape=torch.Size([1, 12, 190141782]), dtype=torch.float32)
First 100 elements: tensor([-0.4589, -0.2462, -0.6681, -0.1851, -0.2513, -0.6317, -1.1006, -0.8751,
        -0.8524, -0.9050, -0.6308, -0.2895, -0.3045, -0.1393, -0.4792, -0.4254,
        -0.0694,  0.4052,  0.0424, -0.0556,  0.3370, -0.1343, -0.2787, -0.2342,
        -0.5062, -0.3863, -0.7464, -1.1864, -1.6300, -1.6949, -2.1117, -2.0106,
        -1.8432, -1.6034, -2.0317, -2.3320, -2.1361, -1.9291, -1.4852, -1.8764,
        -1.4811, -1.8514, -1.9527, -2.1313, -1.9454, -1.6433, -1.1508, -0.7592,
        -0.8964, -1.0375, -1.4984, -1.4724, -1.8429, -1.6399, -1.8164, -2.1719,
        -2.2262, -1.7638, -1.2724, -1.1706, -1.4035, -1.8790, -1.3882, -1.6496,
        -1.3155, -1.0198, -1.4230, -1.3276, -0.8853, -1.1644, -1.4762, -1.3428,
        -1.2475, -1.5237, -1.6037, -1.3140, -1.2811, -1.4143, -1.6583, -1.7813,
        -2.2415, -2.5892, -2.7918, -2.6340, -2.8167, -2.7168, -2.4892, -2.5322,
        -2.5098, -2.3980, -2.6220, -2.7368, -2.8772, -2.5450, -2.9231, -2.7528,
        -2.6155, -2.3263, -2.2101, -2.1735])
[Worker 0] Completed Task 1321

[Worker 0] Processing Task 1325: paddle.Tensor.cumsum(Tensor([22817014, 100],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.cumsum(Tensor([22817014, 100],"int64"), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 70.012695GB memory has been allocated and available memory is only 9.172180GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 1325

[Worker 0] Processing Task 1331: paddle.Tensor.diff(x=Tensor([10, 429496730],"float16"), axis=0, prepend=Tensor([4, 429496730],"float16"), append=Tensor([4, 429496730],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([10, 429496730],"float16"), axis=0, prepend=Tensor([4, 429496730],"float16"), append=Tensor([4, 429496730],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 7154565445 / 7301444410 (98.0%)
Greatest absolute difference: 1.0 at index (0, 3857406) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([17, 429496730]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([17, 429496730]), dtype=torch.float16)
First 100 elements: tensor([ 0.0631,  0.2460, -0.2297, -0.4551,  0.5454,  0.5718,  0.5225, -0.5566,
        -0.1033, -0.5762,  0.0615, -0.0208, -0.8213,  0.1072,  0.7598, -0.2234,
        -0.5815, -0.1433,  0.1951,  0.1168,  0.6646, -0.4253, -0.1368,  0.7920,
        -0.1636, -0.0413, -0.4160,  0.0886, -0.6196, -0.0048, -0.1160,  0.2181,
         0.5630, -0.6904,  0.3667,  0.7969, -0.0522, -0.1008,  0.2185, -0.0251,
        -0.2839, -0.3247,  0.6704, -0.3086,  0.0652, -0.2018, -0.1575, -0.2336,
         0.2025, -0.0297,  0.8789,  0.0127, -0.5444,  0.0771, -0.2109, -0.4043,
         0.0508, -0.4187, -0.0537, -0.2566, -0.6133,  0.9346,  0.6074,  0.6670,
         0.4446, -0.3159,  0.0582, -0.3381,  0.4294, -0.3333, -0.5713,  0.2288,
         0.2001,  0.3423, -0.4497,  0.2429, -0.1770,  0.0950,  0.6436,  0.4023,
         0.1874, -0.1100, -0.6260,  0.0524,  0.3813,  0.2915, -0.4436, -0.0923,
         0.4705,  0.8320,  0.5254,  0.1460, -0.6694,  0.3271, -0.7241, -0.2544,
        -0.4858, -0.0686, -0.2185, -0.4331], dtype=torch.float16)
[Worker 0] Completed Task 1331

[Worker 0] Processing Task 1337: paddle.Tensor.diff(x=Tensor([2281701379],"int32"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([2281701379],"int32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281684029 / 2281701378 (100.0%)
Greatest absolute difference: 131069 at index (1882518314,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.int32)
First 100 elements: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0], dtype=torch.int32)
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.int32)
First 100 elements: tensor([  40388,  -80643,  -13780,   94829,  -83168,   43073,  -47611,   -3094,
          20059,   67914,  -46336,   65274,   -9251,  -48051,   64181,  -18564,
         -29405,  -79630,  114963,  -98063,   53600,  -15462,   61302,  -32481,
         -17156,  -51970,   57610,   -8683,   -1459,  -10695,  -51533,  111185,
         -44322,   41551,  -84805,    4310,   72923,    6456,    4352,  -95620,
          90045,   23406,  -61070,   23873,   27993,  -51943,  -49004,    3879,
         -17600,   81584,  -74049,   37380,   -8029,  -31835,   77452,  -87026,
          84927,  -74881,   45159,   50784,  -56291,  -27684,   64400,  -44730,
         -32535,  104523,   -7827,    4289,  -70542,  -17953,   43355,   22296,
           1415,  -23020,  -17821,   36152,  -49111,   18618,  -47501,     964,
          -1570,  115977,  -61846,   32751,  -16671,  -50840,   -5411,   10284,
          40439,  -25778,   73754, -105005,   41473,  -25558,   50105,   21496,
          14770,  -52298,    6662,   15134], dtype=torch.int32)
[Worker 0] Completed Task 1337

[Worker 0] Processing Task 1341: paddle.Tensor.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208558304 / 4294967304 (98.0%)
Greatest absolute difference: 1.0 at index (497619,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967304]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967304]), dtype=torch.float16)
First 100 elements: tensor([-0.0403, -0.2202,  0.4404, -0.1801, -0.0403, -0.2202,  0.4404, -0.7007,
         0.1736, -0.1294,  0.4280, -0.1061,  0.1279,  0.1748, -0.6860,  0.7119,
        -0.3574, -0.4766,  0.1953,  0.7383, -0.7471, -0.0962,  0.0715,  0.0813,
         0.4277, -0.3828, -0.2311,  0.5811, -0.3330,  0.3572,  0.0178,  0.2432,
        -0.5479, -0.3135,  0.2443, -0.0978,  0.4663, -0.1066, -0.6221,  0.2175,
        -0.0754,  0.1803,  0.6465, -0.1755, -0.4751, -0.0861,  0.3364, -0.3950,
         0.6514,  0.0264, -0.0500, -0.7002,  0.4829, -0.5479,  0.1421,  0.6958,
         0.0320,  0.0085, -0.2439, -0.5049,  0.6436, -0.7407,  0.7217,  0.0259,
        -0.7715,  0.1991, -0.1102,  0.0435,  0.3123,  0.2141, -0.2451, -0.3501,
         0.8022, -0.1421, -0.1436, -0.1722, -0.3186,  0.3564, -0.3745,  0.1152,
         0.6338, -0.5503, -0.2397,  0.2249,  0.1287,  0.4985, -0.4082, -0.2461,
         0.0225,  0.2242, -0.1956, -0.1128, -0.1548,  0.2073,  0.1770,  0.3262,
        -0.2438,  0.4460, -0.6611,  0.3447], dtype=torch.float16)
[Worker 0] Completed Task 1341

[Worker 0] Processing Task 1347: paddle.Tensor.lerp(x=Tensor([214748365, 5, 4],"float16"), y=Tensor([214748365, 5, 4],"float16"), weight=0.5, )
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([214748365, 5, 4],"float16"), y=Tensor([214748365, 5, 4],"float16"), weight=0.5, ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[[-0.0878, -0.0411,  0.0781, -0.2412],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]],

        ...,

        [[ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]], dtype=torch.float16),
    expected=tensor([[[-0.0878, -0.0411,  0.0781, -0.2412],
         [-0.1272, -0.1783,  0.2150,  0.1578],
         [-0.1686, -0.1558, -0.0573, -0.0784],
         [ 0.0803, -0.1840, -0.0797, -0.0408],
         [-0.1112,  0.1952, -0.0560,  0.0723]],

        [[-0.0888, -0.2247,  0.1206,  0.2157],
         [ 0.1164,  0.1295, -0.0771, -0.1169],
         [ 0.2172,  0.0564,  0.0126,  0.2158],
         [ 0.1517, -0.1807, -0.0667,  0.0917],
         [ 0.0382,  0.1324, -0.1747, -0.0681]],

        [[ 0.0452,  0.0477, -0.1307, -0.0937],
         [ 0.0402,  0.1501, -0.1600, -0.0617],
         [ 0.1844,  0.1144,  0.1360,  0.1082],
         [-0.1339, -0.1493, -0.1222, -0.0944],
         [-0.0624,  0.2448,  0.1285, -0.2493]],

        ...,

        [[ 0.1583, -0.2065, -0.0551,  0.2424],
         [-0.0313, -0.2402, -0.1128,  0.1520],
         [-0.0699,  0.1704,  0.2051,  0.2463],
         [-0.1874, -0.0468, -0.0847,  0.1582],
         [ 0.0242,  0.1675,  0.0303, -0.1654]],

        [[ 0.2407, -0.2496, -0.0046, -0.1213],
         [ 0.1205, -0.1688, -0.1958, -0.1631],
         [-0.1963, -0.2491, -0.1390, -0.2297],
         [-0.0217,  0.1032, -0.0274,  0.0477],
         [ 0.1248, -0.1125,  0.0334, -0.2393]],

        [[-0.1938,  0.1310,  0.1619, -0.1586],
         [ 0.0968, -0.1329,  0.1799, -0.0351],
         [-0.1428,  0.1997, -0.1838, -0.1028],
         [-0.1364,  0.2104,  0.1074,  0.2148],
         [ 0.2432, -0.1963,  0.1997, -0.0470]]], dtype=torch.float16),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 0] Completed Task 1347

[Worker 0] Processing Task 1350: paddle.Tensor.lerp(x=Tensor([4, 1073741825],"float16"), y=Tensor([4, 1073741825],"float16"), weight=0.5, )
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 1073741825],"float16"), y=Tensor([4, 1073741825],"float16"), weight=0.5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4121342269 / 4294967300 (96.0%)
Greatest absolute difference: 0.25 at index (0, 3373) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 1073741825]), dtype=torch.float16)
First 100 elements: tensor([-0.0878, -0.0411,  0.0781, -0.2412,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 1073741825]), dtype=torch.float16)
First 100 elements: tensor([-0.0878, -0.0411,  0.0781, -0.2412, -0.1272, -0.1783,  0.2150,  0.1578,
        -0.1686, -0.1558, -0.0573, -0.0784,  0.0803, -0.1840, -0.0797, -0.0408,
        -0.1112,  0.1952, -0.0560,  0.0723, -0.0888, -0.2247,  0.1206,  0.2157,
         0.1164,  0.1295, -0.0771, -0.1169,  0.2172,  0.0564,  0.0126,  0.2158,
         0.1517, -0.1807, -0.0667,  0.0917,  0.0382,  0.1324, -0.1747, -0.0681,
         0.0452,  0.0477, -0.1307, -0.0937,  0.0402,  0.1501, -0.1600, -0.0617,
         0.1844,  0.1144,  0.1360,  0.1082, -0.1339, -0.1493, -0.1222, -0.0944,
        -0.0624,  0.2448,  0.1285, -0.2493,  0.0835,  0.1786,  0.1733,  0.0972,
         0.2019, -0.0408,  0.1378, -0.0020, -0.1648, -0.1882,  0.0735,  0.1322,
         0.0230,  0.0760, -0.2473, -0.2296, -0.2400,  0.1669,  0.1487,  0.2300,
         0.0234, -0.2042, -0.0123, -0.0599, -0.0936,  0.0356, -0.1002, -0.1973,
         0.0834,  0.1870, -0.0144, -0.0269,  0.1432,  0.1759, -0.2494,  0.2340,
         0.0708,  0.2374,  0.0416, -0.0723], dtype=torch.float16)
[Worker 0] Completed Task 1350

[Worker 0] Processing Task 1356: paddle.Tensor.lerp(x=Tensor([4, 5, 71582789, 3],"float16"), y=Tensor([4, 5, 71582789, 3],"float16"), weight=0.0, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.16 GiB is free. Process 20592 has 74.02 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 1356: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.16 GiB is free. Process 20592 has 74.02 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 1356: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.16 GiB is free. Process 20592 has 74.02 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 1358: paddle.Tensor.lerp(x=Tensor([4, 5, 71582789, 3],"float16"), y=Tensor([4, 5, 71582789, 3],"float16"), weight=1.0, )
W0522 19:26:56.920477 47188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:26:56.921527 47188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 5, 71582789, 3],"float16"), y=Tensor([4, 5, 71582789, 3],"float16"), weight=1.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208158656 / 4294967340 (98.0%)
Greatest absolute difference: 0.5 at index (0, 0, 285, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 14, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 5, 71582789, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.0201,  0.1191, -0.0827,  0.1686,  0.0080,  0.1490,  0.1674,  0.4971,
        -0.3921,  0.3848,  0.1788, -0.1810,  0.2874, -0.4778,  0.2690,  0.2876,
        -0.3923,  0.4644, -0.0311,  0.0286,  0.1270, -0.2983, -0.2319,  0.0201,
         0.0862,  0.4783,  0.2864, -0.2303, -0.2448, -0.3760, -0.3350, -0.4099,
        -0.3682,  0.3574, -0.0239, -0.2339, -0.0709, -0.4800,  0.2705, -0.1538,
         0.2739, -0.4333, -0.3066,  0.0547,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 5, 71582789, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.0201,  0.1191, -0.0827,  0.1686,  0.0080,  0.1490,  0.1674,  0.4971,
        -0.3921,  0.3848,  0.1788, -0.1810,  0.2874, -0.4778,  0.2690,  0.2876,
        -0.3923,  0.4644, -0.0311,  0.0286,  0.1270, -0.2983, -0.2319,  0.0201,
         0.0862,  0.4783,  0.2864, -0.2303, -0.2448, -0.3760, -0.3350, -0.4099,
        -0.3682,  0.3574, -0.0239, -0.2339, -0.0709, -0.4800,  0.2705, -0.1538,
         0.2739, -0.4333, -0.3066,  0.0547,  0.0481,  0.0547,  0.4995, -0.4463,
         0.2935, -0.3398, -0.0174,  0.2416, -0.2091,  0.0594, -0.0532,  0.0096,
        -0.2671, -0.1438,  0.3352, -0.3972,  0.4902,  0.4309,  0.0793,  0.2024,
         0.1126, -0.2822,  0.0224,  0.4294, -0.3606, -0.4961,  0.0451,  0.1860,
        -0.2098,  0.2749, -0.3523,  0.3232,  0.4592, -0.0165,  0.2666, -0.1753,
         0.1979,  0.2003, -0.0359, -0.4832, -0.2766, -0.3938,  0.3679,  0.1277,
         0.0634, -0.0407,  0.0778, -0.1120, -0.0555,  0.1187, -0.1667,  0.4561,
        -0.0483,  0.4524,  0.3074,  0.4834], dtype=torch.float16)
[Worker 0] Completed Task 1358

[Worker 0] Processing Task 1366: paddle.Tensor.lerp(x=Tensor([858993460, 5],"float16"), y=Tensor([1],"float16"), weight=0.2, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 33883 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 1366: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 33883 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 1366: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 33883 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 1367: paddle.Tensor.lerp(x=Tensor([858993460, 5],"float16"), y=Tensor([858993460, 5],"float16"), weight=0.5, )
W0522 19:29:36.470996 47739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:29:36.472317 47739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([858993460, 5],"float16"), y=Tensor([858993460, 5],"float16"), weight=0.5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4121368993 / 4294967300 (96.0%)
Greatest absolute difference: 0.25 at index (99, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([858993460, 5]), dtype=torch.float16)
First 100 elements: tensor([-0.1049,  0.0856, -0.0947, -0.0071,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([858993460, 5]), dtype=torch.float16)
First 100 elements: tensor([-0.1049,  0.0856, -0.0947, -0.0071,  0.1593, -0.0702,  0.0350,  0.1448,
         0.1135, -0.1240, -0.1688, -0.1445, -0.0910,  0.0059,  0.0203, -0.1680,
         0.2440, -0.1028,  0.2253, -0.1016,  0.1796, -0.1329,  0.0689,  0.1638,
        -0.1208,  0.1318, -0.1100, -0.0252,  0.1395,  0.0204, -0.1281, -0.0668,
         0.1395, -0.1489, -0.1086, -0.0184, -0.0289, -0.0875, -0.2184,  0.1508,
         0.0938, -0.0851,  0.1383,  0.0240,  0.1821, -0.2466,  0.0730, -0.1892,
        -0.0594, -0.0057,  0.0287,  0.1896, -0.1266, -0.1357, -0.0468,  0.0282,
         0.1516, -0.1674,  0.0874, -0.1925, -0.0967,  0.2175, -0.0759,  0.2007,
        -0.0307,  0.1953,  0.0502, -0.1203,  0.1589, -0.2004, -0.0904,  0.1777,
        -0.0581, -0.2247, -0.1705,  0.0311, -0.1108, -0.1947, -0.0591,  0.0637,
        -0.1727, -0.1508,  0.0880,  0.1505, -0.1624, -0.0844,  0.2479, -0.1755,
        -0.1366, -0.1914,  0.0205,  0.1959,  0.2086, -0.1189, -0.0735, -0.1591,
        -0.2041,  0.0084, -0.0467, -0.1013], dtype=torch.float16)
[Worker 0] Completed Task 1367

[Worker 0] Processing Task 1372: paddle.Tensor.logit(x=Tensor([4, 107374183, 2, 5],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([4, 107374183, 2, 5],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147494061 / 4294967320 (50.0%)
Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 107374183, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6465e+00,  0.0000e+00,
         1.8506e+00,  0.0000e+00,  0.0000e+00,  3.5977e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.3594e+01,  1.8594e+00,
         0.0000e+00,  6.3281e-01,  0.0000e+00,  0.0000e+00,  5.0098e-01,
        -1.8057e+00,  0.0000e+00, -9.0576e-01, -5.6793e-02,  1.2822e+00,
        -5.7422e-01,  0.0000e+00,  4.5508e+00,  0.0000e+00, -3.5488e+00,
         0.0000e+00, -1.1641e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -1.4785e+00,  2.8418e+00, -8.2861e-01,  0.0000e+00,  0.0000e+00,
         5.8672e+00, -3.0273e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -9.3018e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  1.5771e+00, -1.6797e+00, -2.9844e+00,
        -3.3276e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0117e+00,  1.6553e+00,
        -3.4805e+00,  6.3770e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         7.0264e-01,  0.0000e+00,  0.0000e+00, -2.6266e+01,  0.0000e+00,
         0.0000e+00,  1.2158e+00, -7.0820e+00,  0.0000e+00,  0.0000e+00,
        -1.4521e+00,  2.1641e+00,  0.0000e+00,  1.6230e+00, -2.5610e-01,
         0.0000e+00,  1.5190e+03, -1.0605e+00,  4.9844e+00,  0.0000e+00,
         0.0000e+00,  6.2383e+00,  0.0000e+00, -2.6523e+00, -1.5148e+01,
         0.0000e+00, -1.4980e+00, -3.3516e+00,  0.0000e+00,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 107374183, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([        nan,         nan,         nan, -1.6465e+00,         nan,
         1.8506e+00,         nan,         nan,  3.5977e+00,         nan,
                nan,         nan,         nan, -4.3594e+01,  1.8594e+00,
                nan,  6.3281e-01,         nan,         nan,  5.0098e-01,
        -1.8057e+00,         nan, -9.0576e-01, -5.6793e-02,  1.2822e+00,
        -5.7422e-01,         nan,  4.5508e+00,         nan, -3.5488e+00,
                nan, -1.1641e+00,         nan,         nan,         nan,
        -1.4785e+00,  2.8418e+00, -8.2861e-01,         nan,         nan,
         5.8672e+00, -3.0273e+00,         nan,         nan,         nan,
                nan, -9.3018e-01,         nan,         nan,         nan,
                nan,         nan,  1.5771e+00, -1.6797e+00, -2.9844e+00,
        -3.3276e-01,         nan,         nan,         nan,         nan,
                nan,         nan,         nan,  1.0117e+00,  1.6553e+00,
        -3.4805e+00,  6.3770e-01,         nan,         nan,         nan,
         7.0264e-01,         nan,         nan, -2.6266e+01,         nan,
                nan,  1.2158e+00, -7.0820e+00,         nan,         nan,
        -1.4521e+00,  2.1641e+00,         nan,  1.6230e+00, -2.5610e-01,
                nan,  1.5190e+03, -1.0605e+00,  4.9844e+00,         nan,
                nan,  6.2383e+00,         nan, -2.6523e+00, -1.5148e+01,
                nan, -1.4980e+00, -3.3516e+00,         nan,         nan],
       dtype=torch.float16)
[Worker 0] Completed Task 1372

[Worker 0] Processing Task 1376: paddle.Tensor.logit(x=Tensor([4, 536870913, 2],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([4, 536870913, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147494048 / 4294967304 (50.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 536870913, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0088e+00,  0.0000e+00,
         6.8506e-01,  0.0000e+00,  0.0000e+00,  2.5684e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.7750e+01, -2.0645e+00,
         0.0000e+00, -8.0615e-01,  0.0000e+00,  0.0000e+00, -1.4980e+00,
         4.2031e+00,  0.0000e+00,  2.1562e+00, -8.1641e-01,  1.4453e+00,
        -1.0879e+00,  0.0000e+00,  5.1484e+00,  0.0000e+00,  3.7754e+00,
         0.0000e+00, -2.0288e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -5.8789e-01,  1.6240e+00, -1.2002e+00,  0.0000e+00,  0.0000e+00,
        -9.4531e-01, -1.9922e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  1.1699e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00, -6.7090e-01, -6.3843e-02,  7.8711e-01,
         3.4375e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00, -8.1094e+00, -8.7891e-01,
         3.0703e+00, -6.6357e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         1.2305e+00,  0.0000e+00,  0.0000e+00, -3.8781e+01,  0.0000e+00,
         0.0000e+00, -4.6606e-01, -9.5078e+00,  0.0000e+00,  0.0000e+00,
        -1.6650e+00, -1.9365e+00,  0.0000e+00,  5.1514e-01, -1.4414e+00,
         0.0000e+00,  2.6640e+03,  1.3262e+00, -5.0898e+00,  0.0000e+00,
         0.0000e+00, -6.1602e+00,  0.0000e+00, -2.2578e+00,  1.8252e+00,
         0.0000e+00,  2.8184e+00, -2.0469e+00,  0.0000e+00,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 536870913, 2]), dtype=torch.float16)
First 100 elements: tensor([        nan,         nan,         nan,  1.0088e+00,         nan,
         6.8506e-01,         nan,         nan,  2.5684e+00,         nan,
                nan,         nan,         nan, -4.7750e+01, -2.0645e+00,
                nan, -8.0615e-01,         nan,         nan, -1.4980e+00,
         4.2031e+00,         nan,  2.1562e+00, -8.1641e-01,  1.4453e+00,
        -1.0879e+00,         nan,  5.1484e+00,         nan,  3.7754e+00,
                nan, -2.0288e-01,         nan,         nan,         nan,
        -5.8789e-01,  1.6240e+00, -1.2002e+00,         nan,         nan,
        -9.4531e-01, -1.9922e+00,         nan,         nan,         nan,
                nan,  1.1699e+00,         nan,         nan,         nan,
                nan,         nan, -6.7090e-01, -6.3843e-02,  7.8711e-01,
         3.4375e+00,         nan,         nan,         nan,         nan,
                nan,         nan,         nan, -8.1094e+00, -8.7891e-01,
         3.0703e+00, -6.6357e-01,         nan,         nan,         nan,
         1.2305e+00,         nan,         nan, -3.8781e+01,         nan,
                nan, -4.6606e-01, -9.5078e+00,         nan,         nan,
        -1.6650e+00, -1.9365e+00,         nan,  5.1514e-01, -1.4414e+00,
                nan,  2.6640e+03,  1.3262e+00, -5.0898e+00,         nan,
                nan, -6.1602e+00,         nan, -2.2578e+00,  1.8252e+00,
                nan,  2.8184e+00, -2.0469e+00,         nan,         nan],
       dtype=torch.float16)
[Worker 0] Completed Task 1376

[Worker 0] Processing Task 1380: paddle.Tensor.nansum(Tensor([477218589, 3, 3],"float16"), axis=0, keepdim=True, )
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 1551: paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([171798692, 5, 1, 5],"float16"), list[list[3,1,2,],list[1,2,3,],], )
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 1663: paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([171798692, 5, 1, 5],"float16"), list[list[1,2,0,],list[1,3,2,],], )
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 1679: paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[1,3,],list[1,0,],], )
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 1774: paddle.tensordot(Tensor([5, 171798692, 5, 1],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[2,3,0,],list[1,2,0,],], )
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2009: paddle.tensordot(Tensor([5, 5, 5, 34359739],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[1,2,0,],list[1,2,3,],], )
[accuracy error] backward  paddle.tensordot(Tensor([5, 5, 5, 34359739],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[1,2,0,],list[1,2,3,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 125 (0.8%)
Greatest absolute difference: 0.2578125 at index (0, 3, 0, 2) (up to 0.01 allowed)
Greatest relative difference: 0.06494140625 at index (0, 3, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5, 1, 5]), dtype=torch.float16)
First 100 elements: tensor([ -856.5000, -1612.0000,   377.2500, -1670.0000, -1366.0000,   259.7500,
         1340.0000,  1491.0000,  2520.0000,   301.2500,  -497.0000,  -784.5000,
          467.2500,  -934.5000, -1654.0000,  -751.0000,  1650.0000,     3.7109,
        -2222.0000,   309.2500,   352.2500,  -180.3750,  -197.7500,   610.0000,
          -61.2500,   153.2500,   539.0000,   776.5000,  1165.0000,   735.5000,
        -1060.0000,  1526.0000,   777.5000,  -410.5000,  -512.0000,   463.5000,
          927.5000,  -652.5000,  -449.7500,   -26.7188,   -66.5625, -1150.0000,
         1734.0000,  -555.0000,  -367.7500,  -289.7500,   835.5000,  -419.2500,
         -938.0000,  -485.5000,  -212.0000, -1879.0000, -2162.0000,  -103.8750,
        -1259.0000, -1384.0000,   728.0000,   289.0000,  1608.0000,  -287.5000,
           68.2500, -1692.0000,   909.0000, -1094.0000,   661.0000,   629.0000,
          470.0000,  -307.5000,   -61.0000,   962.0000,  1424.0000, -1435.0000,
         -795.0000,  1217.0000,   198.8750,  2916.0000, -1526.0000,  2866.0000,
         1180.0000, -1067.0000,  1168.0000,  -569.0000,    -9.4297,  -682.0000,
        -1793.0000,   109.0000,  1673.0000,   127.8750, -1210.0000,   -88.2500,
        -1525.0000,    92.6875, -1495.0000, -1180.0000,  -686.0000, -1392.0000,
         1836.0000,   633.0000,  -164.1250,  -906.5000], dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 5, 1, 5]), dtype=torch.float16)
First 100 elements: tensor([ -856.5000, -1612.0000,   377.5000, -1670.0000, -1366.0000,   259.7500,
         1341.0000,  1491.0000,  2520.0000,   301.2500,  -497.0000,  -784.5000,
          467.2500,  -934.5000, -1654.0000,  -751.0000,  1651.0000,     3.9688,
        -2222.0000,   309.2500,   352.2500,  -180.2500,  -197.8750,   610.0000,
          -61.0625,   153.2500,   539.0000,   776.5000,  1165.0000,   735.5000,
        -1060.0000,  1527.0000,   777.5000,  -410.5000,  -512.0000,   463.7500,
          927.5000,  -653.0000,  -449.5000,   -26.9219,   -66.6250, -1150.0000,
         1734.0000,  -555.0000,  -368.0000,  -290.0000,   836.0000,  -419.2500,
         -937.5000,  -485.5000,  -211.8750, -1879.0000, -2162.0000,  -103.8125,
        -1259.0000, -1384.0000,   728.0000,   288.7500,  1607.0000,  -287.5000,
           68.3125, -1692.0000,   909.0000, -1095.0000,   661.5000,   629.0000,
          470.2500,  -307.2500,   -60.9062,   962.0000,  1424.0000, -1435.0000,
         -795.0000,  1217.0000,   199.0000,  2916.0000, -1526.0000,  2866.0000,
         1180.0000, -1067.0000,  1168.0000,  -569.0000,    -9.4141,  -682.0000,
        -1793.0000,   109.3125,  1673.0000,   127.8750, -1210.0000,   -88.3125,
        -1525.0000,    92.6875, -1495.0000, -1180.0000,  -686.0000, -1392.0000,
         1836.0000,   633.0000,  -164.3750,  -906.5000], dtype=torch.float16)
[Worker 0] Completed Task 2009

[Worker 0] Processing Task 2103: paddle.tril(Tensor([1, 1, 2281701379, 1],"float32"), )
[accuracy error] paddle.tril(Tensor([1, 1, 2281701379, 1],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 131533627 / 2281701379 (5.8%)
Greatest absolute difference: 0.5 at index (0, 0, 2158593791, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 2147483648, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 2281701379, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.1415,  0.4548, -0.2494,  0.2761,  0.4474, -0.0838, -0.1689, -0.0283,
         0.4270, -0.3176,  0.2318,  0.1521, -0.4215, -0.0016, -0.0149,  0.2369,
         0.2913, -0.4010,  0.1253, -0.1391,  0.0979, -0.1670, -0.1232,  0.2076,
        -0.3408,  0.3418, -0.2666,  0.0463,  0.0272,  0.2928,  0.3020,  0.1028,
        -0.4588,  0.4113,  0.3994,  0.3695, -0.3745,  0.2621, -0.4565, -0.0634,
        -0.4558,  0.3122, -0.0086,  0.4070, -0.3193,  0.3399, -0.2748,  0.0265,
         0.2710, -0.3658,  0.2977, -0.4207, -0.0855,  0.2817, -0.3967,  0.0710,
        -0.1520,  0.3490, -0.0723,  0.4523, -0.1199, -0.2915, -0.2713,  0.4349,
         0.1699,  0.4543,  0.2816, -0.2470,  0.1089,  0.3956,  0.0764, -0.4978,
        -0.0634,  0.0367,  0.1019, -0.1698,  0.3574, -0.2173, -0.4266, -0.1223,
         0.0351, -0.0722, -0.3297,  0.3975,  0.2914, -0.3383,  0.3192,  0.1577,
         0.1689, -0.1410, -0.2772, -0.1667,  0.2361,  0.3592, -0.0333,  0.2139,
        -0.0716, -0.3276,  0.3362,  0.1061])
DESIRED: (shape=torch.Size([1, 1, 2281701379, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.1415,  0.4548, -0.2494,  0.2761,  0.4474, -0.0838, -0.1689, -0.0283,
         0.4270, -0.3176,  0.2318,  0.1521, -0.4215, -0.0016, -0.0149,  0.2369,
         0.2913, -0.4010,  0.1253, -0.1391,  0.0979, -0.1670, -0.1232,  0.2076,
        -0.3408,  0.3418, -0.2666,  0.0463,  0.0272,  0.2928,  0.3020,  0.1028,
        -0.4588,  0.4113,  0.3994,  0.3695, -0.3745,  0.2621, -0.4565, -0.0634,
        -0.4558,  0.3122, -0.0086,  0.4070, -0.3193,  0.3399, -0.2748,  0.0265,
         0.2710, -0.3658,  0.2977, -0.4207, -0.0855,  0.2817, -0.3967,  0.0710,
        -0.1520,  0.3490, -0.0723,  0.4523, -0.1199, -0.2915, -0.2713,  0.4349,
         0.1699,  0.4543,  0.2816, -0.2470,  0.1089,  0.3956,  0.0764, -0.4978,
        -0.0634,  0.0367,  0.1019, -0.1698,  0.3574, -0.2173, -0.4266, -0.1223,
         0.0351, -0.0722, -0.3297,  0.3975,  0.2914, -0.3383,  0.3192,  0.1577,
         0.1689, -0.1410, -0.2772, -0.1667,  0.2361,  0.3592, -0.0333,  0.2139,
        -0.0716, -0.3276,  0.3362,  0.1061])
[Worker 0] Completed Task 2103

[Worker 0] Processing Task 2106: paddle.tril(Tensor([114085069, 20, 1],"float32"), 0, )
[accuracy error] paddle.tril(Tensor([114085069, 20, 1],"float32"), 0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 131533628 / 2281701380 (5.8%)
Greatest absolute difference: 0.5 at index (107929689, 11, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (107374182, 8, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([114085069, 20, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.1415,  0.4548, -0.2494,  0.2761,  0.4474, -0.0838, -0.1689, -0.0283,
         0.4270, -0.3176,  0.2318,  0.1521, -0.4215, -0.0016, -0.0149,  0.2369,
         0.2913, -0.4010,  0.1253, -0.1391,  0.0979, -0.1670, -0.1232,  0.2076,
        -0.3408,  0.3418, -0.2666,  0.0463,  0.0272,  0.2928,  0.3020,  0.1028,
        -0.4588,  0.4113,  0.3994,  0.3695, -0.3745,  0.2621, -0.4565, -0.0634,
        -0.4558,  0.3122, -0.0086,  0.4070, -0.3193,  0.3399, -0.2748,  0.0265,
         0.2710, -0.3658,  0.2977, -0.4207, -0.0855,  0.2817, -0.3967,  0.0710,
        -0.1520,  0.3490, -0.0723,  0.4523, -0.1199, -0.2915, -0.2713,  0.4349,
         0.1699,  0.4543,  0.2816, -0.2470,  0.1089,  0.3956,  0.0764, -0.4978,
        -0.0634,  0.0367,  0.1019, -0.1698,  0.3574, -0.2173, -0.4266, -0.1223,
         0.0351, -0.0722, -0.3297,  0.3975,  0.2914, -0.3383,  0.3192,  0.1577,
         0.1689, -0.1410, -0.2772, -0.1667,  0.2361,  0.3592, -0.0333,  0.2139,
        -0.0716, -0.3276,  0.3362,  0.1061])
DESIRED: (shape=torch.Size([114085069, 20, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.1415,  0.4548, -0.2494,  0.2761,  0.4474, -0.0838, -0.1689, -0.0283,
         0.4270, -0.3176,  0.2318,  0.1521, -0.4215, -0.0016, -0.0149,  0.2369,
         0.2913, -0.4010,  0.1253, -0.1391,  0.0979, -0.1670, -0.1232,  0.2076,
        -0.3408,  0.3418, -0.2666,  0.0463,  0.0272,  0.2928,  0.3020,  0.1028,
        -0.4588,  0.4113,  0.3994,  0.3695, -0.3745,  0.2621, -0.4565, -0.0634,
        -0.4558,  0.3122, -0.0086,  0.4070, -0.3193,  0.3399, -0.2748,  0.0265,
         0.2710, -0.3658,  0.2977, -0.4207, -0.0855,  0.2817, -0.3967,  0.0710,
        -0.1520,  0.3490, -0.0723,  0.4523, -0.1199, -0.2915, -0.2713,  0.4349,
         0.1699,  0.4543,  0.2816, -0.2470,  0.1089,  0.3956,  0.0764, -0.4978,
        -0.0634,  0.0367,  0.1019, -0.1698,  0.3574, -0.2173, -0.4266, -0.1223,
         0.0351, -0.0722, -0.3297,  0.3975,  0.2914, -0.3383,  0.3192,  0.1577,
         0.1689, -0.1410, -0.2772, -0.1667,  0.2361,  0.3592, -0.0333,  0.2139,
        -0.0716, -0.3276,  0.3362,  0.1061])
[Worker 0] Completed Task 2106

[Worker 0] Processing Task 2109: paddle.tril(Tensor([40139882, 107],"float16"), )
[accuracy error] paddle.tril(Tensor([40139882, 107],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 38971820 / 4294967374 (0.9%)
Greatest absolute difference: 0.5 at index (39768313, 64) (up to 0.01 allowed)
Greatest relative difference: inf at index (39768215, 76) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([40139882, 107]), dtype=torch.float16)
First 100 elements: tensor([0.4880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([40139882, 107]), dtype=torch.float16)
First 100 elements: tensor([0.4880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000], dtype=torch.float16)
[Worker 0] Completed Task 2109

[Worker 0] Processing Task 2112: paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=-1, )
[accuracy error] paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 526126867 / 4294967300 (12.2%)
Greatest absolute difference: 0.5 at index (536877039, 1, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000, -0.4163,  0.0000,  0.0000,  0.0000,  0.4775,  0.0000,
         0.0000,  0.0000, -0.0127,  0.0000,  0.0000,  0.0000,  0.3169,  0.0000,
         0.0000,  0.0000,  0.0666,  0.0000,  0.0000,  0.0000,  0.3987,  0.0000,
         0.0000,  0.0000, -0.4739,  0.0000,  0.0000,  0.0000, -0.1416,  0.0000,
         0.0000,  0.0000,  0.2988,  0.0000,  0.0000,  0.0000,  0.0537,  0.0000,
         0.0000,  0.0000,  0.0377,  0.0000,  0.0000,  0.0000,  0.3743,  0.0000,
         0.0000,  0.0000,  0.3293,  0.0000,  0.0000,  0.0000,  0.4341,  0.0000,
         0.0000,  0.0000, -0.1401,  0.0000,  0.0000,  0.0000,  0.4290,  0.0000,
         0.0000,  0.0000,  0.3489,  0.0000,  0.0000,  0.0000,  0.2764,  0.0000,
         0.0000,  0.0000, -0.2449,  0.0000,  0.0000,  0.0000, -0.2267,  0.0000,
         0.0000,  0.0000,  0.2271,  0.0000,  0.0000,  0.0000,  0.1921,  0.0000,
         0.0000,  0.0000, -0.0764,  0.0000,  0.0000,  0.0000,  0.1472,  0.0000,
         0.0000,  0.0000, -0.1550,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000, -0.4163,  0.0000,  0.0000,  0.0000,  0.4775,  0.0000,
         0.0000,  0.0000, -0.0127,  0.0000,  0.0000,  0.0000,  0.3169,  0.0000,
         0.0000,  0.0000,  0.0666,  0.0000,  0.0000,  0.0000,  0.3987,  0.0000,
         0.0000,  0.0000, -0.4739,  0.0000,  0.0000,  0.0000, -0.1416,  0.0000,
         0.0000,  0.0000,  0.2988,  0.0000,  0.0000,  0.0000,  0.0537,  0.0000,
         0.0000,  0.0000,  0.0377,  0.0000,  0.0000,  0.0000,  0.3743,  0.0000,
         0.0000,  0.0000,  0.3293,  0.0000,  0.0000,  0.0000,  0.4341,  0.0000,
         0.0000,  0.0000, -0.1401,  0.0000,  0.0000,  0.0000,  0.4290,  0.0000,
         0.0000,  0.0000,  0.3489,  0.0000,  0.0000,  0.0000,  0.2764,  0.0000,
         0.0000,  0.0000, -0.2449,  0.0000,  0.0000,  0.0000, -0.2267,  0.0000,
         0.0000,  0.0000,  0.2271,  0.0000,  0.0000,  0.0000,  0.1921,  0.0000,
         0.0000,  0.0000, -0.0764,  0.0000,  0.0000,  0.0000,  0.1472,  0.0000,
         0.0000,  0.0000, -0.1550,  0.0000], dtype=torch.float16)
[Worker 0] Completed Task 2112

[Worker 0] Processing Task 2115: paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=1, )
[accuracy error] paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104503633 / 4294967298 (49.0%)
Greatest absolute difference: 0.5 at index (1, 357919821, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 357913941, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
[Worker 0] Completed Task 2115

[Worker 0] Processing Task 2118: paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=-5, )
[accuracy error] paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=-5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104503622 / 4294967298 (49.0%)
Greatest absolute difference: 0.5 at index (1, 357919821, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 357913941, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.0127,  0.0000, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.0127,  0.0000, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
[Worker 0] Completed Task 2118

[Worker 0] Processing Task 2122: paddle.triu(Tensor([114085069, 20, 1],"float32"), 0, )
[accuracy error] paddle.triu(Tensor([114085069, 20, 1],"float32"), 0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 6576420 / 2281701380 (0.3%)
Greatest absolute difference: 0.49999988079071045 at index (110607611, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (107374183, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([114085069, 20, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.1415,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0979,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        -0.4558,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, -0.1199,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0351,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000])
DESIRED: (shape=torch.Size([114085069, 20, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.1415,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0979,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        -0.4558,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, -0.1199,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0351,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000])
[Worker 0] Completed Task 2122

[Worker 0] Processing Task 2124: paddle.triu(Tensor([2, 21262215, 1, 101],"float16"), )
[accuracy error] paddle.triu(Tensor([2, 21262215, 1, 101],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 121414996 / 4294967430 (2.8%)
Greatest absolute difference: 0.5 at index (1, 20035597, 0, 95) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 20035547, 0, 48) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 21262215, 1, 101]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 21262215, 1, 101]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
[Worker 0] Completed Task 2124

[Worker 0] Processing Task 2128: paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=0, )
[accuracy error] paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1578376768 / 4294967300 (36.7%)
Greatest absolute difference: 0.5 at index (536873852, 0, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737,  0.0000, -0.0798,  0.3398, -0.1699,  0.0000,  0.3110,
        -0.1593, -0.0215,  0.0000,  0.2649, -0.4666,  0.4961,  0.0000,  0.0825,
         0.4998, -0.3057,  0.0000,  0.0782, -0.1240, -0.4622,  0.0000,  0.4529,
        -0.2781, -0.2515,  0.0000,  0.2040, -0.3792,  0.3049,  0.0000, -0.1439,
        -0.4121, -0.0345,  0.0000,  0.3613,  0.1371,  0.1434,  0.0000, -0.0834,
         0.2544,  0.3274,  0.0000,  0.1500, -0.3755, -0.1399,  0.0000,  0.3752,
        -0.0502, -0.1364,  0.0000, -0.3921, -0.1783,  0.0695,  0.0000,  0.2018,
        -0.0301,  0.3704,  0.0000, -0.0461, -0.3423, -0.4998,  0.0000, -0.0667,
         0.4802,  0.2427,  0.0000,  0.0007,  0.1543, -0.4954,  0.0000,  0.4182,
         0.4604,  0.3950,  0.0000,  0.2111,  0.2400, -0.2169,  0.0000, -0.4033,
        -0.1981, -0.3398,  0.0000,  0.3894, -0.3508,  0.1793,  0.0000,  0.1432,
         0.0246,  0.2216,  0.0000, -0.1836,  0.3599,  0.1956,  0.0000, -0.4001,
         0.2449,  0.1449,  0.0000, -0.0489], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737,  0.0000, -0.0798,  0.3398, -0.1699,  0.0000,  0.3110,
        -0.1593, -0.0215,  0.0000,  0.2649, -0.4666,  0.4961,  0.0000,  0.0825,
         0.4998, -0.3057,  0.0000,  0.0782, -0.1240, -0.4622,  0.0000,  0.4529,
        -0.2781, -0.2515,  0.0000,  0.2040, -0.3792,  0.3049,  0.0000, -0.1439,
        -0.4121, -0.0345,  0.0000,  0.3613,  0.1371,  0.1434,  0.0000, -0.0834,
         0.2544,  0.3274,  0.0000,  0.1500, -0.3755, -0.1399,  0.0000,  0.3752,
        -0.0502, -0.1364,  0.0000, -0.3921, -0.1783,  0.0695,  0.0000,  0.2018,
        -0.0301,  0.3704,  0.0000, -0.0461, -0.3423, -0.4998,  0.0000, -0.0667,
         0.4802,  0.2427,  0.0000,  0.0007,  0.1543, -0.4954,  0.0000,  0.4182,
         0.4604,  0.3950,  0.0000,  0.2111,  0.2400, -0.2169,  0.0000, -0.4033,
        -0.1981, -0.3398,  0.0000,  0.3894, -0.3508,  0.1793,  0.0000,  0.1432,
         0.0246,  0.2216,  0.0000, -0.1836,  0.3599,  0.1956,  0.0000, -0.4001,
         0.2449,  0.1449,  0.0000, -0.0489], dtype=torch.float16)
[Worker 0] Completed Task 2128

[Worker 0] Processing Task 2131: paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=-5, )
[accuracy error] paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=-5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104503635 / 4294967300 (49.0%)
Greatest absolute difference: 0.5 at index (536873852, 0, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
[Worker 0] Completed Task 2131

[Worker 0] Processing Task 2134: paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=-1, )
[accuracy error] paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 7 / 4294967298 (0.0%)
Greatest absolute difference: 0.460693359375 at index (2, 1, 715827877) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1, 715827876) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649, -0.4666,  0.4961,  0.3169,  0.0825,
         0.4998, -0.3057,  0.0666,  0.0782, -0.1240, -0.4622,  0.3987,  0.4529,
        -0.2781, -0.2515, -0.4739,  0.2040, -0.3792,  0.3049, -0.1416, -0.1439,
        -0.4121, -0.0345,  0.2988,  0.3613,  0.1371,  0.1434,  0.0537, -0.0834,
         0.2544,  0.3274,  0.0377,  0.1500, -0.3755, -0.1399,  0.3743,  0.3752,
        -0.0502, -0.1364,  0.3293, -0.3921, -0.1783,  0.0695,  0.4341,  0.2018,
        -0.0301,  0.3704, -0.1401, -0.0461, -0.3423, -0.4998,  0.4290, -0.0667,
         0.4802,  0.2427,  0.3489,  0.0007,  0.1543, -0.4954,  0.2764,  0.4182,
         0.4604,  0.3950, -0.2449,  0.2111,  0.2400, -0.2169, -0.2267, -0.4033,
        -0.1981, -0.3398,  0.2271,  0.3894, -0.3508,  0.1793,  0.1921,  0.1432,
         0.0246,  0.2216, -0.0764, -0.1836,  0.3599,  0.1956,  0.1472, -0.4001,
         0.2449,  0.1449, -0.1550, -0.0489], dtype=torch.float16)
[Worker 0] Completed Task 2134

[Worker 0] Processing Task 2137: paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=0, )
[accuracy error] paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 4294967298 (0.0%)
Greatest absolute difference: 0.376953125 at index (2, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737,  0.0000, -0.0798,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737,  0.0000, -0.0798,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
[Worker 0] Completed Task 2137

[Worker 0] Processing Task 2140: paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=-5, )
[accuracy error] paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=-5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 13 / 4294967298 (0.0%)
Greatest absolute difference: 0.485107421875 at index (2, 3, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649,  0.0000,  0.4961,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4880, -0.0737, -0.4163, -0.0798,  0.3398, -0.1699,  0.4775,  0.3110,
        -0.1593, -0.0215, -0.0127,  0.2649,  0.0000,  0.4961,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
[Worker 0] Completed Task 2140

[Worker 0] Processing Task 2199: paddle.argmax(Tensor([13, 2, 2742430, 16, 2],"float32"), axis=-1, )
[cuda error] paddle.argmax(Tensor([13, 2, 2742430, 16, 2],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927342 (unix time) try "date -d @1747927342" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc0e1) received by PID 49377 (TID 0x7f2766dac740) from PID 49377 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2201: paddle.argmax(Tensor([2, 536870913, 4],"float16"), axis=-1, keepdim=True, )
W0522 23:23:46.593499 49719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:23:46.594262 49719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmax(Tensor([2, 536870913, 4],"float16"), axis=-1, keepdim=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927428 (unix time) try "date -d @1747927428" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc237) received by PID 49719 (TID 0x7f2766dac740) from PID 49719 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2206: paddle.argmax(Tensor([3, 3, 3, 17674763, 3, 3],"float16"), axis=0, )
W0522 23:25:30.301827 50001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:25:30.302559 50001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmax(Tensor([3, 3, 3, 17674763, 3, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927531 (unix time) try "date -d @1747927531" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc351) received by PID 50001 (TID 0x7f2766dac740) from PID 50001 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2212: paddle.argmax(Tensor([4, 16777217, 4, 4, 4],"float16"), axis=0, )
[cuda error] paddle.argmax(Tensor([4, 16777217, 4, 4, 4],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927696 (unix time) try "date -d @1747927696" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc469) received by PID 50281 (TID 0x7f2766dac740) from PID 50281 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2215: paddle.argmax(Tensor([4, 4, 4, 4, 16777217],"float16"), axis=0, )
W0522 23:30:08.708554 50658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:30:08.709328 50658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmax(Tensor([4, 4, 4, 4, 16777217],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927810 (unix time) try "date -d @1747927810" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc5e2) received by PID 50658 (TID 0x7f2766dac740) from PID 50658 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2223: paddle.argmax(x=Tensor([357913942, 3, 4],"float16"), axis=1, keepdim=False, )
[cuda error] paddle.argmax(x=Tensor([357913942, 3, 4],"float16"), axis=1, keepdim=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927985 (unix time) try "date -d @1747927985" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc6fc) received by PID 50940 (TID 0x7f2766dac740) from PID 50940 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2232: paddle.argmin(Tensor([3, 3, 3, 3, 3, 17674763],"float16"), axis=0, )
W0522 23:35:00.634977 51502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:35:00.635828 51502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmin(Tensor([3, 3, 3, 3, 3, 17674763],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928101 (unix time) try "date -d @1747928101" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc92e) received by PID 51502 (TID 0x7f2766dac740) from PID 51502 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2237: paddle.argmin(Tensor([4, 4, 4, 16777217, 4],"float16"), axis=0, )
W0522 23:36:21.116869 51692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:36:21.117686 51692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmin(Tensor([4, 4, 4, 16777217, 4],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928182 (unix time) try "date -d @1747928182" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc9ec) received by PID 51692 (TID 0x7f2766dac740) from PID 51692 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2248: paddle.broadcast_to(Tensor([10140896, 1, 15, 15],"bool"), list[10,8,15,15,], )
[torch error] paddle.broadcast_to(Tensor([10140896, 1, 15, 15],"bool"), list[10,8,15,15,], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: The expanded size of the tensor (10) must match the existing size (10140896) at non-singleton dimension 0.  Target sizes: [10, 8, 15, 15].  Tensor sizes: [10140896, 1, 15, 15]
[Worker 0] Completed Task 2248

[Worker 0] Processing Task 2252: paddle.copysign(Tensor([10, 228170138],"float32"), Tensor([10, 228170138],"float32"), )
[cuda error] paddle.copysign(Tensor([10, 228170138],"float32"), Tensor([10, 228170138],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928397 (unix time) try "date -d @1747928397" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcb06) received by PID 51974 (TID 0x7f2766dac740) from PID 51974 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2256: paddle.copysign(Tensor([12, 178956971, 2],"float16"), Tensor([12, 178956971, 2],"float16"), )
W0522 23:41:56.113528 52619 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:41:56.114542 52619 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([12, 178956971, 2],"float16"), Tensor([12, 178956971, 2],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928533 (unix time) try "date -d @1747928533" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcd8b) received by PID 52619 (TID 0x7f2766dac740) from PID 52619 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2259: paddle.copysign(Tensor([12, 95070891, 2],"float32"), Tensor([12, 95070891, 2],"float32"), )
W0522 23:43:37.166481 52939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:43:37.167447 52939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([12, 95070891, 2],"float32"), Tensor([12, 95070891, 2],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928632 (unix time) try "date -d @1747928632" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcecb) received by PID 52939 (TID 0x7f2766dac740) from PID 52939 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2264: paddle.copysign(Tensor([214748365, 20],"float16"), Tensor([214748365, 20],"float16"), )
W0522 23:46:02.237290 53490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:46:02.238668 53490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([214748365, 20],"float16"), Tensor([214748365, 20],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928778 (unix time) try "date -d @1747928778" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd0f2) received by PID 53490 (TID 0x7f2766dac740) from PID 53490 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2268: paddle.copysign(Tensor([3, 286331154, 5],"float16"), Tensor([5],"float16"), )
W0522 23:48:18.001914 53946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:48:18.003578 53946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([3, 286331154, 5],"float16"), Tensor([5],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928914 (unix time) try "date -d @1747928914" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd2ba) received by PID 53946 (TID 0x7f2766dac740) from PID 53946 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2272: paddle.copysign(Tensor([8, 17, 5, 6, 1052689],"float16"), Tensor([8, 17, 5, 6, 1052689],"float16"), )
W0522 23:50:30.708619 54423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:50:30.710036 54423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([8, 17, 5, 6, 1052689],"float16"), Tensor([8, 17, 5, 6, 1052689],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747929047 (unix time) try "date -d @1747929047" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd497) received by PID 54423 (TID 0x7f2766dac740) from PID 54423 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2296: paddle.cumsum(Tensor([1140850690, 2],"int64"), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([1140850690, 2],"int64"), axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2296

[Worker 0] Processing Task 2300: paddle.cumsum(Tensor([21939437, 104],"int64"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([21939437, 104],"int64"), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000001GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2300

[Worker 0] Processing Task 2302: paddle.cumsum(Tensor([22369622, 102],"int64"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([22369622, 102],"int64"), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000001GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2302

[Worker 0] Processing Task 2310: paddle.cumsum(Tensor([3, 760567127],"int64"), axis=-2, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([3, 760567127],"int64"), axis=-2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2310

[Worker 0] Processing Task 2312: paddle.cumsum(Tensor([38028357, 60],"int32"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.cumsum(Tensor([38028357, 60],"int32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01

ACTUAL: (shape=torch.Size([38028357, 60]), dtype=torch.int32)
First 100 elements: tensor([  23527,  -22775,   41252,   36728,   49595,   40843,  -18372,  -49760,
          30578,   25913,  -25378,   41762,    3394,   42950,  -53825,   43185,
          64708,    4140,   -3915,    2743,  -60570,   42946,   55754,   17716,
           3559,  -20207,  -48893,   56751,   64148,  -13945,  -40324,    3271,
          12461,   -4612,  -36495,  -43892,  -38403,  -34673,   61722,   58098,
         -43013,  -61531,   59805,  -43240,   18284,   63433,   32289,   58985,
          42872,   17383,  -20304,  -43708,   43892,   19312,  -62379,   23109,
          30829,  -44963,   54305,  -24092,   60769,  -56679,   11460,   58838,
           -402,   85522,  -35593,  -54393,  -17217,    2528,  -13141,   85356,
           2185,  -16086, -115517,   89579,   17001,  -36081,  -57426,  -15896,
        -109494,  -14409,   23920,  -13324,  -30804,   12282,  -18677,   12380,
          79840,  -53206,  -23074,  -56622,   62992,  -49583,  -46417,  -40886,
         -70886,  -58741,    5246,   70542], dtype=torch.int32)
DESIRED: (shape=torch.Size([38028357, 60]), dtype=torch.int64)
First 100 elements: tensor([  23527,  -22775,   41252,   36728,   49595,   40843,  -18372,  -49760,
          30578,   25913,  -25378,   41762,    3394,   42950,  -53825,   43185,
          64708,    4140,   -3915,    2743,  -60570,   42946,   55754,   17716,
           3559,  -20207,  -48893,   56751,   64148,  -13945,  -40324,    3271,
          12461,   -4612,  -36495,  -43892,  -38403,  -34673,   61722,   58098,
         -43013,  -61531,   59805,  -43240,   18284,   63433,   32289,   58985,
          42872,   17383,  -20304,  -43708,   43892,   19312,  -62379,   23109,
          30829,  -44963,   54305,  -24092,   60769,  -56679,   11460,   58838,
           -402,   85522,  -35593,  -54393,  -17217,    2528,  -13141,   85356,
           2185,  -16086, -115517,   89579,   17001,  -36081,  -57426,  -15896,
        -109494,  -14409,   23920,  -13324,  -30804,   12282,  -18677,   12380,
          79840,  -53206,  -23074,  -56622,   62992,  -49583,  -46417,  -40886,
         -70886,  -58741,    5246,   70542])
[Worker 0] Completed Task 2312

[Worker 0] Processing Task 2314: paddle.cumsum(Tensor([50704476, 45],"int64"), axis=1, )
[torch error] paddle.cumsum(Tensor([50704476, 45],"int64"), axis=1, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 50611 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 2314

[Worker 0] Processing Task 2315: paddle.cumsum(Tensor([51856850, 44],"int64"), axis=1, )
[torch error] paddle.cumsum(Tensor([51856850, 44],"int64"), axis=1, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 50611 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 2315

[Worker 0] Processing Task 2316: paddle.cumsum(Tensor([570425345, 4],"int64"), axis=0, )
[torch error] paddle.cumsum(Tensor([570425345, 4],"int64"), axis=0, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 50611 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 2316

[Worker 0] Processing Task 2317: paddle.cumsum(Tensor([570425345, 4],"int64"), axis=-2, )
[torch error] paddle.cumsum(Tensor([570425345, 4],"int64"), axis=-2, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 50611 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Completed Task 2317

[Worker 0] Processing Task 2318: paddle.cumsum(Tensor([760567127, 3],"float32"), axis=0, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 50611 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 2318: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 50611 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 2318: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 50611 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2323: paddle.cumsum(x=Tensor([1, 16, 96, 2796203],"float16"), axis=2, )
W0523 00:05:30.122465 55770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:05:30.123600 55770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.cumsum(x=Tensor([1, 16, 96, 2796203],"float16"), axis=2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 54691 / 4294967808 (0.0%)
Greatest absolute difference: 0.03515625 at index (0, 7, 79, 1301573) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 1, 75, 1083969) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 96, 2796203]), dtype=torch.float16)
First 100 elements: tensor([-0.2223, -0.1606, -0.3594,  0.4724,  0.0349,  0.3037, -0.4492,  0.2947,
        -0.0872,  0.2307,  0.3760, -0.0715,  0.2312,  0.0999, -0.4744, -0.0915,
        -0.2102, -0.1439,  0.0315, -0.2581,  0.4866,  0.3003,  0.3752, -0.2700,
        -0.1177,  0.0276, -0.2510, -0.1379, -0.2043,  0.3591,  0.4854, -0.3262,
        -0.3838, -0.4688,  0.4690, -0.4766, -0.2253,  0.1521, -0.4009,  0.2944,
        -0.4827, -0.3870,  0.4529, -0.2812,  0.1697, -0.0254,  0.3066,  0.1787,
         0.4980,  0.2366, -0.1897, -0.3135, -0.1338, -0.4014,  0.4785, -0.3186,
         0.4487, -0.0715,  0.4775, -0.3408,  0.2416,  0.1995, -0.0418, -0.1793,
         0.0018,  0.4521, -0.2898,  0.2080,  0.3054,  0.2435, -0.1710,  0.0267,
         0.2126, -0.4548,  0.2747,  0.4692, -0.4944, -0.0523, -0.3643, -0.4614,
        -0.4844, -0.3103,  0.4868, -0.4214, -0.1753, -0.3596,  0.2512,  0.3489,
        -0.2732,  0.4819,  0.1422,  0.1707, -0.0066,  0.0299,  0.2561,  0.2054,
         0.4734,  0.3877,  0.4846, -0.0900], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 96, 2796203]), dtype=torch.float16)
First 100 elements: tensor([-0.2223, -0.1606, -0.3594,  0.4724,  0.0349,  0.3037, -0.4492,  0.2947,
        -0.0872,  0.2307,  0.3760, -0.0715,  0.2312,  0.0999, -0.4744, -0.0915,
        -0.2102, -0.1439,  0.0315, -0.2581,  0.4866,  0.3003,  0.3752, -0.2700,
        -0.1177,  0.0276, -0.2510, -0.1379, -0.2043,  0.3591,  0.4854, -0.3262,
        -0.3838, -0.4688,  0.4690, -0.4766, -0.2253,  0.1521, -0.4009,  0.2944,
        -0.4827, -0.3870,  0.4529, -0.2812,  0.1697, -0.0254,  0.3066,  0.1787,
         0.4980,  0.2366, -0.1897, -0.3135, -0.1338, -0.4014,  0.4785, -0.3186,
         0.4487, -0.0715,  0.4775, -0.3408,  0.2416,  0.1995, -0.0418, -0.1793,
         0.0018,  0.4521, -0.2898,  0.2080,  0.3054,  0.2435, -0.1710,  0.0267,
         0.2126, -0.4548,  0.2747,  0.4692, -0.4944, -0.0523, -0.3643, -0.4614,
        -0.4844, -0.3103,  0.4868, -0.4214, -0.1753, -0.3596,  0.2512,  0.3489,
        -0.2732,  0.4819,  0.1422,  0.1707, -0.0066,  0.0299,  0.2561,  0.2054,
         0.4734,  0.3877,  0.4846, -0.0900], dtype=torch.float16)
[Worker 0] Completed Task 2323

[Worker 0] Processing Task 2327: paddle.cumsum(x=Tensor([87382, 16, 96, 32],"float16"), axis=2, )
[accuracy error] paddle.cumsum(x=Tensor([87382, 16, 96, 32],"float16"), axis=2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 116090 / 4295000064 (0.0%)
Greatest absolute difference: 9.0390625 at index (87381, 11, 82, 11) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 3, 83, 6) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([87382, 16, 96, 32]), dtype=torch.float16)
First 100 elements: tensor([-0.2223, -0.1606, -0.3594,  0.4724,  0.0349,  0.3037, -0.4492,  0.2947,
        -0.0872,  0.2307,  0.3760, -0.0715,  0.2312,  0.0999, -0.4744, -0.0915,
        -0.2102, -0.1439,  0.0315, -0.2581,  0.4866,  0.3003,  0.3752, -0.2700,
        -0.1177,  0.0276, -0.2510, -0.1379, -0.2043,  0.3591,  0.4854, -0.3262,
        -0.6060, -0.6294,  0.1096, -0.0042, -0.1904,  0.4558, -0.8501,  0.5889,
        -0.5698, -0.1562,  0.8291, -0.3528,  0.4009,  0.0745, -0.1677,  0.0872,
         0.2878,  0.0927, -0.1582, -0.5713,  0.3528, -0.1011,  0.8535, -0.5889,
         0.3311, -0.0439,  0.2266, -0.4788,  0.0372,  0.5586,  0.4436, -0.5054,
        -0.6045, -0.1772, -0.1802,  0.2039,  0.1150,  0.6992, -1.0215,  0.6157,
        -0.3572, -0.6113,  1.1035,  0.1165, -0.0935,  0.0222, -0.5322, -0.3743,
        -0.1965, -0.2177,  0.3286, -0.9932,  0.1775, -0.4607,  1.1055, -0.2397,
         0.0578,  0.4380,  0.3687, -0.3081,  0.0307,  0.5884,  0.6997, -0.3000,
        -0.1309,  0.2104,  0.3044,  0.1138], dtype=torch.float16)
DESIRED: (shape=torch.Size([87382, 16, 96, 32]), dtype=torch.float16)
First 100 elements: tensor([-0.2223, -0.1606, -0.3594,  0.4724,  0.0349,  0.3037, -0.4492,  0.2947,
        -0.0872,  0.2307,  0.3760, -0.0715,  0.2312,  0.0999, -0.4744, -0.0915,
        -0.2102, -0.1439,  0.0315, -0.2581,  0.4866,  0.3003,  0.3752, -0.2700,
        -0.1177,  0.0276, -0.2510, -0.1379, -0.2043,  0.3591,  0.4854, -0.3262,
        -0.6060, -0.6294,  0.1096, -0.0042, -0.1904,  0.4558, -0.8501,  0.5889,
        -0.5698, -0.1562,  0.8291, -0.3528,  0.4009,  0.0745, -0.1677,  0.0872,
         0.2878,  0.0927, -0.1582, -0.5713,  0.3528, -0.1011,  0.8535, -0.5889,
         0.3311, -0.0439,  0.2266, -0.4788,  0.0372,  0.5586,  0.4436, -0.5054,
        -0.6040, -0.1772, -0.1802,  0.2039,  0.1150,  0.6992, -1.0215,  0.6157,
        -0.3572, -0.6113,  1.1035,  0.1165, -0.0935,  0.0222, -0.5322, -0.3743,
        -0.1965, -0.2177,  0.3286, -0.9927,  0.1775, -0.4607,  1.1045, -0.2400,
         0.0579,  0.4380,  0.3687, -0.3081,  0.0307,  0.5884,  0.6997, -0.2998,
        -0.1306,  0.2104,  0.3044,  0.1138], dtype=torch.float16)
[Worker 0] Completed Task 2327

[Worker 0] Processing Task 2340: paddle.dist(Tensor([1140850690, 2],"float32"), Tensor([1140850690, 2],"float32"), 0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[cuda error] paddle.dist(Tensor([1140850690, 2],"float32"), Tensor([1140850690, 2],"float32"), 0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Error on Task 2340: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] OOM on Task 2340: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2344: paddle.dist(x=Tensor([2, 2147483649],"float16"), y=Tensor([2, 2147483649],"float16"), p=0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
W0523 00:11:14.156386 56039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:11:14.157491 56039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.dist(x=Tensor([2, 2147483649],"float16"), y=Tensor([2, 2147483649],"float16"), p=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Error on Task 2344: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] OOM on Task 2344: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2348: paddle.dist(x=Tensor([4, 570425345],"float32"), y=Tensor([4, 570425345],"float32"), )
W0523 00:12:32.085721 56415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:12:32.086699 56415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.dist(x=Tensor([4, 570425345],"float32"), y=Tensor([4, 570425345],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930354 (unix time) try "date -d @1747930354" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdc5f) received by PID 56415 (TID 0x7f2766dac740) from PID 56415 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2351: paddle.frac(Tensor([10, 20, 11408507],"float32"), )
W0523 00:13:55.836176 56701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:13:55.837139 56701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.frac(Tensor([10, 20, 11408507],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930452 (unix time) try "date -d @1747930452" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdd7d) received by PID 56701 (TID 0x7f2766dac740) from PID 56701 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2355: paddle.frac(Tensor([760567127, 3],"float32"), )
W0523 00:15:27.620687 57118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:15:27.622044 57118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.frac(Tensor([760567127, 3],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930541 (unix time) try "date -d @1747930541" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdf1e) received by PID 57118 (TID 0x7f2766dac740) from PID 57118 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2514: paddle.linalg.lstsq(Tensor([10, 228170138],"float32"), Tensor([10, 8],"float32"), rcond=None, driver="gels", )
[torch error] paddle.linalg.lstsq(Tensor([10, 228170138],"float32"), Tensor([10, 8],"float32"), rcond=None, driver="gels", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Error on Task 2514: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] OOM on Task 2514: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2515: paddle.linalg.lstsq(Tensor([253522376, 9],"float32"), Tensor([253522376, 5],"float32"), rcond=1e-15, driver="gels", )
[torch error] paddle.linalg.lstsq(Tensor([253522376, 9],"float32"), Tensor([253522376, 5],"float32"), rcond=1e-15, driver="gels", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Error on Task 2515: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] OOM on Task 2515: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2520: paddle.linalg.matrix_rank(Tensor([3, 25352238, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
[torch error] paddle.linalg.matrix_rank(Tensor([3, 25352238, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Error on Task 2520: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] OOM on Task 2520: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2524: paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=1, axis=list[0,1,], keepdim=False, )
W0523 00:43:24.786031 58851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:43:24.787071 58851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=1, axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 1.0 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([1., 1., 1., 1.], dtype=torch.float16)
[Worker 0] Completed Task 2524

[Worker 0] Processing Task 2628: paddle.nansum(Tensor([1431655765, 3],"float32"), axis=None, keepdim=True, name=None, )
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2632: paddle.nansum(Tensor([3, 1431655765],"float32"), keepdim=True, )
W0523 01:26:16.658726 59401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:26:16.659673 59401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2636: paddle.nansum(Tensor([858993459, 5],"float32"), keepdim=True, )
W0523 01:56:29.398490 59781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:56:29.400409 59781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2640: paddle.nn.functional.adaptive_max_pool2d(Tensor([29217465, 3, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Error on Task 2640: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] OOM on Task 2640: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2642: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([29217465, 3, 7, 7],"float32"), output_size=list[2,5,], )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Error on Task 2642: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] OOM on Task 2642: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2646: paddle.nn.functional.grid_sample(Tensor([56, 3, 6790778, 2],"float32"), Tensor([56, 2, 6790778, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
W0523 02:28:59.352691 60755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:28:59.353644 60755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 6790778, 2],"float32"), Tensor([56, 2, 6790778, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938555 (unix time) try "date -d @1747938555" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xed53) received by PID 60755 (TID 0x7f2766dac740) from PID 60755 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2651: paddle.nn.functional.grid_sample(Tensor([5821, 4, 280, 350],"float32"), Tensor([5821, 280, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
W0523 02:30:32.081251 61285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:30:32.082585 61285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([5821, 4, 280, 350],"float32"), Tensor([5821, 280, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938646 (unix time) try "date -d @1747938646" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xef65) received by PID 61285 (TID 0x7f2766dac740) from PID 61285 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2654: paddle.nn.functional.grid_sample(Tensor([727584, 4, 28, 28],"float32"), Tensor([727584, 28, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )
W0523 02:32:01.635335 61627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:32:01.636400 61627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([727584, 4, 28, 28],"float32"), Tensor([727584, 28, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938739 (unix time) try "date -d @1747938739" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf0bb) received by PID 61627 (TID 0x7f2766dac740) from PID 61627 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2657: paddle.nn.functional.grid_sample(Tensor([742742, 3, 32, 32],"float32"), Tensor([742742, 32, 32, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
W0523 02:33:38.446367 61971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:33:38.447474 61971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([742742, 3, 32, 32],"float32"), Tensor([742742, 32, 32, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938833 (unix time) try "date -d @1747938833" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf213) received by PID 61971 (TID 0x7f2766dac740) from PID 61971 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2662: paddle.nn.functional.normalize(Tensor([1, 128, 557057, 32],"float32"), axis=1, )
W0523 02:35:41.151328 62500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:35:41.152369 62500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 128, 557057, 32],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938955 (unix time) try "date -d @1747938955" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf424) received by PID 62500 (TID 0x7f2766dac740) from PID 62500 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2666: paddle.nn.functional.normalize(Tensor([1, 557057, 64, 64],"float32"), axis=1, )
W0523 02:37:43.441946 62957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:37:43.443353 62957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 557057, 64, 64],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939077 (unix time) try "date -d @1747939077" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf5ed) received by PID 62957 (TID 0x7f2766dac740) from PID 62957 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2670: paddle.nn.functional.normalize(Tensor([10, 228170138],"float32"), )
W0523 02:39:40.556281 63434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:39:40.557361 63434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([10, 228170138],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939311 (unix time) try "date -d @1747939311" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf7ca) received by PID 63434 (TID 0x7f2766dac740) from PID 63434 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2677: paddle.nn.functional.normalize(Tensor([2, 16297867, 7, 10],"float32"), axis=1, )
W0523 02:43:41.404070 64230 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:43:41.405073 64230 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([2, 16297867, 7, 10],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939447 (unix time) try "date -d @1747939447" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfae6) received by PID 64230 (TID 0x7f2766dac740) from PID 64230 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2680: paddle.nn.functional.normalize(Tensor([207427399, 11],"float32"), axis=1, )
W0523 02:45:20.141023 64574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:45:20.142189 64574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([207427399, 11],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939536 (unix time) try "date -d @1747939536" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfc3e) received by PID 64574 (TID 0x7f2766dac740) from PID 64574 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2683: paddle.nn.functional.normalize(Tensor([228170138, 10],"float32"), p=1.5, )
W0523 02:46:49.853173 64916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:46:49.854251 64916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([228170138, 10],"float32"), p=1.5, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939625 (unix time) try "date -d @1747939625" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfd94) received by PID 64916 (TID 0x7f2766dac740) from PID 64916 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2686: paddle.nn.functional.normalize(Tensor([325957340, 7],"float32"), axis=0, )
W0523 02:49:19.010285 65279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:49:19.011281 65279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([325957340, 7],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939947 (unix time) try "date -d @1747939947" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfeff) received by PID 65279 (TID 0x7f2766dac740) from PID 65279 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2695: paddle.nn.functional.normalize(Tensor([45, 50704476],"float32"), axis=0, )
W0523 02:53:39.974543 66284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:53:39.975585 66284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([45, 50704476],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940035 (unix time) try "date -d @1747940035" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x102ec) received by PID 66284 (TID 0x7f2766dac740) from PID 66284 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2698: paddle.nn.functional.normalize(Tensor([60, 38028357],"float32"), axis=0, )
W0523 02:55:10.850067 66627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:55:10.851081 66627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([60, 38028357],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940125 (unix time) try "date -d @1747940125" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10443) received by PID 66627 (TID 0x7f2766dac740) from PID 66627 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2700: paddle.nn.functional.normalize(Tensor([80, 28521268],"float32"), axis=-1, )
W0523 02:57:08.720499 66837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:57:08.721575 66837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([80, 28521268],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940254 (unix time) try "date -d @1747940254" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10515) received by PID 66837 (TID 0x7f2766dac740) from PID 66837 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2701: paddle.nn.functional.normalize(Tensor([8388609, 512],"float16"), )
W0523 02:59:25.787801 66970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:59:25.789194 66970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([8388609, 512],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940380 (unix time) try "date -d @1747940380" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1059a) received by PID 66970 (TID 0x7f2766dac740) from PID 66970 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2704: paddle.nn.functional.normalize(x=Tensor([143165577, 5, 6],"float16"), )
W0523 03:01:30.874508 67310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:01:30.875566 67310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([143165577, 5, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940508 (unix time) try "date -d @1747940508" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x106ee) received by PID 67310 (TID 0x7f2766dac740) from PID 67310 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2708: paddle.nn.functional.normalize(x=Tensor([20452226, 5, 6, 7],"float16"), p=4, axis=3, )
W0523 03:03:46.273223 67747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:03:46.274197 67747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([20452226, 5, 6, 7],"float16"), p=4, axis=3, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940641 (unix time) try "date -d @1747940641" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x108a3) received by PID 67747 (TID 0x7f2766dac740) from PID 67747 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2712: paddle.nn.functional.normalize(x=Tensor([4, 5, 214748365],"float16"), )
W0523 03:06:01.414711 68203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:06:01.416115 68203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 5, 214748365],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940776 (unix time) try "date -d @1747940776" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10a6b) received by PID 68203 (TID 0x7f2766dac740) from PID 68203 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2714: paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), p=1, )
W0523 03:08:04.391247 68431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:08:04.392551 68431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 5, 30678338, 7],"float16"), p=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940901 (unix time) try "date -d @1747940901" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10b4f) received by PID 68431 (TID 0x7f2766dac740) from PID 68431 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2716: paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), )
W0523 03:10:12.816581 68659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:10:12.817539 68659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941028 (unix time) try "date -d @1747941028" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10c33) received by PID 68659 (TID 0x7f2766dac740) from PID 68659 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2719: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -1, 1e-06, False, None, )
W0523 03:12:21.233139 68999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:12:21.234109 68999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941155 (unix time) try "date -d @1747941155" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10d87) received by PID 68999 (TID 0x7f2766dac740) from PID 68999 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2723: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 2.0, 1e-06, False, None, )
W0523 03:14:23.077347 69437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:14:23.078332 69437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 2.0, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941277 (unix time) try "date -d @1747941277" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10f3d) received by PID 69437 (TID 0x7f2766dac740) from PID 69437 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2728: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -1, 1e-06, False, None, )
W0523 03:16:26.383596 69911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:16:26.384559 69911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941422 (unix time) try "date -d @1747941422" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11117) received by PID 69911 (TID 0x7f2766dac740) from PID 69911 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2732: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), math.inf, 1e-06, False, None, )
W0523 03:18:55.192984 70295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:18:55.194046 70295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941543 (unix time) try "date -d @1747941543" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11297) received by PID 70295 (TID 0x7f2766dac740) from PID 70295 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2736: paddle.nn.functional.pairwise_distance(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), 1, 1e-06, False, None, )
W0523 03:20:59.354966 70675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:20:59.356037 70675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([1431655766, 3],"float16"), Tensor([1431655766, 3],"float16"), 1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941670 (unix time) try "date -d @1747941670" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11413) received by PID 70675 (TID 0x7f2766dac740) from PID 70675 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2745: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -1, 1e-06, True, None, )
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -1, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941799 (unix time) try "date -d @1747941799" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11612) received by PID 71186 (TID 0x7f2766dac740) from PID 71186 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2747: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 2, 1e-06, True, None, )
W0523 03:24:59.791710 71622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:24:59.792723 71622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 2, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941902 (unix time) try "date -d @1747941902" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x117c6) received by PID 71622 (TID 0x7f2766dac740) from PID 71622 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2750: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), math.inf, 1e-06, True, None, )
W0523 03:26:14.533874 71964 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:26:14.535179 71964 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941976 (unix time) try "date -d @1747941976" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1191c) received by PID 71964 (TID 0x7f2766dac740) from PID 71964 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2755: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -1, 1e-06, True, None, )
W0523 03:28:09.789559 72514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:28:09.790517 72514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -1, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942095 (unix time) try "date -d @1747942095" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11b42) received by PID 72514 (TID 0x7f2766dac740) from PID 72514 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2759: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -math.inf, 1e-06, False, None, )
W0523 03:30:16.822919 72991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:30:16.823958 72991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), -math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942222 (unix time) try "date -d @1747942222" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11d1f) received by PID 72991 (TID 0x7f2766dac740) from PID 72991 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2764: paddle.nn.functional.pairwise_distance(Tensor([858993460, 5],"float16"), Tensor([858993460, 5],"float16"), 2, 1e-06, False, None, )
W0523 03:32:21.080806 73559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:32:21.081888 73559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([858993460, 5],"float16"), Tensor([858993460, 5],"float16"), 2, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942349 (unix time) try "date -d @1747942349" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11f57) received by PID 73559 (TID 0x7f2766dac740) from PID 73559 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2768: paddle.nn.functional.rrelu(Tensor([2, 3, 4, 95070891],"float32"), 0.1, 0.3, training=False, )
W0523 03:34:13.113343 74017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:34:13.114377 74017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 4, 95070891],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1384)

[Worker 0] Completed Task 2768

[Worker 0] Processing Task 2783: paddle.std(x=Tensor([3, 3, 477218589],"float16"), axis=0, unbiased=False, )
[accuracy error] backward  paddle.std(x=Tensor([3, 3, 477218589],"float16"), axis=0, unbiased=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 15063 / 4294967301 (0.0%)
Greatest absolute difference: nan at index (0, 0, 3964794) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 3964794) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3, 477218589]), dtype=torch.float16)
First 100 elements: tensor([-1.0321e-01,  2.8934e-03,  2.9785e-02, -3.1982e-02, -2.5040e-02,
        -7.1777e-02,  1.0473e-04, -8.8379e-02, -1.1981e-01, -4.8004e-02,
         2.0325e-01,  1.5430e-01,  1.3452e-01, -1.3135e-01,  8.8074e-02,
         4.8462e-02, -1.7303e-02, -6.0638e-02,  5.8746e-02, -1.2878e-01,
        -4.3976e-02, -2.4658e-02, -2.1973e-01, -2.5513e-02,  1.7090e-01,
        -4.9286e-02, -4.3732e-02, -2.0275e-03,  5.9624e-03, -4.4128e-02,
        -7.1030e-03, -6.5498e-03,  8.5571e-02,  4.0527e-02, -5.4474e-02,
        -6.6414e-03,  7.3730e-02, -1.4849e-03, -1.8158e-02, -8.3252e-02,
         3.4271e-02,  1.4026e-01,  1.3562e-01,  6.7234e-04,  6.8115e-02,
        -4.4861e-03,  4.6082e-02, -1.3416e-01,  1.6541e-01,  1.0651e-01,
         1.0999e-01, -1.4526e-01,  4.9469e-02, -1.1249e-01,  7.0129e-02,
         9.0075e-04,  2.2186e-02,  1.4404e-01,  1.1238e-02, -5.8350e-02,
         1.2195e-01,  7.8308e-02, -2.5826e-03,  1.2280e-01, -1.1102e-01,
        -1.2164e-01, -1.7166e-02,  1.5533e-02, -1.2817e-01, -1.3232e-01,
         1.4990e-01,  5.2612e-02,  1.0925e-02, -2.0068e-01, -4.1412e-02,
         5.1697e-02,  2.1805e-02, -2.0105e-01,  4.3396e-02, -1.9116e-01,
         5.6366e-02, -5.8044e-02, -1.2372e-01, -1.0864e-01, -1.9678e-01,
        -9.6069e-02, -7.4707e-02,  7.9712e-02,  2.2278e-02, -1.6772e-01,
        -7.4585e-02,  2.1408e-02,  3.4485e-02,  4.8706e-02, -2.6283e-03,
         1.1194e-01, -1.5259e-01, -1.0663e-01,  8.4778e-02, -3.0716e-02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 3, 477218589]), dtype=torch.float16)
First 100 elements: tensor([-1.0327e-01,  2.8152e-03,  2.9785e-02, -3.1982e-02, -2.5055e-02,
        -7.1838e-02,  1.0365e-04, -8.8440e-02, -1.1975e-01, -4.7974e-02,
         2.0325e-01,  1.5430e-01,  1.3452e-01, -1.3135e-01,  8.8074e-02,
         4.8462e-02, -1.7319e-02, -6.0638e-02,  5.8746e-02, -1.2866e-01,
        -4.3976e-02, -2.4658e-02, -2.1948e-01, -2.5513e-02,  1.7090e-01,
        -4.9286e-02, -4.3732e-02, -2.0332e-03,  5.9547e-03, -4.4128e-02,
        -6.9923e-03, -6.5536e-03,  8.5571e-02,  4.0527e-02, -5.4443e-02,
        -6.6452e-03,  7.3669e-02, -1.4858e-03, -1.8158e-02, -8.3252e-02,
         3.4271e-02,  1.4026e-01,  1.3562e-01,  6.7282e-04,  6.8176e-02,
        -4.4708e-03,  4.6082e-02, -1.3416e-01,  1.6541e-01,  1.0657e-01,
         1.0999e-01, -1.4526e-01,  4.9469e-02, -1.1249e-01,  7.0129e-02,
         9.2363e-04,  2.2202e-02,  1.4392e-01,  1.1246e-02, -5.8380e-02,
         1.2195e-01,  7.8308e-02, -2.5845e-03,  1.2280e-01, -1.1102e-01,
        -1.2158e-01, -1.7136e-02,  1.5526e-02, -1.2817e-01, -1.3245e-01,
         1.4990e-01,  5.2673e-02,  1.0925e-02, -2.0068e-01, -4.1443e-02,
         5.1666e-02,  2.1805e-02, -2.0105e-01,  4.3335e-02, -1.9116e-01,
         5.6335e-02, -5.8044e-02, -1.2372e-01, -1.0864e-01, -1.9690e-01,
        -9.6069e-02, -7.4707e-02,  7.9712e-02,  2.2247e-02, -1.6772e-01,
        -7.4646e-02,  2.1423e-02,  3.4485e-02,  4.8706e-02, -2.6608e-03,
         1.1188e-01, -1.5271e-01, -1.0681e-01,  8.4839e-02, -3.0701e-02],
       dtype=torch.float16)
[Worker 0] Completed Task 2783

[Worker 0] Processing Task 2788: paddle.std(x=Tensor([3, 477218589, 3],"float16"), axis=0, unbiased=False, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.57 GiB is free. Process 99731 has 73.61 GiB memory in use. Of the allocated memory 29.33 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 2788: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.57 GiB is free. Process 99731 has 73.61 GiB memory in use. Of the allocated memory 29.33 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 2788: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.57 GiB is free. Process 99731 has 73.61 GiB memory in use. Of the allocated memory 29.33 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2831: paddle.Tensor.argmax(Tensor([4, 285212673, 2],"float32"), axis=-1, )
[cuda error] paddle.Tensor.argmax(Tensor([4, 285212673, 2],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943152 (unix time) try "date -d @1747943152" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1221a) received by PID 74266 (TID 0x7f2766dac740) from PID 74266 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2832: paddle.Tensor.argmax(Tensor([67908, 1, 33600],"float32"), axis=-2, )
W0523 03:47:06.193360 74380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:47:06.194276 74380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.Tensor.argmax(Tensor([67908, 1, 33600],"float32"), axis=-2, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943227 (unix time) try "date -d @1747943227" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1228c) received by PID 74380 (TID 0x7f2766dac740) from PID 74380 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2836: paddle.Tensor.argmax(Tensor([93991, 1, 24276],"float32"), axis=-2, )
W0523 03:48:16.804342 74661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:48:16.805276 74661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.Tensor.argmax(Tensor([93991, 1, 24276],"float32"), axis=-2, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943297 (unix time) try "date -d @1747943297" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x123a5) received by PID 74661 (TID 0x7f2766dac740) from PID 74661 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2848: paddle.Tensor.cumsum(Tensor([1, 192, 11883862],"float32"), 2, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 192, 11883862],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 8622 / 2281701504 (0.0%)
Greatest absolute difference: 0.013534381985664368 at index (0, 166, 6740970) (up to 0.01 allowed)
Greatest relative difference: 263.7579345703125 at index (0, 166, 9208809) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 192, 11883862]), dtype=torch.float32)
First 100 elements: tensor([ 0.0154,  0.2152, -0.1761, -0.5169, -0.9368, -1.2996, -1.2942, -1.0611,
        -0.8261, -0.5639, -0.2488, -0.3099,  0.0197,  0.4428,  0.2101, -0.0605,
         0.1374,  0.6266,  1.0671,  1.0782,  1.4198,  1.1471,  0.6494,  0.7655,
         1.0252,  0.6077,  0.7536,  1.0836,  0.6486,  0.9997,  1.1614,  1.3402,
         1.1470,  1.5786,  1.4154,  1.0364,  0.7401,  1.0048,  1.3502,  1.3333,
         1.4521,  1.3501,  0.9863,  0.6548,  1.0207,  0.8839,  0.5602,  0.8477,
         0.9113,  1.0585,  0.8362,  1.0238,  1.2171,  0.8998,  0.7224,  0.8347,
         1.0783,  0.9883,  1.0457,  0.9526,  1.4083,  1.3186,  1.6026,  1.8882,
         1.6099,  1.3145,  1.6550,  2.0067,  1.9390,  2.3725,  2.2983,  2.7669,
         2.4164,  2.1643,  2.4133,  2.4864,  2.2651,  1.9628,  1.8693,  2.1724,
         2.2850,  1.9049,  2.3021,  2.6794,  2.3101,  2.6894,  2.7249,  2.8470,
         3.1312,  2.6955,  2.6523,  2.7199,  2.7061,  2.9506,  2.9823,  3.2940,
         3.2068,  3.3761,  3.3700,  3.2969])
DESIRED: (shape=torch.Size([1, 192, 11883862]), dtype=torch.float32)
First 100 elements: tensor([ 0.0154,  0.2152, -0.1761, -0.5169, -0.9368, -1.2996, -1.2942, -1.0611,
        -0.8261, -0.5639, -0.2488, -0.3099,  0.0197,  0.4428,  0.2101, -0.0605,
         0.1374,  0.6266,  1.0671,  1.0782,  1.4198,  1.1471,  0.6494,  0.7655,
         1.0252,  0.6077,  0.7536,  1.0836,  0.6486,  0.9997,  1.1614,  1.3402,
         1.1470,  1.5786,  1.4154,  1.0364,  0.7401,  1.0048,  1.3502,  1.3333,
         1.4521,  1.3501,  0.9863,  0.6548,  1.0207,  0.8839,  0.5602,  0.8477,
         0.9113,  1.0585,  0.8362,  1.0238,  1.2171,  0.8998,  0.7224,  0.8347,
         1.0783,  0.9883,  1.0457,  0.9526,  1.4083,  1.3186,  1.6026,  1.8882,
         1.6099,  1.3145,  1.6550,  2.0067,  1.9390,  2.3725,  2.2983,  2.7669,
         2.4164,  2.1643,  2.4133,  2.4864,  2.2651,  1.9628,  1.8693,  2.1724,
         2.2850,  1.9049,  2.3021,  2.6794,  2.3101,  2.6894,  2.7249,  2.8470,
         3.1312,  2.6955,  2.6523,  2.7199,  2.7061,  2.9506,  2.9823,  3.2940,
         3.2068,  3.3761,  3.3700,  3.2969])
[Worker 0] Completed Task 2848

[Worker 0] Processing Task 2851: paddle.Tensor.cumsum(Tensor([1, 285212673, 8],"float32"), 1, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 285212673, 8],"float32"), 1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 15299629 / 2281701384 (0.7%)
Greatest absolute difference: 0.8589553833007812 at index (0, 260224532, 2) (up to 0.01 allowed)
Greatest relative difference: 313425.46875 at index (0, 269713737, 7) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 285212673, 8]), dtype=torch.float32)
First 100 elements: tensor([ 0.0154,  0.1998, -0.3913, -0.3408, -0.4200, -0.3628,  0.0054,  0.2331,
         0.2504,  0.4620, -0.0762, -0.4019, -0.0904,  0.0604, -0.2273, -0.0376,
         0.4484,  0.9512,  0.3643, -0.3909,  0.2512, -0.2123, -0.7251,  0.0785,
         0.7082,  0.5337,  0.5102, -0.0609, -0.1838,  0.1388, -0.5633,  0.2573,
         0.5150,  0.9654,  0.3470, -0.4398, -0.4801,  0.4034, -0.2179,  0.2404,
         0.6337,  0.8633, -0.0168, -0.7713, -0.1142,  0.2666, -0.5415,  0.5278,
         0.6973,  1.0105, -0.2391, -0.5837,  0.0791, -0.0507, -0.7190,  0.6401,
         0.9410,  0.9205, -0.1816, -0.6769,  0.5348, -0.1405, -0.4350,  0.9257,
         0.6627,  0.6251,  0.1590, -0.3252,  0.4672,  0.2930, -0.5091,  1.3943,
         0.3123,  0.3729,  0.4080, -0.2521,  0.2458, -0.0092, -0.6027,  1.6975,
         0.4248, -0.0071,  0.8052,  0.1252, -0.1235,  0.3701, -0.5672,  1.8196,
         0.7091, -0.4428,  0.7619,  0.1927, -0.1373,  0.6146, -0.5355,  2.1313,
         0.6219, -0.2735,  0.7558,  0.1196])
DESIRED: (shape=torch.Size([1, 285212673, 8]), dtype=torch.float32)
First 100 elements: tensor([ 0.0154,  0.1998, -0.3913, -0.3408, -0.4200, -0.3628,  0.0054,  0.2331,
         0.2504,  0.4620, -0.0762, -0.4019, -0.0904,  0.0604, -0.2273, -0.0376,
         0.4484,  0.9512,  0.3643, -0.3909,  0.2512, -0.2123, -0.7251,  0.0785,
         0.7082,  0.5337,  0.5102, -0.0609, -0.1838,  0.1388, -0.5633,  0.2573,
         0.5150,  0.9654,  0.3470, -0.4398, -0.4801,  0.4034, -0.2179,  0.2404,
         0.6337,  0.8633, -0.0168, -0.7713, -0.1142,  0.2666, -0.5415,  0.5278,
         0.6973,  1.0105, -0.2391, -0.5837,  0.0791, -0.0507, -0.7190,  0.6401,
         0.9410,  0.9205, -0.1816, -0.6769,  0.5348, -0.1405, -0.4350,  0.9257,
         0.6627,  0.6251,  0.1590, -0.3252,  0.4672,  0.2930, -0.5091,  1.3943,
         0.3123,  0.3729,  0.4080, -0.2521,  0.2458, -0.0092, -0.6027,  1.6975,
         0.4248, -0.0071,  0.8052,  0.1252, -0.1235,  0.3701, -0.5672,  1.8196,
         0.7091, -0.4428,  0.7619,  0.1927, -0.1373,  0.6146, -0.5355,  2.1313,
         0.6219, -0.2735,  0.7558,  0.1196])
[Worker 0] Completed Task 2851

[Worker 0] Processing Task 2862: paddle.Tensor.cumsum(Tensor([285212673, 4, 2],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.cumsum(Tensor([285212673, 4, 2],"int64"), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2862

[Worker 0] Processing Task 2871: paddle.Tensor.cumsum(Tensor([3, 760567127],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.cumsum(Tensor([3, 760567127],"int64"), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2871

[Worker 0] Processing Task 2875: paddle.Tensor.cumsum(Tensor([570425345, 4],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.cumsum(Tensor([570425345, 4],"int64"), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2875

[Worker 0] Processing Task 2890: paddle.trapezoid(y=Tensor([1073741825, 4],"float16"), x=Tensor([1073741825, 4],"float16"), )
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   SliceGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::slice_grad(paddle::Tensor const&, paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, paddle::Tensor*)
4   void phi::SliceGradStridedKernel<phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, std::vector<long, std::allocator<long> > const&, std::vector<long, std::allocator<long> > const&, phi::DenseTensor*)
5   phi::DeviceContext::Alloc(phi::TensorBase*, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::RetryAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::StreamSafeCUDAAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
12  paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944114 (unix time) try "date -d @1747944114" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12545) received by PID 75077 (TID 0x7f2766dac740) from PID 75077 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2892: paddle.trunc(input=Tensor([19884108, 6, 6, 6],"float16"), )
W0523 04:03:20.239004 75440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:03:20.240020 75440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([19884108, 6, 6, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944215 (unix time) try "date -d @1747944215" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x126b0) received by PID 75440 (TID 0x7f2766dac740) from PID 75440 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2896: paddle.trunc(input=Tensor([3, 6628036, 6, 6, 6],"float16"), )
W0523 04:05:36.870362 75856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:05:36.871423 75856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([3, 6628036, 6, 6, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944356 (unix time) try "date -d @1747944356" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12850) received by PID 75856 (TID 0x7f2766dac740) from PID 75856 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2899: paddle.trunc(input=Tensor([6, 119304648, 6],"float16"), )
W0523 04:08:03.928232 76198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:08:03.929601 76198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([6, 119304648, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944500 (unix time) try "date -d @1747944500" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x129a6) received by PID 76198 (TID 0x7f2766dac740) from PID 76198 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2904: paddle.trunc(input=Tensor([6, 6, 6, 19884108],"float16"), )
W0523 04:10:22.436450 76558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:10:22.437481 76558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([6, 6, 6, 19884108],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944642 (unix time) try "date -d @1747944642" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12b0e) received by PID 76558 (TID 0x7f2766dac740) from PID 76558 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2907: paddle.trunc(Tensor([114085069, 20, 1],"float32"), )
W0523 04:12:22.182245 76882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:12:22.183429 76882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(Tensor([114085069, 20, 1],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944756 (unix time) try "date -d @1747944756" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12c52) received by PID 76882 (TID 0x7f2766dac740) from PID 76882 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2910: paddle.unique_consecutive(x=Tensor([570425345, 4],"float32"), return_inverse=True, return_counts=True, axis=0, )
W0523 04:14:24.283946 77224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:14:24.284840 77224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_unique_consecutive(_object*, _object*, _object*)
1   unique_consecutive_ad_func(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> >, phi::DataType)
2   paddle::experimental::unique_consecutive(paddle::Tensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType)
3   void phi::UniqueConsecutiveKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, bool, bool, std::vector<int, std::allocator<int> > const&, phi::DataType, phi::DenseTensor*, phi::DenseTensor*, phi::DenseTensor*)
4   void phi::IndexSelect<phi::GPUContext, float, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*, int)

----------------------
Error Message Summary:
----------------------
FatalError: `Segmentation fault` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944876 (unix time) try "date -d @1747944876" if you are using GNU date ***]
  [SignalInfo: *** SIGSEGV (@0x7f0837ffd010) received by PID 77224 (TID 0x7f2766dac740) from PID 939511824 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 2951: paddle.var(x=Tensor([477218589, 3, 3],"float16"), axis=tuple(0,1,), keepdim=True, )paddle.argsort(Tensor([2, 1140850690],"int64"), axis=1, stable=True, )
[Worker 0] Error on Task 2951: multiple values for argument 'x'

[Worker 0] Processing Task 2952: paddle.argsort(Tensor([228170138, 10],"int64"), axis=1, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([228170138, 10],"int64"), axis=1, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2952

[Worker 0] Processing Task 2955: paddle.argsort(Tensor([285212673, 4, 2],"int64"), axis=2, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([285212673, 4, 2],"int64"), axis=2, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2955

[Worker 0] Processing Task 2958: paddle.argsort(Tensor([3, 760567127],"int64"), axis=1, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([3, 760567127],"int64"), axis=1, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2958

[Worker 0] Processing Task 2961: paddle.argsort(Tensor([570425345, 4],"int64"), axis=1, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([570425345, 4],"int64"), axis=1, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 2961

[Worker 0] Processing Task 2976: paddle.chunk(Tensor([13, 4, 7, 6268411],"float32"), 3, axis=-1, )
[paddle error] paddle.chunk(Tensor([13, 4, 7, 6268411],"float32"), 3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [13, 4, 7, 6268411], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 2976

[Worker 0] Processing Task 2979: paddle.chunk(Tensor([16, 5593, 25500],"float32"), 2, axis=1, )
[paddle error] paddle.chunk(Tensor([16, 5593, 25500],"float32"), 2, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [16, 5593, 25500], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 2979

[Worker 0] Processing Task 2982: paddle.chunk(Tensor([4, 262145, 64, 64],"float16"), 3, axis=1, )
[paddle error] paddle.chunk(Tensor([4, 262145, 64, 64],"float16"), 3, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [4, 262145, 64, 64], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 2982

[Worker 0] Processing Task 2985: paddle.chunk(Tensor([8192, 278529],"float32"), 2, axis=-1, )
[paddle error] paddle.chunk(Tensor([8192, 278529],"float32"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [8192, 278529], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 2985

[Worker 0] Processing Task 2988: paddle.chunk(x=Tensor([3, 1431655766],"float16"), chunks=3, axis=-1, )
[paddle error] paddle.chunk(x=Tensor([3, 1431655766],"float16"), chunks=3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [3, 1431655766], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 2988

[Worker 0] Processing Task 2990: paddle.chunk(x=Tensor([3, 760567127],"int32"), chunks=3, axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.chunk(x=Tensor([3, 760567127],"int32"), chunks=3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [3, 760567127], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 2990

[Worker 0] Processing Task 3067: paddle.flatten(Tensor([268435457, 4, 2],"float64"), )
[accuracy error] backward  paddle.flatten(Tensor([268435457, 4, 2],"float64"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[[ 0.4105, -0.2045],
         [ 0.4919, -0.3034],
         [ 0.0911,  0.2495],
         [ 0.4197,  0.3076]],

        [[ 0.2873, -0.0007],
         [ 0.2801, -0.1041],
         [-0.4268,  0.3327],
         [ 0.4138,  0.0787]],

        [[-0.1982,  0.0941],
         [-0.1065, -0.3525],
         [ 0.1996, -0.2045],
         [-0.4213, -0.4415]],

        ...,

        [[-0.4637, -0.0188],
         [ 0.1153,  0.1966],
         [-0.3285,  0.3510],
         [ 0.3903,  0.2958]],

        [[-0.4708,  0.0968],
         [ 0.0210, -0.0713],
         [-0.2276, -0.2045],
         [ 0.2488, -0.0583]],

        [[ 0.4543,  0.2412],
         [-0.1600,  0.0424],
         [-0.0233, -0.3926],
         [ 0.3309, -0.0115]]], dtype=torch.float64),
    expected=tensor([[[ 0.4105, -0.2045],
         [ 0.4919, -0.3034],
         [ 0.0911,  0.2495],
         [ 0.4197,  0.3076]],

        [[ 0.2873, -0.0007],
         [ 0.2801, -0.1041],
         [-0.4268,  0.3327],
         [ 0.4138,  0.0787]],

        [[-0.1982,  0.0941],
         [-0.1065, -0.3525],
         [ 0.1996, -0.2045],
         [-0.4213, -0.4415]],

        ...,

        [[-0.4637, -0.0188],
         [ 0.1153,  0.1966],
         [-0.3285,  0.3510],
         [ 0.3903,  0.2958]],

        [[-0.4708,  0.0968],
         [ 0.0210, -0.0713],
         [-0.2276, -0.2045],
         [ 0.2488, -0.0583]],

        [[ 0.4543,  0.2412],
         [-0.1600,  0.0424],
         [-0.0233, -0.3926],
         [ 0.3309, -0.0115]]], dtype=torch.float64),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 0] Completed Task 3067

[Worker 0] Processing Task 3076: paddle.flatten(Tensor([3, 715827883, 2],"int32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.flatten(Tensor([3, 715827883, 2],"int32"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([ -4338,  -2006, -32035,  ..., -24478, -28640, -50317],
       dtype=torch.int32),
    expected=tensor([ -4338,  -2006, -32035,  ..., -24478, -28640, -50317],
       dtype=torch.int32),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 0] Completed Task 3076

[Worker 0] Processing Task 3083: paddle.flatten(Tensor([536870912, 4, 2],"int32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.flatten(Tensor([536870912, 4, 2],"int32"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([ -4338,  -2006, -32035,  ...,  22214,  51301, -24478],
       dtype=torch.int32),
    expected=tensor([ -4338,  -2006, -32035,  ...,  22214,  51301, -24478],
       dtype=torch.int32),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 0] Completed Task 3083

[Worker 0] Processing Task 3085: paddle.fmin(Tensor([1],"int64"), Tensor([2281701379],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.fmin(Tensor([1],"int64"), Tensor([2281701379],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::fmin(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::FMinKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.614258GB memory has been allocated and available memory is only 9.570618GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3085

[Worker 0] Processing Task 3089: paddle.frac(Tensor([2, 2147483649],"float16"), )
[cuda error] paddle.frac(Tensor([2, 2147483649],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747948066 (unix time) try "date -d @1747948066" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12ee9) received by PID 77545 (TID 0x7f2766dac740) from PID 77545 ***]

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3101: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), "nuc", )
[torch error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), "nuc", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Error on Task 3101: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] OOM on Task 3101: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3119: paddle.maximum(Tensor([1],"float64"), Tensor([2147483649],"float64"), )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 11.57 GiB is free. Process 117432 has 67.61 GiB memory in use. Of the allocated memory 66.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 3119: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 11.57 GiB is free. Process 117432 has 67.61 GiB memory in use. Of the allocated memory 66.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 3119: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 11.57 GiB is free. Process 117432 has 67.61 GiB memory in use. Of the allocated memory 66.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3125: paddle.nanmean(Tensor([1431655765, 3],"float32"), None, False, )
W0523 05:15:06.461158 78436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:15:06.462953 78436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3129: paddle.nanmean(Tensor([2, 107374183, 4, 5],"float32"), list[0,1,2,3,], False, )
W0523 05:45:16.628011 78819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:45:16.629159 78819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3133: paddle.nanmean(Tensor([2, 2147483648],"float32"), -1, False, )
W0523 06:15:37.775409 79199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:15:37.776403 79199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3137: paddle.nanmean(Tensor([2, 3, 143165577, 5],"float32"), 2, True, )
W0523 06:45:50.895651 79579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:45:50.896674 79579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3141: paddle.nanmean(Tensor([2, 3, 143165577, 5],"float32"), None, False, )
W0523 07:15:49.626122 79959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:15:49.627149 79959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3145: paddle.nanmean(Tensor([2, 3, 4, 178956971],"float32"), list[], False, )
W0523 07:45:57.534883 80339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:45:57.535995 80339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3149: paddle.nanmean(Tensor([3, 1431655765],"float32"), axis=None, )
W0523 08:16:16.882264 80719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:16:16.883220 80719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3153: paddle.nanmean(Tensor([71582789, 3, 4, 5],"float32"), list[0,1,2,3,], False, )
W0523 08:46:24.224355 81099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:46:24.225353 81099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3157: paddle.nanmean(Tensor([71582789, 3, 4, 5],"float32"), tuple(0,2,), False, )
W0523 09:16:35.319144 81479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:16:35.320178 81479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3161: paddle.nn.functional.normalize(Tensor([2, 2147483648],"float32"), axis=1, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.58 GiB is free. Process 32400 has 65.60 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 3161: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.58 GiB is free. Process 32400 has 65.60 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 3161: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.58 GiB is free. Process 32400 has 65.60 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3165: paddle.nn.functional.normalize(Tensor([2281701379],"float32"), axis=0, epsilon=1e-12, )
W0523 09:47:58.651675 82161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:47:58.652894 82161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(Tensor([2281701379],"float32"), axis=0, epsilon=1e-12, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281701379 / 2281701379 (100.0%)
Greatest absolute difference: 499999997952.0 at index (73334775,) (up to 0.01 allowed)
Greatest relative difference: 1.3789401599442944e+16 at index (4,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([-1.9837e+11,  4.5010e+11, -1.4111e+10, -2.3987e+11,  4.3154e+11,
         4.7699e+11, -4.6692e+10, -1.3365e+11, -3.6215e+11, -1.5455e+11,
        -1.2949e+11,  2.2740e+11, -3.1177e+11,  3.7347e+11, -8.0551e+10,
         3.7384e+09, -2.1904e+11,  3.9897e+11, -2.1325e+11, -2.6712e+11,
         2.7039e+11,  2.8928e+11, -3.4854e+11, -6.0735e+10,  3.0464e+11,
        -2.2093e+11,  2.3920e+11,  3.4940e+11, -3.0181e+11,  3.4294e+11,
        -2.9322e+11,  1.7263e+10,  1.3604e+11, -4.3646e+11,  2.7366e+11,
        -1.6530e+11, -4.6882e+11, -1.9307e+11,  6.1513e+10,  6.0459e+10,
         1.5279e+11, -1.9301e+11, -7.8831e+10,  2.0691e+10,  2.1340e+11,
        -4.5448e+11, -1.5756e+11, -2.3791e+11,  3.0069e+11, -4.7018e+11,
        -4.2775e+10,  4.5400e+11, -4.3818e+11,  3.1041e+11, -4.9106e+11,
        -4.6375e+11, -3.3478e+11,  6.2047e+10, -1.3586e+11,  4.4317e+11,
        -2.1716e+11,  4.5591e+11,  2.0335e+11,  1.4794e+11, -1.9065e+10,
         3.2208e+11, -3.8036e+11, -1.2063e+11,  1.0966e+11, -5.8111e+10,
        -1.6885e+11, -4.9967e+11,  4.2299e+11,  4.4440e+10, -4.6672e+10,
         4.6302e+11, -3.3658e+11, -3.3627e+11, -3.3702e+10, -4.6167e+11,
         8.2419e+10, -1.9853e+11, -3.9905e+11, -3.6784e+11, -2.0050e+11,
         8.9892e+10,  1.1008e+11,  3.8768e+11,  4.5885e+11,  4.0789e+11,
         1.8006e+11,  4.7313e+11,  4.6019e+11,  2.1249e+11,  3.6605e+10,
        -3.8838e+11, -4.1323e+11,  4.2055e+11, -1.0628e+11,  2.5845e+11])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([-1.4386e-05,  3.2641e-05, -1.0233e-06, -1.7395e-05,  3.1295e-05,
         3.4591e-05, -3.3861e-06, -9.6921e-06, -2.6263e-05, -1.1208e-05,
        -9.3909e-06,  1.6491e-05, -2.2609e-05,  2.7084e-05, -5.8415e-06,
         2.7111e-07, -1.5884e-05,  2.8933e-05, -1.5465e-05, -1.9371e-05,
         1.9608e-05,  2.0978e-05, -2.5276e-05, -4.4045e-06,  2.2092e-05,
        -1.6022e-05,  1.7347e-05,  2.5339e-05, -2.1887e-05,  2.4870e-05,
        -2.1264e-05,  1.2519e-06,  9.8654e-06, -3.1652e-05,  1.9845e-05,
        -1.1987e-05, -3.3999e-05, -1.4002e-05,  4.4609e-06,  4.3845e-06,
         1.1080e-05, -1.3997e-05, -5.7168e-06,  1.5005e-06,  1.5476e-05,
        -3.2959e-05, -1.1426e-05, -1.7253e-05,  2.1806e-05, -3.4097e-05,
        -3.1020e-06,  3.2924e-05, -3.1777e-05,  2.2511e-05, -3.5612e-05,
        -3.3631e-05, -2.4278e-05,  4.4996e-06, -9.8527e-06,  3.2139e-05,
        -1.5748e-05,  3.3062e-05,  1.4747e-05,  1.0729e-05, -1.3826e-06,
         2.3357e-05, -2.7583e-05, -8.7481e-06,  7.9528e-06, -4.2142e-06,
        -1.2245e-05, -3.6236e-05,  3.0675e-05,  3.2228e-06, -3.3846e-06,
         3.3578e-05, -2.4409e-05, -2.4386e-05, -2.4440e-06, -3.3480e-05,
         5.9770e-06, -1.4398e-05, -2.8939e-05, -2.6676e-05, -1.4540e-05,
         6.5189e-06,  7.9828e-06,  2.8115e-05,  3.3276e-05,  2.9580e-05,
         1.3058e-05,  3.4311e-05,  3.3372e-05,  1.5410e-05,  2.6546e-06,
        -2.8165e-05, -2.9967e-05,  3.0498e-05, -7.7072e-06,  1.8743e-05])
[Worker 0] Completed Task 3165

[Worker 0] Processing Task 3171: paddle.nn.functional.normalize(x=Tensor([2147483649, 2],"float16"), p=1.2, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 574.31 MiB is free. Process 43207 has 78.62 GiB memory in use. Of the allocated memory 56.00 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Error on Task 3171: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 574.31 MiB is free. Process 43207 has 78.62 GiB memory in use. Of the allocated memory 56.00 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] OOM on Task 3171: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 574.31 MiB is free. Process 43207 has 78.62 GiB memory in use. Of the allocated memory 56.00 GiB is allocated by PyTorch, and 4.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 0] Started on GPU 0

[Worker 0] Processing Task 3174: paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), 1, 1e-06, False, None, )
W0523 09:51:06.017740 82599 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:51:06.019189 82599 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), 1, 1e-06, False, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 2 (100.0%)
Greatest absolute difference: 2176.0 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2]), dtype=torch.float16)
All elements: tensor([0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([2]), dtype=torch.float16)
All elements: tensor([2176., 2176.], dtype=torch.float16)
[Worker 0] Completed Task 3174

[Worker 0] Processing Task 3183: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 1, 1e-06, True, None, )
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 1, 1e-06, True, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 2281.701904296875 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1]), dtype=torch.float32)
All elements: tensor([2281.7019])
[Worker 0] Completed Task 3183

[Worker 0] Processing Task 3231: paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[1,], keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[1,], keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 52.270508GB memory has been allocated and available memory is only 26.914368GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3231

[Worker 0] Processing Task 3232: paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[-1,], keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=list[-1,], keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 52.270508GB memory has been allocated and available memory is only 26.914368GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3232

[Worker 0] Processing Task 3241: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=-1, keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=-1, keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 48.008789GB memory has been allocated and available memory is only 31.176086GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3241

[Worker 0] Processing Task 3246: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[-1,], keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[-1,], keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 48.008789GB memory has been allocated and available memory is only 31.176086GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3246

[Worker 0] Processing Task 3283: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=2, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=2, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 49.610352GB memory has been allocated and available memory is only 29.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3283

[Worker 0] Processing Task 3291: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=tuple(0,2,), keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=tuple(0,2,), keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.612305GB memory has been allocated and available memory is only 1.572571GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3291

[Worker 0] Processing Task 3325: paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=2, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=2, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 49.610352GB memory has been allocated and available memory is only 29.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3325

[Worker 0] Processing Task 3348: paddle.Tensor.chunk(Tensor([1, 1, 11109, 205393],"float32"), 2, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 1, 11109, 205393],"float32"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 1, 11109, 205393], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 3348

[Worker 0] Processing Task 3353: paddle.Tensor.chunk(Tensor([1, 101, 22591103],"float32"), 2, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 101, 22591103],"float32"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 101, 22591103], Attr(dim) = 2.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 3353

[Worker 0] Processing Task 3357: paddle.Tensor.chunk(Tensor([13, 5484860, 32],"float32"), 8, axis=1, )
[paddle error] paddle.Tensor.chunk(Tensor([13, 5484860, 32],"float32"), 8, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 8, input(X)'s shape = [13, 5484860, 32], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:4 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 3357

[Worker 0] Processing Task 3361: paddle.Tensor.chunk(Tensor([75304, 300, 101],"float32"), 16, )
[paddle error] paddle.Tensor.chunk(Tensor([75304, 300, 101],"float32"), 16, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 16, input(X)'s shape = [75304, 300, 101], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:8 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 0] Completed Task 3361

[Worker 0] Processing Task 3439: paddle.Tensor.gcd(x=Tensor([2281701379],"int32"), y=Tensor([1],"int32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.gcd(x=Tensor([2281701379],"int32"), y=Tensor([1],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   not_equal_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::not_equal(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::NotEqualRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 2.125000GB memory on GPU 0, 78.124023GB memory has been allocated and available memory is only 1.060852GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 0] Completed Task 3439
[Worker 0] Received stop signal.

[Worker 1] Processing Task 150: paddle.atan2(Tensor([58099, 222, 333],"float16"), Tensor([222, 333],"float16"), )
[accuracy error] backward  paddle.atan2(Tensor([58099, 222, 333],"float16"), Tensor([222, 333],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 49346 / 4295026674 (0.0%)
Greatest absolute difference: nan at index (30020, 99, 207) (up to 0.01 allowed)
Greatest relative difference: nan at index (1, 179, 89) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([58099, 222, 333]), dtype=torch.float16)
First 100 elements: tensor([ 4.9652e-02, -8.9478e-02,  6.1768e-01, -1.6675e-01, -2.6025e-01,
         5.5054e-02, -1.6650e-01, -1.9373e-01,  1.1121e-01,  6.9275e-02,
         1.5533e-02,  1.2306e-02, -3.9246e-02, -9.4070e-03, -5.9174e-02,
        -1.0498e-01,  3.8013e-01, -1.6614e-01,  2.2290e-01,  4.0436e-02,
         1.1493e-01, -3.5474e-01,  1.8298e-01, -6.0089e-02, -5.0781e-02,
         4.8096e-02, -2.1375e-01,  2.6587e-01, -8.0872e-02, -5.0583e-03,
        -3.2013e-02, -9.4177e-02, -3.4302e-01,  3.0655e-02, -1.2439e-01,
         9.8999e-02, -1.4258e-01, -3.1036e-02,  5.2295e-01, -4.7192e-01,
        -2.2205e-01, -3.4821e-02,  8.6121e-02,  1.1353e-01, -6.5979e-02,
        -6.3049e-02,  2.1814e-01, -6.9189e-01, -4.3896e-01,  4.1968e-01,
         3.8525e-01,  1.4709e-01, -1.9702e-01,  1.4685e-01, -1.7725e-01,
         2.3975e-01,  3.2715e-01,  5.4590e-01, -1.5967e-01,  2.5781e-01,
        -7.0251e-02,  5.2765e-02, -6.9519e-02, -3.3173e-02, -2.7319e-01,
        -2.0312e-01,  2.1204e-01, -9.4604e-03, -3.4454e-02, -2.7686e-01,
         3.1375e+01,  9.9304e-02,  3.9331e-01,  4.8584e-02, -5.2002e-01,
        -2.8931e-02, -9.0332e-02, -3.4277e-01,  1.5918e-01, -3.8745e-01,
         4.4849e-01, -8.3643e-01, -1.8176e-01,  4.4019e-01,  8.4229e-03,
        -5.6689e-01,  5.2338e-03, -8.9893e-01, -6.5369e-02,  9.8022e-02,
         3.9136e-01, -2.2522e-02,  3.8550e-01,  6.3171e-02, -2.1069e-01,
         1.4941e-01,  4.0507e-04,  1.0811e+00, -5.8789e-01, -7.3633e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([58099, 222, 333]), dtype=torch.float16)
First 100 elements: tensor([ 4.9683e-02, -8.9539e-02,  6.1816e-01, -1.6663e-01, -2.6025e-01,
         5.5054e-02, -1.6650e-01, -1.9360e-01,  1.1121e-01,  6.9336e-02,
         1.5526e-02,  1.2306e-02, -3.9246e-02, -9.4070e-03, -5.9174e-02,
        -1.0492e-01,  3.7988e-01, -1.6614e-01,  2.2290e-01,  4.0436e-02,
         1.1499e-01, -3.5449e-01,  1.8311e-01, -6.0059e-02, -5.0781e-02,
         4.8126e-02, -2.1375e-01,  2.6562e-01, -8.0872e-02, -5.0545e-03,
        -3.2013e-02, -9.4116e-02, -3.4302e-01,  3.0640e-02, -1.2433e-01,
         9.9060e-02, -1.4258e-01, -3.1052e-02,  5.2295e-01, -4.7192e-01,
        -2.2205e-01, -3.4821e-02,  8.6121e-02,  1.1359e-01, -6.5979e-02,
        -6.3049e-02,  2.1814e-01, -6.9189e-01, -4.3896e-01,  4.1992e-01,
         3.8525e-01,  1.4722e-01, -1.9702e-01,  1.4685e-01, -1.7725e-01,
         2.3975e-01,  3.2715e-01,  5.4590e-01, -1.5967e-01,  2.5781e-01,
        -7.0251e-02,  5.2765e-02, -6.9519e-02, -3.3173e-02, -2.7319e-01,
        -2.0325e-01,  2.1216e-01, -9.4528e-03, -3.4454e-02, -2.7661e-01,
         3.1391e+01,  9.9243e-02,  3.9331e-01,  4.8584e-02, -5.1953e-01,
        -2.8915e-02, -9.0393e-02, -3.4253e-01,  1.5918e-01, -3.8745e-01,
         4.4849e-01, -8.3643e-01, -1.8164e-01,  4.4043e-01,  8.4229e-03,
        -5.6689e-01,  5.2338e-03, -8.9844e-01, -6.5369e-02,  9.7961e-02,
         3.9160e-01, -2.2507e-02,  3.8525e-01,  6.3171e-02, -2.1082e-01,
         1.4954e-01,  4.0507e-04,  1.0811e+00, -5.8789e-01, -7.3682e-01],
       dtype=torch.float16)
[Worker 1] Completed Task 150

[Worker 1] Processing Task 191: paddle.conj(Tensor([2, 357913942, 2, 3],"float32"), )
W0522 15:55:56.696089 42879 backward.cc:441] While running Node (ConjGradNode) raises a std::exception: paddle::memory::allocation::BadAlloc
[paddle error] paddle.conj(Tensor([2, 357913942, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   ConjGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::conj(paddle::Tensor const&)
4   void phi::ConjKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.610352GB memory has been allocated and available memory is only 13.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 191

[Worker 1] Processing Task 197: paddle.diff(Tensor([2, 1140850690],"float32"), n=1, axis=0, prepend=Tensor([2, 1140850690],"float32"), append=Tensor([2, 1140850690],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 1140850690],"float32"), n=1, axis=0, prepend=Tensor([2, 1140850690],"float32"), append=Tensor([2, 1140850690],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 5589608130 / 5704253450 (98.0%)
Greatest absolute difference: 0.9999799728393555 at index (0, 937286268) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([5, 1140850690]), dtype=torch.float32)
First 100 elements: tensor([-0.0193, -0.1406, -0.1552,  0.6341,  0.2106, -0.3153, -0.3076,  0.0892,
         0.2924, -0.0326, -0.3654,  0.2380, -0.3438, -0.4240, -0.0389,  0.5734,
         0.6994,  0.6802,  0.0567,  0.0114, -0.0882, -0.5205, -0.0857, -0.3589,
        -0.2943, -0.3225,  0.0601, -0.1390, -0.1749,  0.1027, -0.0988,  0.1950,
        -0.4487,  0.2342, -0.0232, -0.2727, -0.5803,  0.3283,  0.2420,  0.7627,
        -0.7661,  0.7447, -0.1139, -0.1969, -0.1512, -0.0854,  0.0078, -0.6137,
         0.0202,  0.4373, -0.7869,  0.5481,  0.1923, -0.3788,  0.3087,  0.1723,
         0.3721, -0.3650, -0.5934, -0.2849, -0.1400,  0.0248, -0.3934,  0.6678,
         0.1646, -0.1461,  0.3386, -0.3035,  0.7441, -0.1537, -0.1563, -0.0772,
         0.2081, -0.5160, -0.7175, -0.6848,  0.2932,  0.5064,  0.2900,  0.4702,
         0.3357, -0.1482,  0.1421, -0.4325,  0.8365,  0.0262,  0.2854,  0.6832,
        -0.0518, -0.0717,  0.5080, -0.5067, -0.6301,  0.2863,  0.0258, -0.3586,
        -0.4586, -0.3971, -0.0554, -0.1417])
[Worker 1] Completed Task 197

[Worker 1] Processing Task 204: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=Tensor([2, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235838299 / 2281701392 (98.0%)
Greatest absolute difference: 0.9999690055847168 at index (463164065, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425348, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425348, 4]), dtype=torch.float32)
First 100 elements: tensor([-0.3734,  0.2288, -0.3413,  0.5850,  0.1335, -0.3025,  0.2328, -0.5983,
         0.5473,  0.5210,  0.0684,  0.0771, -0.7793, -0.7944, -0.1110,  0.0410,
         0.3214,  0.8798, -0.3277,  0.7018,  0.2110, -0.2945, -0.0724, -0.4675,
         0.1997, -0.0851,  0.6391,  0.0787, -0.1335, -0.2304, -0.3163, -0.0958,
        -0.0122,  0.1547,  0.0513, -0.3150,  0.2788, -0.3447,  0.0508,  0.3288,
        -0.1546,  0.5946,  0.0106,  0.4156,  0.1196, -0.5021,  0.2498, -0.7188,
        -0.2625,  0.5151, -0.4032,  0.0781, -0.4423, -0.3851,  0.2102,  0.1806,
         0.7867, -0.0729,  0.2726, -0.4224, -0.8967, -0.0404, -0.5420,  0.3030,
         0.0205, -0.0928,  0.6109, -0.2404,  0.1721,  0.7873, -0.2406,  0.7650,
         0.3959, -0.7006, -0.3517, -0.7820, -0.0155,  0.5735, -0.0125,  0.5664,
        -0.5583,  0.0159, -0.0258, -0.5800,  0.4709, -0.2114, -0.1949,  0.6585,
         0.2626, -0.0267,  0.7501, -0.2581,  0.0571, -0.1178, -0.8183,  0.0739,
        -0.4600, -0.4084,  0.7986, -0.3232])
[Worker 1] Completed Task 204

[Worker 1] Processing Task 208: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([570425345, 4],"float32"), append=Tensor([2, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([570425345, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258651815 / 2281701388 (99.0%)
Greatest absolute difference: 1.998679757118225 at index (327216887, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425347, 4]), dtype=torch.float32)
First 100 elements: tensor([ 5.0690e-01, -5.3129e-01,  5.7419e-01, -1.1832e+00,  4.1378e-01,
         8.2346e-01, -1.6447e-01,  6.7537e-01, -1.3266e+00, -1.3154e+00,
        -1.7935e-01, -3.6095e-02,  1.1007e+00,  1.6743e+00, -2.1668e-01,
         6.6077e-01, -1.1046e-01, -1.1744e+00,  2.5525e-01, -1.1693e+00,
        -1.1243e-02,  2.0943e-01,  7.1146e-01,  5.4625e-01, -3.3322e-01,
        -1.4535e-01, -9.5536e-01, -1.7452e-01,  1.2128e-01,  3.8514e-01,
         3.6759e-01, -2.1924e-01,  2.9102e-01, -4.9943e-01, -4.9078e-04,
         6.4388e-01, -4.3342e-01,  9.3929e-01, -4.0247e-02,  8.6780e-02,
         2.7424e-01, -1.0967e+00,  2.3921e-01, -1.1344e+00, -3.8211e-01,
         1.0172e+00, -6.5292e-01,  7.9688e-01, -1.7985e-01, -9.0015e-01,
         6.1331e-01,  1.0252e-01,  1.2290e+00,  3.1219e-01,  6.2426e-02,
        -6.0305e-01, -1.6834e+00,  3.2460e-02, -8.1455e-01,  7.2543e-01,
         9.1719e-01, -5.2389e-02,  1.1528e+00, -5.4343e-01,  1.5161e-01,
         8.8012e-01, -8.5152e-01,  1.0055e+00,  2.2381e-01, -1.4880e+00,
        -1.1107e-01, -1.5470e+00, -4.1139e-01,  1.2741e+00,  3.3921e-01,
         1.3484e+00, -5.4281e-01, -5.5753e-01, -1.3282e-02, -1.1464e+00,
         1.0292e+00, -2.2735e-01, -1.6915e-01,  1.2385e+00, -2.0827e-01,
         1.8472e-01,  9.4506e-01, -9.1660e-01, -2.0552e-01, -9.1046e-02,
        -1.5684e+00,  3.3201e-01, -5.1706e-01, -2.9067e-01,  1.6169e+00,
        -3.9718e-01,  9.3923e-01,  1.1438e+00, -8.5222e-01,  7.0410e-01])
[Worker 1] Completed Task 208

[Worker 1] Processing Task 212: paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=None, append=None, )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=None, append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235838283 / 2281701376 (98.0%)
Greatest absolute difference: 0.9999690055847168 at index (463164065, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425344, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425344, 4]), dtype=torch.float32)
First 100 elements: tensor([-0.3734,  0.2288, -0.3413,  0.5850,  0.1335, -0.3025,  0.2328, -0.5983,
         0.5473,  0.5210,  0.0684,  0.0771, -0.7793, -0.7944, -0.1110,  0.0410,
         0.3214,  0.8798, -0.3277,  0.7018,  0.2110, -0.2945, -0.0724, -0.4675,
         0.1997, -0.0851,  0.6391,  0.0787, -0.1335, -0.2304, -0.3163, -0.0958,
        -0.0122,  0.1547,  0.0513, -0.3150,  0.2788, -0.3447,  0.0508,  0.3288,
        -0.1546,  0.5946,  0.0106,  0.4156,  0.1196, -0.5021,  0.2498, -0.7188,
        -0.2625,  0.5151, -0.4032,  0.0781, -0.4423, -0.3851,  0.2102,  0.1806,
         0.7867, -0.0729,  0.2726, -0.4224, -0.8967, -0.0404, -0.5420,  0.3030,
         0.0205, -0.0928,  0.6109, -0.2404,  0.1721,  0.7873, -0.2406,  0.7650,
         0.3959, -0.7006, -0.3517, -0.7820, -0.0155,  0.5735, -0.0125,  0.5664,
        -0.5583,  0.0159, -0.0258, -0.5800,  0.4709, -0.2114, -0.1949,  0.6585,
         0.2626, -0.0267,  0.7501, -0.2581,  0.0571, -0.1178, -0.8183,  0.0739,
        -0.4600, -0.4084,  0.7986, -0.3232])
[Worker 1] Completed Task 212

[Worker 1] Processing Task 215: paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235838299 / 2281701392 (98.0%)
Greatest absolute difference: 0.9999690055847168 at index (463164067, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425348, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425348, 4]), dtype=torch.float32)
First 100 elements: tensor([-0.3734,  0.2288, -0.3413,  0.5850,  0.3734, -0.2288,  0.3413, -0.5850,
        -0.3734,  0.2288, -0.3413,  0.5850,  0.1335, -0.3025,  0.2328, -0.5983,
         0.5473,  0.5210,  0.0684,  0.0771, -0.7793, -0.7944, -0.1110,  0.0410,
         0.3214,  0.8798, -0.3277,  0.7018,  0.2110, -0.2945, -0.0724, -0.4675,
         0.1997, -0.0851,  0.6391,  0.0787, -0.1335, -0.2304, -0.3163, -0.0958,
        -0.0122,  0.1547,  0.0513, -0.3150,  0.2788, -0.3447,  0.0508,  0.3288,
        -0.1546,  0.5946,  0.0106,  0.4156,  0.1196, -0.5021,  0.2498, -0.7188,
        -0.2625,  0.5151, -0.4032,  0.0781, -0.4423, -0.3851,  0.2102,  0.1806,
         0.7867, -0.0729,  0.2726, -0.4224, -0.8967, -0.0404, -0.5420,  0.3030,
         0.0205, -0.0928,  0.6109, -0.2404,  0.1721,  0.7873, -0.2406,  0.7650,
         0.3959, -0.7006, -0.3517, -0.7820, -0.0155,  0.5735, -0.0125,  0.5664,
        -0.5583,  0.0159, -0.0258, -0.5800,  0.4709, -0.2114, -0.1949,  0.6585,
         0.2626, -0.0267,  0.7501, -0.2581])
[Worker 1] Completed Task 215

[Worker 1] Processing Task 219: paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258651807 / 2281701380 (99.0%)
Greatest absolute difference: 1.998679757118225 at index (327216887, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([ 5.0690e-01, -5.3129e-01,  5.7419e-01, -1.1832e+00,  4.1378e-01,
         8.2346e-01, -1.6447e-01,  6.7537e-01, -1.3266e+00, -1.3154e+00,
        -1.7935e-01, -3.6095e-02,  1.1007e+00,  1.6743e+00, -2.1668e-01,
         6.6077e-01, -1.1046e-01, -1.1744e+00,  2.5525e-01, -1.1693e+00,
        -1.1243e-02,  2.0943e-01,  7.1146e-01,  5.4625e-01, -3.3322e-01,
        -1.4535e-01, -9.5536e-01, -1.7452e-01,  1.2128e-01,  3.8514e-01,
         3.6759e-01, -2.1924e-01,  2.9102e-01, -4.9943e-01, -4.9078e-04,
         6.4388e-01, -4.3342e-01,  9.3929e-01, -4.0247e-02,  8.6780e-02,
         2.7424e-01, -1.0967e+00,  2.3921e-01, -1.1344e+00, -3.8211e-01,
         1.0172e+00, -6.5292e-01,  7.9688e-01, -1.7985e-01, -9.0015e-01,
         6.1331e-01,  1.0252e-01,  1.2290e+00,  3.1219e-01,  6.2426e-02,
        -6.0305e-01, -1.6834e+00,  3.2460e-02, -8.1455e-01,  7.2543e-01,
         9.1719e-01, -5.2389e-02,  1.1528e+00, -5.4343e-01,  1.5161e-01,
         8.8012e-01, -8.5152e-01,  1.0055e+00,  2.2381e-01, -1.4880e+00,
        -1.1107e-01, -1.5470e+00, -4.1139e-01,  1.2741e+00,  3.3921e-01,
         1.3484e+00, -5.4281e-01, -5.5753e-01, -1.3282e-02, -1.1464e+00,
         1.0292e+00, -2.2735e-01, -1.6915e-01,  1.2385e+00, -2.0827e-01,
         1.8472e-01,  9.4506e-01, -9.1660e-01, -2.0552e-01, -9.1046e-02,
        -1.5684e+00,  3.3201e-01, -5.1706e-01, -2.9067e-01,  1.6169e+00,
        -3.9718e-01,  9.3923e-01,  1.1438e+00, -8.5222e-01,  7.0410e-01])
[Worker 1] Completed Task 219

[Worker 1] Processing Task 223: paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([570425345, 4],"float32"), n=2, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 43896 has 69.61 GiB memory in use. Of the allocated memory 51.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 223

[Worker 1] Processing Task 224: paddle.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([1073741825, 4],"float16"), append=Tensor([4, 4],"float16"), )
[accuracy error] paddle.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([1073741825, 4],"float16"), append=Tensor([4, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208565366 / 4294967352 (98.0%)
Greatest absolute difference: 1.0 at index (50141, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([ 6.8311e-01,  5.4199e-02, -6.1768e-01, -2.8906e-01,  5.8472e-02,
         4.7021e-01,  3.9062e-01, -5.3516e-01, -6.9824e-01,  1.4392e-01,
        -3.2739e-01,  1.6406e-01,  6.7578e-01, -6.8018e-01, -5.1636e-02,
         3.3594e-01, -5.0488e-01,  2.8076e-02,  8.5693e-02, -5.4980e-01,
        -1.6504e-01,  3.0518e-01, -7.8369e-02,  5.2441e-01,  5.5908e-01,
        -4.7729e-01,  4.9414e-01,  3.3911e-01, -1.1212e-01,  3.6963e-01,
        -6.2061e-01, -3.4399e-01, -4.7827e-01, -3.3203e-02,  6.1914e-01,
         3.5889e-01,  7.7197e-01, -2.4536e-02, -1.9702e-01, -7.0117e-01,
        -6.1914e-01,  2.2900e-01, -5.0049e-01,  6.6113e-01,  1.6028e-01,
        -9.6741e-02,  4.0625e-01, -3.5400e-02,  7.7454e-02,  3.2104e-01,
        -2.2485e-01, -4.1821e-01,  1.4648e-02, -2.9224e-01,  2.9785e-02,
         1.7322e-01,  2.2900e-01,  1.0822e-01,  3.5693e-01, -4.8340e-01,
        -6.1035e-01,  2.2070e-01, -8.0994e-02,  4.3921e-01,  7.8418e-01,
        -4.2969e-01,  3.1616e-01, -9.3445e-02, -3.8208e-01, -1.1230e-02,
        -6.7480e-01,  5.1172e-01,  2.6367e-01,  1.7920e-01,  3.6353e-01,
        -3.0811e-01,  1.7651e-01, -5.1904e-01,  4.8633e-01,  2.1252e-01,
        -3.9502e-01,  4.8022e-01, -8.4180e-01, -1.8054e-01, -1.4587e-01,
        -3.9307e-01, -7.5928e-02, -3.9771e-01,  1.4880e-01, -7.3242e-04,
         4.1626e-01,  7.0947e-01, -4.3921e-01, -3.1006e-02, -8.3069e-02,
        -8.2910e-01,  5.6641e-02,  5.9033e-01,  4.3884e-02, -7.8857e-02],
       dtype=torch.float16)
[Worker 1] Completed Task 224

[Worker 1] Processing Task 228: paddle.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), )
[accuracy error] paddle.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208556853 / 4294967306 (98.0%)
Greatest absolute difference: 1.0 at index (13478197,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967306]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967306]), dtype=torch.float16)
First 100 elements: tensor([ 0.1807,  0.6426,  0.0674, -0.2076, -0.4482, -0.0291,  0.3960,  0.1399,
        -0.0365, -0.1086, -0.5298, -0.0232,  0.8057, -0.5801, -0.0382,  0.4885,
        -0.5508,  0.0486,  0.3494, -0.3525, -0.0173,  0.1062, -0.2861,  0.0322,
         0.4529, -0.2773,  0.3167,  0.0669, -0.5835,  0.6938,  0.1617, -0.3843,
        -0.1017, -0.2964,  0.4382, -0.5186,  0.3433,  0.3560,  0.1781, -0.1055,
        -0.4531,  0.1835, -0.3257, -0.0237,  0.3950, -0.5459,  0.8359, -0.5244,
         0.1379, -0.0429,  0.3940, -0.4116,  0.3816, -0.5889,  0.2007,  0.0212,
         0.0749, -0.2668,  0.3442,  0.0769, -0.0458, -0.0183, -0.4963, -0.0498,
         0.7852, -0.3201,  0.0239,  0.2949, -0.4287,  0.4258, -0.3857,  0.0063,
        -0.0576, -0.2377,  0.8008, -0.2415, -0.1422, -0.0534,  0.1292,  0.2430,
        -0.8379,  0.9521, -0.1448, -0.3645,  0.0373, -0.3701,  0.5166, -0.3298,
        -0.2098, -0.0530,  0.1949,  0.2167, -0.3594,  0.3640,  0.4883, -0.9321,
         0.0488,  0.3120, -0.2578, -0.0464], dtype=torch.float16)
[Worker 1] Completed Task 228

[Worker 1] Processing Task 232: paddle.diff(x=Tensor([2281701379],"int32"), )
[accuracy error] paddle.diff(x=Tensor([2281701379],"int32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281683948 / 2281701378 (100.0%)
Greatest absolute difference: 131069 at index (565379009,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.int32)
First 100 elements: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0], dtype=torch.int32)
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.int32)
First 100 elements: tensor([  66629,     192,   -9773,  -31504,  -42176,   88871,  -31163,  -25377,
           4862,  -65143,   88173,    3284,   15609,  -95620,   14612,   26185,
          -6186,   43907,  -62239,   23968,   34464,   26473,  -28142,  -65773,
          88708,  -86085,     319,   34824,   -1507,  -38814,  -18837,   44253,
          72395,  -88414,  -10520,  -12767,   73866,  -57644,   99333,  -15225,
           2371, -104087,   46485,   65278,  -61818,   64809, -112089,   74189,
         -48910,   88030,  -32123,  -39025,  -49469,   23230,   61849,   20727,
         -51379,  -43143,   60410,  -47915,   13723,   81164, -107377,  -10952,
          14086,   30460,     -59,  -47206,   90267,    5557,    6594,  -86540,
         -12311,   67429,   56133,  -44117,   13343,  -19552,   38223,  -95529,
         -10030,   66786,   24790,  -30721,   14510,   -8689,  -44314,   57778,
         -62344,   68185,  -66597,    8750,    9355,   17628,   -5659,  -50953,
          19276,   25436,   74955,  -46924], dtype=torch.int32)
[Worker 1] Completed Task 232

[Worker 1] Processing Task 236: paddle.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4],"float16"), )
[accuracy error] paddle.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), append=Tensor([4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208556851 / 4294967304 (98.0%)
Greatest absolute difference: 1.0 at index (13478201,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967304]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967304]), dtype=torch.float16)
First 100 elements: tensor([ 0.1807,  0.6426,  0.0674, -0.8906,  0.1807,  0.6426,  0.0674, -0.2076,
        -0.4482, -0.0291,  0.3960,  0.1399, -0.0365, -0.1086, -0.5298, -0.0232,
         0.8057, -0.5801, -0.0382,  0.4885, -0.5508,  0.0486,  0.3494, -0.3525,
        -0.0173,  0.1062, -0.2861,  0.0322,  0.4529, -0.2773,  0.3167,  0.0669,
        -0.5835,  0.6938,  0.1617, -0.3843, -0.1017, -0.2964,  0.4382, -0.5186,
         0.3433,  0.3560,  0.1781, -0.1055, -0.4531,  0.1835, -0.3257, -0.0237,
         0.3950, -0.5459,  0.8359, -0.5244,  0.1379, -0.0429,  0.3940, -0.4116,
         0.3816, -0.5889,  0.2007,  0.0212,  0.0749, -0.2668,  0.3442,  0.0769,
        -0.0458, -0.0183, -0.4963, -0.0498,  0.7852, -0.3201,  0.0239,  0.2949,
        -0.4287,  0.4258, -0.3857,  0.0063, -0.0576, -0.2377,  0.8008, -0.2415,
        -0.1422, -0.0534,  0.1292,  0.2430, -0.8379,  0.9521, -0.1448, -0.3645,
         0.0373, -0.3701,  0.5166, -0.3298, -0.2098, -0.0530,  0.1949,  0.2167,
        -0.3594,  0.3640,  0.4883, -0.9321], dtype=torch.float16)
[Worker 1] Completed Task 236

[Worker 1] Processing Task 241: paddle.digamma(Tensor([10, 21474837, 10, 2],"float16"), )
[accuracy error] paddle.digamma(Tensor([10, 21474837, 10, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 273 / 4294967400 (0.0%)
Greatest absolute difference: nan at index (0, 989974, 4, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 989974, 4, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 21474837, 10, 2]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([10, 21474837, 10, 2]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
[Worker 1] Completed Task 241

[Worker 1] Processing Task 245: paddle.digamma(Tensor([2, 5, 429496730],"float16"), )
[accuracy error] paddle.digamma(Tensor([2, 5, 429496730],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 273 / 4294967300 (0.0%)
Greatest absolute difference: nan at index (0, 0, 19799489) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 19799489) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 5, 429496730]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 5, 429496730]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
[Worker 1] Completed Task 245

[Worker 1] Processing Task 249: paddle.digamma(Tensor([429496730, 5, 2],"float16"), )
[accuracy error] paddle.digamma(Tensor([429496730, 5, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 273 / 4294967300 (0.0%)
Greatest absolute difference: nan at index (1979948, 4, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (1979948, 4, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([429496730, 5, 2]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([429496730, 5, 2]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
[Worker 1] Completed Task 249

[Worker 1] Processing Task 253: paddle.digamma(x=Tensor([119304648, 6, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([119304648, 6, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 273 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (549985, 4, 5) (up to 0.01 allowed)
Greatest relative difference: nan at index (549985, 4, 5) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([119304648, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([119304648, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
[Worker 1] Completed Task 253

[Worker 1] Processing Task 257: paddle.digamma(x=Tensor([3, 6, 6, 6, 6628036],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([3, 6, 6, 6, 6628036],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 273 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 0, 0, 2, 6543417) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 2, 6543417) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 6, 6, 6, 6628036]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 6, 6, 6, 6628036]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
[Worker 1] Completed Task 257

[Worker 1] Processing Task 261: paddle.digamma(x=Tensor([3314018, 6, 6, 6, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([3314018, 6, 6, 6, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 273 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (15277, 2, 1, 4, 5) (up to 0.01 allowed)
Greatest relative difference: nan at index (15277, 2, 1, 4, 5) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3314018, 6, 6, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3314018, 6, 6, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
[Worker 1] Completed Task 261

[Worker 1] Processing Task 265: paddle.digamma(x=Tensor([6, 6, 19884108, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([6, 6, 19884108, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 273 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 0, 3299914, 5) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 3299914, 5) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([6, 6, 19884108, 6]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([6, 6, 19884108, 6]), dtype=torch.float16)
First 100 elements: tensor([ 3.8666e-02,  1.8584e+00, -3.2324e+00, -2.6270e+00, -5.7617e+00,
         2.6504e+00,  2.1992e+00, -1.0211e+01, -4.3711e+00, -5.1484e+00,
        -1.0758e+01,  6.4453e-01,  4.3115e-01, -2.9766e+00,  3.2988e+00,
         2.5859e+00, -4.8164e+00,  1.7119e+00,  2.3730e+00, -1.5367e+01,
         2.3242e+00,  2.0762e+00,  4.1328e+00,  1.9141e-01,  4.8218e-01,
        -4.1175e+02,  2.4863e+00, -2.4453e+01, -9.6094e+00,  2.6147e-01,
        -4.8281e+00, -2.7070e+00,  2.9200e+02,  8.7500e+00,  9.4580e-01,
        -2.7578e+01,  2.0020e-01,  6.3984e+00, -4.8633e+00, -2.5918e+00,
        -3.6250e+00,  5.2578e+00, -4.9062e+01,  2.0430e+00,  1.7363e+00,
        -1.5586e+01,  2.1765e-01, -2.9160e+00,  5.0352e+00,  3.2062e+01,
         1.2906e+01, -3.2656e+00,  1.0234e+01, -3.6211e+00,  2.1367e+00,
         9.4922e+00,  1.2367e+01,  6.2100e+02,  2.5898e+00, -1.3695e+01,
        -6.9102e+00, -9.7891e+00, -1.1766e+01,  8.8135e-01,  4.1553e-01,
        -3.1934e+00, -1.3725e+02, -3.2594e+01, -3.2051e+00,  9.0078e+00,
        -3.2344e+00,  1.5375e+01,  1.7188e+01,  8.0156e+00,  1.4717e+00,
        -2.2383e+00, -5.0938e+00, -1.5727e+01, -8.3125e+01, -7.4453e+00,
        -2.6797e+00,  4.5337e-01, -1.9707e+00, -2.9375e+00,  9.2062e+01,
        -3.8250e+01,  1.5615e+00, -6.0977e+00,  5.5156e+00,  1.3047e+00,
         7.7100e-01,  3.4316e+00,  1.2825e+02,  1.2969e+00,  3.1100e+02,
        -2.0391e+00,  5.1367e-01,  9.7705e-01,  1.0859e+01,  1.5557e+00],
       dtype=torch.float16)
[Worker 1] Completed Task 265

[Worker 1] Processing Task 269: paddle.dist(Tensor([2, 190141782, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[accuracy error] paddle.dist(Tensor([2, 190141782, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 14737.1142578125 but got 0.0.
Absolute difference: 14737.1142578125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([14737.1143])
[Worker 1] Completed Task 269

[Worker 1] Processing Task 273: paddle.dist(Tensor([2, 2, 3, 190141782],"float32"), Tensor([1, 1, 3, 190141782],"float32"), 2, )
[accuracy error] paddle.dist(Tensor([2, 2, 3, 190141782],"float32"), Tensor([1, 1, 3, 190141782],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 16887.939453125 but got 0.0.
Absolute difference: 16887.939453125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([16887.9395])
[Worker 1] Completed Task 273

[Worker 1] Processing Task 281: paddle.fft.ifftshift(x=Tensor([4, 67108865, 4, 4],"float16"), )
[accuracy error] paddle.fft.ifftshift(x=Tensor([4, 67108865, 4, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 127 / 4294967360 (0.0%)
Greatest absolute difference: 0.49755859375 at index (3, 33554429, 1, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (3, 33554429, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 67108865, 4, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.3320,  0.1096, -0.1541,  0.4060,  0.2866,  0.0709, -0.1149, -0.4902,
         0.0887, -0.2556, -0.1177, -0.3574,  0.0903, -0.1577,  0.1819, -0.3176,
        -0.3396,  0.3030,  0.1334,  0.2325, -0.1389,  0.0021,  0.0311, -0.2179,
         0.4800, -0.2480, -0.0379, -0.4133,  0.0060, -0.2517, -0.4802,  0.2698,
         0.1627, -0.3672,  0.4226, -0.1907,  0.0881,  0.3071, -0.1658,  0.4060,
         0.1200,  0.4990, -0.4614, -0.3635,  0.0133,  0.0900,  0.0342,  0.3860,
         0.1796,  0.4014,  0.2040,  0.0850, -0.3650, -0.2612,  0.0628,  0.0988,
        -0.2827, -0.2546,  0.2407, -0.1127,  0.3149,  0.0115, -0.0272,  0.4980,
         0.1624, -0.1283,  0.2534, -0.4136,  0.2612,  0.2230,  0.2659, -0.2430,
        -0.1835,  0.3621, -0.4214, -0.3821,  0.2612,  0.2321, -0.4465, -0.4094,
        -0.4141, -0.1536,  0.4614, -0.0404,  0.3513, -0.3364,  0.3042,  0.1376,
        -0.4260, -0.4819, -0.0624,  0.4214, -0.4629, -0.3772,  0.4451,  0.3799,
         0.3604,  0.3132,  0.0277,  0.0219], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 67108865, 4, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.3320,  0.1096, -0.1541,  0.4060,  0.2866,  0.0709, -0.1149, -0.4902,
         0.0887, -0.2556, -0.1177, -0.3574,  0.0903, -0.1577,  0.1819, -0.3176,
        -0.3396,  0.3030,  0.1334,  0.2325, -0.1389,  0.0021,  0.0311, -0.2179,
         0.4800, -0.2480, -0.0379, -0.4133,  0.0060, -0.2517, -0.4802,  0.2698,
         0.1627, -0.3672,  0.4226, -0.1907,  0.0881,  0.3071, -0.1658,  0.4060,
         0.1200,  0.4990, -0.4614, -0.3635,  0.0133,  0.0900,  0.0342,  0.3860,
         0.1796,  0.4014,  0.2040,  0.0850, -0.3650, -0.2612,  0.0628,  0.0988,
        -0.2827, -0.2546,  0.2407, -0.1127,  0.3149,  0.0115, -0.0272,  0.4980,
         0.1624, -0.1283,  0.2534, -0.4136,  0.2612,  0.2230,  0.2659, -0.2430,
        -0.1835,  0.3621, -0.4214, -0.3821,  0.2612,  0.2321, -0.4465, -0.4094,
        -0.4141, -0.1536,  0.4614, -0.0404,  0.3513, -0.3364,  0.3042,  0.1376,
        -0.4260, -0.4819, -0.0624,  0.4214, -0.4629, -0.3772,  0.4451,  0.3799,
         0.3604,  0.3132,  0.0277,  0.0219], dtype=torch.float16)
[Worker 1] Completed Task 281

[Worker 1] Processing Task 529: paddle.isreal(Tensor([134217728, 32],"int16"), )
[accuracy error] paddle.isreal(Tensor([134217728, 32],"int16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    expected=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 1] Completed Task 529

[Worker 1] Processing Task 549: paddle.isreal(Tensor([64, 67108864],"bool"), )
[accuracy error] paddle.isreal(Tensor([64, 67108864],"bool"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    expected=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 1] Completed Task 549

[Worker 1] Processing Task 552: paddle.isreal(Tensor([64, 67108864],"int16"), )
[accuracy error] paddle.isreal(Tensor([64, 67108864],"int16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    expected=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 1] Completed Task 552

[Worker 1] Processing Task 566: paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([2910334, 28, 28],"float32"), 1.0, )
[accuracy error] backward  paddle.lerp(Tensor([1, 28, 28],"float32"), Tensor([2910334, 28, 28],"float32"), 1.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235602722 / 2281701856 (98.0%)
Greatest absolute difference: 0.5 at index (15883, 3, 3) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2910334, 28, 28]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2910334, 28, 28]), dtype=torch.float32)
First 100 elements: tensor([ 0.1998,  0.1838, -0.3651, -0.0835, -0.1514,  0.1122, -0.2344, -0.3300,
         0.1447, -0.3057, -0.1587,  0.4499,  0.4704, -0.0756,  0.1915,  0.3618,
         0.0721,  0.0088, -0.0869,  0.4827, -0.0472, -0.3423,  0.3566, -0.2029,
         0.1109, -0.1164,  0.0576,  0.4881,  0.3269,  0.1515, -0.2739,  0.4114,
         0.4414, -0.1983, -0.1762, -0.1480,  0.2990,  0.2446,  0.0122,  0.1032,
         0.0010,  0.0933, -0.1156,  0.4925,  0.2637,  0.2030, -0.1946,  0.3008,
         0.2436,  0.4067,  0.2223, -0.0902,  0.3740, -0.1379, -0.0567,  0.1610,
         0.4197,  0.4737,  0.0294, -0.3683,  0.1273, -0.2872,  0.3930,  0.3120,
        -0.0524,  0.1079,  0.4098, -0.2491, -0.2846,  0.0400, -0.3700,  0.3180,
        -0.4552,  0.2724,  0.1786,  0.2762, -0.4787, -0.2642,  0.0378,  0.0014,
        -0.2231, -0.4543, -0.2854,  0.1717,  0.2680,  0.4178,  0.1164, -0.3174,
        -0.1897, -0.4622, -0.2821, -0.1728, -0.2015, -0.1649,  0.2766, -0.0349,
         0.4503, -0.4532, -0.3783, -0.4289])
[Worker 1] Completed Task 566

[Worker 1] Processing Task 572: paddle.lerp(Tensor([1],"float16"), Tensor([4294967297],"float16"), Tensor([1],"float16"), )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43896 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 572: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43896 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 572: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.66 GiB is free. Process 43896 has 75.52 GiB memory in use. Of the allocated memory 48.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 574: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 0.3, )
W0522 16:45:21.352449 43521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:45:21.353412 43521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 0.3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 2 (100.0%)
Greatest absolute difference: 9949.1015625 at index (1, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1, 1, 1]), dtype=torch.float32)
All elements: tensor([0., 0.])
DESIRED: (shape=torch.Size([2, 1, 1, 1]), dtype=torch.float32)
All elements: tensor([-6179.5732, -9949.1016])
[Worker 1] Completed Task 574

[Worker 1] Processing Task 578: paddle.lerp(Tensor([2, 17825793, 8, 8],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 1.1, )
[accuracy error] backward  paddle.lerp(Tensor([2, 17825793, 8, 8],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 1.1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1820736257 / 2281701504 (79.8%)
Greatest absolute difference: 0.05000000074505806 at index (0, 982402, 0, 6) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 17825793, 8, 8]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2, 17825793, 8, 8]), dtype=torch.float32)
First 100 elements: tensor([ 0.0384,  0.0193,  0.0055, -0.0151,  0.0082, -0.0098, -0.0386,  0.0055,
        -0.0307,  0.0393,  0.0326,  0.0218, -0.0049,  0.0213, -0.0044,  0.0037,
         0.0296, -0.0416,  0.0325, -0.0376,  0.0235,  0.0467, -0.0105, -0.0231,
         0.0064, -0.0002,  0.0305, -0.0268, -0.0377,  0.0371, -0.0195, -0.0009,
        -0.0419,  0.0225,  0.0472,  0.0390,  0.0020, -0.0209,  0.0007,  0.0305,
         0.0364,  0.0434, -0.0396,  0.0014,  0.0337,  0.0473,  0.0024, -0.0466,
         0.0360, -0.0041,  0.0323,  0.0036,  0.0342, -0.0097, -0.0398, -0.0391,
        -0.0399,  0.0210, -0.0427, -0.0188, -0.0363, -0.0193,  0.0039,  0.0217,
        -0.0378,  0.0437,  0.0305, -0.0333, -0.0275, -0.0118, -0.0260, -0.0382,
        -0.0255,  0.0037,  0.0387, -0.0180,  0.0286, -0.0316, -0.0498, -0.0001,
        -0.0477, -0.0297, -0.0178,  0.0218, -0.0376, -0.0014, -0.0283, -0.0244,
         0.0100, -0.0410,  0.0124,  0.0073, -0.0251, -0.0264, -0.0462, -0.0270,
        -0.0147,  0.0444,  0.0282, -0.0213])
[Worker 1] Completed Task 578

[Worker 1] Processing Task 581: paddle.linalg.cond(Tensor([142606337, 4, 4],"float32"), p="fro", )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.35 GiB is free. Process 93031 has 74.83 GiB memory in use. Of the allocated memory 28.96 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 581: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.35 GiB is free. Process 93031 has 74.83 GiB memory in use. Of the allocated memory 28.96 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 581: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.35 GiB is free. Process 93031 has 74.83 GiB memory in use. Of the allocated memory 28.96 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 621: paddle.linalg.norm(Tensor([4294967295],"float32"), )
[accuracy error] paddle.linalg.norm(Tensor([4294967295],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18918.548828125 but got 0.0.
Absolute difference: 18918.548828125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([18918.5488])
[Worker 1] Completed Task 621

[Worker 1] Processing Task 623: paddle.linalg.norm(Tensor([4294967295],"float32"), p=1, )
[accuracy error] paddle.linalg.norm(Tensor([4294967295],"float32"), p=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 1073739904.0 but got 0.0.
Absolute difference: 1073739904.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([1.0737e+09])
[Worker 1] Completed Task 623

[Worker 1] Processing Task 625: paddle.linalg.norm(Tensor([50, 50, 1717987],"float16"), p=2.0, axis=-1, )
[accuracy error] paddle.linalg.norm(Tensor([50, 50, 1717987],"float16"), p=2.0, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2500 / 2500 (100.0%)
Greatest absolute difference: 356.5 at index (24, 5) (up to 0.01 allowed)
Greatest relative difference: 0.9404296875 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([50, 50]), dtype=torch.float16)
First 100 elements: tensor([22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250,
        22.6250, 22.6250, 22.6250, 22.6250], dtype=torch.float16)
DESIRED: (shape=torch.Size([50, 50]), dtype=torch.float16)
First 100 elements: tensor([378.5000, 378.2500, 378.2500, 378.2500, 378.2500, 378.2500, 378.2500,
        378.5000, 378.5000, 378.5000, 378.5000, 378.5000, 378.2500, 378.5000,
        378.2500, 378.2500, 378.5000, 378.2500, 378.5000, 378.5000, 378.2500,
        378.2500, 378.2500, 378.5000, 378.5000, 378.5000, 378.5000, 378.5000,
        378.2500, 378.2500, 378.2500, 378.5000, 378.2500, 378.5000, 378.2500,
        378.2500, 378.5000, 378.5000, 378.5000, 378.5000, 378.5000, 378.5000,
        378.2500, 378.2500, 378.2500, 378.5000, 378.5000, 378.2500, 378.5000,
        378.5000, 378.2500, 378.2500, 378.5000, 378.2500, 378.2500, 378.2500,
        378.2500, 378.2500, 378.2500, 378.5000, 378.5000, 378.2500, 378.2500,
        378.5000, 378.5000, 378.5000, 378.2500, 378.2500, 378.5000, 378.5000,
        378.2500, 378.2500, 378.2500, 378.5000, 378.5000, 378.5000, 378.5000,
        378.2500, 378.2500, 378.2500, 378.5000, 378.2500, 378.2500, 378.5000,
        378.7500, 378.5000, 378.5000, 378.2500, 378.2500, 378.2500, 378.2500,
        378.5000, 378.5000, 378.2500, 378.2500, 378.2500, 378.2500, 378.2500,
        378.5000, 378.2500], dtype=torch.float16)
[Worker 1] Completed Task 625

[Worker 1] Processing Task 626: paddle.linalg.norm(Tensor([715827883, 6],"float32"), )
[accuracy error] paddle.linalg.norm(Tensor([715827883, 6],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18918.548828125 but got 0.31723010540008545.
Absolute difference: 18918.2315980196 (up to 0.01 allowed)
Relative difference: 0.9999832317949816 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.3172])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([18918.5488])
[Worker 1] Completed Task 626

[Worker 1] Processing Task 628: paddle.linalg.norm(x=Tensor([1431655766, 3],"float16"), axis=None, p="fro", )
[accuracy error] paddle.linalg.norm(x=Tensor([1431655766, 3],"float16"), axis=None, p="fro", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.492431640625.
Absolute difference: 18911.507568359375 (up to 0.01 allowed)
Relative difference: 0.9999739619479365 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.4924], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 1] Completed Task 628

[Worker 1] Processing Task 629: paddle.linalg.norm(x=Tensor([190141782, 3, 4],"float32"), )
[accuracy error] paddle.linalg.norm(x=Tensor([190141782, 3, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 13789.26953125 but got 0.0.
Absolute difference: 13789.26953125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([13789.2695])
[Worker 1] Completed Task 629

[Worker 1] Processing Task 630: paddle.linalg.norm(x=Tensor([190141782, 3, 4],"float32"), p=math.inf, axis=0, keepdim=False, )
[accuracy error] backward  paddle.linalg.norm(x=Tensor([190141782, 3, 4],"float32"), p=math.inf, axis=0, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 70 / 2281701384 (0.0%)
Greatest absolute difference: 0.44287100434303284 at index (19119830, 1, 1) (up to 0.01 allowed)
Greatest relative difference: 9.0 at index (19119830, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([190141782, 3, 4]), dtype=torch.float32)
First 100 elements: tensor([-0., -0., 0., -0., -0., 0., -0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., -0., 0., -0., -0., -0.,
        -0., 0., 0., -0., 0., 0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0.,
        0., 0., 0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., 0., 0., -0., -0., 0., -0.,
        -0., 0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0.,
        -0., 0., -0., 0.])
DESIRED: (shape=torch.Size([190141782, 3, 4]), dtype=torch.float32)
First 100 elements: tensor([-0., -0., 0., -0., -0., 0., -0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., -0., 0., -0., -0., -0.,
        -0., 0., 0., -0., 0., 0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0.,
        0., 0., 0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., 0., 0., -0., -0., 0., -0.,
        -0., 0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0.,
        -0., 0., -0., 0.])
[Worker 1] Completed Task 630

[Worker 1] Processing Task 631: paddle.linalg.norm(x=Tensor([190141782, 3, 4],"float32"), p=math.inf, axis=0, keepdim=True, )
[accuracy error] backward  paddle.linalg.norm(x=Tensor([190141782, 3, 4],"float32"), p=math.inf, axis=0, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 70 / 2281701384 (0.0%)
Greatest absolute difference: 0.44287100434303284 at index (19119830, 1, 1) (up to 0.01 allowed)
Greatest relative difference: 9.0 at index (19119830, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([190141782, 3, 4]), dtype=torch.float32)
First 100 elements: tensor([-0., -0., 0., -0., -0., 0., -0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., -0., 0., -0., -0., -0.,
        -0., 0., 0., -0., 0., 0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0.,
        0., 0., 0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., 0., 0., -0., -0., 0., -0.,
        -0., 0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0.,
        -0., 0., -0., 0.])
DESIRED: (shape=torch.Size([190141782, 3, 4]), dtype=torch.float32)
First 100 elements: tensor([-0., -0., 0., -0., -0., 0., -0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., -0., 0., -0., -0., -0.,
        -0., 0., 0., -0., 0., 0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0.,
        0., 0., 0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., 0., 0., -0., -0., 0., -0.,
        -0., 0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0.,
        -0., 0., -0., 0.])
[Worker 1] Completed Task 631

[Worker 1] Processing Task 632: paddle.linalg.norm(x=Tensor([2, 285212673, 4],"float32"), )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 285212673, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 13789.26953125 but got 0.0.
Absolute difference: 13789.26953125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([13789.2695])
[Worker 1] Completed Task 632

[Worker 1] Processing Task 633: paddle.linalg.norm(x=Tensor([2, 285212673, 4],"float32"), p=math.inf, axis=0, keepdim=False, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 7.04 GiB is free. Process 126137 has 72.14 GiB memory in use. Of the allocated memory 57.39 GiB is allocated by PyTorch, and 4.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 633: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 7.04 GiB is free. Process 126137 has 72.14 GiB memory in use. Of the allocated memory 57.39 GiB is allocated by PyTorch, and 4.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 633: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 7.04 GiB is free. Process 126137 has 72.14 GiB memory in use. Of the allocated memory 57.39 GiB is allocated by PyTorch, and 4.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 634: paddle.linalg.norm(x=Tensor([2, 285212673, 4],"float32"), p=math.inf, axis=0, keepdim=True, )
W0522 17:02:53.773593 44342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 17:02:53.774472 44342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.linalg.norm(x=Tensor([2, 285212673, 4],"float32"), p=math.inf, axis=0, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 90 / 2281701384 (0.0%)
Greatest absolute difference: 0.24986976385116577 at index (0, 258713663, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 11817604, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 285212673, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.0000, -0.0000,  0.2508,  0.0000,  0.0000,  0.0434,  0.2274, -0.4412,
        -0.0000,  0.0000,  0.0000, -0.1793,  0.0000,  0.0000,  0.3780,  0.3650,
         0.0939,  0.2196, -0.0000,  0.0000, -0.3551,  0.4091,  0.2309,  0.3390,
        -0.0000,  0.0000,  0.0000, -0.0222, -0.0553, -0.0000,  0.0000,  0.4343,
        -0.3005,  0.4252,  0.0000,  0.0000,  0.2952,  0.2888, -0.1500,  0.0000,
        -0.1887, -0.0000,  0.0000,  0.1259, -0.0761, -0.0304, -0.3403, -0.4285,
        -0.0000, -0.0555, -0.3671, -0.0000,  0.4763,  0.0000, -0.0000, -0.0034,
        -0.2250,  0.0000,  0.4449,  0.1703,  0.0000,  0.0000, -0.2876, -0.0000,
        -0.0211,  0.2785,  0.2598, -0.0750,  0.2447, -0.0000,  0.0000,  0.2588,
         0.0000, -0.0000, -0.0017,  0.0383, -0.2706, -0.0000,  0.0000, -0.0000,
        -0.1898, -0.0000,  0.0000, -0.1553, -0.0000,  0.0000,  0.0000,  0.0000,
        -0.0000, -0.4560, -0.1439,  0.0196, -0.0000, -0.4539,  0.4310,  0.0343,
        -0.0677,  0.3528, -0.3162, -0.0000])
DESIRED: (shape=torch.Size([2, 285212673, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.0000, -0.0000,  0.2508,  0.0000,  0.0000,  0.0434,  0.2274, -0.4412,
        -0.0000,  0.0000,  0.0000, -0.1793,  0.0000,  0.0000,  0.3780,  0.3650,
         0.0939,  0.2196, -0.0000,  0.0000, -0.3551,  0.4091,  0.2309,  0.3390,
        -0.0000,  0.0000,  0.0000, -0.0222, -0.0553, -0.0000,  0.0000,  0.4343,
        -0.3005,  0.4252,  0.0000,  0.0000,  0.2952,  0.2888, -0.1500,  0.0000,
        -0.1887, -0.0000,  0.0000,  0.1259, -0.0761, -0.0304, -0.3403, -0.4285,
        -0.0000, -0.0555, -0.3671, -0.0000,  0.4763,  0.0000, -0.0000, -0.0034,
        -0.2250,  0.0000,  0.4449,  0.1703,  0.0000,  0.0000, -0.2876, -0.0000,
        -0.0211,  0.2785,  0.2598, -0.0750,  0.2447, -0.0000,  0.0000,  0.2588,
         0.0000, -0.0000, -0.0017,  0.0383, -0.2706, -0.0000,  0.0000, -0.0000,
        -0.1898, -0.0000,  0.0000, -0.1553, -0.0000,  0.0000,  0.0000,  0.0000,
        -0.0000, -0.4560, -0.1439,  0.0196, -0.0000, -0.4539,  0.4310,  0.0343,
        -0.0677,  0.3528, -0.3162, -0.0000])
[Worker 1] Completed Task 634

[Worker 1] Processing Task 638: paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.12249755859375.
Absolute difference: 18911.877502441406 (up to 0.01 allowed)
Relative difference: 0.9999935227602267 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.1225], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 1] Completed Task 638

[Worker 1] Processing Task 641: paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=2, axis=-1, keepdim=False, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=2, axis=-1, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: 7700.0 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.9970703125 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3]), dtype=torch.float16)
All elements: tensor([22.6250, 22.6250, 22.6250, 22.6250, 22.6250, 22.6250],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 3]), dtype=torch.float16)
All elements: tensor([7724., 7724., 7724., 7724., 7724., 7724.], dtype=torch.float16)
[Worker 1] Completed Task 641

[Worker 1] Processing Task 650: paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=math.inf, axis=list[0,1,], keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=math.inf, axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 1] Completed Task 650

[Worker 1] Processing Task 657: paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=2, axis=1, keepdim=False, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=2, axis=1, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: 10896.0 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 0.99755859375 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([22.6250, 22.6250, 22.6250], dtype=torch.float16)
DESIRED: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([10920., 10920., 10920.], dtype=torch.float16)
[Worker 1] Completed Task 657

[Worker 1] Processing Task 662: paddle.linalg.norm(x=Tensor([3, 477218589, 3],"float16"), axis=list[1,2,], p=1, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 477218589, 3],"float16"), axis=list[1,2,], p=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([inf, inf, inf], dtype=torch.float16)
[Worker 1] Completed Task 662

[Worker 1] Processing Task 671: paddle.linalg.vector_norm(x=Tensor([2, 3, 715827883],"float32"), p=math.inf, axis=0, keepdim=True, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 33651 has 78.11 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 671: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 33651 has 78.11 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 671: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 33651 has 78.11 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 674: paddle.linalg.vector_norm(x=Tensor([2, 536870912, 4],"float32"), p=math.inf, axis=0, keepdim=False, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 68878 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 674: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 68878 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 674: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 68878 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 676: paddle.linalg.vector_norm(x=Tensor([3, 1431655765],"float32"), p=2, axis=None, keepdim=False, )
W0522 17:29:55.036470 45232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 17:29:55.037441 45232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.vector_norm(x=Tensor([3, 1431655765],"float32"), p=2, axis=None, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18918.328125 but got 0.0.
Absolute difference: 18918.328125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([18918.3281])
[Worker 1] Completed Task 676

[Worker 1] Processing Task 680: paddle.linalg.vector_norm(x=Tensor([357913942, 3, 4],"float32"), p=math.inf, axis=None, keepdim=False, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.57 GiB is free. Process 80656 has 53.61 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 680: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.57 GiB is free. Process 80656 has 53.61 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 680: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 25.57 GiB is free. Process 80656 has 53.61 GiB memory in use. Of the allocated memory 36.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 681: paddle.linalg.vector_norm(x=Tensor([357913942, 3, 4],"float32"), p=math.inf, axis=None, keepdim=True, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 93712 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 681: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 93712 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 681: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 93712 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 982: paddle.nn.functional.grid_sample(Tensor([61896, 1, 192, 192],"float32"), Tensor([61896, 1, 12544, 2],"float32"), align_corners=False, )
[cuda error] paddle.nn.functional.grid_sample(Tensor([61896, 1, 192, 192],"float32"), Tensor([61896, 1, 12544, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747909224 (unix time) try "date -d @1747909224" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xb22f) received by PID 45615 (TID 0x7f2766dac740) from PID 45615 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 987: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([715827883, 2, 3],"float16"), epsilon=1e-05, )
W0522 18:22:25.839213 46068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:22:25.840229 46068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([715827883, 2, 3],"float16"), epsilon=1e-05, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 9 / 4294967298 (0.0%)
Greatest absolute difference: 0.025634765625 at index (501177965, 1, 1) (up to 0.01 allowed)
Greatest relative difference: 7.3203125 at index (13416923, 1, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([715827883, 2, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.9736, -0.1836, -0.5981,  1.0332, -0.1501, -1.0742,  0.3708,  0.9717,
        -1.2100,  0.1208, -0.7188,  0.4656,  0.3625,  0.3704,  0.8677,  0.1079,
        -1.2285, -0.4805, -1.1553, -0.0690,  0.3750,  1.3281,  0.9443, -1.4229,
         1.8271,  1.1299, -0.9766,  0.3159, -1.2900, -1.0049, -1.3994, -0.5693,
        -1.4082,  1.0312,  0.8389,  1.5068,  0.5020,  1.9502,  0.2192, -2.6250,
        -0.5244,  0.4775,  0.4077, -0.4072,  1.0566, -0.1313,  0.1665, -1.0928,
        -1.0674, -0.2418, -0.5112,  0.8462,  1.2119, -0.2388,  0.3118, -0.9580,
        -0.0029, -0.2510,  0.1553,  0.7461,  2.6191, -0.7178, -2.4062, -0.8584,
         0.3149,  1.0488, -0.1113, -1.6074,  1.0869,  0.4741,  0.2375, -0.0796,
        -0.6646,  0.2100,  0.5557,  1.1133, -0.5845, -0.6289,  0.3867,  0.5713,
         0.4375, -0.6997,  0.0382, -0.7344,  0.0762, -0.8853,  0.1680,  0.9321,
         0.7354, -1.0273,  0.7964, -0.0161,  1.6855, -1.3145,  0.0635, -1.2139,
         0.3589,  1.6699, -0.6602, -0.9062], dtype=torch.float16)
DESIRED: (shape=torch.Size([715827883, 2, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.9731, -0.1837, -0.5981,  1.0332, -0.1504, -1.0742,  0.3708,  0.9717,
        -1.2100,  0.1206, -0.7192,  0.4658,  0.3623,  0.3704,  0.8677,  0.1081,
        -1.2285, -0.4805, -1.1553, -0.0689,  0.3752,  1.3281,  0.9443, -1.4229,
         1.8271,  1.1299, -0.9766,  0.3159, -1.2900, -1.0059, -1.3984, -0.5698,
        -1.4082,  1.0312,  0.8384,  1.5068,  0.5024,  1.9512,  0.2196, -2.6250,
        -0.5254,  0.4773,  0.4075, -0.4070,  1.0566, -0.1310,  0.1666, -1.0928,
        -1.0674, -0.2417, -0.5112,  0.8462,  1.2119, -0.2382,  0.3115, -0.9580,
        -0.0029, -0.2512,  0.1550,  0.7456,  2.6191, -0.7183, -2.4062, -0.8584,
         0.3147,  1.0488, -0.1111, -1.6074,  1.0869,  0.4741,  0.2377, -0.0797,
        -0.6646,  0.2097,  0.5557,  1.1123, -0.5840, -0.6289,  0.3867,  0.5718,
         0.4377, -0.6997,  0.0382, -0.7344,  0.0762, -0.8853,  0.1680,  0.9321,
         0.7354, -1.0264,  0.7959, -0.0155,  1.6846, -1.3154,  0.0632, -1.2129,
         0.3589,  1.6699, -0.6602, -0.9058], dtype=torch.float16)
[Worker 1] Completed Task 987

[Worker 1] Processing Task 992: paddle.nn.functional.layer_norm(Tensor([570425345, 4],"float32"), list[4,], None, None, )
[accuracy error] backward  paddle.nn.functional.layer_norm(Tensor([570425345, 4],"float32"), list[4,], None, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 21 / 2281701380 (0.0%)
Greatest absolute difference: 0.04280364513397217 at index (542697133, 3) (up to 0.01 allowed)
Greatest relative difference: 0.8544470071792603 at index (150950936, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.4607, -1.2674,  1.3707, -0.5640,  0.5412,  0.3416, -0.5204, -0.3624,
        -0.5310,  0.0416,  0.6148, -0.1255,  0.3778,  0.9134, -1.0462, -0.2450,
        -0.0319, -0.0874, -0.1310,  0.2503,  0.3179, -2.1578,  0.1604,  1.6795,
        -0.0450, -1.0798,  0.6485,  0.4764,  0.7828, -0.8131,  0.2339, -0.2036,
        -0.2737, -0.1422,  0.8252, -0.4093,  1.4148, -1.4219, -0.6714,  0.6785,
        -0.6427, -0.4311,  0.8119,  0.2619, -1.3538,  0.8214,  0.6075, -0.0751,
        -3.2833, -0.1362,  2.4219,  0.9976,  0.0142, -0.5950, -0.1036,  0.6845,
        -0.8978,  0.0986, -0.3124,  1.1116, -0.6597, -0.2435,  1.1821, -0.2789,
         0.8256, -0.4956, -0.2395, -0.0905,  0.8208, -1.2946,  1.4631, -0.9893,
        -0.1817, -0.2824,  0.4709, -0.0068, -0.8598,  1.1735,  0.5099, -0.8236,
         0.0675,  0.0148, -0.1468,  0.0645, -0.0584,  0.4465,  2.2903, -2.6783,
        -0.3214,  1.0379, -0.3085, -0.4079, -1.4347,  0.3408, -0.3108,  1.4047,
        -0.6010,  0.6468,  0.4770, -0.5227])
DESIRED: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.4607, -1.2674,  1.3707, -0.5640,  0.5412,  0.3416, -0.5204, -0.3624,
        -0.5310,  0.0416,  0.6148, -0.1255,  0.3778,  0.9134, -1.0462, -0.2450,
        -0.0319, -0.0874, -0.1310,  0.2503,  0.3179, -2.1578,  0.1604,  1.6795,
        -0.0450, -1.0798,  0.6485,  0.4764,  0.7828, -0.8131,  0.2339, -0.2036,
        -0.2737, -0.1422,  0.8252, -0.4093,  1.4148, -1.4219, -0.6714,  0.6785,
        -0.6427, -0.4311,  0.8119,  0.2619, -1.3538,  0.8214,  0.6075, -0.0751,
        -3.2833, -0.1362,  2.4219,  0.9976,  0.0142, -0.5950, -0.1036,  0.6845,
        -0.8978,  0.0986, -0.3124,  1.1116, -0.6597, -0.2435,  1.1821, -0.2789,
         0.8256, -0.4956, -0.2395, -0.0905,  0.8208, -1.2946,  1.4631, -0.9893,
        -0.1817, -0.2824,  0.4709, -0.0068, -0.8598,  1.1735,  0.5099, -0.8236,
         0.0675,  0.0148, -0.1468,  0.0645, -0.0584,  0.4465,  2.2903, -2.6783,
        -0.3214,  1.0379, -0.3085, -0.4079, -1.4347,  0.3408, -0.3108,  1.4047,
        -0.6010,  0.6468,  0.4770, -0.5227])
[Worker 1] Completed Task 992

[Worker 1] Processing Task 998: paddle.nn.functional.normalize(x=Tensor([4, 25565282, 6, 7],"float16"), p=4, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 7.81 GiB is free. Process 57423 has 71.37 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 998: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 7.81 GiB is free. Process 57423 has 71.37 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 998: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 7.81 GiB is free. Process 57423 has 71.37 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 999: paddle.nn.functional.normalize(x=Tensor([4, 25565282, 6, 7],"float16"), p=4, axis=3, )
W0522 18:26:50.524374 46527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:26:50.525307 46527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(x=Tensor([4, 25565282, 6, 7],"float16"), p=4, axis=3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 4294967376 (0.0%)
Greatest absolute difference: 0.0205078125 at index (1, 9662126, 0, 5) (up to 0.01 allowed)
Greatest relative difference: 0.02142333984375 at index (1, 9662126, 0, 5) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 25565282, 6, 7]), dtype=torch.float16)
First 100 elements: tensor([-0.6294, -0.6616, -0.6055,  0.5015, -0.7290, -0.3850, -0.6235, -0.6528,
         0.7593, -0.5044,  0.6885,  0.2612, -0.6104, -0.4844,  0.2158, -0.6040,
         0.7798,  0.1202,  0.0166, -0.8384, -0.1163, -0.5977, -0.7969,  0.5508,
         0.1431,  0.3569,  0.2981, -0.7700, -0.3589, -0.1997, -0.8657, -0.4888,
        -0.5439, -0.3569,  0.7144,  0.6270,  0.3408,  0.3850, -0.9443,  0.1318,
         0.3503, -0.0083,  0.0492, -0.7280,  0.8281, -0.2106, -0.0035, -0.7021,
        -0.2385, -0.4324,  0.3293, -0.5107, -0.3306,  0.9604, -0.3911, -0.1148,
         0.4463, -0.7437, -0.7402, -0.7637, -0.2910, -0.2739,  0.2091, -0.7017,
         0.0699, -0.7769, -0.2568, -0.2981,  0.7148, -0.5859,  0.7236, -0.3867,
        -0.4255,  0.8115, -0.3628,  0.0374, -0.6855,  0.1021,  0.1000, -0.6045,
        -0.2732, -0.3728,  0.4507, -0.9458, -0.5776,  0.6846, -0.3186, -0.5293,
        -0.8662,  0.2800,  0.3286,  0.6279,  0.5884, -0.4316, -0.6597, -0.1143,
         0.8418, -0.1265, -0.6826,  0.4238], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 25565282, 6, 7]), dtype=torch.float16)
First 100 elements: tensor([-0.6294, -0.6616, -0.6055,  0.5015, -0.7290, -0.3850, -0.6235, -0.6528,
         0.7593, -0.5044,  0.6885,  0.2612, -0.6104, -0.4844,  0.2158, -0.6040,
         0.7798,  0.1202,  0.0166, -0.8384, -0.1163, -0.5977, -0.7969,  0.5508,
         0.1431,  0.3569,  0.2981, -0.7700, -0.3589, -0.1997, -0.8657, -0.4888,
        -0.5439, -0.3569,  0.7144,  0.6270,  0.3408,  0.3850, -0.9443,  0.1318,
         0.3503, -0.0083,  0.0492, -0.7280,  0.8281, -0.2106, -0.0035, -0.7021,
        -0.2385, -0.4324,  0.3293, -0.5107, -0.3306,  0.9604, -0.3911, -0.1148,
         0.4463, -0.7437, -0.7402, -0.7637, -0.2910, -0.2739,  0.2091, -0.7021,
         0.0699, -0.7773, -0.2571, -0.2983,  0.7153, -0.5864,  0.7236, -0.3867,
        -0.4255,  0.8115, -0.3628,  0.0374, -0.6855,  0.1021,  0.1000, -0.6045,
        -0.2732, -0.3728,  0.4507, -0.9458, -0.5776,  0.6846, -0.3186, -0.5293,
        -0.8662,  0.2800,  0.3286,  0.6279,  0.5884, -0.4316, -0.6597, -0.1143,
         0.8418, -0.1265, -0.6826,  0.4238], dtype=torch.float16)
[Worker 1] Completed Task 999

[Worker 1] Processing Task 1003: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 1],"float32"), 2.0, 1e-06, False, None, )
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 1],"float32"), 2.0, 1e-06, False, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 48.62255859375 at index (27,) (up to 0.01 allowed)
Greatest relative difference: 0.02594829350709915 at index (58,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([100]), dtype=torch.float32)
All elements: tensor([1681.6730, 1382.6588, 1558.1011, 1967.2450, 2674.4219, 1572.8202,
        2331.1782, 1365.3706, 2075.6362, 1359.5674, 1359.7139, 1956.3807,
        1463.8557, 1932.8324, 1744.7428, 1797.1172, 1359.6482, 2691.1438,
        1491.6708, 2184.2468, 2649.9077, 2342.5833, 1361.0735, 2165.4431,
        1980.6583, 2691.6792, 1363.4193, 2441.8726, 2295.1155, 1676.8600,
        1564.8165, 1868.8824, 2274.1040, 1466.6051, 1360.1984, 2356.6621,
        1642.7881, 1881.7593, 1478.2460, 2105.2522, 2651.0535, 1364.1287,
        1362.1658, 1360.9290, 1422.0568, 2056.2961, 1959.9985, 2146.3789,
        1637.7556, 2147.2771, 1901.1920, 1469.8356, 1369.7252, 2334.6226,
        1614.0416, 1700.3611, 1562.2084, 1547.2843, 1774.0044, 1382.0730,
        2257.1306, 2351.6230, 1872.2161, 2406.3093, 2126.4688, 1466.9406,
        2552.0522, 1982.4093, 2199.5610, 1533.4832, 1485.2400, 1506.9625,
        1460.0809, 1889.5420, 1842.7914, 1756.4434, 2712.4558, 2708.1792,
        1485.2202, 2179.9531, 2341.0845, 2093.3386, 2236.2622, 1755.3116,
        1476.9960, 2353.2515, 2290.3049, 2075.3943, 1939.9641, 1483.2444,
        1734.5016, 1740.7363, 1853.2935, 1542.4491, 1904.9689, 2281.6711,
        1996.3447, 1620.1001, 1666.0662, 2080.5271])
DESIRED: (shape=torch.Size([100]), dtype=torch.float32)
All elements: tensor([1723.1687, 1415.9547, 1598.7488, 2008.3452, 2713.8250, 1613.4896,
        2379.2815, 1392.3031, 2110.8389, 1380.0861, 1380.5531, 1998.4995,
        1489.0693, 1977.3291, 1789.6570, 1843.5004, 1379.9971, 2730.3022,
        1523.4158, 2228.7202, 2689.4534, 2390.5981, 1385.8335, 2207.4802,
        2020.4883, 2730.9727, 1389.4675, 2490.4951, 2342.6252, 1718.1255,
        1605.4694, 1914.4409, 2321.2834, 1492.3895, 1382.9525, 2404.6714,
        1683.4539, 1927.6329, 1506.4828, 2141.6521, 2690.6775, 1390.8563,
        1387.8352, 1384.9943, 1447.7867, 2091.1990, 2001.8335, 2186.1860,
        1678.4423, 2187.2546, 1947.8824, 1496.2440, 1399.5458, 2382.6318,
        1654.8987, 1742.8533, 1602.7963, 1587.9407, 1821.2631, 1415.4584,
        2303.9453, 2399.6501, 1917.8215, 2454.6221, 2164.3992, 1492.7495,
        2594.7231, 2022.0635, 2244.5525, 1573.4243, 1515.1842, 1542.4301,
        1484.7092, 1935.7094, 1888.2629, 1802.2080, 2751.6128, 2747.3884,
        1515.1615, 2224.0208, 2389.1243, 2129.1304, 2282.5713, 1801.0098,
        1505.0190, 2401.4395, 2337.7686, 2110.5735, 1983.6471, 1512.7242,
        1778.8650, 1785.3317, 1898.7933, 1583.2465, 1951.8864, 2329.0012,
        2034.8378, 1660.9523, 1707.1174, 2115.7695])
[Worker 1] Completed Task 1003

[Worker 1] Processing Task 1007: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 1, 1e-06, True, None, )
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 1, 1e-06, True, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 4.813709259033203 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.21097010374069214 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([100, 1]), dtype=torch.float32)
All elements: tensor([27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307])
DESIRED: (shape=torch.Size([100, 1]), dtype=torch.float32)
All elements: tensor([22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170])
[Worker 1] Completed Task 1007

[Worker 1] Processing Task 1021: paddle.nn.functional.rrelu(Tensor([2, 57042535, 4, 5],"float32"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 57042535, 4, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2182838205 / 2281701400 (95.7%)
Greatest absolute difference: 0.5 at index (0, 1785173, 0, 3) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 57042535, 4, 5]), dtype=torch.float32)
First 100 elements: tensor([-0.0649,  0.0673, -0.0508,  0.3056,  0.4893,  0.1754,  0.4059, -0.0120,
        -0.1003,  0.0117,  0.0134, -0.0908, -0.0353,  0.2966, -0.0716, -0.0769,
         0.0105,  0.4934,  0.1355,  0.3666, -0.1450, -0.1227, -0.0087,  0.3609,
         0.3091,  0.4936,  0.0354, -0.1303, -0.1189,  0.2146, -0.0516, -0.0834,
         0.3910,  0.1196,  0.0225, -0.1237, -0.0607, -0.0846, -0.0381,  0.3431,
         0.4837, -0.0116, -0.0099, -0.0081,  0.0924, -0.0988,  0.3037,  0.3552,
         0.2004, -0.1066,  0.2880,  0.1215, -0.0150, -0.1220, -0.0575, -0.0669,
        -0.0513,  0.1649, -0.0747,  0.0668, -0.1159, -0.1233, -0.0837,  0.4251,
         0.3492, -0.0359,  0.4601, -0.0929,  0.3708,  0.1588,  0.1313,  0.1447,
        -0.0346, -0.0854,  0.2701, -0.0728, -0.1495, -0.1492, -0.0395, -0.1096,
         0.4083, -0.1019, -0.1142,  0.2426, -0.0378, -0.1235,  0.3951,  0.3345,
        -0.0896,  0.1302,  0.2352,  0.2374,  0.2732,  0.1629, -0.0868,  0.3929,
        -0.0940,  0.1938, -0.0632, -0.1008])
DESIRED: (shape=torch.Size([2, 57042535, 4, 5]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
[Worker 1] Completed Task 1021

[Worker 1] Processing Task 1023: paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.1, 0.3, training=False, )
[accuracy error] backward  paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.1, 0.3, training=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4034612607 / 4294967340 (93.9%)
Greatest absolute difference: 0.5 at index (52, 2, 3, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 2, 0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float16)
First 100 elements: tensor([ 9.9869e-03,  5.9082e-02,  4.7729e-02,  1.4648e-01, -2.0493e-02,
        -4.2542e-02,  8.1421e-02, -1.9608e-02,  2.8735e-01, -3.9062e-02,
        -2.0813e-01,  8.2214e-02, -4.1687e-02, -1.5793e-02,  3.9526e-01,
         1.8326e-02,  3.0737e-01, -3.1299e-01,  3.9209e-01,  6.4514e-02,
        -3.5919e-02, -5.9082e-02, -9.8633e-02, -2.3621e-01, -2.7490e-01,
         1.8579e-01, -1.3684e-01, -4.6234e-02,  7.9215e-05, -6.8893e-03,
         6.7688e-02, -9.8145e-02, -9.2285e-02,  7.3730e-02,  5.1544e-02,
         8.0776e-04, -2.8906e-01,  2.8247e-01, -9.9869e-03, -1.6785e-01,
         4.1626e-01, -6.8054e-02,  3.5059e-01,  6.7200e-02,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float16)
First 100 elements: tensor([ 9.9945e-03,  5.9082e-02,  4.7760e-02,  1.4648e-01, -2.0493e-02,
        -4.2542e-02,  8.1421e-02, -1.9623e-02,  2.8735e-01, -3.9093e-02,
        -2.0813e-01,  8.2214e-02, -4.1687e-02, -1.5793e-02,  3.9526e-01,
         1.8341e-02,  3.0737e-01, -3.1299e-01,  3.9209e-01,  6.4575e-02,
        -3.5919e-02, -5.9082e-02, -9.8633e-02, -2.3621e-01, -2.7490e-01,
         1.8579e-01, -1.3684e-01, -4.6234e-02,  7.9274e-05, -6.8893e-03,
         6.7688e-02, -9.8206e-02, -9.2346e-02,  7.3730e-02,  5.1544e-02,
         8.0776e-04, -2.8906e-01,  2.8247e-01, -9.9945e-03, -1.6785e-01,
         4.1626e-01, -6.8054e-02,  3.5059e-01,  6.7261e-02,  2.5464e-01,
        -7.6904e-02, -1.0139e-02,  6.1432e-02,  8.6899e-03,  2.2476e-02,
         4.3359e-01, -4.2877e-02, -1.3229e-02, -2.8540e-01, -2.7885e-03,
         5.4871e-02,  2.6733e-01,  6.4209e-02,  6.1920e-02,  9.4910e-03,
        -1.0880e-02,  6.3599e-02,  1.6968e-01,  3.5950e-02, -2.9199e-01,
        -8.2031e-02, -9.1187e-02, -9.1019e-03,  1.2741e-02, -4.4556e-02,
         4.7119e-01, -4.2542e-02,  8.8928e-02,  4.1943e-01,  8.4961e-02,
         1.0822e-01,  5.3772e-02,  4.4556e-01,  7.4280e-02,  2.3346e-02,
        -9.1919e-02,  9.2926e-03, -4.5581e-01,  4.4037e-02, -4.1565e-02,
         3.3276e-01, -8.9966e-02, -2.5192e-02, -6.1707e-02,  2.0789e-01,
        -3.7231e-01,  1.9896e-04,  3.7256e-01,  3.3630e-02,  2.4994e-02,
         8.9600e-02, -1.3367e-01, -8.7891e-02,  6.9702e-02,  1.4148e-01],
       dtype=torch.float16)
[Worker 1] Completed Task 1023

[Worker 1] Processing Task 1148: paddle.roll(Tensor([1, 16, 14, 14, 1369569],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 14, 1369569],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3213 / 4294968384 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 13, 13, 1368679) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 2, 2, 1368481) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 14, 1369569]), dtype=torch.float16)
First 100 elements: tensor([ 0.1445, -0.0922,  0.4434,  0.3352,  0.1487,  0.4319,  0.0349,  0.0722,
         0.1752, -0.3411,  0.3203,  0.0569,  0.3955,  0.3674,  0.3372,  0.4324,
         0.3162,  0.1088, -0.0182,  0.4978,  0.1201,  0.3323,  0.4673,  0.1367,
        -0.2487, -0.3118, -0.1531,  0.0073, -0.3286,  0.1582, -0.2056,  0.3711,
         0.2869, -0.1276,  0.4612, -0.3962, -0.1956,  0.0877,  0.3938,  0.4861,
         0.4368, -0.2646, -0.3884,  0.3162,  0.3501,  0.3223,  0.1294,  0.2250,
         0.3879, -0.4409,  0.2118, -0.1383,  0.4080,  0.2141, -0.3853, -0.0806,
         0.4058, -0.4248,  0.1747, -0.0887, -0.3127, -0.2620,  0.3264,  0.2744,
        -0.4075, -0.4363,  0.2781, -0.2410, -0.4575, -0.3547, -0.1926, -0.2037,
        -0.1027,  0.2578,  0.2347, -0.3030, -0.2627,  0.4065, -0.4651,  0.1283,
         0.2158,  0.1556, -0.2756, -0.2891, -0.4407,  0.0157,  0.0292, -0.2561,
        -0.0306,  0.1910, -0.0765,  0.2534,  0.2128,  0.0184, -0.2771, -0.2825,
         0.1918, -0.3604, -0.4409, -0.2333], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 14, 1369569]), dtype=torch.float16)
First 100 elements: tensor([ 0.1445, -0.0922,  0.4434,  0.3352,  0.1487,  0.4319,  0.0349,  0.0722,
         0.1752, -0.3411,  0.3203,  0.0569,  0.3955,  0.3674,  0.3372,  0.4324,
         0.3162,  0.1088, -0.0182,  0.4978,  0.1201,  0.3323,  0.4673,  0.1367,
        -0.2487, -0.3118, -0.1531,  0.0073, -0.3286,  0.1582, -0.2056,  0.3711,
         0.2869, -0.1276,  0.4612, -0.3962, -0.1956,  0.0877,  0.3938,  0.4861,
         0.4368, -0.2646, -0.3884,  0.3162,  0.3501,  0.3223,  0.1294,  0.2250,
         0.3879, -0.4409,  0.2118, -0.1383,  0.4080,  0.2141, -0.3853, -0.0806,
         0.4058, -0.4248,  0.1747, -0.0887, -0.3127, -0.2620,  0.3264,  0.2744,
        -0.4075, -0.4363,  0.2781, -0.2410, -0.4575, -0.3547, -0.1926, -0.2037,
        -0.1027,  0.2578,  0.2347, -0.3030, -0.2627,  0.4065, -0.4651,  0.1283,
         0.2158,  0.1556, -0.2756, -0.2891, -0.4407,  0.0157,  0.0292, -0.2561,
        -0.0306,  0.1910, -0.0765,  0.2534,  0.2128,  0.0184, -0.2771, -0.2825,
         0.1918, -0.3604, -0.4409, -0.2333], dtype=torch.float16)
[Worker 1] Completed Task 1148

[Worker 1] Processing Task 1152: paddle.roll(Tensor([1, 16, 14, 24967, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 24967, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 305013 / 4295122944 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 2, 24764, 666) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 2, 24764, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 24967, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.1024,  0.3984, -0.0008,  0.4160,  0.3047,  0.1226, -0.1913,  0.2725,
         0.3181, -0.0053, -0.4753,  0.2871, -0.0591, -0.3105, -0.2299,  0.4961,
         0.0327, -0.0742,  0.1493,  0.1089,  0.4629,  0.1041,  0.0998,  0.0510,
         0.2893,  0.0578, -0.0954, -0.1130,  0.3611, -0.1655, -0.0220,  0.0368,
        -0.0088,  0.1792,  0.1122, -0.4143, -0.0365, -0.0988, -0.3486,  0.3342,
        -0.0493, -0.3611, -0.2522,  0.2783, -0.1825, -0.3342, -0.3093,  0.0192,
         0.1774, -0.1512, -0.2869, -0.3665, -0.0280, -0.1632, -0.2642,  0.4304,
         0.2896,  0.0479, -0.4146, -0.1466,  0.1049, -0.4084, -0.3530, -0.3506,
         0.1107,  0.4871, -0.0553, -0.0739,  0.3074,  0.4546, -0.2864, -0.3567,
        -0.1660, -0.1648,  0.2834, -0.1096,  0.4731,  0.0058,  0.0635,  0.2778,
        -0.3655, -0.2734, -0.2908, -0.1755,  0.4465, -0.4744, -0.2136, -0.4119,
        -0.0893, -0.4099,  0.0536, -0.0892, -0.4319, -0.4226, -0.2712,  0.0634,
        -0.4973,  0.2905, -0.0516, -0.0705], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 24967, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.1024,  0.3984, -0.0008,  0.4160,  0.3047,  0.1226, -0.1913,  0.2725,
         0.3181, -0.0053, -0.4753,  0.2871, -0.0591, -0.3105, -0.2299,  0.4961,
         0.0327, -0.0742,  0.1493,  0.1089,  0.4629,  0.1041,  0.0998,  0.0510,
         0.2893,  0.0578, -0.0954, -0.1130,  0.3611, -0.1655, -0.0220,  0.0368,
        -0.0088,  0.1792,  0.1122, -0.4143, -0.0365, -0.0988, -0.3486,  0.3342,
        -0.0493, -0.3611, -0.2522,  0.2783, -0.1825, -0.3342, -0.3093,  0.0192,
         0.1774, -0.1512, -0.2869, -0.3665, -0.0280, -0.1632, -0.2642,  0.4304,
         0.2896,  0.0479, -0.4146, -0.1466,  0.1049, -0.4084, -0.3530, -0.3506,
         0.1107,  0.4871, -0.0553, -0.0739,  0.3074,  0.4546, -0.2864, -0.3567,
        -0.1660, -0.1648,  0.2834, -0.1096,  0.4731,  0.0058,  0.0635,  0.2778,
        -0.3655, -0.2734, -0.2908, -0.1755,  0.4465, -0.4744, -0.2136, -0.4119,
        -0.0893, -0.4099,  0.0536, -0.0892, -0.4319, -0.4226, -0.2712,  0.0634,
        -0.4973,  0.2905, -0.0516, -0.0705], dtype=torch.float16)
[Worker 1] Completed Task 1152

[Worker 1] Processing Task 1156: paddle.roll(Tensor([1, 16, 14, 7, 2739138],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 7, 2739138],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2138 / 4294968384 (0.0%)
Greatest absolute difference: 0.49951171875 at index (0, 15, 2, 6, 2738168) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 2, 6, 2738050) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 7, 2739138]), dtype=torch.float16)
First 100 elements: tensor([ 0.0619, -0.4097,  0.4392,  0.2360, -0.1797,  0.3098,  0.4219,  0.1930,
        -0.4868,  0.0289, -0.0318,  0.4102,  0.2637,  0.2812,  0.3604,  0.0956,
        -0.1198, -0.3213, -0.2161, -0.3606, -0.3525,  0.1224, -0.0747, -0.2239,
         0.4436, -0.1613,  0.3743, -0.2318,  0.2267, -0.2500, -0.0724,  0.2256,
        -0.3608, -0.0498, -0.4614,  0.2661,  0.4968,  0.4143,  0.2808, -0.4536,
        -0.2737, -0.3577,  0.4897,  0.3723, -0.3730, -0.4871,  0.0953,  0.0007,
        -0.0099,  0.2827,  0.3882, -0.3008,  0.4417, -0.3550, -0.4758,  0.3748,
        -0.3008, -0.0403, -0.2356, -0.3489, -0.4895,  0.0035,  0.4509, -0.1122,
         0.4861, -0.3748,  0.3518,  0.1093, -0.0269, -0.1281,  0.4905,  0.0122,
        -0.3792, -0.4929,  0.0462, -0.4729,  0.4854,  0.4209, -0.4766,  0.3062,
         0.4700,  0.1884,  0.4478, -0.4380,  0.0106,  0.3467, -0.0934,  0.2378,
        -0.4558,  0.4802, -0.1903,  0.2036, -0.2966, -0.4124,  0.1865,  0.2395,
         0.4910, -0.3506,  0.4441, -0.1192], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 7, 2739138]), dtype=torch.float16)
First 100 elements: tensor([ 0.0619, -0.4097,  0.4392,  0.2360, -0.1797,  0.3098,  0.4219,  0.1930,
        -0.4868,  0.0289, -0.0318,  0.4102,  0.2637,  0.2812,  0.3604,  0.0956,
        -0.1198, -0.3213, -0.2161, -0.3606, -0.3525,  0.1224, -0.0747, -0.2239,
         0.4436, -0.1613,  0.3743, -0.2318,  0.2267, -0.2500, -0.0724,  0.2256,
        -0.3608, -0.0498, -0.4614,  0.2661,  0.4968,  0.4143,  0.2808, -0.4536,
        -0.2737, -0.3577,  0.4897,  0.3723, -0.3730, -0.4871,  0.0953,  0.0007,
        -0.0099,  0.2827,  0.3882, -0.3008,  0.4417, -0.3550, -0.4758,  0.3748,
        -0.3008, -0.0403, -0.2356, -0.3489, -0.4895,  0.0035,  0.4509, -0.1122,
         0.4861, -0.3748,  0.3518,  0.1093, -0.0269, -0.1281,  0.4905,  0.0122,
        -0.3792, -0.4929,  0.0462, -0.4729,  0.4854,  0.4209, -0.4766,  0.3062,
         0.4700,  0.1884,  0.4478, -0.4380,  0.0106,  0.3467, -0.0934,  0.2378,
        -0.4558,  0.4802, -0.1903,  0.2036, -0.2966, -0.4124,  0.1865,  0.2395,
         0.4910, -0.3506,  0.4441, -0.1192], dtype=torch.float16)
[Worker 1] Completed Task 1156

[Worker 1] Processing Task 1160: paddle.roll(Tensor([1, 16, 21, 33289, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 21, 33289, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 221893 / 4295079936 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 2, 2, 47) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 21, 33289, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.1936, -0.4373,  0.0730,  0.0362,  0.1010, -0.4893, -0.2981, -0.1043,
         0.1492,  0.3867,  0.4138, -0.3494,  0.3708, -0.0758,  0.0604,  0.4216,
        -0.4058,  0.4365, -0.1467,  0.3044,  0.4890,  0.2032, -0.2827,  0.1858,
         0.0804, -0.4080,  0.0210, -0.4788, -0.4407, -0.0535,  0.3345,  0.0331,
        -0.0256, -0.2520, -0.0181, -0.3792,  0.0537,  0.4792,  0.0534,  0.3918,
        -0.4651,  0.0322, -0.2299, -0.0511,  0.4919,  0.3667,  0.0735,  0.3386,
        -0.3232,  0.2693, -0.2947, -0.1385,  0.2371, -0.4839, -0.0912,  0.1609,
        -0.1131,  0.3115, -0.2117,  0.4558, -0.1848, -0.0671, -0.2971,  0.3574,
        -0.0032, -0.4243,  0.3171, -0.2693, -0.0718,  0.2174, -0.3884,  0.3760,
        -0.2454,  0.0448,  0.1686,  0.2986,  0.4475,  0.2520, -0.3469, -0.0966,
        -0.2656, -0.4014,  0.1641,  0.4233,  0.0441,  0.1459, -0.4329,  0.3140,
         0.1197, -0.2715, -0.0279, -0.2939,  0.0210, -0.1115, -0.2698, -0.4482,
        -0.0056,  0.1385, -0.1473, -0.1915], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 21, 33289, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.1936, -0.4373,  0.0730,  0.0362,  0.1010, -0.4893, -0.2981, -0.1043,
         0.1492,  0.3867,  0.4138, -0.3494,  0.3708, -0.0758,  0.0604,  0.4216,
        -0.4058,  0.4365, -0.1467,  0.3044,  0.4890,  0.2032, -0.2827,  0.1858,
         0.0804, -0.4080,  0.0210, -0.4788, -0.4407, -0.0535,  0.3345,  0.0331,
        -0.0256, -0.2520, -0.0181, -0.3792,  0.0537,  0.4792,  0.0534,  0.3918,
        -0.4651,  0.0322, -0.2299, -0.0511,  0.4919,  0.3667,  0.0735,  0.3386,
        -0.3232,  0.2693, -0.2947, -0.1385,  0.2371, -0.4839, -0.0912,  0.1609,
        -0.1131,  0.3115, -0.2117,  0.4558, -0.1848, -0.0671, -0.2971,  0.3574,
        -0.0032, -0.4243,  0.3171, -0.2693, -0.0718,  0.2174, -0.3884,  0.3760,
        -0.2454,  0.0448,  0.1686,  0.2986,  0.4475,  0.2520, -0.3469, -0.0966,
        -0.2656, -0.4014,  0.1641,  0.4233,  0.0441,  0.1459, -0.4329,  0.3140,
         0.1197, -0.2715, -0.0279, -0.2939,  0.0210, -0.1115, -0.2698, -0.4482,
        -0.0056,  0.1385, -0.1473, -0.1915], dtype=torch.float16)
[Worker 1] Completed Task 1160

[Worker 1] Processing Task 1164: paddle.roll(Tensor([1, 16, 33289, 21, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 33289, 21, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 134373 / 4295079936 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 0, 8, 259) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 33289, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0203, -0.2469,  0.0991, -0.4949, -0.1846,  0.1616, -0.3882, -0.1743,
         0.4185,  0.3438,  0.3567,  0.1323, -0.2201, -0.1549, -0.1493,  0.1830,
         0.0413, -0.3208,  0.4014,  0.2783, -0.4006, -0.4915,  0.0285, -0.3604,
         0.4026,  0.0969, -0.3684, -0.1812,  0.4312,  0.3618, -0.0698, -0.1951,
         0.3420, -0.1836,  0.2111, -0.4521,  0.2651,  0.3809, -0.1412,  0.3540,
         0.3440,  0.4885, -0.2384, -0.3518,  0.0283, -0.0844, -0.3313,  0.2720,
         0.1017,  0.3757,  0.2418, -0.2227, -0.0701,  0.0173, -0.0829,  0.4609,
         0.0227, -0.1881, -0.3318,  0.2322, -0.4243,  0.1993,  0.1387,  0.4561,
         0.1545, -0.3274,  0.3694, -0.0168,  0.4597, -0.2144,  0.4709,  0.0058,
         0.2793,  0.2291, -0.3481, -0.0408,  0.4236,  0.0642,  0.3877,  0.3630,
         0.0952, -0.2390,  0.4436, -0.4939, -0.0920,  0.0468, -0.1481, -0.2457,
         0.1516, -0.1350, -0.0804, -0.2266,  0.1153,  0.1804,  0.3496,  0.0270,
         0.3828, -0.1930,  0.4529,  0.2839], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 33289, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0203, -0.2469,  0.0991, -0.4949, -0.1846,  0.1616, -0.3882, -0.1743,
         0.4185,  0.3438,  0.3567,  0.1323, -0.2201, -0.1549, -0.1493,  0.1830,
         0.0413, -0.3208,  0.4014,  0.2783, -0.4006, -0.4915,  0.0285, -0.3604,
         0.4026,  0.0969, -0.3684, -0.1812,  0.4312,  0.3618, -0.0698, -0.1951,
         0.3420, -0.1836,  0.2111, -0.4521,  0.2651,  0.3809, -0.1412,  0.3540,
         0.3440,  0.4885, -0.2384, -0.3518,  0.0283, -0.0844, -0.3313,  0.2720,
         0.1017,  0.3757,  0.2418, -0.2227, -0.0701,  0.0173, -0.0829,  0.4609,
         0.0227, -0.1881, -0.3318,  0.2322, -0.4243,  0.1993,  0.1387,  0.4561,
         0.1545, -0.3274,  0.3694, -0.0168,  0.4597, -0.2144,  0.4709,  0.0058,
         0.2793,  0.2291, -0.3481, -0.0408,  0.4236,  0.0642,  0.3877,  0.3630,
         0.0952, -0.2390,  0.4436, -0.4939, -0.0920,  0.0468, -0.1481, -0.2457,
         0.1516, -0.1350, -0.0804, -0.2266,  0.1153,  0.1804,  0.3496,  0.0270,
         0.3828, -0.1930,  0.4529,  0.2839], dtype=torch.float16)
[Worker 1] Completed Task 1164

[Worker 1] Processing Task 1168: paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 68226 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 49921, 1, 284) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 49920, 0, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.4143, -0.0329,  0.1223, -0.1633,  0.0396,  0.3950,  0.0797,  0.2072,
         0.3018, -0.2317, -0.0924, -0.0415,  0.2688,  0.2542, -0.4631,  0.0790,
        -0.4106,  0.1013,  0.3079, -0.1693, -0.2622, -0.3845, -0.0170,  0.0416,
         0.4990, -0.4404,  0.2683,  0.0443,  0.2203, -0.4409, -0.4033, -0.4805,
        -0.3628,  0.1008,  0.2959, -0.3237, -0.4597, -0.2004,  0.2864,  0.3208,
        -0.4941, -0.2678, -0.3640,  0.3909, -0.4092,  0.2742, -0.1918,  0.4644,
        -0.4148, -0.2412, -0.2153,  0.4719, -0.4487,  0.1442,  0.0801,  0.3721,
        -0.2905, -0.2546, -0.4646, -0.0314,  0.2961, -0.3804,  0.2505,  0.3887,
         0.2494, -0.3105,  0.3481,  0.0190, -0.4924,  0.1558,  0.1735, -0.0008,
         0.1655,  0.4453,  0.1187,  0.4724,  0.4419,  0.1721,  0.4766,  0.4297,
         0.4043,  0.4133, -0.3171, -0.2935,  0.4016, -0.3074,  0.1388,  0.1174,
        -0.3901, -0.3677,  0.2477,  0.2385,  0.1056, -0.2426,  0.4878,  0.0094,
         0.3152, -0.4573,  0.2881,  0.0294], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.4143, -0.0329,  0.1223, -0.1633,  0.0396,  0.3950,  0.0797,  0.2072,
         0.3018, -0.2317, -0.0924, -0.0415,  0.2688,  0.2542, -0.4631,  0.0790,
        -0.4106,  0.1013,  0.3079, -0.1693, -0.2622, -0.3845, -0.0170,  0.0416,
         0.4990, -0.4404,  0.2683,  0.0443,  0.2203, -0.4409, -0.4033, -0.4805,
        -0.3628,  0.1008,  0.2959, -0.3237, -0.4597, -0.2004,  0.2864,  0.3208,
        -0.4941, -0.2678, -0.3640,  0.3909, -0.4092,  0.2742, -0.1918,  0.4644,
        -0.4148, -0.2412, -0.2153,  0.4719, -0.4487,  0.1442,  0.0801,  0.3721,
        -0.2905, -0.2546, -0.4646, -0.0314,  0.2961, -0.3804,  0.2505,  0.3887,
         0.2494, -0.3105,  0.3481,  0.0190, -0.4924,  0.1558,  0.1735, -0.0008,
         0.1655,  0.4453,  0.1187,  0.4724,  0.4419,  0.1721,  0.4766,  0.4297,
         0.4043,  0.4133, -0.3171, -0.2935,  0.4016, -0.3074,  0.1388,  0.1174,
        -0.3901, -0.3677,  0.2477,  0.2385,  0.1056, -0.2426,  0.4878,  0.0094,
         0.3152, -0.4573,  0.2881,  0.0294], dtype=torch.float16)
[Worker 1] Completed Task 1168

[Worker 1] Processing Task 1172: paddle.roll(Tensor([1, 16, 7, 14, 2739138],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 14, 2739138],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2130 / 4294968384 (0.0%)
Greatest absolute difference: 0.499755859375 at index (0, 15, 6, 13, 2738738) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 2, 2738050) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 14, 2739138]), dtype=torch.float16)
First 100 elements: tensor([ 0.4604,  0.0297, -0.4985,  0.2502,  0.3640,  0.3962, -0.3264,  0.4629,
         0.4321,  0.4536,  0.3901, -0.3252, -0.3206,  0.2712,  0.3884,  0.3555,
        -0.0813, -0.2158, -0.3401, -0.3979, -0.2021, -0.1631,  0.0278,  0.0955,
        -0.1038, -0.1351, -0.3572,  0.3406, -0.4543,  0.2140, -0.4558, -0.2378,
         0.1685, -0.0537,  0.1400, -0.0316,  0.4661, -0.4351, -0.3687, -0.3247,
         0.0500, -0.3250, -0.3159,  0.2278, -0.2059,  0.4731, -0.3967,  0.2827,
         0.2313, -0.0429, -0.0826,  0.2712, -0.4614,  0.1864,  0.1737, -0.4944,
        -0.3293,  0.2430,  0.4131, -0.1230,  0.1572,  0.2891,  0.4482,  0.1196,
        -0.1327,  0.1052,  0.1284,  0.0189,  0.3130,  0.4514,  0.2522,  0.0700,
        -0.2524,  0.4512,  0.2705, -0.1343,  0.1786, -0.3625,  0.1300, -0.1857,
        -0.2274,  0.1212,  0.4905,  0.2798,  0.3921, -0.0529,  0.4170, -0.0771,
        -0.1580,  0.3464, -0.2703, -0.3340,  0.4402,  0.2671,  0.4739, -0.2864,
        -0.3042,  0.1727, -0.3525,  0.0014], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 14, 2739138]), dtype=torch.float16)
First 100 elements: tensor([ 0.4604,  0.0297, -0.4985,  0.2502,  0.3640,  0.3962, -0.3264,  0.4629,
         0.4321,  0.4536,  0.3901, -0.3252, -0.3206,  0.2712,  0.3884,  0.3555,
        -0.0813, -0.2158, -0.3401, -0.3979, -0.2021, -0.1631,  0.0278,  0.0955,
        -0.1038, -0.1351, -0.3572,  0.3406, -0.4543,  0.2140, -0.4558, -0.2378,
         0.1685, -0.0537,  0.1400, -0.0316,  0.4661, -0.4351, -0.3687, -0.3247,
         0.0500, -0.3250, -0.3159,  0.2278, -0.2059,  0.4731, -0.3967,  0.2827,
         0.2313, -0.0429, -0.0826,  0.2712, -0.4614,  0.1864,  0.1737, -0.4944,
        -0.3293,  0.2430,  0.4131, -0.1230,  0.1572,  0.2891,  0.4482,  0.1196,
        -0.1327,  0.1052,  0.1284,  0.0189,  0.3130,  0.4514,  0.2522,  0.0700,
        -0.2524,  0.4512,  0.2705, -0.1343,  0.1786, -0.3625,  0.1300, -0.1857,
        -0.2274,  0.1212,  0.4905,  0.2798,  0.3921, -0.0529,  0.4170, -0.0771,
        -0.1580,  0.3464, -0.2703, -0.3340,  0.4402,  0.2671,  0.4739, -0.2864,
        -0.3042,  0.1727, -0.3525,  0.0014], dtype=torch.float16)
[Worker 1] Completed Task 1172

[Worker 1] Processing Task 1176: paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 70486 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 6, 49853, 284) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.2815,  0.4910, -0.0790,  0.2434,  0.2264, -0.0843, -0.2218,  0.3020,
        -0.3513,  0.0911, -0.1004, -0.3442,  0.2344,  0.4856,  0.4326, -0.2983,
         0.3301, -0.3467, -0.0782, -0.3525, -0.4824,  0.2910, -0.2059,  0.2695,
        -0.3098,  0.0807, -0.2644,  0.2729, -0.3127, -0.0196, -0.4902,  0.2461,
         0.4619, -0.3254,  0.3250,  0.4509,  0.1293, -0.3042,  0.3828,  0.2991,
         0.3401, -0.0452, -0.4138,  0.2561, -0.0914,  0.2678,  0.2428, -0.0384,
         0.1836,  0.4106, -0.0836,  0.1000,  0.2480,  0.0856,  0.1015, -0.3066,
         0.3623, -0.1489, -0.4185,  0.4749,  0.1261, -0.1187, -0.2605, -0.4561,
         0.0042, -0.2898,  0.3091,  0.0646,  0.1599, -0.0876,  0.3745, -0.0634,
         0.2247, -0.3083, -0.2837, -0.4612,  0.3953, -0.3652, -0.4795, -0.1809,
         0.2332, -0.4099, -0.0620,  0.2241,  0.0974,  0.0233, -0.0539, -0.1982,
        -0.3845,  0.2048, -0.4456,  0.3560,  0.3733, -0.0406, -0.0454, -0.3606,
        -0.4666,  0.2260,  0.1825,  0.0575], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.2815,  0.4910, -0.0790,  0.2434,  0.2264, -0.0843, -0.2218,  0.3020,
        -0.3513,  0.0911, -0.1004, -0.3442,  0.2344,  0.4856,  0.4326, -0.2983,
         0.3301, -0.3467, -0.0782, -0.3525, -0.4824,  0.2910, -0.2059,  0.2695,
        -0.3098,  0.0807, -0.2644,  0.2729, -0.3127, -0.0196, -0.4902,  0.2461,
         0.4619, -0.3254,  0.3250,  0.4509,  0.1293, -0.3042,  0.3828,  0.2991,
         0.3401, -0.0452, -0.4138,  0.2561, -0.0914,  0.2678,  0.2428, -0.0384,
         0.1836,  0.4106, -0.0836,  0.1000,  0.2480,  0.0856,  0.1015, -0.3066,
         0.3623, -0.1489, -0.4185,  0.4749,  0.1261, -0.1187, -0.2605, -0.4561,
         0.0042, -0.2898,  0.3091,  0.0646,  0.1599, -0.0876,  0.3745, -0.0634,
         0.2247, -0.3083, -0.2837, -0.4612,  0.3953, -0.3652, -0.4795, -0.1809,
         0.2332, -0.4099, -0.0620,  0.2241,  0.0974,  0.0233, -0.0539, -0.1982,
        -0.3845,  0.2048, -0.4456,  0.3560,  0.3733, -0.0406, -0.0454, -0.3606,
        -0.4666,  0.2260,  0.1825,  0.0575], dtype=torch.float16)
[Worker 1] Completed Task 1176

[Worker 1] Processing Task 1180: paddle.roll(Tensor([1, 38044, 14, 21, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 38044, 14, 21, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 71065 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 38043, 0, 6, 176) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 38043, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 38044, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0839,  0.1531,  0.3066,  0.3794, -0.1532, -0.1411,  0.2185, -0.0279,
        -0.4697,  0.0216, -0.1931,  0.2896, -0.2360, -0.2156, -0.2267,  0.1938,
         0.3521, -0.1863,  0.1978,  0.0344,  0.4873, -0.0060, -0.3855,  0.3069,
        -0.2286, -0.1941,  0.4136, -0.1512, -0.0028,  0.1382,  0.1835, -0.3923,
        -0.1735,  0.0846, -0.1923,  0.0699,  0.4712,  0.0624, -0.3560,  0.4163,
        -0.2336, -0.3062, -0.1893, -0.3447,  0.2886,  0.1586,  0.2250, -0.2216,
         0.1848,  0.2769, -0.3525, -0.1881,  0.4648,  0.4829, -0.1355,  0.0890,
        -0.0162, -0.3181,  0.0618, -0.3735,  0.3091,  0.2534, -0.2920, -0.1196,
         0.1019, -0.0760, -0.2301,  0.2079, -0.0210,  0.3613, -0.0887, -0.2128,
        -0.1471, -0.1180,  0.2886, -0.0560,  0.1843,  0.0472, -0.2649, -0.4819,
        -0.2607, -0.4722,  0.0007, -0.3103,  0.3438,  0.3167, -0.3435, -0.0566,
         0.4609, -0.0745, -0.4485,  0.4175, -0.0216,  0.2964,  0.3540, -0.4429,
        -0.0844,  0.1110,  0.2639,  0.2048], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 38044, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0839,  0.1531,  0.3066,  0.3794, -0.1532, -0.1411,  0.2185, -0.0279,
        -0.4697,  0.0216, -0.1931,  0.2896, -0.2360, -0.2156, -0.2267,  0.1938,
         0.3521, -0.1863,  0.1978,  0.0344,  0.4873, -0.0060, -0.3855,  0.3069,
        -0.2286, -0.1941,  0.4136, -0.1512, -0.0028,  0.1382,  0.1835, -0.3923,
        -0.1735,  0.0846, -0.1923,  0.0699,  0.4712,  0.0624, -0.3560,  0.4163,
        -0.2336, -0.3062, -0.1893, -0.3447,  0.2886,  0.1586,  0.2250, -0.2216,
         0.1848,  0.2769, -0.3525, -0.1881,  0.4648,  0.4829, -0.1355,  0.0890,
        -0.0162, -0.3181,  0.0618, -0.3735,  0.3091,  0.2534, -0.2920, -0.1196,
         0.1019, -0.0760, -0.2301,  0.2079, -0.0210,  0.3613, -0.0887, -0.2128,
        -0.1471, -0.1180,  0.2886, -0.0560,  0.1843,  0.0472, -0.2649, -0.4819,
        -0.2607, -0.4722,  0.0007, -0.3103,  0.3438,  0.3167, -0.3435, -0.0566,
         0.4609, -0.0745, -0.4485,  0.4175, -0.0216,  0.2964,  0.3540, -0.4429,
        -0.0844,  0.1110,  0.2639,  0.2048], dtype=torch.float16)
[Worker 1] Completed Task 1180

[Worker 1] Processing Task 1184: paddle.roll(Tensor([1, 57066, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 57066, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 63215 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 57065, 1, 7, 378) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 57065, 0, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 57066, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.0407, -0.1283,  0.1267,  0.1923, -0.2317,  0.3928,  0.4641,  0.0539,
        -0.1234, -0.4866, -0.1152,  0.3040, -0.2578, -0.3538, -0.1132,  0.2598,
        -0.1156,  0.3613,  0.3450,  0.4990, -0.2634, -0.0634,  0.1094,  0.4907,
         0.2893, -0.2189, -0.2979,  0.1416,  0.1721, -0.1422, -0.4731, -0.0897,
         0.4749,  0.3374, -0.0091,  0.1101,  0.2048, -0.2979, -0.1370,  0.3025,
        -0.0377, -0.2438,  0.2502,  0.4519, -0.2189, -0.1304, -0.2493, -0.0176,
        -0.4739, -0.0513, -0.0891,  0.3193,  0.2235,  0.0811, -0.4790,  0.0546,
        -0.1897,  0.0451,  0.0541,  0.2273,  0.1354,  0.4116,  0.3293, -0.1722,
        -0.3997, -0.0353,  0.4346, -0.3511, -0.0306, -0.4246,  0.0820,  0.2332,
        -0.1459, -0.0562, -0.3853,  0.3555,  0.2590,  0.4851,  0.2220, -0.4312,
         0.3506, -0.0724, -0.4697, -0.0230, -0.4404,  0.4226,  0.1964, -0.4265,
        -0.4729,  0.0923, -0.0085, -0.4387, -0.3931, -0.3218, -0.3762,  0.3865,
         0.4038, -0.0338, -0.1331,  0.1263], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 57066, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.0407, -0.1283,  0.1267,  0.1923, -0.2317,  0.3928,  0.4641,  0.0539,
        -0.1234, -0.4866, -0.1152,  0.3040, -0.2578, -0.3538, -0.1132,  0.2598,
        -0.1156,  0.3613,  0.3450,  0.4990, -0.2634, -0.0634,  0.1094,  0.4907,
         0.2893, -0.2189, -0.2979,  0.1416,  0.1721, -0.1422, -0.4731, -0.0897,
         0.4749,  0.3374, -0.0091,  0.1101,  0.2048, -0.2979, -0.1370,  0.3025,
        -0.0377, -0.2438,  0.2502,  0.4519, -0.2189, -0.1304, -0.2493, -0.0176,
        -0.4739, -0.0513, -0.0891,  0.3193,  0.2235,  0.0811, -0.4790,  0.0546,
        -0.1897,  0.0451,  0.0541,  0.2273,  0.1354,  0.4116,  0.3293, -0.1722,
        -0.3997, -0.0353,  0.4346, -0.3511, -0.0306, -0.4246,  0.0820,  0.2332,
        -0.1459, -0.0562, -0.3853,  0.3555,  0.2590,  0.4851,  0.2220, -0.4312,
         0.3506, -0.0724, -0.4697, -0.0230, -0.4404,  0.4226,  0.1964, -0.4265,
        -0.4729,  0.0923, -0.0085, -0.4387, -0.3931, -0.3218, -0.3762,  0.3865,
         0.4038, -0.0338, -0.1331,  0.1263], dtype=torch.float16)
[Worker 1] Completed Task 1184

[Worker 1] Processing Task 1188: paddle.roll(Tensor([1, 57066, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 57066, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 49429 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 57065, 2, 12, 281) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 57065, 2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 57066, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.1150, -0.3281,  0.1055,  0.1242, -0.1550, -0.3689, -0.4839, -0.3335,
         0.0052,  0.3101,  0.1425, -0.0095,  0.1997,  0.0684, -0.3633,  0.1393,
         0.1991, -0.0553,  0.0330,  0.3423, -0.1361,  0.1428,  0.3665,  0.0155,
         0.1709,  0.3000,  0.0360, -0.2561, -0.1250, -0.4585,  0.2303,  0.1259,
         0.1127,  0.2385, -0.1742, -0.1191, -0.4092,  0.3359, -0.4771,  0.3662,
         0.4822,  0.2373,  0.1630,  0.0708, -0.2198,  0.3477,  0.2927,  0.3406,
        -0.2725, -0.0230, -0.4761, -0.1719,  0.4773, -0.3738,  0.2717, -0.4045,
        -0.3477, -0.0429, -0.4607,  0.1761, -0.4824, -0.3418,  0.4500,  0.4583,
         0.2147,  0.1056,  0.4275, -0.2462,  0.4961,  0.3318, -0.0779,  0.0623,
         0.0410,  0.0007, -0.1815, -0.4661, -0.2593,  0.0482,  0.3013, -0.0398,
        -0.1832, -0.2451,  0.1210,  0.4077,  0.4646, -0.3467, -0.1342, -0.0462,
         0.1068,  0.3003,  0.2878, -0.0240, -0.3748,  0.1797, -0.3984,  0.1750,
         0.3350, -0.0482,  0.1282, -0.4434], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 57066, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.1150, -0.3281,  0.1055,  0.1242, -0.1550, -0.3689, -0.4839, -0.3335,
         0.0052,  0.3101,  0.1425, -0.0095,  0.1997,  0.0684, -0.3633,  0.1393,
         0.1991, -0.0553,  0.0330,  0.3423, -0.1361,  0.1428,  0.3665,  0.0155,
         0.1709,  0.3000,  0.0360, -0.2561, -0.1250, -0.4585,  0.2303,  0.1259,
         0.1127,  0.2385, -0.1742, -0.1191, -0.4092,  0.3359, -0.4771,  0.3662,
         0.4822,  0.2373,  0.1630,  0.0708, -0.2198,  0.3477,  0.2927,  0.3406,
        -0.2725, -0.0230, -0.4761, -0.1719,  0.4773, -0.3738,  0.2717, -0.4045,
        -0.3477, -0.0429, -0.4607,  0.1761, -0.4824, -0.3418,  0.4500,  0.4583,
         0.2147,  0.1056,  0.4275, -0.2462,  0.4961,  0.3318, -0.0779,  0.0623,
         0.0410,  0.0007, -0.1815, -0.4661, -0.2593,  0.0482,  0.3013, -0.0398,
        -0.1832, -0.2451,  0.1210,  0.4077,  0.4646, -0.3467, -0.1342, -0.0462,
         0.1068,  0.3003,  0.2878, -0.0240, -0.3748,  0.1797, -0.3984,  0.1750,
         0.3350, -0.0482,  0.1282, -0.4434], dtype=torch.float16)
[Worker 1] Completed Task 1188

[Worker 1] Processing Task 1192: paddle.roll(Tensor([2378, 16, 14, 21, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([2378, 16, 14, 21, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 513572 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (2377, 11, 0, 6, 176) (up to 0.01 allowed)
Greatest relative difference: inf at index (2377, 11, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2378, 16, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.2585,  0.1904, -0.4988,  0.1919, -0.4292, -0.0273,  0.2366,  0.4395,
        -0.2847,  0.2245, -0.0685,  0.4856, -0.4155, -0.1731, -0.4709, -0.0721,
         0.3159,  0.1632,  0.4294,  0.2211, -0.2634,  0.1124, -0.0786, -0.4663,
         0.0406, -0.0919,  0.2073, -0.1427, -0.3960,  0.0693,  0.2260, -0.3279,
         0.2158,  0.0499,  0.3708, -0.4905,  0.1801,  0.4651,  0.3770,  0.0823,
        -0.4963,  0.4131,  0.1233, -0.1887,  0.4858,  0.3748,  0.2208,  0.2194,
        -0.3872, -0.0446, -0.1567, -0.3972,  0.1791,  0.1835, -0.2705, -0.2891,
        -0.2031,  0.1902,  0.2712, -0.3350, -0.3708,  0.4998, -0.2115, -0.3616,
         0.0984, -0.4851,  0.4319,  0.1270, -0.0889,  0.0266,  0.1087,  0.1143,
        -0.0349,  0.1517,  0.0977,  0.0751,  0.2139, -0.0032,  0.2778,  0.1967,
         0.0313, -0.3281,  0.3213, -0.4272,  0.3010,  0.4377,  0.3135,  0.1984,
        -0.3933, -0.1212, -0.3887,  0.4192, -0.0082,  0.2057, -0.1903, -0.0197,
        -0.2517,  0.2896, -0.2134,  0.3218], dtype=torch.float16)
DESIRED: (shape=torch.Size([2378, 16, 14, 21, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.2585,  0.1904, -0.4988,  0.1919, -0.4292, -0.0273,  0.2366,  0.4395,
        -0.2847,  0.2245, -0.0685,  0.4856, -0.4155, -0.1731, -0.4709, -0.0721,
         0.3159,  0.1632,  0.4294,  0.2211, -0.2634,  0.1124, -0.0786, -0.4663,
         0.0406, -0.0919,  0.2073, -0.1427, -0.3960,  0.0693,  0.2260, -0.3279,
         0.2158,  0.0499,  0.3708, -0.4905,  0.1801,  0.4651,  0.3770,  0.0823,
        -0.4963,  0.4131,  0.1233, -0.1887,  0.4858,  0.3748,  0.2208,  0.2194,
        -0.3872, -0.0446, -0.1567, -0.3972,  0.1791,  0.1835, -0.2705, -0.2891,
        -0.2031,  0.1902,  0.2712, -0.3350, -0.3708,  0.4998, -0.2115, -0.3616,
         0.0984, -0.4851,  0.4319,  0.1270, -0.0889,  0.0266,  0.1087,  0.1143,
        -0.0349,  0.1517,  0.0977,  0.0751,  0.2139, -0.0032,  0.2778,  0.1967,
         0.0313, -0.3281,  0.3213, -0.4272,  0.3010,  0.4377,  0.3135,  0.1984,
        -0.3933, -0.1212, -0.3887,  0.4192, -0.0082,  0.2057, -0.1903, -0.0197,
        -0.2517,  0.2896, -0.2134,  0.3218], dtype=torch.float16)
[Worker 1] Completed Task 1192

[Worker 1] Processing Task 1196: paddle.roll(Tensor([3, 1431655766],"float16"), shifts=1, )
[accuracy error] paddle.roll(Tensor([3, 1431655766],"float16"), shifts=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 4294967298 (0.0%)
Greatest absolute difference: 0.308349609375 at index (2, 1431655764) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1431655764) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.4224, -0.3665, -0.3850, -0.3523,  0.2920, -0.4243, -0.2241, -0.3628,
        -0.3789,  0.4407, -0.2930,  0.3997,  0.1516, -0.3542, -0.2812,  0.1019,
        -0.2852,  0.3679,  0.0567,  0.0078, -0.3958, -0.0549, -0.3210, -0.4280,
         0.2959,  0.0768,  0.1918,  0.1602, -0.4136, -0.1681, -0.0935, -0.4053,
        -0.2289, -0.2546, -0.1671,  0.3345,  0.3240,  0.1760,  0.1989, -0.4878,
         0.0681,  0.1810, -0.0043,  0.0231, -0.3416,  0.3884, -0.0988, -0.0016,
        -0.3293, -0.1119, -0.1752,  0.1334, -0.2069, -0.1339,  0.3889, -0.1584,
        -0.0465,  0.2759, -0.4597, -0.4575, -0.4722, -0.1799, -0.1693,  0.1293,
        -0.4263,  0.0424, -0.4719, -0.1560, -0.1810,  0.4341, -0.3560,  0.4456,
        -0.2382, -0.2620,  0.4998, -0.2234,  0.0230, -0.4221,  0.0418,  0.0410,
        -0.2478, -0.1119, -0.1528,  0.1847, -0.3877, -0.2744,  0.3252, -0.1514,
        -0.2515, -0.4116,  0.1331,  0.1561,  0.3372,  0.3159, -0.2318, -0.3542,
        -0.0614,  0.4521, -0.0679, -0.3811], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.4224, -0.3665, -0.3850, -0.3523,  0.2920, -0.4243, -0.2241, -0.3628,
        -0.3789,  0.4407, -0.2930,  0.3997,  0.1516, -0.3542, -0.2812,  0.1019,
        -0.2852,  0.3679,  0.0567,  0.0078, -0.3958, -0.0549, -0.3210, -0.4280,
         0.2959,  0.0768,  0.1918,  0.1602, -0.4136, -0.1681, -0.0935, -0.4053,
        -0.2289, -0.2546, -0.1671,  0.3345,  0.3240,  0.1760,  0.1989, -0.4878,
         0.0681,  0.1810, -0.0043,  0.0231, -0.3416,  0.3884, -0.0988, -0.0016,
        -0.3293, -0.1119, -0.1752,  0.1334, -0.2069, -0.1339,  0.3889, -0.1584,
        -0.0465,  0.2759, -0.4597, -0.4575, -0.4722, -0.1799, -0.1693,  0.1293,
        -0.4263,  0.0424, -0.4719, -0.1560, -0.1810,  0.4341, -0.3560,  0.4456,
        -0.2382, -0.2620,  0.4998, -0.2234,  0.0230, -0.4221,  0.0418,  0.0410,
        -0.2478, -0.1119, -0.1528,  0.1847, -0.3877, -0.2744,  0.3252, -0.1514,
        -0.2515, -0.4116,  0.1331,  0.1561,  0.3372,  0.3159, -0.2318, -0.3542,
        -0.0614,  0.4521, -0.0679, -0.3811], dtype=torch.float16)
[Worker 1] Completed Task 1196

[Worker 1] Processing Task 1200: paddle.roll(Tensor([3567, 16, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([3567, 16, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 505487 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (3566, 9, 1, 2, 378) (up to 0.01 allowed)
Greatest relative difference: inf at index (3566, 9, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3567, 16, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.1087, -0.4907, -0.4990,  0.4365,  0.3552,  0.1015,  0.0217,  0.0801,
        -0.3474,  0.1918,  0.4316, -0.2527,  0.1460,  0.4365,  0.0440,  0.0559,
         0.2649, -0.3833, -0.1766,  0.2830,  0.4048,  0.2195, -0.4531, -0.4473,
         0.4131,  0.4678,  0.1832,  0.1948, -0.3418,  0.1780,  0.4924, -0.2666,
         0.0838,  0.1758,  0.3474, -0.3354, -0.0118,  0.1012,  0.2944,  0.4951,
        -0.0992, -0.2805,  0.1062, -0.1903, -0.4109,  0.2086, -0.4526, -0.1377,
        -0.0315, -0.1724, -0.0991, -0.2966, -0.1490,  0.3689, -0.2632, -0.0776,
         0.2018,  0.1907,  0.2537,  0.1617,  0.4832,  0.0808,  0.2915,  0.0217,
        -0.4390,  0.1781, -0.1326,  0.1453,  0.4937, -0.2070, -0.4771, -0.4695,
         0.3027, -0.4929, -0.2517,  0.1838,  0.0830,  0.0250, -0.3142, -0.0092,
        -0.0761, -0.1592, -0.0265,  0.1083, -0.2568, -0.3970, -0.4504, -0.2495,
        -0.4448,  0.0883,  0.3259,  0.1444, -0.4504, -0.1578, -0.0694,  0.4983,
         0.2668, -0.0854, -0.4890,  0.3091], dtype=torch.float16)
DESIRED: (shape=torch.Size([3567, 16, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.1087, -0.4907, -0.4990,  0.4365,  0.3552,  0.1015,  0.0217,  0.0801,
        -0.3474,  0.1918,  0.4316, -0.2527,  0.1460,  0.4365,  0.0440,  0.0559,
         0.2649, -0.3833, -0.1766,  0.2830,  0.4048,  0.2195, -0.4531, -0.4473,
         0.4131,  0.4678,  0.1832,  0.1948, -0.3418,  0.1780,  0.4924, -0.2666,
         0.0838,  0.1758,  0.3474, -0.3354, -0.0118,  0.1012,  0.2944,  0.4951,
        -0.0992, -0.2805,  0.1062, -0.1903, -0.4109,  0.2086, -0.4526, -0.1377,
        -0.0315, -0.1724, -0.0991, -0.2966, -0.1490,  0.3689, -0.2632, -0.0776,
         0.2018,  0.1907,  0.2537,  0.1617,  0.4832,  0.0808,  0.2915,  0.0217,
        -0.4390,  0.1781, -0.1326,  0.1453,  0.4937, -0.2070, -0.4771, -0.4695,
         0.3027, -0.4929, -0.2517,  0.1838,  0.0830,  0.0250, -0.3142, -0.0092,
        -0.0761, -0.1592, -0.0265,  0.1083, -0.2568, -0.3970, -0.4504, -0.2495,
        -0.4448,  0.0883,  0.3259,  0.1444, -0.4504, -0.1578, -0.0694,  0.4983,
         0.2668, -0.0854, -0.4890,  0.3091], dtype=torch.float16)
[Worker 1] Completed Task 1200

[Worker 1] Processing Task 1208: paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=1, axis=None, )
[accuracy error] paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=1, axis=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 4294967298 (0.0%)
Greatest absolute difference: 0.308349609375 at index (2, 1431655764) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1431655764) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.4224, -0.3665, -0.3850, -0.3523,  0.2920, -0.4243, -0.2241, -0.3628,
        -0.3789,  0.4407, -0.2930,  0.3997,  0.1516, -0.3542, -0.2812,  0.1019,
        -0.2852,  0.3679,  0.0567,  0.0078, -0.3958, -0.0549, -0.3210, -0.4280,
         0.2959,  0.0768,  0.1918,  0.1602, -0.4136, -0.1681, -0.0935, -0.4053,
        -0.2289, -0.2546, -0.1671,  0.3345,  0.3240,  0.1760,  0.1989, -0.4878,
         0.0681,  0.1810, -0.0043,  0.0231, -0.3416,  0.3884, -0.0988, -0.0016,
        -0.3293, -0.1119, -0.1752,  0.1334, -0.2069, -0.1339,  0.3889, -0.1584,
        -0.0465,  0.2759, -0.4597, -0.4575, -0.4722, -0.1799, -0.1693,  0.1293,
        -0.4263,  0.0424, -0.4719, -0.1560, -0.1810,  0.4341, -0.3560,  0.4456,
        -0.2382, -0.2620,  0.4998, -0.2234,  0.0230, -0.4221,  0.0418,  0.0410,
        -0.2478, -0.1119, -0.1528,  0.1847, -0.3877, -0.2744,  0.3252, -0.1514,
        -0.2515, -0.4116,  0.1331,  0.1561,  0.3372,  0.3159, -0.2318, -0.3542,
        -0.0614,  0.4521, -0.0679, -0.3811], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-0.4224, -0.3665, -0.3850, -0.3523,  0.2920, -0.4243, -0.2241, -0.3628,
        -0.3789,  0.4407, -0.2930,  0.3997,  0.1516, -0.3542, -0.2812,  0.1019,
        -0.2852,  0.3679,  0.0567,  0.0078, -0.3958, -0.0549, -0.3210, -0.4280,
         0.2959,  0.0768,  0.1918,  0.1602, -0.4136, -0.1681, -0.0935, -0.4053,
        -0.2289, -0.2546, -0.1671,  0.3345,  0.3240,  0.1760,  0.1989, -0.4878,
         0.0681,  0.1810, -0.0043,  0.0231, -0.3416,  0.3884, -0.0988, -0.0016,
        -0.3293, -0.1119, -0.1752,  0.1334, -0.2069, -0.1339,  0.3889, -0.1584,
        -0.0465,  0.2759, -0.4597, -0.4575, -0.4722, -0.1799, -0.1693,  0.1293,
        -0.4263,  0.0424, -0.4719, -0.1560, -0.1810,  0.4341, -0.3560,  0.4456,
        -0.2382, -0.2620,  0.4998, -0.2234,  0.0230, -0.4221,  0.0418,  0.0410,
        -0.2478, -0.1119, -0.1528,  0.1847, -0.3877, -0.2744,  0.3252, -0.1514,
        -0.2515, -0.4116,  0.1331,  0.1561,  0.3372,  0.3159, -0.2318, -0.3542,
        -0.0614,  0.4521, -0.0679, -0.3811], dtype=torch.float16)
[Worker 1] Completed Task 1208

[Worker 1] Processing Task 1212: paddle.rsqrt(x=Tensor([2, 3, 715827883],"float16"), )
[accuracy error] backward  paddle.rsqrt(x=Tensor([2, 3, 715827883],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2010489 / 4294967298 (0.0%)
Greatest absolute difference: inf at index (0, 0, 1388) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 1388) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 715827883]), dtype=torch.float16)
First 100 elements: tensor([     nan,      nan,      nan,   1.2188,      nan,      nan,      nan,
             nan,  -0.7417,      nan,   0.1310,   2.4180,      nan,      nan,
         -4.1094,      nan,  -0.6934,  -1.7568,  39.1875,      nan,      nan,
             nan,      nan,   1.2734,  10.7031,   0.2708,  -0.0993,      nan,
             nan,      nan,      nan,      nan,      nan,      nan,  -0.6953,
         -1.2080,  -0.5024,  -0.6577,      nan,  -1.3066,   2.9570,      nan,
         29.6250,      nan,   0.9292,      nan,      nan,      nan,      nan,
             nan,  -3.8242,      nan,      nan,  -0.9233,      nan,      nan,
         -1.2031,      nan,      nan,      nan,      nan,      nan,   2.6172,
             nan, -19.9062,      nan,      nan,      nan,  -0.7568,      nan,
          0.5200,      nan,      nan,  -0.6099,      nan, -57.5625,      nan,
         17.7969, -27.9844,      nan,      nan,      nan,  -3.1426,      nan,
             nan,   0.5122,      nan,      nan,      nan,  -4.8281,   1.8613,
          0.0966,  -0.2793,      nan,      nan,      nan,   0.4600,      nan,
             nan,   0.8130], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 3, 715827883]), dtype=torch.float16)
First 100 elements: tensor([     nan,      nan,      nan,   1.2178,      nan,      nan,      nan,
             nan,  -0.7417,      nan,   0.1310,   2.4160,      nan,      nan,
         -4.1094,      nan,  -0.6929,  -1.7568,  39.2188,      nan,      nan,
             nan,      nan,   1.2725,  10.7031,   0.2710,  -0.0994,      nan,
             nan,      nan,      nan,      nan,      nan,      nan,  -0.6953,
         -1.2080,  -0.5024,  -0.6577,      nan,  -1.3066,   2.9551,      nan,
         29.6094,      nan,   0.9287,      nan,      nan,      nan,      nan,
             nan,  -3.8242,      nan,      nan,  -0.9233,      nan,      nan,
         -1.2031,      nan,      nan,      nan,      nan,      nan,   2.6172,
             nan, -19.9219,      nan,      nan,      nan,  -0.7568,      nan,
          0.5200,      nan,      nan,  -0.6094,      nan, -57.5312,      nan,
         17.7969, -27.9844,      nan,      nan,      nan,  -3.1426,      nan,
             nan,   0.5122,      nan,      nan,      nan,  -4.8281,   1.8613,
          0.0965,  -0.2793,      nan,      nan,      nan,   0.4600,      nan,
             nan,   0.8135], dtype=torch.float16)
[Worker 1] Completed Task 1212

[Worker 1] Processing Task 1310: paddle.Tensor.bmm(Tensor([5309, 143264, 3],"float32"), Tensor([5309, 3, 2],"float32"), )
[accuracy error] backward  paddle.Tensor.bmm(Tensor([5309, 143264, 3],"float32"), Tensor([5309, 3, 2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 182 / 31854 (0.6%)
Greatest absolute difference: 0.03742671012878418 at index (2005, 1, 1) (up to 0.01 allowed)
Greatest relative difference: 3.866079568862915 at index (2384, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5309, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([-43.1987, -24.4453,   0.8440,  12.4009, -53.3783,   6.4719, -36.4564,
        -67.0104,   3.9548,   2.6015,  17.1645,  10.0988, -44.1751, -19.3458,
        -26.7713, -79.7799, -42.2755,  13.4522,  24.7448, -23.0665,  41.4817,
        -33.4915,   5.4460,  -0.8832,  18.5900, -42.8728,  12.2927,  24.6073,
         26.9558, -11.7727,  13.6793,   7.7810, -17.6019, -28.7336, -25.0600,
         -6.1737,  26.4889,  22.7829,  -2.3324, -58.9237,  -0.2416,  36.7416,
         -7.1906,   2.3068,   0.9359,   5.5648, -25.7617,  -6.7830,  16.5801,
         -6.5540, -11.7588,  32.1573,  45.8735, -63.7817, -12.8820,  12.5254,
         19.0060, -11.0088,   2.5150,  -0.4903,  20.9046,  -6.5673, -27.4732,
        -46.0848,  48.1837,  15.9082,  69.7517,  21.0514,  40.9609,   3.8103,
        -27.0035, -16.9936,  -8.3840,  32.6570,  -5.2681,  24.3831,   5.5305,
          3.3208, -17.6074,  31.5650,   9.0276, -70.3705, -48.4507, -32.8517,
         11.5774,   9.5296,  -5.0312, -14.8717, -12.0517, -44.7416, -31.7770,
        -21.1024,  -9.4815,  20.8573,  24.6865,  39.3928, -10.1154,   6.9506,
        -49.3333,  10.0824])
DESIRED: (shape=torch.Size([5309, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([-43.2064, -24.4357,   0.8403,  12.4046, -53.4021,   6.4919, -36.4537,
        -67.0169,   3.9425,   2.5881,  17.1932,  10.1193, -44.1934, -19.3673,
        -26.7878, -79.8045, -42.3018,  13.4602,  24.7679, -23.0847,  41.5092,
        -33.4976,   5.4304,  -0.8859,  18.5883, -42.8992,  12.3027,  24.6069,
         26.9795, -11.7839,  13.6671,   7.7992, -17.6070, -28.7458, -25.0645,
         -6.1806,  26.5005,  22.7765,  -2.3403, -58.9337,  -0.2620,  36.7594,
         -7.2028,   2.3191,   0.9426,   5.5529, -25.7729,  -6.7931,  16.5880,
         -6.5488, -11.7612,  32.1504,  45.8905, -63.7912, -12.8982,  12.5283,
         19.0103, -11.0155,   2.5056,  -0.4794,  20.9006,  -6.5821, -27.5017,
        -46.1176,  48.1806,  15.9063,  69.7837,  21.0518,  40.9887,   3.8257,
        -27.0180, -16.9991,  -8.3911,  32.6560,  -5.2590,  24.4112,   5.5259,
          3.3289, -17.6141,  31.5887,   9.0394, -70.4162, -48.4710, -32.8684,
         11.5730,   9.5337,  -5.0464, -14.8754, -12.0388, -44.7524, -31.7851,
        -21.0814,  -9.4764,  20.8737,  24.7030,  39.3985, -10.1253,   6.9265,
        -49.3480,  10.0994])
[Worker 1] Completed Task 1310

[Worker 1] Processing Task 1322: paddle.Tensor.cumsum(Tensor([1, 2281701379],"float32"), axis=-1, )
[accuracy error] backward  paddle.Tensor.cumsum(Tensor([1, 2281701379],"float32"), axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 540101 / 2281701379 (0.0%)
Greatest absolute difference: 0.035753726959228516 at index (0, 564346759) (up to 0.01 allowed)
Greatest relative difference: 4768.18798828125 at index (0, 1258648309) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([6398.5356, 6398.6714, 6398.3936, 6398.4175, 6398.6831, 6398.6782,
        6399.0029, 6398.9580, 6398.6299, 6398.6958, 6398.6973, 6398.4810,
        6398.5254, 6398.9590, 6398.5918, 6398.6357, 6398.7886, 6398.7026,
        6398.6113, 6398.3706, 6398.4395, 6398.9263, 6399.3706, 6399.7026,
        6399.7383, 6400.0210, 6400.3252, 6399.8706, 6400.2085, 6400.4302,
        6400.4341, 6400.1821, 6400.6636, 6400.9927, 6401.2065, 6400.9771,
        6401.2485, 6401.0239, 6400.8579, 6401.1611, 6401.6401, 6401.9038,
        6402.0298, 6402.2637, 6401.7920, 6401.8818, 6401.9824, 6401.5488,
        6401.1670, 6401.2065, 6400.9585, 6400.7715, 6400.6479, 6400.1519,
        6399.8984, 6400.1890, 6400.3936, 6400.4956, 6400.9023, 6400.5137,
        6400.4912, 6400.6753, 6400.2563, 6400.1372, 6399.9111, 6399.6880,
        6400.0581, 6400.4731, 6400.1143, 6400.2461, 6400.5195, 6400.9077,
        6401.0928, 6401.0205, 6401.0146, 6401.0015, 6400.9995, 6400.8438,
        6401.2598, 6401.6255, 6401.2466, 6401.5400, 6401.8960, 6402.2295,
        6402.0249, 6402.3647, 6401.9062, 6401.9692, 6401.7998, 6401.5889,
        6401.8232, 6401.4375, 6401.1084, 6400.9644, 6400.7207, 6400.7080,
        6401.0596, 6400.9082, 6401.2451, 6401.6802])
DESIRED: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([6398.5420, 6398.6777, 6398.3999, 6398.4238, 6398.6895, 6398.6846,
        6399.0093, 6398.9644, 6398.6362, 6398.7021, 6398.7036, 6398.4873,
        6398.5317, 6398.9653, 6398.5981, 6398.6421, 6398.7949, 6398.7090,
        6398.6177, 6398.3770, 6398.4458, 6398.9326, 6399.3770, 6399.7090,
        6399.7446, 6400.0273, 6400.3315, 6399.8770, 6400.2148, 6400.4365,
        6400.4404, 6400.1885, 6400.6699, 6400.9990, 6401.2124, 6400.9829,
        6401.2544, 6401.0298, 6400.8638, 6401.1670, 6401.6460, 6401.9087,
        6402.0347, 6402.2686, 6401.7969, 6401.8867, 6401.9873, 6401.5537,
        6401.1719, 6401.2119, 6400.9639, 6400.7769, 6400.6533, 6400.1572,
        6399.9038, 6400.1943, 6400.3989, 6400.5010, 6400.9077, 6400.5190,
        6400.4966, 6400.6807, 6400.2617, 6400.1426, 6399.9175, 6399.6943,
        6400.0645, 6400.4795, 6400.1206, 6400.2524, 6400.5259, 6400.9141,
        6401.0991, 6401.0269, 6401.0210, 6401.0078, 6401.0059, 6400.8501,
        6401.2661, 6401.6318, 6401.2529, 6401.5464, 6401.9023, 6402.2358,
        6402.0312, 6402.3711, 6401.9131, 6401.9761, 6401.8066, 6401.5957,
        6401.8301, 6401.4443, 6401.1152, 6400.9712, 6400.7261, 6400.7134,
        6401.0649, 6400.9136, 6401.2505, 6401.6855])
[Worker 1] Completed Task 1322

[Worker 1] Processing Task 1327: paddle.Tensor.diff(Tensor([2281701379],"float32"), )
[accuracy error] paddle.Tensor.diff(Tensor([2281701379],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235837461 / 2281701378 (98.0%)
Greatest absolute difference: 0.9999760389328003 at index (1817986639,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([ 0.2836, -0.2367,  0.4750,  0.1837, -0.3139,  0.2305, -0.4460, -0.2944,
         0.3462,  0.0017, -0.3162,  0.1851,  0.4144, -0.5354, -0.0174,  0.2667,
         0.4829, -0.3579,  0.2311, -0.8500,  0.0746,  0.3797,  0.3900, -0.0518,
         0.1845, -0.4582, -0.4695,  0.0377,  0.6111, -0.3866, -0.1060,  0.6690,
        -0.2714, -0.0971, -0.4350,  0.2103, -0.0797,  0.1549,  0.4702,  0.1406,
        -0.5225,  0.0057,  0.0059,  0.1195, -0.4216,  0.6329,  0.0514, -0.1547,
        -0.5559,  0.6435, -0.1665, -0.1716, -0.3567,  0.2152, -0.0316,  0.0520,
         0.3361, -0.4140,  0.3159, -0.4532, -0.0247,  0.1321,  0.7041, -0.0759,
        -0.4688,  0.5796, -0.7697,  0.6804, -0.2120, -0.0275,  0.0134, -0.2599,
        -0.1693,  0.5546, -0.5129, -0.2556,  0.0010,  0.3659, -0.2337,  0.7735,
        -0.7479, -0.0412,  0.6234, -0.3687, -0.2854,  0.8067, -0.0606, -0.6330,
         0.4288,  0.1050,  0.0022,  0.0358, -0.1103, -0.4521,  0.6821, -0.7062,
         0.5071, -0.4044, -0.1253,  0.7795])
[Worker 1] Completed Task 1327

[Worker 1] Processing Task 1328: paddle.Tensor.diff(Tensor([4294967297],"float16"), )
[accuracy error] paddle.Tensor.diff(Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208553349 / 4294967296 (98.0%)
Greatest absolute difference: 1.0 at index (2854466,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967296]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967296]), dtype=torch.float16)
First 100 elements: tensor([-0.0186,  0.0327,  0.6445, -0.7163,  0.2002, -0.1387, -0.0161,  0.8193,
        -0.7334,  0.6924, -0.2480, -0.5059,  0.0730,  0.3831, -0.3870,  0.6533,
        -0.3113, -0.0489, -0.4036,  0.3408, -0.2661, -0.1069,  0.7236, -0.2190,
         0.1149, -0.0316, -0.5737,  0.2455,  0.0746, -0.3118,  0.1764, -0.0258,
         0.0875,  0.5015, -0.0105, -0.1479,  0.0228, -0.6865,  0.5557,  0.1129,
        -0.1853,  0.0274, -0.3647,  0.7300, -0.4873,  0.0971, -0.3276,  0.2175,
        -0.0633,  0.3086, -0.3403,  0.0730,  0.5229, -0.5474,  0.1119,  0.3223,
        -0.7354,  0.0022, -0.0146,  0.2922,  0.0106,  0.2986, -0.5557,  0.4688,
        -0.5142,  0.3159, -0.0250,  0.6152, -0.7900,  0.8018, -0.6836, -0.0238,
         0.7617, -0.7231,  0.2463, -0.4451,  0.4639, -0.0009, -0.2888,  0.1359,
        -0.0409,  0.3374, -0.5723,  0.1133,  0.5996, -0.4766, -0.1001, -0.1602,
         0.5449,  0.0231,  0.1810, -0.0212, -0.5479, -0.1224,  0.2930,  0.5137,
        -0.5200, -0.3132,  0.6177, -0.5693], dtype=torch.float16)
[Worker 1] Completed Task 1328

[Worker 1] Processing Task 1333: paddle.Tensor.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208553359 / 4294967306 (98.0%)
Greatest absolute difference: 1.0 at index (2854466,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967306]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967306]), dtype=torch.float16)
First 100 elements: tensor([-0.0186,  0.0327,  0.6445, -0.7163,  0.2002, -0.1387, -0.0161,  0.8193,
        -0.7334,  0.6924, -0.2480, -0.5059,  0.0730,  0.3831, -0.3870,  0.6533,
        -0.3113, -0.0489, -0.4036,  0.3408, -0.2661, -0.1069,  0.7236, -0.2190,
         0.1149, -0.0316, -0.5737,  0.2455,  0.0746, -0.3118,  0.1764, -0.0258,
         0.0875,  0.5015, -0.0105, -0.1479,  0.0228, -0.6865,  0.5557,  0.1129,
        -0.1853,  0.0274, -0.3647,  0.7300, -0.4873,  0.0971, -0.3276,  0.2175,
        -0.0633,  0.3086, -0.3403,  0.0730,  0.5229, -0.5474,  0.1119,  0.3223,
        -0.7354,  0.0022, -0.0146,  0.2922,  0.0106,  0.2986, -0.5557,  0.4688,
        -0.5142,  0.3159, -0.0250,  0.6152, -0.7900,  0.8018, -0.6836, -0.0238,
         0.7617, -0.7231,  0.2463, -0.4451,  0.4639, -0.0009, -0.2888,  0.1359,
        -0.0409,  0.3374, -0.5723,  0.1133,  0.5996, -0.4766, -0.1001, -0.1602,
         0.5449,  0.0231,  0.1810, -0.0212, -0.5479, -0.1224,  0.2930,  0.5137,
        -0.5200, -0.3132,  0.6177, -0.5693], dtype=torch.float16)
[Worker 1] Completed Task 1333

[Worker 1] Processing Task 1335: paddle.Tensor.diff(x=Tensor([1073741825, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([4, 4],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([1073741825, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([4, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208562776 / 4294967328 (98.0%)
Greatest absolute difference: 1.0 at index (1207126, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741832, 4]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741832, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.0579,  0.1609, -0.0105, -0.6709,  0.8652, -0.0688,  0.7627,  0.5303,
        -0.7949,  0.0117, -0.2979, -0.4368, -0.0122, -0.1038, -0.4541,  0.5771,
        -0.0579,  0.1609, -0.0105, -0.6709,  0.8652, -0.0688,  0.7627,  0.5303,
        -0.7949,  0.0117, -0.2979, -0.4368,  0.7222,  0.3379, -0.0941, -0.1106,
        -0.4229, -0.3777, -0.4358,  0.6914,  0.1317,  0.5127,  0.5879, -0.7095,
        -0.2449, -0.2852, -0.5654,  0.1847, -0.0865, -0.0736,  0.7397,  0.5527,
         0.4307,  0.3660, -0.8223, -0.2559,  0.0050, -0.2031,  0.5107, -0.4097,
         0.2074, -0.0945, -0.0247,  0.0122, -0.5005, -0.0764,  0.1350,  0.1224,
        -0.0220,  0.5640, -0.2920,  0.1604,  0.4097, -0.8486, -0.2991, -0.4258,
        -0.4558,  0.2905,  0.5869,  0.0459,  0.2224, -0.3027, -0.2852,  0.2452,
         0.3916,  0.1160,  0.6016, -0.0571, -0.6963,  0.8555, -0.6689,  0.2612,
        -0.1602, -0.4580,  0.2644, -0.2708,  0.3101, -0.1947,  0.1437, -0.1399,
        -0.1625,  0.4780, -0.3359,  0.1362], dtype=torch.float16)
[Worker 1] Completed Task 1335

[Worker 1] Processing Task 1340: paddle.Tensor.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208553353 / 4294967300 (98.0%)
Greatest absolute difference: 1.0 at index (2854470,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967300]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967300]), dtype=torch.float16)
First 100 elements: tensor([-0.0186,  0.0327,  0.6445, -0.6582, -0.0186,  0.0327,  0.6445, -0.7163,
         0.2002, -0.1387, -0.0161,  0.8193, -0.7334,  0.6924, -0.2480, -0.5059,
         0.0730,  0.3831, -0.3870,  0.6533, -0.3113, -0.0489, -0.4036,  0.3408,
        -0.2661, -0.1069,  0.7236, -0.2190,  0.1149, -0.0316, -0.5737,  0.2455,
         0.0746, -0.3118,  0.1764, -0.0258,  0.0875,  0.5015, -0.0105, -0.1479,
         0.0228, -0.6865,  0.5557,  0.1129, -0.1853,  0.0274, -0.3647,  0.7300,
        -0.4873,  0.0971, -0.3276,  0.2175, -0.0633,  0.3086, -0.3403,  0.0730,
         0.5229, -0.5474,  0.1119,  0.3223, -0.7354,  0.0022, -0.0146,  0.2922,
         0.0106,  0.2986, -0.5557,  0.4688, -0.5142,  0.3159, -0.0250,  0.6152,
        -0.7900,  0.8018, -0.6836, -0.0238,  0.7617, -0.7231,  0.2463, -0.4451,
         0.4639, -0.0009, -0.2888,  0.1359, -0.0409,  0.3374, -0.5723,  0.1133,
         0.5996, -0.4766, -0.1001, -0.1602,  0.5449,  0.0231,  0.1810, -0.0212,
        -0.5479, -0.1224,  0.2930,  0.5137], dtype=torch.float16)
[Worker 1] Completed Task 1340

[Worker 1] Processing Task 1344: paddle.Tensor.kthvalue(Tensor([1140851, 200, 10],"float32"), k=200, axis=1, )
element 1 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.kthvalue(Tensor([1140851, 200, 10],"float32"), k=200, axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 11 / 11408510 (0.0%)
Greatest absolute difference: 171 at index (847736, 3) (up to 0.01 allowed)
Greatest relative difference: 6.75 at index (798606, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1140851, 10]), dtype=torch.int64)
First 100 elements: tensor([102, 129,  41,  95,  45,  49,  43, 135, 170,  46,  15,   1,  19,  51,
        132,  87,  61,  16,  14,  72,  63,  14,  80, 136, 158,  51, 191, 141,
        108, 179,  69, 138,  98, 109, 124,  91, 109,  50, 174, 108, 194,  23,
         97, 140, 103, 177, 158, 131,  22,  60, 130,   0, 192, 182, 122, 168,
         85, 187,  25,  59,   5, 151,   9,  52, 149,  76, 106, 133,  83, 172,
        122,  38, 170, 174, 197,  35,  10,  51,   3,  97, 133, 199,  89,  38,
        137,  64, 191,  69,  63, 127, 103,  41, 117,  49, 120, 144,  87, 150,
        132,   0])
DESIRED: (shape=torch.Size([1140851, 10]), dtype=torch.int64)
First 100 elements: tensor([102, 129,  41,  95,  45,  49,  43, 135, 170,  46,  15,   1,  19,  51,
        132,  87,  61,  16,  14,  72,  63,  14,  80, 136, 158,  51, 191, 141,
        108, 179,  69, 138,  98, 109, 124,  91, 109,  50, 174, 108, 194,  23,
         97, 140, 103, 177, 158, 131,  22,  60, 130,   0, 192, 182, 122, 168,
         85, 187,  25,  59,   5, 151,   9,  52, 149,  76, 106, 133,  83, 172,
        122,  38, 170, 174, 197,  35,  10,  51,   3,  97, 133, 199,  89,  38,
        137,  64, 191,  69,  63, 127, 103,  41, 117,  49, 120, 144,  87, 150,
        132,   0])
[Worker 1] Completed Task 1344

[Worker 1] Processing Task 1345: paddle.Tensor.kthvalue(Tensor([2, 114085069, 10],"float32"), k=200, axis=1, )
element 1 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.kthvalue(Tensor([2, 114085069, 10],"float32"), k=200, axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 20 (10.0%)
Greatest absolute difference: 38783972 at index (0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.6640923619270325 at index (0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 10]), dtype=torch.int64)
All elements: tensor([ 40681594,  30662692,  51507276, 110303455,  89416046, 108159056,
         38498378,   2266441, 104711776,  30056612,  51632592,  80814401,
         34433088,  26962051, 102787328,  66404492,  76831901,  83848389,
        112251960,  60854285])
DESIRED: (shape=torch.Size([2, 10]), dtype=torch.int64)
All elements: tensor([ 79465566,  30662692,  51507276, 110303455,  53732623, 108159056,
         38498378,   2266441, 104711776,  30056612,  51949953,  80814401,
         34433088,  26962051, 102787328,  66404492,  76831901,  83848389,
        112251960,  60854285])
[Worker 1] Completed Task 1345

[Worker 1] Processing Task 1348: paddle.Tensor.lerp(x=Tensor([2281701379],"float32"), y=Tensor([2281701379],"float32"), weight=0.5, )
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([2281701379],"float32"), y=Tensor([2281701379],"float32"), weight=0.5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2189516722 / 2281701379 (96.0%)
Greatest absolute difference: 0.25 at index (21999813,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([-0.0679,  0.1388, -0.0120, -0.1327,  0.0025, -0.1624,  0.0223,  0.1640,
        -0.0329, -0.0007,  0.1081, -0.0222, -0.2168,  0.1835, -0.0219, -0.0763,
         0.0431,  0.0456,  0.1204, -0.0344, -0.2434, -0.2222, -0.1661, -0.0179,
        -0.1413, -0.1522,  0.2274, -0.1688, -0.1109, -0.0021,  0.1259, -0.2406,
        -0.1645, -0.1067,  0.1148, -0.1359,  0.1123,  0.0831, -0.1517, -0.2394,
        -0.1318, -0.0630, -0.1170,  0.2358, -0.0450, -0.0502,  0.2168,  0.1910,
        -0.0199,  0.1241,  0.0936,  0.0619,  0.2480,  0.1268, -0.1452, -0.1023,
        -0.0511, -0.2033,  0.1943,  0.0112, -0.0921,  0.2094,  0.0596,  0.1126,
         0.1117, -0.1850, -0.2076,  0.1794, -0.0659, -0.1367, -0.1942, -0.0925,
         0.0362,  0.0030,  0.0066,  0.0010,  0.0778, -0.2079, -0.1828,  0.1896,
        -0.1468, -0.1780, -0.1667,  0.1022, -0.1699,  0.2293, -0.0315,  0.0847,
         0.1055, -0.1171,  0.1928,  0.1646,  0.0719,  0.1225,  0.0063, -0.1758,
         0.0756, -0.1686, -0.2176,  0.2003])
[Worker 1] Completed Task 1348

[Worker 1] Processing Task 1352: paddle.Tensor.lerp(x=Tensor([4, 5, 214748365],"float16"), y=Tensor([4, 5, 214748365],"float16"), weight=0.5, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.66 GiB is free. Process 114798 has 76.52 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 1352: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.66 GiB is free. Process 114798 has 76.52 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 1352: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.66 GiB is free. Process 114798 has 76.52 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 1355: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 53687092],"float16"), y=Tensor([4, 5, 4, 53687092],"float16"), weight=1.0, )
W0522 19:25:48.043900 47095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:25:48.045336 47095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 5, 4, 53687092],"float16"), y=Tensor([4, 5, 4, 53687092],"float16"), weight=1.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208159058 / 4294967360 (98.0%)
Greatest absolute difference: 0.5 at index (0, 0, 0, 1202) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 64) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 5, 4, 53687092]), dtype=torch.float16)
First 100 elements: tensor([ 0.3147, -0.2898, -0.2268, -0.4675,  0.1069,  0.2355,  0.2708,  0.1852,
        -0.1299, -0.4121,  0.4387, -0.3640,  0.4331,  0.3867, -0.3389, -0.3638,
         0.2238,  0.0437,  0.3884, -0.1289, -0.3113, -0.1266,  0.3579,  0.1477,
         0.0149, -0.2573, -0.1315,  0.4219,  0.0279,  0.2512, -0.0524, -0.1401,
        -0.0991,  0.3147, -0.0609,  0.3372,  0.1333,  0.1718,  0.4319,  0.4675,
        -0.0831,  0.1880,  0.1348, -0.2551, -0.2100,  0.1699, -0.1054,  0.2776,
        -0.3999, -0.4026,  0.2413,  0.2571,  0.2037, -0.1185,  0.3865, -0.0903,
         0.3679, -0.4839, -0.1476,  0.0994, -0.3835,  0.3567, -0.3760,  0.0817,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 5, 4, 53687092]), dtype=torch.float16)
First 100 elements: tensor([ 0.3147, -0.2898, -0.2268, -0.4675,  0.1069,  0.2355,  0.2708,  0.1852,
        -0.1299, -0.4121,  0.4387, -0.3640,  0.4331,  0.3867, -0.3389, -0.3638,
         0.2238,  0.0437,  0.3884, -0.1289, -0.3113, -0.1266,  0.3579,  0.1477,
         0.0149, -0.2573, -0.1315,  0.4219,  0.0279,  0.2512, -0.0524, -0.1401,
        -0.0991,  0.3147, -0.0609,  0.3372,  0.1333,  0.1718,  0.4319,  0.4675,
        -0.0831,  0.1880,  0.1348, -0.2551, -0.2100,  0.1699, -0.1054,  0.2776,
        -0.3999, -0.4026,  0.2413,  0.2571,  0.2037, -0.1185,  0.3865, -0.0903,
         0.3679, -0.4839, -0.1476,  0.0994, -0.3835,  0.3567, -0.3760,  0.0817,
         0.1210,  0.2043, -0.3284, -0.1584,  0.1755, -0.3975,  0.1222, -0.1429,
         0.1053,  0.2327,  0.0413,  0.4729, -0.3848,  0.0376, -0.0315,  0.2937,
        -0.3115, -0.2756,  0.0544,  0.1287,  0.3325,  0.1735,  0.1616, -0.2576,
         0.2820, -0.0703,  0.1138,  0.3027, -0.2198, -0.0961,  0.2120, -0.3660,
         0.2081, -0.2810,  0.4612,  0.1586], dtype=torch.float16)
[Worker 1] Completed Task 1355

[Worker 1] Processing Task 1362: paddle.Tensor.lerp(x=Tensor([4294967297],"float16"), y=Tensor([4294967297],"float16"), weight=0.5, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 23228 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 1362: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 23228 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 1362: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 23228 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 1363: paddle.Tensor.lerp(x=Tensor([71582789, 5, 4, 3],"float16"), y=Tensor([71582789, 5, 4, 3],"float16"), weight=0.0, )
W0522 19:28:35.550130 47513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:28:35.551167 47513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([71582789, 5, 4, 3],"float16"), y=Tensor([71582789, 5, 4, 3],"float16"), weight=0.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208175691 / 4294967340 (98.0%)
Greatest absolute difference: 0.5 at index (47, 2, 3, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 3, 2, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([71582789, 5, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.0472,  0.0704, -0.4299, -0.1965, -0.2092, -0.0293, -0.3242,  0.4133,
        -0.2019, -0.2366,  0.0164, -0.1538, -0.4873,  0.2913,  0.0851,  0.4060,
         0.1730,  0.3147, -0.4136, -0.1519, -0.2524, -0.4763, -0.4763, -0.4880,
        -0.2993, -0.1472, -0.2710, -0.3691,  0.1411,  0.4929,  0.4824, -0.3945,
        -0.0378,  0.0013,  0.4236, -0.2130,  0.3757,  0.2834,  0.4858,  0.2688,
        -0.4392, -0.1036, -0.1731,  0.0119,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([71582789, 5, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.0472,  0.0704, -0.4299, -0.1965, -0.2092, -0.0293, -0.3242,  0.4133,
        -0.2019, -0.2366,  0.0164, -0.1538, -0.4873,  0.2913,  0.0851,  0.4060,
         0.1730,  0.3147, -0.4136, -0.1519, -0.2524, -0.4763, -0.4763, -0.4880,
        -0.2993, -0.1472, -0.2710, -0.3691,  0.1411,  0.4929,  0.4824, -0.3945,
        -0.0378,  0.0013,  0.4236, -0.2130,  0.3757,  0.2834,  0.4858,  0.2688,
        -0.4392, -0.1036, -0.1731,  0.0119, -0.4365, -0.3699,  0.3311,  0.2622,
        -0.1610, -0.4016,  0.1730, -0.1569, -0.0163,  0.2544, -0.0422,  0.0150,
         0.4204, -0.4529,  0.2267, -0.3896,  0.3203, -0.1755, -0.2871,  0.1771,
        -0.1173,  0.1219, -0.3657, -0.2783, -0.2042, -0.3062,  0.2773, -0.2742,
        -0.2125,  0.1525, -0.4465,  0.1362, -0.3467, -0.1187,  0.3013, -0.1925,
         0.2445, -0.0411, -0.3208,  0.4219,  0.1890, -0.4592, -0.0502,  0.0427,
         0.3687, -0.0417, -0.2573, -0.3167, -0.1959,  0.2881,  0.0666,  0.4670,
        -0.3650,  0.4814, -0.4614,  0.4973], dtype=torch.float16)
[Worker 1] Completed Task 1363

[Worker 1] Processing Task 1368: paddle.Tensor.logit(x=Tensor([143165577, 3, 2, 5],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([143165577, 3, 2, 5],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147494827 / 4294967310 (50.0%)
Greatest absolute difference: nan at index (0, 0, 0, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([143165577, 3, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([  1.9297,  -1.7754,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          3.3848,   6.6875,   0.0000,  -4.2539,   0.0000,  -0.7095,   0.1067,
          0.0000,   0.0000,   1.5605,   0.0000,   0.0000,  -1.6367,   0.0000,
         -0.7871,   0.0000,   9.1719,  -0.1814,   0.1642,   1.9570,   0.0000,
          0.9214,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  -0.5044,
          0.6426,  -2.8906,  -7.9766,  -1.4473,  -1.3516,   0.0000,  -2.6309,
          0.0000,   2.4160,  -8.4844,   0.0000,  -1.4043,   0.0000,   1.4189,
         -0.7905,   0.0000,  -0.8057,  -2.4219,   0.0000,   0.7720,   0.0000,
         -1.1025,   0.0000,   1.5303,  -0.1688,   0.0000,  -3.4395,  -0.9697,
          0.0000,   0.4443,  28.9219,  -2.3516,  20.4062,  -1.8477,   4.3203,
          2.6875,  -0.0980,  -2.5703,   0.0000,   0.0000,   1.9775,   6.9844,
          0.0000,   0.0000,   1.7686,   0.0000,   0.0000,  -0.5000,   2.2129,
          0.0000,  -1.4971,   0.0000,  -1.3027,   0.0000,   6.6250,  -0.3284,
          0.0000,  -1.0166,   1.4854, -18.5000,   0.0000,   2.4023,   0.0000,
          0.0000,   0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([143165577, 3, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([  1.9297,  -1.7754,      nan,      nan,      nan,      nan,      nan,
          3.3848,   6.6875,      nan,  -4.2539,      nan,  -0.7095,   0.1067,
             nan,      nan,   1.5605,      nan,      nan,  -1.6367,      nan,
         -0.7871,      nan,   9.1719,  -0.1814,   0.1642,   1.9570,      nan,
          0.9214,      nan,      nan,      nan,      nan,      nan,  -0.5044,
          0.6426,  -2.8906,  -7.9766,  -1.4473,  -1.3516,      nan,  -2.6309,
             nan,   2.4160,  -8.4844,      nan,  -1.4043,      nan,   1.4189,
         -0.7905,      nan,  -0.8057,  -2.4219,      nan,   0.7720,      nan,
         -1.1025,      nan,   1.5303,  -0.1688,      nan,  -3.4395,  -0.9697,
             nan,   0.4443,  28.9219,  -2.3516,  20.4062,  -1.8477,   4.3203,
          2.6875,  -0.0980,  -2.5703,      nan,      nan,   1.9775,   6.9844,
             nan,      nan,   1.7686,      nan,      nan,  -0.5000,   2.2129,
             nan,  -1.4971,      nan,  -1.3027,      nan,   6.6250,  -0.3284,
             nan,  -1.0166,   1.4854, -18.5000,      nan,   2.4023,      nan,
             nan,      nan], dtype=torch.float16)
[Worker 1] Completed Task 1368

[Worker 1] Processing Task 1370: paddle.Tensor.logit(x=Tensor([2281701379],"float32"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([2281701379],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1140850884 / 2281701379 (50.0%)
Greatest absolute difference: nan at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 0.0000,  0.0682,  2.4485, -0.1556,  0.9724, -2.3423,  0.0000,  0.0000,
         0.0000, 19.9571, -0.3783,  0.0000, -2.7999,  0.8808,  0.0000,  0.0000,
        -3.5746,  0.0000,  0.0000, -2.1752,  0.0000,  0.3180, -9.3697,  0.0000,
         0.0000,  0.5426, -9.4575,  0.0000,  1.2716,  1.8750,  0.0000, -7.7493,
         1.0355,  0.0000,  0.0000, -0.3898,  0.0000,  1.7906,  0.0000, 20.2882,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.9068,  0.0000, -1.3221,
         0.0000, -1.5631, -0.3617,  2.0617,  1.1141,  0.9206, -0.0875, -1.9478,
        -0.8674,  0.0000,  2.7342, -0.7534,  0.0000,  0.0000,  3.2742,  0.0000,
         0.0000,  0.0000, -0.4920, -7.1423,  1.0329,  0.0000,  0.0000, -0.3028,
        -6.9036,  0.8153, -0.8886, -0.3100,  0.4031,  0.0000,  0.0000,  0.9780,
         0.0000,  0.0000,  0.0000, -0.3384,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  1.8926,  0.0000,  1.2588,  1.5466,  0.0000,
         0.0000,  0.0000,  0.0000,  1.6374])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([    nan,  0.0682,  2.4485, -0.1556,  0.9724, -2.3423,     nan,     nan,
            nan, 19.9571, -0.3783,     nan, -2.7999,  0.8808,     nan,     nan,
        -3.5746,     nan,     nan, -2.1752,     nan,  0.3180, -9.3697,     nan,
            nan,  0.5426, -9.4575,     nan,  1.2716,  1.8750,     nan, -7.7493,
         1.0355,     nan,     nan, -0.3898,     nan,  1.7906,     nan, 20.2882,
            nan,     nan,     nan,     nan,     nan,  0.9068,     nan, -1.3221,
            nan, -1.5631, -0.3617,  2.0617,  1.1141,  0.9206, -0.0875, -1.9478,
        -0.8674,     nan,  2.7342, -0.7534,     nan,     nan,  3.2742,     nan,
            nan,     nan, -0.4920, -7.1423,  1.0329,     nan,     nan, -0.3028,
        -6.9036,  0.8153, -0.8886, -0.3100,  0.4031,     nan,     nan,  0.9780,
            nan,     nan,     nan, -0.3384,     nan,     nan,     nan,     nan,
            nan,     nan,     nan,  1.8926,     nan,  1.2588,  1.5466,     nan,
            nan,     nan,     nan,  1.6374])
[Worker 1] Completed Task 1370

[Worker 1] Processing Task 1377: paddle.Tensor.logit(x=Tensor([4294967297],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([4294967297],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147494819 / 4294967297 (50.0%)
Greatest absolute difference: nan at index (2,) (up to 0.01 allowed)
Greatest relative difference: nan at index (2,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([  0.0476,  -1.9639,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          2.0664,  -2.1602,   0.0000,   2.4648,   0.0000,   0.0616,   3.7656,
          0.0000,   0.0000,  -1.8369,   0.0000,   0.0000,  -1.1699,   0.0000,
         -0.5884,   0.0000, -13.1875,  -1.1963,  -2.2324,  -1.4248,   0.0000,
         -1.1143,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  -0.5098,
          1.5869,  -1.5215,   7.0078,  -0.2913,  -1.4160,   0.0000,   1.8135,
          0.0000,  -0.7959,   0.8115,   0.0000,  -0.1689,   0.0000,  -1.4912,
         -0.8042,   0.0000,   1.3057,   3.5273,   0.0000,   1.9668,   0.0000,
         10.9141,   0.0000,  -0.0866,  -1.3711,   0.0000,   3.4023,   2.4062,
          0.0000,  -1.3047, -12.9688,   2.7812, -11.7109,  -1.1211,  -0.6831,
          1.4434,   0.0679,  -2.2852,   0.0000,   0.0000,   1.2676,   1.1475,
          0.0000,   0.0000,  -0.9331,   0.0000,   0.0000,   0.7090,   2.5527,
          0.0000,  -0.8862,   0.0000,  -1.4561,   0.0000,   9.8047,  -0.0265,
          0.0000,  -0.7300,  -0.9878,  11.0703,   0.0000,  -1.0791,   0.0000,
          0.0000,   0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([  0.0476,  -1.9639,      nan,      nan,      nan,      nan,      nan,
          2.0664,  -2.1602,      nan,   2.4648,      nan,   0.0616,   3.7656,
             nan,      nan,  -1.8369,      nan,      nan,  -1.1699,      nan,
         -0.5884,      nan, -13.1875,  -1.1963,  -2.2324,  -1.4248,      nan,
         -1.1143,      nan,      nan,      nan,      nan,      nan,  -0.5098,
          1.5869,  -1.5215,   7.0078,  -0.2913,  -1.4160,      nan,   1.8135,
             nan,  -0.7959,   0.8115,      nan,  -0.1689,      nan,  -1.4912,
         -0.8042,      nan,   1.3057,   3.5273,      nan,   1.9668,      nan,
         10.9141,      nan,  -0.0866,  -1.3711,      nan,   3.4023,   2.4062,
             nan,  -1.3047, -12.9688,   2.7812, -11.7109,  -1.1211,  -0.6831,
          1.4434,   0.0679,  -2.2852,      nan,      nan,   1.2676,   1.1475,
             nan,      nan,  -0.9331,      nan,      nan,   0.7090,   2.5527,
             nan,  -0.8862,      nan,  -1.4561,      nan,   9.8047,  -0.0265,
             nan,  -0.7300,  -0.9878,  11.0703,      nan,  -1.0791,      nan,
             nan,      nan], dtype=torch.float16)
[Worker 1] Completed Task 1377

[Worker 1] Processing Task 1381: paddle.Tensor.repeat_interleave(Tensor([2, 1140850690],"int64"), 2, axis=0, )
cannot reshape array of size 4300000000 into shape (4,1140850690)
[accuracy error] paddle.Tensor.repeat_interleave(Tensor([2, 1140850690],"int64"), 2, axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 268433515 / 4563402760 (5.9%)
Greatest absolute difference: 65535 at index (3, 872462969) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (3, 872415226) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 1140850690]), dtype=torch.int64)
First 100 elements: tensor([ 64291, -26323,  -8961, -63464, -34458,  -7745, -23874, -23358,  14645,
        -54466,  -8716,  59138,  51919,  21518,  27971, -54411, -39511,  17566,
        -27016, -22005, -27948, -46215, -36854, -30639,  14626,  -7281, -32185,
         19629,  14516, -43374,  57786, -31009, -46285,  45190,   6315, -13476,
          4063, -18803,  27377,  48207,  -6101, -53084,  13108, -49307,  49300,
         40175, -34009,  17458, -52064, -18055,  30904,   6175,  52508,  34117,
         -9801, -63177,  44868,   7988, -62672, -24824,  22141,  15914, -29353,
         -9642,   3693,  -3266, -37482, -54244, -25104, -19474, -57350,  31801,
        -63026, -24841, -58601,  60814,  32227, -44602,  49066,  -4544,    857,
        -54297,  -6981, -41824,  65292,   9977,  33901, -48541,  31385,  35967,
          3088,  34773, -38951, -50175,  34985,  16156,  21075,  58483,  52129,
        -32129])
DESIRED: (shape=torch.Size([4, 1140850690]), dtype=torch.int64)
First 100 elements: tensor([ 64291, -26323,  -8961, -63464, -34458,  -7745, -23874, -23358,  14645,
        -54466,  -8716,  59138,  51919,  21518,  27971, -54411, -39511,  17566,
        -27016, -22005, -27948, -46215, -36854, -30639,  14626,  -7281, -32185,
         19629,  14516, -43374,  57786, -31009, -46285,  45190,   6315, -13476,
          4063, -18803,  27377,  48207,  -6101, -53084,  13108, -49307,  49300,
         40175, -34009,  17458, -52064, -18055,  30904,   6175,  52508,  34117,
         -9801, -63177,  44868,   7988, -62672, -24824,  22141,  15914, -29353,
         -9642,   3693,  -3266, -37482, -54244, -25104, -19474, -57350,  31801,
        -63026, -24841, -58601,  60814,  32227, -44602,  49066,  -4544,    857,
        -54297,  -6981, -41824,  65292,   9977,  33901, -48541,  31385,  35967,
          3088,  34773, -38951, -50175,  34985,  16156,  21075,  58483,  52129,
        -32129])
[Worker 1] Completed Task 1381

[Worker 1] Processing Task 1383: paddle.Tensor.repeat_interleave(Tensor([22817014, 1, 10, 10],"int64"), 2, axis=0, )
[torch error] paddle.Tensor.repeat_interleave(Tensor([22817014, 1, 10, 10],"int64"), 2, axis=0, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 57, in test
    if not self.gen_torch_input():
  File "/luozeyu01_api_test/PaddleAPITest/tester/base.py", line 764, in gen_torch_input
    self.torch_kwargs[key] = arg_config.get_torch_tensor(self.api_config)
  File "/luozeyu01_api_test/PaddleAPITest/tester/api_config/config_analyzer.py", line 1804, in get_torch_tensor
    self.torch_tensor = torch.tensor(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 48702 has 69.61 GiB memory in use. Of the allocated memory 17.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1383

[Worker 1] Processing Task 1384: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,1,3,2,],list[1,3,0,2,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,1,3,2,],list[1,3,0,2,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1384

[Worker 1] Processing Task 1385: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,1,3,2,],list[2,3,0,1,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,1,3,2,],list[2,3,0,1,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1385

[Worker 1] Processing Task 1386: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,2,3,],list[0,1,2,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,2,3,],list[0,1,2,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1386

[Worker 1] Processing Task 1387: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,3,1,2,],list[3,2,1,0,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[0,3,1,2,],list[3,2,1,0,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1387

[Worker 1] Processing Task 1388: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,0,2,3,],list[3,0,1,2,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,0,2,3,],list[3,0,1,2,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1388

[Worker 1] Processing Task 1389: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,0,3,],list[2,3,0,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,0,3,],list[2,3,0,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1389

[Worker 1] Processing Task 1390: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,0,3,2,],list[2,3,0,1,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,0,3,2,],list[2,3,0,1,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1390

[Worker 1] Processing Task 1391: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,2,0,3,],list[0,2,1,3,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,2,0,3,],list[0,2,1,3,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1391

[Worker 1] Processing Task 1392: paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,2,3,0,],list[1,3,0,2,],], )
[torch error] paddle.tensordot(Tensor([1, 1, 1, 4294967297],"float16"), Tensor([1, 5, 1, 1],"float16"), list[list[1,2,3,0,],list[1,3,0,2,],], )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1320, in tensordot
    return handle_torch_function(tensordot, (a, b), a, b, dims=dims, out=out)
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/functional.py", line 1360, in tensordot
    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.57 GiB is free. Process 48702 has 77.61 GiB memory in use. Of the allocated memory 25.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 1392

[Worker 1] Processing Task 1496: paddle.tensordot(Tensor([1, 1, 1, 5],"float16"), Tensor([1, 5, 858993460, 1],"float16"), list[list[2,3,0,],list[3,1,0,],], )
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 1, 5],"float16"), Tensor([1, 5, 858993460, 1],"float16"), list[list[2,3,0,],list[3,1,0,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 4294967300 (0.0%)
Greatest absolute difference: 0.0161285400390625 at index (0, 4, 858993459, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 4, 858993457, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 5, 858993460, 1]), dtype=torch.float16)
First 100 elements: tensor([-0.1053, -0.0090,  0.0607,  0.2067,  0.1595, -0.1003,  0.0705, -0.1926,
         0.2172, -0.0841, -0.2025, -0.1198,  0.2004, -0.0275, -0.0145, -0.1009,
         0.2142,  0.0701, -0.0949, -0.1368, -0.0645, -0.0489, -0.1015,  0.0843,
         0.0210,  0.1096,  0.0963,  0.0908, -0.1260, -0.0823,  0.0803,  0.1282,
        -0.1009,  0.1208,  0.2252, -0.2079, -0.1251,  0.1960,  0.1702, -0.2335,
         0.1219,  0.1852,  0.0407,  0.1079,  0.1301, -0.0692,  0.1748,  0.1299,
         0.2285,  0.1686, -0.0030,  0.1792, -0.1090,  0.0593,  0.0990, -0.0140,
        -0.1853,  0.2054,  0.1840, -0.0347, -0.0028, -0.0263,  0.0514,  0.1076,
         0.2401, -0.0669, -0.1171, -0.1530, -0.0542, -0.0779, -0.2039, -0.1785,
         0.1700,  0.0603, -0.0421, -0.2278,  0.0177, -0.0737,  0.1304, -0.0377,
         0.1282,  0.2039, -0.0923, -0.0646,  0.0619,  0.0528,  0.1255, -0.2017,
         0.2025,  0.1140,  0.0117, -0.1310, -0.0047,  0.1037,  0.0668, -0.0141,
        -0.1532,  0.1272,  0.1133,  0.1786], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 5, 858993460, 1]), dtype=torch.float16)
First 100 elements: tensor([-0.1053, -0.0090,  0.0607,  0.2067,  0.1595, -0.1003,  0.0705, -0.1926,
         0.2172, -0.0841, -0.2025, -0.1198,  0.2004, -0.0275, -0.0145, -0.1009,
         0.2142,  0.0701, -0.0949, -0.1368, -0.0645, -0.0489, -0.1015,  0.0843,
         0.0210,  0.1096,  0.0963,  0.0908, -0.1260, -0.0823,  0.0803,  0.1282,
        -0.1009,  0.1208,  0.2252, -0.2079, -0.1251,  0.1960,  0.1702, -0.2335,
         0.1219,  0.1852,  0.0407,  0.1079,  0.1301, -0.0692,  0.1748,  0.1299,
         0.2285,  0.1686, -0.0030,  0.1792, -0.1090,  0.0593,  0.0990, -0.0140,
        -0.1853,  0.2054,  0.1840, -0.0347, -0.0028, -0.0263,  0.0514,  0.1076,
         0.2401, -0.0669, -0.1171, -0.1530, -0.0542, -0.0779, -0.2039, -0.1785,
         0.1700,  0.0603, -0.0421, -0.2278,  0.0177, -0.0737,  0.1304, -0.0377,
         0.1282,  0.2039, -0.0923, -0.0646,  0.0619,  0.0528,  0.1255, -0.2017,
         0.2025,  0.1140,  0.0117, -0.1310, -0.0047,  0.1037,  0.0668, -0.0141,
        -0.1532,  0.1272,  0.1133,  0.1786], dtype=torch.float16)
[Worker 1] Completed Task 1496

[Worker 1] Processing Task 1530: paddle.tensordot(Tensor([1, 1, 1, 5],"float16"), Tensor([858993460, 5, 1, 1],"float16"), list[list[3,1,2,],list[1,3,2,],], )
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 1658: paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([171798692, 1, 1, 1],"float16"), list[list[3,0,],list[2,1,],], )
[accuracy error] backward  paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([171798692, 1, 1, 1],"float16"), list[list[3,0,],list[2,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 109126 / 171798692 (0.1%)
Greatest absolute difference: 0.12890625 at index (12868839, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (82270096, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([171798692, 1, 1, 1]), dtype=torch.float16)
First 100 elements: tensor([  -532.0000, -11664.0000,   -139.5000, -11344.0000,  -6552.0000,
        -13344.0000,    680.0000,   -865.5000, -11368.0000,  -8256.0000,
          6232.0000,  -4024.0000,   6004.0000,  -2238.0000,   4584.0000,
         11464.0000,  18080.0000,  -4312.0000, -11744.0000,   1956.0000,
          2028.0000,   4018.0000,  -1664.0000,   -378.2500,   3564.0000,
         14712.0000,   1274.0000,  11936.0000, -12368.0000,  -9400.0000,
          2162.0000,   3720.0000,  -2026.0000,   6048.0000,  -8352.0000,
         -5052.0000,  -5372.0000,   7876.0000, -10128.0000,  -1261.0000,
         10576.0000, -11320.0000,   2178.0000,  -1442.0000,   4608.0000,
         -1901.0000,  -7076.0000, -16864.0000,  -8720.0000,  -7972.0000,
         -5488.0000,    385.5000,   4592.0000,   2652.0000,  -1277.0000,
         -2594.0000,  -1463.0000,   1939.0000,  -5016.0000, -12496.0000,
         -7892.0000,   2040.0000,  -6376.0000,    400.2500,    204.0000,
         11400.0000,  -2778.0000,  12752.0000,  -3914.0000,  -5724.0000,
         -3232.0000,  -4320.0000,  -1663.0000,  -8624.0000,  -3994.0000,
           -55.4062,  -7540.0000,    810.5000,   5216.0000,   2306.0000,
         -1431.0000, -11896.0000,   4696.0000,  -7148.0000,  -3682.0000,
         -1239.0000,   2168.0000, -10368.0000,   4188.0000,   7948.0000,
         -1962.0000,   3238.0000,   2356.0000,  -1825.0000,  -2326.0000,
          6712.0000,  10928.0000,  13904.0000,  10120.0000,   2694.0000],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([171798692, 1, 1, 1]), dtype=torch.float16)
First 100 elements: tensor([  -532.0000, -11664.0000,   -139.6250, -11344.0000,  -6552.0000,
        -13344.0000,    680.0000,   -865.5000, -11368.0000,  -8256.0000,
          6232.0000,  -4024.0000,   6004.0000,  -2238.0000,   4584.0000,
         11464.0000,  18080.0000,  -4312.0000, -11744.0000,   1956.0000,
          2028.0000,   4018.0000,  -1664.0000,   -378.2500,   3564.0000,
         14712.0000,   1274.0000,  11936.0000, -12368.0000,  -9400.0000,
          2162.0000,   3720.0000,  -2026.0000,   6048.0000,  -8352.0000,
         -5052.0000,  -5372.0000,   7876.0000, -10128.0000,  -1261.0000,
         10576.0000, -11320.0000,   2178.0000,  -1442.0000,   4608.0000,
         -1901.0000,  -7076.0000, -16864.0000,  -8712.0000,  -7972.0000,
         -5488.0000,    385.7500,   4592.0000,   2652.0000,  -1277.0000,
         -2594.0000,  -1464.0000,   1939.0000,  -5016.0000, -12496.0000,
         -7896.0000,   2040.0000,  -6376.0000,    400.2500,    204.1250,
         11400.0000,  -2778.0000,  12752.0000,  -3914.0000,  -5724.0000,
         -3232.0000,  -4320.0000,  -1663.0000,  -8624.0000,  -3994.0000,
           -55.4688,  -7540.0000,    810.5000,   5216.0000,   2306.0000,
         -1431.0000, -11896.0000,   4696.0000,  -7148.0000,  -3682.0000,
         -1239.0000,   2168.0000, -10368.0000,   4184.0000,   7948.0000,
         -1962.0000,   3238.0000,   2356.0000,  -1825.0000,  -2326.0000,
          6712.0000,  10928.0000,  13904.0000,  10120.0000,   2694.0000],
       dtype=torch.float16)
[Worker 1] Completed Task 1658

[Worker 1] Processing Task 1669: paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([171798692, 5, 1, 5],"float16"), list[list[2,3,0,],list[1,2,0,],], )
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 1769: paddle.tensordot(Tensor([5, 171798692, 5, 1],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[0,2,3,],list[0,1,2,],], )
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 1780: paddle.tensordot(Tensor([5, 171798692, 5, 1],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[3,2,0,],list[2,1,0,],], )
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
W0522 22:09:36.438509 49282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 22:09:36.439499 49282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 1947: paddle.tensordot(Tensor([5, 5, 5, 1],"float16"), Tensor([5, 5, 1, 171798692],"float16"), list[list[3,2,0,],list[2,1,0,],], )
[accuracy error] paddle.tensordot(Tensor([5, 5, 5, 1],"float16"), Tensor([5, 5, 1, 171798692],"float16"), list[list[3,2,0,],list[2,1,0,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 11 / 858993460 (0.0%)
Greatest absolute difference: 0.0838623046875 at index (3, 171798688) (up to 0.01 allowed)
Greatest relative difference: 3.06640625 at index (4, 171798688) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 171798692]), dtype=torch.float16)
First 100 elements: tensor([ 5.0049e-01,  1.1914e-01, -5.8154e-01, -2.4121e-01, -6.6797e-01,
         3.2593e-01, -1.1270e+00, -3.3911e-01, -1.4807e-01, -4.9829e-01,
        -3.5425e-01,  1.5894e-01, -3.7134e-01,  1.4832e-01, -6.4502e-01,
        -2.0493e-02, -6.0400e-01, -1.2744e-01,  2.1692e-01, -2.5439e-01,
        -7.0020e-01,  1.7847e-01,  2.4512e-01,  7.4512e-01, -3.9404e-01,
         2.3743e-02,  4.1919e-01,  3.9624e-01,  4.8804e-01,  3.9697e-01,
        -1.0193e-01, -9.7168e-02, -5.2344e-01,  2.7515e-01,  4.0601e-01,
        -5.2246e-01, -4.7058e-02, -2.0593e-01, -3.6896e-02, -3.8501e-01,
         5.7220e-02, -6.5967e-01,  3.7012e-01, -2.0911e-01, -3.2910e-01,
         4.4336e-01, -6.1920e-02, -3.9380e-01,  4.0723e-01,  5.1056e-02,
        -4.8389e-01,  2.9565e-01,  4.6204e-02,  3.9673e-01, -9.9805e-01,
         4.1821e-01, -2.8589e-01, -2.6855e-01,  3.4424e-01, -5.7129e-01,
        -5.2734e-01,  8.4375e-01, -3.1372e-02,  4.2847e-01, -7.7667e-03,
        -4.0234e-01,  1.8723e-02, -1.6663e-01,  2.8244e-02,  9.5520e-02,
         4.2432e-01, -2.5073e-01,  4.9658e-01, -6.8848e-02, -2.3608e-01,
        -6.0547e-01,  2.8564e-01,  3.7329e-01, -5.3809e-01, -1.3574e-01,
         2.2900e-01,  4.7192e-01,  3.9575e-01,  7.8583e-04,  8.1116e-02,
         1.2988e-01, -2.4023e-01,  9.0027e-02, -6.3135e-01,  1.5454e-01,
        -3.0420e-01,  2.2913e-01, -7.9834e-01,  2.3157e-01, -1.1957e-01,
         7.7100e-01,  1.2421e-01,  3.4155e-01,  8.6304e-02, -3.9233e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 171798692]), dtype=torch.float16)
First 100 elements: tensor([ 5.0049e-01,  1.1914e-01, -5.8154e-01, -2.4121e-01, -6.6797e-01,
         3.2593e-01, -1.1270e+00, -3.3911e-01, -1.4807e-01, -4.9829e-01,
        -3.5425e-01,  1.5894e-01, -3.7134e-01,  1.4832e-01, -6.4502e-01,
        -2.0493e-02, -6.0400e-01, -1.2744e-01,  2.1692e-01, -2.5439e-01,
        -7.0020e-01,  1.7847e-01,  2.4512e-01,  7.4512e-01, -3.9404e-01,
         2.3743e-02,  4.1919e-01,  3.9624e-01,  4.8804e-01,  3.9697e-01,
        -1.0193e-01, -9.7168e-02, -5.2344e-01,  2.7515e-01,  4.0601e-01,
        -5.2246e-01, -4.7058e-02, -2.0593e-01, -3.6896e-02, -3.8501e-01,
         5.7220e-02, -6.5967e-01,  3.7012e-01, -2.0911e-01, -3.2910e-01,
         4.4336e-01, -6.1920e-02, -3.9380e-01,  4.0723e-01,  5.1056e-02,
        -4.8389e-01,  2.9565e-01,  4.6204e-02,  3.9673e-01, -9.9805e-01,
         4.1821e-01, -2.8589e-01, -2.6855e-01,  3.4424e-01, -5.7129e-01,
        -5.2734e-01,  8.4375e-01, -3.1372e-02,  4.2847e-01, -7.7667e-03,
        -4.0234e-01,  1.8723e-02, -1.6663e-01,  2.8244e-02,  9.5520e-02,
         4.2432e-01, -2.5073e-01,  4.9658e-01, -6.8848e-02, -2.3608e-01,
        -6.0547e-01,  2.8564e-01,  3.7329e-01, -5.3809e-01, -1.3574e-01,
         2.2900e-01,  4.7192e-01,  3.9575e-01,  7.8583e-04,  8.1116e-02,
         1.2988e-01, -2.4023e-01,  9.0027e-02, -6.3135e-01,  1.5454e-01,
        -3.0420e-01,  2.2913e-01, -7.9834e-01,  2.3157e-01, -1.1957e-01,
         7.7100e-01,  1.2421e-01,  3.4155e-01,  8.6304e-02, -3.9233e-01],
       dtype=torch.float16)
[Worker 1] Completed Task 1947

[Worker 1] Processing Task 2001: paddle.tensordot(Tensor([5, 5, 5, 34359739],"float16"), Tensor([5, 5, 1, 34359739],"float16"), list[list[3,0,],list[2,1,],], )
[accuracy error] backward  paddle.tensordot(Tensor([5, 5, 5, 34359739],"float16"), Tensor([5, 5, 1, 34359739],"float16"), list[list[3,0,],list[2,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 171798695 / 4294967375 (4.0%)
Greatest absolute difference: 1.5 at index (4, 2, 4, 0) (up to 0.01 allowed)
Greatest relative difference: 0.1309814453125 at index (2, 4, 2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5, 5, 34359739]), dtype=torch.float16)
First 100 elements: tensor([1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.,
        1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539., 1539.],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 5, 5, 34359739]), dtype=torch.float16)
First 100 elements: tensor([1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.,
        1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540., 1540.],
       dtype=torch.float16)
[Worker 1] Completed Task 2001

[Worker 1] Processing Task 2010: paddle.tensordot(Tensor([5, 5, 5, 34359739],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[1,2,0,],list[1,3,2,],], )
[accuracy error] backward  paddle.tensordot(Tensor([5, 5, 5, 34359739],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[1,2,0,],list[1,3,2,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 125 (1.6%)
Greatest absolute difference: 0.28125 at index (0, 4, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.06549072265625 at index (2, 0, 0, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5, 1, 5]), dtype=torch.float16)
First 100 elements: tensor([-4.8969e+01, -1.5330e+03,  1.9530e+03, -5.5450e+02, -4.3975e+02,
         8.8550e+02,  1.2980e+03, -2.4150e+02, -1.6990e+03,  1.3525e+02,
         8.1050e+02, -4.5325e+02,  1.1320e+03,  6.5200e+02, -1.7109e+01,
         6.6050e+02, -2.4750e+01, -5.2350e+02,  9.6250e+01,  2.1620e+03,
         1.3398e+01,  1.2460e+03, -2.7260e+03,  5.0850e+02,  9.0400e+02,
        -5.6600e+02, -4.7300e+02,  8.5450e+02, -9.0450e+02, -1.8160e+03,
         4.9150e+02,  1.4720e+03, -4.9025e+02, -7.5700e+02, -4.2775e+02,
        -1.6740e+03,  7.2700e+02, -6.1000e+02,  1.1570e+03, -1.0230e+03,
         5.9600e+02, -1.4060e+03, -1.9450e+02, -2.4662e+02, -2.0560e+03,
        -2.7775e+02, -1.3740e+03, -2.2612e+02,  6.2950e+02,  2.3950e+02,
         1.0640e+03, -8.7900e+02, -2.3965e+00, -3.3656e+01, -8.0850e+02,
         1.4040e+03, -1.8920e+03,  4.8625e+01, -5.5450e+02,  2.0560e+03,
         1.7520e+03,  8.3050e+02,  5.8500e+02,  1.6560e+03,  5.0175e+02,
        -6.4000e+02,  3.0350e+02, -4.4425e+02, -1.6362e+02, -1.2731e+02,
         1.1800e+03, -2.0150e+03, -3.5950e+02, -4.5100e+02, -5.2450e+02,
        -1.9740e+03,  1.1320e+03, -9.1400e+02,  4.3688e+01,  1.6700e+03,
         1.9560e+03,  1.2740e+03, -9.2150e+02,  9.0150e+02,  3.5325e+02,
         4.1031e+01,  3.1775e+02, -7.7550e+02, -1.3925e+02,  6.6450e+02,
         9.8203e+00,  5.7050e+02,  2.6950e+02,  2.1500e+01, -2.1740e+03,
        -6.7950e+02, -9.5850e+02, -7.0900e+02,  1.0290e+03,  4.3900e+02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 5, 1, 5]), dtype=torch.float16)
First 100 elements: tensor([-4.8969e+01, -1.5330e+03,  1.9540e+03, -5.5450e+02, -4.3975e+02,
         8.8600e+02,  1.2980e+03, -2.4162e+02, -1.7000e+03,  1.3525e+02,
         8.1050e+02, -4.5350e+02,  1.1330e+03,  6.5200e+02, -1.7109e+01,
         6.6050e+02, -2.4859e+01, -5.2400e+02,  9.6250e+01,  2.1640e+03,
         1.3117e+01,  1.2460e+03, -2.7260e+03,  5.0825e+02,  9.0400e+02,
        -5.6600e+02, -4.7300e+02,  8.5450e+02, -9.0450e+02, -1.8160e+03,
         4.9175e+02,  1.4730e+03, -4.9025e+02, -7.5700e+02, -4.2775e+02,
        -1.6740e+03,  7.2700e+02, -6.1000e+02,  1.1570e+03, -1.0230e+03,
         5.9600e+02, -1.4070e+03, -1.9462e+02, -2.4662e+02, -2.0560e+03,
        -2.7750e+02, -1.3740e+03, -2.2600e+02,  6.2950e+02,  2.3950e+02,
         1.0640e+03, -8.7900e+02, -2.5645e+00, -3.3625e+01, -8.0850e+02,
         1.4050e+03, -1.8930e+03,  4.8656e+01, -5.5500e+02,  2.0560e+03,
         1.7520e+03,  8.3050e+02,  5.8500e+02,  1.6560e+03,  5.0150e+02,
        -6.4000e+02,  3.0350e+02, -4.4450e+02, -1.6350e+02, -1.2725e+02,
         1.1800e+03, -2.0150e+03, -3.5975e+02, -4.5100e+02, -5.2500e+02,
        -1.9740e+03,  1.1320e+03, -9.1400e+02,  4.3781e+01,  1.6700e+03,
         1.9560e+03,  1.2750e+03, -9.2150e+02,  9.0150e+02,  3.5325e+02,
         4.1250e+01,  3.1775e+02, -7.7600e+02, -1.3912e+02,  6.6450e+02,
         9.7656e+00,  5.7050e+02,  2.6925e+02,  2.1484e+01, -2.1740e+03,
        -6.7950e+02, -9.5850e+02, -7.0900e+02,  1.0290e+03,  4.3900e+02],
       dtype=torch.float16)
[Worker 1] Completed Task 2010

[Worker 1] Processing Task 2104: paddle.tril(Tensor([1, 2281701379, 1, 1],"float32"), )
[accuracy error] paddle.tril(Tensor([1, 2281701379, 1, 1],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 131534464 / 2281701379 (5.8%)
Greatest absolute difference: 0.5 at index (0, 2166745882, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 2147483648, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2281701379, 1, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.2050, -0.0429,  0.3110, -0.2001,  0.2285,  0.4563, -0.1840, -0.2482,
         0.0754, -0.1383, -0.4391, -0.1146, -0.3819, -0.2565,  0.0791, -0.2610,
         0.4525,  0.3049,  0.1365,  0.0591,  0.1765,  0.2657,  0.2000, -0.2699,
         0.2028,  0.4078, -0.1033,  0.1901,  0.3114,  0.3703,  0.0385,  0.4457,
         0.0401, -0.1410, -0.2730, -0.0808,  0.0670,  0.0148, -0.0091,  0.3436,
         0.4235,  0.3060,  0.4223,  0.3548,  0.4394, -0.2798,  0.2169, -0.1861,
        -0.4934,  0.4665,  0.2600, -0.3339,  0.0091,  0.1040,  0.2370,  0.2859,
         0.3132,  0.0301, -0.0129,  0.1371, -0.1924, -0.3224,  0.0573, -0.3989,
         0.3773, -0.1403, -0.4378,  0.3969,  0.1000,  0.3250, -0.1297, -0.1011,
        -0.2581, -0.2133, -0.1710,  0.1151, -0.3648,  0.4259,  0.3921, -0.2325,
         0.1031, -0.4200,  0.3223, -0.2006,  0.2879, -0.3676, -0.3376, -0.2254,
         0.3244,  0.0115, -0.1337,  0.1928,  0.3057,  0.2698, -0.0611, -0.4188,
         0.1227,  0.1652,  0.0352,  0.0569])
DESIRED: (shape=torch.Size([1, 2281701379, 1, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.2050, -0.0429,  0.3110, -0.2001,  0.2285,  0.4563, -0.1840, -0.2482,
         0.0754, -0.1383, -0.4391, -0.1146, -0.3819, -0.2565,  0.0791, -0.2610,
         0.4525,  0.3049,  0.1365,  0.0591,  0.1765,  0.2657,  0.2000, -0.2699,
         0.2028,  0.4078, -0.1033,  0.1901,  0.3114,  0.3703,  0.0385,  0.4457,
         0.0401, -0.1410, -0.2730, -0.0808,  0.0670,  0.0148, -0.0091,  0.3436,
         0.4235,  0.3060,  0.4223,  0.3548,  0.4394, -0.2798,  0.2169, -0.1861,
        -0.4934,  0.4665,  0.2600, -0.3339,  0.0091,  0.1040,  0.2370,  0.2859,
         0.3132,  0.0301, -0.0129,  0.1371, -0.1924, -0.3224,  0.0573, -0.3989,
         0.3773, -0.1403, -0.4378,  0.3969,  0.1000,  0.3250, -0.1297, -0.1011,
        -0.2581, -0.2133, -0.1710,  0.1151, -0.3648,  0.4259,  0.3921, -0.2325,
         0.1031, -0.4200,  0.3223, -0.2006,  0.2879, -0.3676, -0.3376, -0.2254,
         0.3244,  0.0115, -0.1337,  0.1928,  0.3057,  0.2698, -0.0611, -0.4188,
         0.1227,  0.1652,  0.0352,  0.0569])
[Worker 1] Completed Task 2104

[Worker 1] Processing Task 2107: paddle.tril(Tensor([2281701379, 1, 1, 1],"float32"), )
[accuracy error] paddle.tril(Tensor([2281701379, 1, 1, 1],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 131534464 / 2281701379 (5.8%)
Greatest absolute difference: 0.5 at index (2166745882, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (2147483648, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379, 1, 1, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.2050, -0.0429,  0.3110, -0.2001,  0.2285,  0.4563, -0.1840, -0.2482,
         0.0754, -0.1383, -0.4391, -0.1146, -0.3819, -0.2565,  0.0791, -0.2610,
         0.4525,  0.3049,  0.1365,  0.0591,  0.1765,  0.2657,  0.2000, -0.2699,
         0.2028,  0.4078, -0.1033,  0.1901,  0.3114,  0.3703,  0.0385,  0.4457,
         0.0401, -0.1410, -0.2730, -0.0808,  0.0670,  0.0148, -0.0091,  0.3436,
         0.4235,  0.3060,  0.4223,  0.3548,  0.4394, -0.2798,  0.2169, -0.1861,
        -0.4934,  0.4665,  0.2600, -0.3339,  0.0091,  0.1040,  0.2370,  0.2859,
         0.3132,  0.0301, -0.0129,  0.1371, -0.1924, -0.3224,  0.0573, -0.3989,
         0.3773, -0.1403, -0.4378,  0.3969,  0.1000,  0.3250, -0.1297, -0.1011,
        -0.2581, -0.2133, -0.1710,  0.1151, -0.3648,  0.4259,  0.3921, -0.2325,
         0.1031, -0.4200,  0.3223, -0.2006,  0.2879, -0.3676, -0.3376, -0.2254,
         0.3244,  0.0115, -0.1337,  0.1928,  0.3057,  0.2698, -0.0611, -0.4188,
         0.1227,  0.1652,  0.0352,  0.0569])
DESIRED: (shape=torch.Size([2281701379, 1, 1, 1]), dtype=torch.float32)
First 100 elements: tensor([ 0.2050, -0.0429,  0.3110, -0.2001,  0.2285,  0.4563, -0.1840, -0.2482,
         0.0754, -0.1383, -0.4391, -0.1146, -0.3819, -0.2565,  0.0791, -0.2610,
         0.4525,  0.3049,  0.1365,  0.0591,  0.1765,  0.2657,  0.2000, -0.2699,
         0.2028,  0.4078, -0.1033,  0.1901,  0.3114,  0.3703,  0.0385,  0.4457,
         0.0401, -0.1410, -0.2730, -0.0808,  0.0670,  0.0148, -0.0091,  0.3436,
         0.4235,  0.3060,  0.4223,  0.3548,  0.4394, -0.2798,  0.2169, -0.1861,
        -0.4934,  0.4665,  0.2600, -0.3339,  0.0091,  0.1040,  0.2370,  0.2859,
         0.3132,  0.0301, -0.0129,  0.1371, -0.1924, -0.3224,  0.0573, -0.3989,
         0.3773, -0.1403, -0.4378,  0.3969,  0.1000,  0.3250, -0.1297, -0.1011,
        -0.2581, -0.2133, -0.1710,  0.1151, -0.3648,  0.4259,  0.3921, -0.2325,
         0.1031, -0.4200,  0.3223, -0.2006,  0.2879, -0.3676, -0.3376, -0.2254,
         0.3244,  0.0115, -0.1337,  0.1928,  0.3057,  0.2698, -0.0611, -0.4188,
         0.1227,  0.1652,  0.0352,  0.0569])
[Worker 1] Completed Task 2107

[Worker 1] Processing Task 2110: paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=0, )
[accuracy error] paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1578382880 / 4294967300 (36.7%)
Greatest absolute difference: 0.5 at index (536871494, 1, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.0000, -0.4333,  0.0792, -0.1527,  0.0000, -0.0141, -0.0589,
        -0.3333,  0.0000, -0.4199,  0.4548,  0.0924,  0.0000,  0.1429, -0.3521,
         0.1592,  0.0000,  0.0456, -0.3892, -0.2903,  0.0000,  0.0822,  0.2649,
         0.4351,  0.0000, -0.4756, -0.2462,  0.0878,  0.0000,  0.0059, -0.2440,
         0.3337,  0.0000,  0.2698,  0.4404, -0.4182,  0.0000, -0.2510, -0.0153,
        -0.3420,  0.0000, -0.3923, -0.0827, -0.0847,  0.0000, -0.2817,  0.0465,
        -0.3833,  0.0000, -0.2460, -0.2148, -0.2942,  0.0000, -0.4316, -0.0526,
        -0.2236,  0.0000,  0.2742,  0.4294,  0.0307,  0.0000, -0.3176,  0.1655,
        -0.1848,  0.0000,  0.0525,  0.1547,  0.4128,  0.0000,  0.2566, -0.1710,
        -0.0595,  0.0000, -0.2009, -0.2598, -0.0305,  0.0000, -0.4915, -0.0903,
         0.0281,  0.0000,  0.2439,  0.3958,  0.3333,  0.0000,  0.3086,  0.4966,
        -0.3916,  0.0000, -0.2791,  0.4590, -0.1404,  0.0000,  0.4646,  0.1840,
        -0.1385,  0.0000,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.0000, -0.4333,  0.0792, -0.1527,  0.0000, -0.0141, -0.0589,
        -0.3333,  0.0000, -0.4199,  0.4548,  0.0924,  0.0000,  0.1429, -0.3521,
         0.1592,  0.0000,  0.0456, -0.3892, -0.2903,  0.0000,  0.0822,  0.2649,
         0.4351,  0.0000, -0.4756, -0.2462,  0.0878,  0.0000,  0.0059, -0.2440,
         0.3337,  0.0000,  0.2698,  0.4404, -0.4182,  0.0000, -0.2510, -0.0153,
        -0.3420,  0.0000, -0.3923, -0.0827, -0.0847,  0.0000, -0.2817,  0.0465,
        -0.3833,  0.0000, -0.2460, -0.2148, -0.2942,  0.0000, -0.4316, -0.0526,
        -0.2236,  0.0000,  0.2742,  0.4294,  0.0307,  0.0000, -0.3176,  0.1655,
        -0.1848,  0.0000,  0.0525,  0.1547,  0.4128,  0.0000,  0.2566, -0.1710,
        -0.0595,  0.0000, -0.2009, -0.2598, -0.0305,  0.0000, -0.4915, -0.0903,
         0.0281,  0.0000,  0.2439,  0.3958,  0.3333,  0.0000,  0.3086,  0.4966,
        -0.3916,  0.0000, -0.2791,  0.4590, -0.1404,  0.0000,  0.4646,  0.1840,
        -0.1385,  0.0000,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2110

[Worker 1] Processing Task 2113: paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=5, )
[accuracy error] paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104509965 / 4294967300 (49.0%)
Greatest absolute difference: 0.5 at index (536871494, 1, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2113

[Worker 1] Processing Task 2116: paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=-1, )
[accuracy error] paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104509960 / 4294967298 (49.0%)
Greatest absolute difference: 0.5 at index (1, 357915106, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 357913941, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000, -0.4333,  0.0000, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000, -0.4333,  0.0000, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2116

[Worker 1] Processing Task 2119: paddle.triu(Tensor([1, 1, 2048, 2097153],"float16"), )
[accuracy error] paddle.triu(Tensor([1, 1, 2048, 2097153],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 8015 / 4294969344 (0.0%)
Greatest absolute difference: 0.5 at index (0, 0, 2047, 2093191) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 2047, 2088964) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 2048, 2097153]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 2048, 2097153]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2119

[Worker 1] Processing Task 2121: paddle.triu(Tensor([1, 429496730, 1, 10],"float16"), diagonal=1, )
[accuracy error] paddle.triu(Tensor([1, 429496730, 1, 10],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 631355534 / 4294967300 (14.7%)
Greatest absolute difference: 0.5 at index (0, 357914075, 0, 6) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 357913941, 0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 429496730, 1, 10]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113,  0.0000,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892,  0.0000,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0000, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
         0.0000, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711,  0.0000, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0000, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.0000, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0000, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731,  0.0000,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 429496730, 1, 10]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113,  0.0000,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892,  0.0000,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0000, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
         0.0000, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711,  0.0000, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0000, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.0000, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0000, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731,  0.0000,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2121

[Worker 1] Processing Task 2125: paddle.triu(Tensor([390451573, 1, 1, 11],"float16"), diagonal=1, )
[accuracy error] paddle.triu(Tensor([390451573, 1, 1, 11],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 318867694 / 4294967303 (7.4%)
Greatest absolute difference: 0.5 at index (357913941, 0, 0, 5) (up to 0.01 allowed)
Greatest relative difference: inf at index (357913941, 0, 0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([390451573, 1, 1, 11]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.0000,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0000,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337,  0.0000,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827,  0.0000, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316,  0.0000,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0000,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305,  0.0000, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
         0.0000, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([390451573, 1, 1, 11]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.0000,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0000,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337,  0.0000,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827,  0.0000, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316,  0.0000,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0000,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305,  0.0000, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
         0.0000, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.0000], dtype=torch.float16)
[Worker 1] Completed Task 2125

[Worker 1] Processing Task 2127: paddle.triu(Tensor([429496730, 1, 1, 10],"float16"), diagonal=1, )
[accuracy error] paddle.triu(Tensor([429496730, 1, 1, 10],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 631355534 / 4294967300 (14.7%)
Greatest absolute difference: 0.5 at index (357914075, 0, 0, 6) (up to 0.01 allowed)
Greatest relative difference: inf at index (357913941, 0, 0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([429496730, 1, 1, 10]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113,  0.0000,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892,  0.0000,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0000, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
         0.0000, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711,  0.0000, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0000, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.0000, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0000, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731,  0.0000,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([429496730, 1, 1, 10]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113,  0.0000,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892,  0.0000,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0000, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
         0.0000, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711,  0.0000, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0000, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.0000, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0000, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731,  0.0000,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2127

[Worker 1] Processing Task 2130: paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=-1, )
[accuracy error] paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104509965 / 4294967300 (49.0%)
Greatest absolute difference: 0.5 at index (536871494, 1, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2130

[Worker 1] Processing Task 2133: paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=1, )
[accuracy error] paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 7 / 4294967298 (0.0%)
Greatest absolute difference: 0.45166015625 at index (2, 1, 715827879) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1, 715827876) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2133

[Worker 1] Processing Task 2136: paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=-5, )
[accuracy error] paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=-5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 7 / 4294967298 (0.0%)
Greatest absolute difference: 0.45166015625 at index (2, 1, 715827879) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1, 715827876) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792, -0.1527,  0.3103, -0.0141, -0.0589,
        -0.3333,  0.0113, -0.4199,  0.4548,  0.0924,  0.3787,  0.1429, -0.3521,
         0.1592, -0.3389,  0.0456, -0.3892, -0.2903,  0.2534,  0.0822,  0.2649,
         0.4351,  0.4434, -0.4756, -0.2462,  0.0878,  0.0596,  0.0059, -0.2440,
         0.3337, -0.2607,  0.2698,  0.4404, -0.4182, -0.2395, -0.2510, -0.0153,
        -0.3420, -0.3862, -0.3923, -0.0827, -0.0847, -0.4985, -0.2817,  0.0465,
        -0.3833,  0.1711, -0.2460, -0.2148, -0.2942, -0.0804, -0.4316, -0.0526,
        -0.2236, -0.3540,  0.2742,  0.4294,  0.0307, -0.1023, -0.3176,  0.1655,
        -0.1848,  0.0933,  0.0525,  0.1547,  0.4128, -0.2605,  0.2566, -0.1710,
        -0.0595,  0.2732, -0.2009, -0.2598, -0.0305, -0.3721, -0.4915, -0.0903,
         0.0281, -0.1752,  0.2439,  0.3958,  0.3333,  0.3601,  0.3086,  0.4966,
        -0.3916, -0.4731, -0.2791,  0.4590, -0.1404, -0.4822,  0.4646,  0.1840,
        -0.1385, -0.4580,  0.2441,  0.3591], dtype=torch.float16)
[Worker 1] Completed Task 2136

[Worker 1] Processing Task 2139: paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=-1, )
[accuracy error] paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 5 / 4294967298 (0.0%)
Greatest absolute difference: 0.43359375 at index (2, 2, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792,  0.0000,  0.3103,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494,  0.3171, -0.4333,  0.0792,  0.0000,  0.3103,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
[Worker 1] Completed Task 2139

[Worker 1] Processing Task 2198: paddle.argmax(Tensor([13, 1371215, 4, 16, 2],"float32"), axis=-1, )
[cuda error] paddle.argmax(Tensor([13, 1371215, 4, 16, 2],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927340 (unix time) try "date -d @1747927340" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc1c5) received by PID 49605 (TID 0x7f2766dac740) from PID 49605 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2205: paddle.argmax(Tensor([3, 3, 17674763, 3, 3, 3],"float16"), axis=0, )
[cuda error] paddle.argmax(Tensor([3, 3, 17674763, 3, 3, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927510 (unix time) try "date -d @1747927510" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc2f1) received by PID 49905 (TID 0x7f2766dac740) from PID 49905 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2207: paddle.argmax(Tensor([3, 3, 3, 3, 17674763, 3],"float16"), axis=0, )
W0522 23:26:31.245299 50094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:26:31.246074 50094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmax(Tensor([3, 3, 3, 3, 17674763, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927592 (unix time) try "date -d @1747927592" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc3ae) received by PID 50094 (TID 0x7f2766dac740) from PID 50094 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2211: paddle.argmax(Tensor([357913942, 3, 4],"float16"), axis=-1, keepdim=True, )
W0522 23:28:19.392875 50470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:28:19.393590 50470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmax(Tensor([357913942, 3, 4],"float16"), axis=-1, keepdim=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927700 (unix time) try "date -d @1747927700" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc526) received by PID 50470 (TID 0x7f2766dac740) from PID 50470 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2214: paddle.argmax(Tensor([4, 4, 4, 16777217, 4],"float16"), axis=0, )
W0522 23:29:37.115197 50565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:29:37.115927 50565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmax(Tensor([4, 4, 4, 16777217, 4],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927778 (unix time) try "date -d @1747927778" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc585) received by PID 50565 (TID 0x7f2766dac740) from PID 50565 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2221: paddle.argmax(x=Tensor([3, 3, 477218589],"float16"), axis=1, keepdim=False, )
[cuda error] paddle.argmax(x=Tensor([3, 3, 477218589],"float16"), axis=1, keepdim=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927942 (unix time) try "date -d @1747927942" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc69e) received by PID 50846 (TID 0x7f2766dac740) from PID 50846 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2235: paddle.argmin(Tensor([4, 16777217, 4, 4, 4],"float16"), axis=0, )
[cuda error] paddle.argmin(Tensor([4, 16777217, 4, 4, 4],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928122 (unix time) try "date -d @1747928122" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc817) received by PID 51223 (TID 0x7f2766dac740) from PID 51223 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2243: paddle.argmin(x=Tensor([3, 3, 477218589],"float16"), axis=1, keepdim=False, )
[cuda error] paddle.argmin(x=Tensor([3, 3, 477218589],"float16"), axis=1, keepdim=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928296 (unix time) try "date -d @1747928296" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcaa6) received by PID 51878 (TID 0x7f2766dac740) from PID 51878 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2255: paddle.copysign(Tensor([114085069, 20],"float32"), Tensor([114085069, 20],"float32"), )
[cuda error] paddle.copysign(Tensor([114085069, 20],"float32"), Tensor([114085069, 20],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928464 (unix time) try "date -d @1747928464" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcc92) received by PID 52370 (TID 0x7f2766dac740) from PID 52370 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2258: paddle.copysign(Tensor([12, 20, 9507090],"float32"), Tensor([12, 20, 9507090],"float32"), )
W0522 23:42:53.135241 52826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:42:53.136300 52826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([12, 20, 9507090],"float32"), Tensor([12, 20, 9507090],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928590 (unix time) try "date -d @1747928590" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xce5a) received by PID 52826 (TID 0x7f2766dac740) from PID 52826 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2261: paddle.copysign(Tensor([2, 107374183, 4, 5],"float16"), Tensor([2, 107374183, 4, 5],"float16"), )
W0522 23:44:37.342890 53167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:44:37.344192 53167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([2, 107374183, 4, 5],"float16"), Tensor([2, 107374183, 4, 5],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928695 (unix time) try "date -d @1747928695" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcfaf) received by PID 53167 (TID 0x7f2766dac740) from PID 53167 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2265: paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([4, 5],"float16"), )
W0522 23:46:50.762423 53625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:46:50.763484 53625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([4, 5],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928826 (unix time) try "date -d @1747928826" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd179) received by PID 53625 (TID 0x7f2766dac740) from PID 53625 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2269: paddle.copysign(Tensor([4, 5],"float16"), Tensor([214748365, 4, 5],"float16"), )
W0522 23:48:55.497952 54081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:48:55.498884 54081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
/usr/local/lib/python3.10/dist-packages/paddle/tensor/math.py:8262: UserWarning: The shape of broadcast output [214748365, 4, 5] is different from the input tensor x with shape: [4, 5], please make sure you are using copysign api correctly.
  warnings.warn(
[cuda error] paddle.copysign(Tensor([4, 5],"float16"), Tensor([214748365, 4, 5],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928952 (unix time) try "date -d @1747928952" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd341) received by PID 54081 (TID 0x7f2766dac740) from PID 54081 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2274: paddle.copysign(Tensor([8, 17, 751921, 6, 7],"float16"), Tensor([8, 17, 751921, 6, 7],"float16"), )
W0522 23:51:09.721683 54630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:51:09.722780 54630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([8, 17, 751921, 6, 7],"float16"), Tensor([8, 17, 751921, 6, 7],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747929088 (unix time) try "date -d @1747929088" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd566) received by PID 54630 (TID 0x7f2766dac740) from PID 54630 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2293: paddle.cumsum(Tensor([1, 2281701379],"float32"), axis=0, )
[torch error] paddle.cumsum(Tensor([1, 2281701379],"float32"), axis=0, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Error on Task 2293: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] OOM on Task 2293: CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2294: paddle.cumsum(Tensor([114085069, 20],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
W0522 23:59:45.248961 55375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:59:45.250110 55375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[paddle error] paddle.cumsum(Tensor([114085069, 20],"int64"), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2294

[Worker 1] Processing Task 2299: paddle.cumsum(Tensor([207427399, 11],"int64"), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([207427399, 11],"int64"), axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2299

[Worker 1] Processing Task 2301: paddle.cumsum(Tensor([22152441, 103],"int64"), 1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([22152441, 103],"int64"), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2301

[Worker 1] Processing Task 2309: paddle.cumsum(Tensor([3, 760567127],"int64"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([3, 760567127],"int64"), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2309

[Worker 1] Processing Task 2311: paddle.cumsum(Tensor([325957340, 7],"int32"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.cumsum(Tensor([325957340, 7],"int32"), axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01

ACTUAL: (shape=torch.Size([325957340, 7]), dtype=torch.int32)
First 100 elements: tensor([  50942,   73303,  104433,   94087,   77069,  141362,  110325,   41021,
          97135,   93385,  124825,   81474,   34392,   30926,  -58181,  -68193,
        -131326,  -78025,  -96628,  -41506,  -75126,   -7217,  -49840,  -45225,
         -76554, -139215,  -76313,  -89090,   -5301,   59930,  125017,  120961,
          92153,  113687,  140255,  -41642,   18293,   43401,   60180,   50377,
          82015,  118944,  -59435,  -54635,   -4457,  -68783,  -40299,  -35993,
         -43770,    6694,   40703,   80284,   70805,   27769,    5883,   59169,
         -33120,  -22774,    -181,   43314,    9693,   44018,   23533,  -19835,
           6464,  -37505,  -50647,  -61487,  -33224,  -37837,  -29104,  -44276,
         -38245,  -38717,   25727,   61706,   77486,  -30372,  -61654,  -27055,
         -17667,  -31818,   -5283,  -32672,    5625,  -30958,  -71126,  -72155,
         -22332,  -31699,  -57314,  -62886, -114806, -146483, -188765, -199387,
        -236527, -265711,   42264,   13583], dtype=torch.int32)
DESIRED: (shape=torch.Size([325957340, 7]), dtype=torch.int64)
First 100 elements: tensor([  50942,   73303,  104433,   94087,   77069,  141362,  110325,   41021,
          97135,   93385,  124825,   81474,   34392,   30926,  -58181,  -68193,
        -131326,  -78025,  -96628,  -41506,  -75126,   -7217,  -49840,  -45225,
         -76554, -139215,  -76313,  -89090,   -5301,   59930,  125017,  120961,
          92153,  113687,  140255,  -41642,   18293,   43401,   60180,   50377,
          82015,  118944,  -59435,  -54635,   -4457,  -68783,  -40299,  -35993,
         -43770,    6694,   40703,   80284,   70805,   27769,    5883,   59169,
         -33120,  -22774,    -181,   43314,    9693,   44018,   23533,  -19835,
           6464,  -37505,  -50647,  -61487,  -33224,  -37837,  -29104,  -44276,
         -38245,  -38717,   25727,   61706,   77486,  -30372,  -61654,  -27055,
         -17667,  -31818,   -5283,  -32672,    5625,  -30958,  -71126,  -72155,
         -22332,  -31699,  -57314,  -62886, -114806, -146483, -188765, -199387,
        -236527, -265711,   42264,   13583])
[Worker 1] Completed Task 2311

[Worker 1] Processing Task 2319: paddle.cumsum(Tensor([76057, 30000],"float32"), axis=-1, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 9097 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 9.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 2319: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 9097 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 9.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 2319: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 9097 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 9.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2322: paddle.cumsum(x=Tensor([1, 16, 8388609, 32],"float16"), axis=2, )
W0523 00:04:58.314962 55677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:04:58.315989 55677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.cumsum(x=Tensor([1, 16, 8388609, 32],"float16"), axis=2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4168129325 / 4294967808 (97.0%)
Greatest absolute difference: 3136.0 at index (0, 10, 7943102, 29) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 3644, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 8388609, 32]), dtype=torch.float16)
First 100 elements: tensor([ 0.0320,  0.3428, -0.0440,  0.1503,  0.2133,  0.0247,  0.4998,  0.0353,
         0.3276, -0.3489,  0.0232, -0.3140,  0.0163,  0.1392,  0.2245, -0.0487,
        -0.0877, -0.2754,  0.1123, -0.1353,  0.1202,  0.4497, -0.2205, -0.4236,
         0.0019,  0.3118, -0.1074,  0.0322, -0.0153,  0.3997, -0.1644,  0.2291,
         0.3687,  0.4202, -0.3440, -0.2457,  0.1626,  0.1624,  0.6021, -0.0634,
         0.2705, -0.4075, -0.3875, -0.5171, -0.1116, -0.3115,  0.1670,  0.0818,
         0.0969, -0.2783, -0.0847, -0.0586, -0.2549,  0.1567, -0.0081, -0.4067,
        -0.1267,  0.2625, -0.5674,  0.2661,  0.2903,  0.8730, -0.2339,  0.6660,
         0.3381,  0.2283, -0.6870, -0.4048, -0.2358,  0.3406,  0.3433,  0.1543,
         0.3105, -0.8994, -0.1602, -0.4382, -0.1947, -0.4885,  0.0077,  0.2773,
         0.0457,  0.0513,  0.2593,  0.0668, -0.6074, -0.2671, -0.3745, -0.1015,
         0.0150,  0.0674, -0.2495,  0.7192,  0.2162,  0.7183,  0.1058,  1.1533,
         0.6343,  0.7280, -0.8535, -0.6572], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 8388609, 32]), dtype=torch.float16)
First 100 elements: tensor([ 0.0320,  0.3428, -0.0440,  0.1503,  0.2133,  0.0247,  0.4998,  0.0353,
         0.3276, -0.3489,  0.0232, -0.3140,  0.0163,  0.1392,  0.2245, -0.0487,
        -0.0877, -0.2754,  0.1123, -0.1353,  0.1202,  0.4497, -0.2205, -0.4236,
         0.0019,  0.3118, -0.1074,  0.0322, -0.0153,  0.3997, -0.1644,  0.2291,
         0.3687,  0.4202, -0.3440, -0.2457,  0.1626,  0.1624,  0.6021, -0.0634,
         0.2705, -0.4075, -0.3875, -0.5171, -0.1116, -0.3115,  0.1670,  0.0818,
         0.0969, -0.2783, -0.0847, -0.0586, -0.2549,  0.1567, -0.0081, -0.4067,
        -0.1267,  0.2625, -0.5674,  0.2661,  0.2903,  0.8730, -0.2339,  0.6660,
         0.3381,  0.2283, -0.6870, -0.4048, -0.2358,  0.3403,  0.3433,  0.1543,
         0.3105, -0.8994, -0.1602, -0.4382, -0.1948, -0.4885,  0.0077,  0.2773,
         0.0457,  0.0513,  0.2593,  0.0668, -0.6074, -0.2671, -0.3745, -0.1016,
         0.0150,  0.0674, -0.2495,  0.7192,  0.2162,  0.7183,  0.1057,  1.1543,
         0.6348,  0.7280, -0.8535, -0.6572], dtype=torch.float16)
[Worker 1] Completed Task 2322

[Worker 1] Processing Task 2341: paddle.dist(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
[cuda error] paddle.dist(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), 0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] Error on Task 2341: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] OOM on Task 2341: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2345: paddle.dist(x=Tensor([2147483649, 2],"float16"), y=Tensor([2147483649, 2],"float16"), p=0, )
Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'
W0523 00:11:26.725069 56132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:11:26.726018 56132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.dist(x=Tensor([2147483649, 2],"float16"), y=Tensor([2147483649, 2],"float16"), p=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] Error on Task 2345: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] OOM on Task 2345: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2349: paddle.dist(x=Tensor([4294967297],"float16"), y=Tensor([4294967297],"float16"), )
W0523 00:12:55.257534 56510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:12:55.258550 56510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.dist(x=Tensor([4294967297],"float16"), y=Tensor([4294967297],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930381 (unix time) try "date -d @1747930381" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdcbe) received by PID 56510 (TID 0x7f2766dac740) from PID 56510 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2354: paddle.frac(Tensor([2, 1140850690],"float32"), )
W0523 00:14:45.134667 56983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:14:45.136016 56983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.frac(Tensor([2, 1140850690],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930500 (unix time) try "date -d @1747930500" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xde97) received by PID 56983 (TID 0x7f2766dac740) from PID 56983 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2508: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), 2, )
[torch error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), 2, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Error on Task 2508: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] OOM on Task 2508: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2511: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), 2, )
[torch error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), 2, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Error on Task 2511: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] OOM on Task 2511: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2516: paddle.linalg.lstsq(Tensor([9, 253522376],"float32"), Tensor([9, 5],"float32"), rcond=1e-15, driver="gels", )
[torch error] paddle.linalg.lstsq(Tensor([9, 253522376],"float32"), Tensor([9, 5],"float32"), rcond=1e-15, driver="gels", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Error on Task 2516: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] OOM on Task 2516: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2519: paddle.linalg.matrix_rank(Tensor([19014179, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
[torch error] paddle.linalg.matrix_rank(Tensor([19014179, 4, 5, 6],"float32"), Tensor([3, 4],"float32"), False, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Error on Task 2519: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] OOM on Task 2519: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2626: paddle.nansum(Tensor([1431655765, 3],"float32"), axis=list[0,], keepdim=True, name=None, )
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2630: paddle.nansum(Tensor([3, 1431655765],"float32"), axis=None, keepdim=False, name=None, )
W0523 01:26:08.297500 59215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:26:08.298491 59215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2634: paddle.nansum(Tensor([858993459, 5],"float32"), axis=None, keepdim=False, name=None, )
W0523 01:56:22.589668 59595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:56:22.590728 59595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2638: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 67108864, 32],"float32"), output_size=16, )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] Error on Task 2638: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] OOM on Task 2638: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2643: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([29217465, 3, 7, 7],"float32"), output_size=list[None,3,], )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] Error on Task 2643: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] OOM on Task 2643: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2648: paddle.nn.functional.grid_sample(Tensor([56, 3, 848848, 16],"float32"), Tensor([56, 16, 848848, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
W0523 02:28:57.390228 60941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:28:57.391287 60941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 848848, 16],"float32"), Tensor([56, 16, 848848, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938554 (unix time) try "date -d @1747938554" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xee0d) received by PID 60941 (TID 0x7f2766dac740) from PID 60941 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2652: paddle.nn.functional.grid_sample(Tensor([5821, 4, 280, 350],"float32"), Tensor([5821, 298, 364, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
W0523 02:31:12.833333 61380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:31:12.834800 61380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([5821, 4, 280, 350],"float32"), Tensor([5821, 298, 364, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938692 (unix time) try "date -d @1747938692" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xefc4) received by PID 61380 (TID 0x7f2766dac740) from PID 61380 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2656: paddle.nn.functional.grid_sample(Tensor([73661, 1, 176, 176],"float32"), Tensor([73661, 1, 12544, 2],"float32"), align_corners=False, )
W0523 02:33:14.639930 61858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:33:14.641023 61858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([73661, 1, 176, 176],"float32"), Tensor([73661, 1, 12544, 2],"float32"), align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938802 (unix time) try "date -d @1747938802" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf1a2) received by PID 61858 (TID 0x7f2766dac740) from PID 61858 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2660: paddle.nn.functional.layer_norm(Tensor([8, 1114113, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, )
W0523 02:35:11.000921 62312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:35:11.001919 62312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.layer_norm(Tensor([8, 1114113, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938925 (unix time) try "date -d @1747938925" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf368) received by PID 62312 (TID 0x7f2766dac740) from PID 62312 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2665: paddle.nn.functional.normalize(Tensor([1, 256, 557057, 16],"float32"), axis=1, )
W0523 02:37:04.002128 62862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:37:04.003296 62862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 256, 557057, 16],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939038 (unix time) try "date -d @1747939038" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf58e) received by PID 62862 (TID 0x7f2766dac740) from PID 62862 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2668: paddle.nn.functional.normalize(Tensor([1, 64, 64, 557057],"float32"), axis=1, )
W0523 02:38:28.844710 63204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:38:28.845826 63204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 64, 64, 557057],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939124 (unix time) try "date -d @1747939124" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf6e4) received by PID 63204 (TID 0x7f2766dac740) from PID 63204 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2671: paddle.nn.functional.normalize(Tensor([10, 228170138],"float32"), axis=0, )
W0523 02:40:00.916785 63548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:40:00.917861 63548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([10, 228170138],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939216 (unix time) try "date -d @1747939216" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf83c) received by PID 63548 (TID 0x7f2766dac740) from PID 63548 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2674: paddle.nn.functional.normalize(Tensor([11883862, 192],"float32"), axis=1, )
W0523 02:41:59.091472 63873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:41:59.092510 63873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([11883862, 192],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939334 (unix time) try "date -d @1747939334" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf981) received by PID 63873 (TID 0x7f2766dac740) from PID 63873 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2676: paddle.nn.functional.normalize(Tensor([17409, 128, 32, 32],"float32"), axis=1, )
W0523 02:43:40.974774 64137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:43:40.975768 64137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([17409, 128, 32, 32],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939437 (unix time) try "date -d @1747939437" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfa89) received by PID 64137 (TID 0x7f2766dac740) from PID 64137 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2679: paddle.nn.functional.normalize(Tensor([2, 8, 7, 20372334],"float32"), axis=1, )
W0523 02:45:12.425544 64481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:45:12.426522 64481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([2, 8, 7, 20372334],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939527 (unix time) try "date -d @1747939527" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfbe1) received by PID 64481 (TID 0x7f2766dac740) from PID 64481 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2684: paddle.nn.functional.normalize(Tensor([253522376, 9],"float32"), axis=1, )
W0523 02:47:19.188063 65028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:47:19.189102 65028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([253522376, 9],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939657 (unix time) try "date -d @1747939657" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfe04) received by PID 65028 (TID 0x7f2766dac740) from PID 65028 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2688: paddle.nn.functional.normalize(Tensor([34817, 256, 16, 16],"float32"), axis=1, )
W0523 02:49:25.855949 65465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:49:25.856932 65465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([34817, 256, 16, 16],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939781 (unix time) try "date -d @1747939781" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xffb9) received by PID 65465 (TID 0x7f2766dac740) from PID 65465 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2691: paddle.nn.functional.normalize(Tensor([4, 570425345],"float32"), axis=0, )
W0523 02:51:29.846705 65808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:51:29.847669 65808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([4, 570425345],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939903 (unix time) try "date -d @1747939903" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10110) received by PID 65808 (TID 0x7f2766dac740) from PID 65808 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2694: paddle.nn.functional.normalize(Tensor([4456449, 512],"float32"), )
W0523 02:53:25.483726 66151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:53:25.484685 66151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([4456449, 512],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940020 (unix time) try "date -d @1747940020" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10267) received by PID 66151 (TID 0x7f2766dac740) from PID 66151 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2699: paddle.nn.functional.normalize(Tensor([760567127, 3],"float32"), axis=0, )
W0523 02:55:33.435299 66721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:55:33.436255 66721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([760567127, 3],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940460 (unix time) try "date -d @1747940460" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x104a1) received by PID 66721 (TID 0x7f2766dac740) from PID 66721 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2706: paddle.nn.functional.normalize(x=Tensor([20452226, 5, 6, 7],"float16"), )
W0523 03:02:25.250895 67536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:02:25.251910 67536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([20452226, 5, 6, 7],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940562 (unix time) try "date -d @1747940562" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x107d0) received by PID 67536 (TID 0x7f2766dac740) from PID 67536 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2710: paddle.nn.functional.normalize(x=Tensor([4, 1073741825],"float16"), p=1.2, )
W0523 03:04:36.915650 67973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:04:36.916692 67973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([4, 1073741825],"float16"), p=1.2, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941126 (unix time) try "date -d @1747941126" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10985) received by PID 67973 (TID 0x7f2766dac740) from PID 67973 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2721: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 2, 1e-06, False, None, )
W0523 03:13:20.244772 69248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:13:20.245810 69248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 2, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941215 (unix time) try "date -d @1747941215" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10e80) received by PID 69248 (TID 0x7f2766dac740) from PID 69248 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2724: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), math.inf, 1e-06, False, None, )
W0523 03:14:46.760701 69533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:14:46.761801 69533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941290 (unix time) try "date -d @1747941290" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10f9d) received by PID 69533 (TID 0x7f2766dac740) from PID 69533 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2727: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -math.inf, 1e-06, True, None, )
W0523 03:16:01.937496 69818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:16:01.938519 69818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941365 (unix time) try "date -d @1747941365" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x110ba) received by PID 69818 (TID 0x7f2766dac740) from PID 69818 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2730: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 2, 1e-06, False, None, )
W0523 03:17:27.289232 70101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:17:27.290381 70101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), 2, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941484 (unix time) try "date -d @1747941484" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x111d5) received by PID 70101 (TID 0x7f2766dac740) from PID 70101 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2733: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -math.inf, 1e-06, False, None, )
W0523 03:19:35.172135 70388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:19:35.173450 70388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941584 (unix time) try "date -d @1747941584" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x112f4) received by PID 70388 (TID 0x7f2766dac740) from PID 70388 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2738: paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), math.inf, 1e-06, False, None, )
W0523 03:20:58.815048 70861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:20:58.816671 70861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941720 (unix time) try "date -d @1747941720" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x114cd) received by PID 70861 (TID 0x7f2766dac740) from PID 70861 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2742: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 1, 1e-06, False, None, )
W0523 03:23:44.318920 71300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:23:44.320211 71300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941826 (unix time) try "date -d @1747941826" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11684) received by PID 71300 (TID 0x7f2766dac740) from PID 71300 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2749: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -math.inf, 1e-06, False, None, )
W0523 03:25:35.856909 71830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:25:35.858062 71830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941938 (unix time) try "date -d @1747941938" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11896) received by PID 71830 (TID 0x7f2766dac740) from PID 71830 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2752: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 1, 1e-06, False, None, )
W0523 03:26:59.546386 72191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:26:59.547514 72191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942026 (unix time) try "date -d @1747942026" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x119ff) received by PID 72191 (TID 0x7f2766dac740) from PID 72191 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2757: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 2, 1e-06, True, None, )
W0523 03:28:57.502207 72742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:28:57.503738 72742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 2, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942143 (unix time) try "date -d @1747942143" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11c26) received by PID 72742 (TID 0x7f2766dac740) from PID 72742 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2760: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), math.inf, 1e-06, True, None, )
W0523 03:30:25.587863 73103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:30:25.588975 73103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942231 (unix time) try "date -d @1747942231" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11d8f) received by PID 73103 (TID 0x7f2766dac740) from PID 73103 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2763: paddle.nn.functional.pairwise_distance(Tensor([760567127, 3],"float32"), Tensor([760567127, 3],"float32"), 2, 1e-06, False, None, )
W0523 03:31:46.919256 73445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:31:46.920388 73445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([760567127, 3],"float32"), Tensor([760567127, 3],"float32"), 2, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942313 (unix time) try "date -d @1747942313" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11ee5) received by PID 73445 (TID 0x7f2766dac740) from PID 73445 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2769: paddle.nn.functional.rrelu(Tensor([2, 3, 76056713, 5],"float32"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 3, 76056713, 5],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1384)

[Worker 1] Completed Task 2769

[Worker 1] Processing Task 2787: paddle.std(x=Tensor([3, 477218589, 3],"float16"), axis=0, )
[accuracy error] backward  paddle.std(x=Tensor([3, 477218589, 3],"float16"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 20047 / 4294967301 (0.0%)
Greatest absolute difference: nan at index (0, 18293, 2) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 18293, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 477218589, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.1838, -0.0725,  0.1907,  0.0137, -0.2754,  0.1188,  0.0431, -0.0807,
         0.0109,  0.0659, -0.2335,  0.0328,  0.0298, -0.0185,  0.1059,  0.0121,
         0.0379,  0.1196, -0.0035, -0.1638, -0.0414,  0.1206,  0.0897, -0.0206,
        -0.0179, -0.0175,  0.0158,  0.0338,  0.0119, -0.0202,  0.2188,  0.0289,
         0.1028,  0.0655,  0.1066,  0.0163, -0.1909,  0.1606, -0.0188, -0.0285,
         0.1243, -0.1076, -0.1196,  0.0710,  0.0891,  0.0378,  0.0095,  0.0026,
        -0.0324, -0.0148, -0.0063, -0.1815,  0.1412,  0.0096,  0.0432, -0.0382,
         0.2324, -0.0569,  0.1082, -0.0006, -0.0882, -0.0598, -0.1593, -0.1837,
        -0.0168,  0.0594,  0.1027,  0.0638,  0.0679,  0.2705, -0.0423, -0.0691,
         0.0960, -0.1184, -0.0616,  0.0084,  0.2629,  0.0416, -0.1455,  0.1835,
         0.1137, -0.0757,  0.0558, -0.2371,  0.2273, -0.0581, -0.0996,  0.1382,
         0.1176, -0.2786, -0.0507,  0.0527,  0.1023,  0.0735,  0.0334,  0.0576,
         0.1687, -0.0035, -0.0083, -0.1021], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 477218589, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.1840, -0.0724,  0.1907,  0.0137, -0.2751,  0.1188,  0.0430, -0.0807,
         0.0109,  0.0659, -0.2335,  0.0328,  0.0298, -0.0185,  0.1059,  0.0120,
         0.0379,  0.1196, -0.0035, -0.1638, -0.0414,  0.1206,  0.0897, -0.0206,
        -0.0179, -0.0175,  0.0158,  0.0339,  0.0119, -0.0202,  0.2188,  0.0289,
         0.1028,  0.0655,  0.1066,  0.0163, -0.1909,  0.1606, -0.0188, -0.0285,
         0.1244, -0.1077, -0.1196,  0.0711,  0.0891,  0.0378,  0.0095,  0.0026,
        -0.0324, -0.0148, -0.0063, -0.1815,  0.1412,  0.0096,  0.0432, -0.0382,
         0.2322, -0.0569,  0.1082, -0.0006, -0.0882, -0.0599, -0.1593, -0.1837,
        -0.0168,  0.0594,  0.1027,  0.0638,  0.0679,  0.2705, -0.0423, -0.0691,
         0.0960, -0.1183, -0.0616,  0.0085,  0.2629,  0.0416, -0.1455,  0.1833,
         0.1136, -0.0757,  0.0558, -0.2372,  0.2273, -0.0581, -0.0996,  0.1382,
         0.1176, -0.2786, -0.0507,  0.0526,  0.1022,  0.0735,  0.0334,  0.0576,
         0.1687, -0.0035, -0.0083, -0.1022], dtype=torch.float16)
[Worker 1] Completed Task 2787

[Worker 1] Processing Task 2828: paddle.Tensor.argmax(Tensor([1, 1, 2281701379],"float32"), axis=-2, )
[cuda error] paddle.Tensor.argmax(Tensor([1, 1, 2281701379],"float32"), axis=-2, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943141 (unix time) try "date -d @1747943141" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1203b) received by PID 73787 (TID 0x7f2766dac740) from PID 73787 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2834: paddle.Tensor.argmax(Tensor([75245, 1, 30324],"float32"), axis=-2, )
W0523 03:47:35.376997 74566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:47:35.377910 74566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.Tensor.argmax(Tensor([75245, 1, 30324],"float32"), axis=-2, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943256 (unix time) try "date -d @1747943256" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12346) received by PID 74566 (TID 0x7f2766dac740) from PID 74566 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2849: paddle.Tensor.cumsum(Tensor([1, 253522376, 9],"float32"), 1, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 253522376, 9],"float32"), 1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 21967869 / 2281701384 (1.0%)
Greatest absolute difference: 2.18902587890625 at index (0, 224829220, 5) (up to 0.01 allowed)
Greatest relative difference: 271213.09375 at index (0, 227650973, 6) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 253522376, 9]), dtype=torch.float32)
First 100 elements: tensor([ 3.3962e-01, -3.0939e-01,  1.9541e-01, -7.4502e-02, -1.5632e-01,
         1.1968e-01, -8.5983e-02,  4.4394e-01, -1.2739e-01,  3.3943e-01,
        -6.5809e-01, -2.9019e-01, -6.0865e-02,  1.6207e-03, -7.7133e-02,
        -1.4480e-02,  6.6096e-01,  8.5327e-02, -1.3166e-01, -6.7515e-01,
        -4.7813e-01, -3.1025e-02, -1.1327e-01,  2.2360e-01, -4.8861e-01,
         1.0692e+00,  7.1299e-02,  3.8034e-02, -4.8976e-01, -4.6466e-01,
         3.4855e-01, -2.8986e-01,  2.1045e-01, -6.1490e-01,  1.0786e+00,
        -1.6864e-02,  1.4751e-01, -3.6473e-01, -1.6862e-01,  3.6220e-01,
        -5.7870e-01,  1.7320e-01, -6.6226e-01,  1.1356e+00,  5.3678e-02,
         3.5695e-01, -6.1999e-01, -5.2937e-01,  2.3782e-01, -2.9807e-01,
         1.4135e-02, -5.9860e-01,  6.9649e-01,  4.4631e-01,  1.7441e-01,
        -2.9858e-01, -8.6997e-01,  6.4452e-01, -2.1178e-01,  3.6111e-01,
        -2.6144e-01,  2.8488e-01,  4.4506e-01,  1.1130e-02, -5.8798e-01,
        -1.1933e+00,  4.3284e-01, -3.9924e-01,  1.3795e-01, -7.1510e-01,
         3.5767e-01,  2.8374e-02,  6.3184e-02, -1.0432e+00, -1.3090e+00,
         2.9172e-01, -8.3824e-01,  5.9056e-02, -9.1696e-01,  2.9461e-01,
         1.0772e-01,  2.2700e-01, -9.1039e-01, -1.7571e+00,  2.2143e-01,
        -9.2968e-01,  3.6492e-01, -4.6726e-01, -9.0797e-02,  1.5667e-01,
         1.4587e-01, -1.3875e+00, -2.2493e+00,  6.5067e-01, -1.1976e+00,
         2.8762e-02, -1.5361e-02, -3.5184e-02,  4.0525e-01,  1.8485e-01])
DESIRED: (shape=torch.Size([1, 253522376, 9]), dtype=torch.float32)
First 100 elements: tensor([ 3.3962e-01, -3.0939e-01,  1.9541e-01, -7.4502e-02, -1.5632e-01,
         1.1968e-01, -8.5983e-02,  4.4394e-01, -1.2739e-01,  3.3943e-01,
        -6.5809e-01, -2.9019e-01, -6.0865e-02,  1.6207e-03, -7.7133e-02,
        -1.4480e-02,  6.6096e-01,  8.5327e-02, -1.3166e-01, -6.7515e-01,
        -4.7813e-01, -3.1025e-02, -1.1327e-01,  2.2360e-01, -4.8861e-01,
         1.0692e+00,  7.1299e-02,  3.8034e-02, -4.8976e-01, -4.6466e-01,
         3.4855e-01, -2.8986e-01,  2.1045e-01, -6.1490e-01,  1.0786e+00,
        -1.6864e-02,  1.4751e-01, -3.6473e-01, -1.6862e-01,  3.6220e-01,
        -5.7870e-01,  1.7320e-01, -6.6226e-01,  1.1356e+00,  5.3678e-02,
         3.5695e-01, -6.1999e-01, -5.2937e-01,  2.3782e-01, -2.9807e-01,
         1.4135e-02, -5.9860e-01,  6.9649e-01,  4.4631e-01,  1.7441e-01,
        -2.9858e-01, -8.6997e-01,  6.4452e-01, -2.1178e-01,  3.6111e-01,
        -2.6144e-01,  2.8488e-01,  4.4506e-01,  1.1130e-02, -5.8798e-01,
        -1.1933e+00,  4.3284e-01, -3.9924e-01,  1.3795e-01, -7.1510e-01,
         3.5767e-01,  2.8374e-02,  6.3184e-02, -1.0432e+00, -1.3090e+00,
         2.9172e-01, -8.3824e-01,  5.9056e-02, -9.1696e-01,  2.9461e-01,
         1.0772e-01,  2.2700e-01, -9.1039e-01, -1.7571e+00,  2.2143e-01,
        -9.2968e-01,  3.6492e-01, -4.6726e-01, -9.0797e-02,  1.5667e-01,
         1.4587e-01, -1.3875e+00, -2.2493e+00,  6.5067e-01, -1.1976e+00,
         2.8762e-02, -1.5361e-02, -3.5184e-02,  4.0525e-01,  1.8485e-01])
[Worker 1] Completed Task 2849

[Worker 1] Processing Task 2857: paddle.Tensor.cumsum(Tensor([162978670, 14],"int32"), -1, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.cumsum(Tensor([162978670, 14],"int32"), -1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01

ACTUAL: (shape=torch.Size([162978670, 14]), dtype=torch.int32)
First 100 elements: tensor([ -42615,  -86746,  -82570,  -40434,  -79651,  -47108,  -77534,  -48347,
           5144,   44224,    3718,   37095,   -2568,    5229,  -11560,    8003,
          33795,   82959,   92862,  149892,  201178,  230016,  250738,  297386,
         287819,  240313,  288118,  328256,   60274,   49689,   77001,  131320,
         170612,  151389,  115677,   89648,   54082,    8375,  -38135,  -15615,
          38129,   23143,  -26554,   17089,   36955,  -10866,    8125,  -26685,
         -38224,   19579,   40197,   11375,  -40191,   22374,  -24826,   -9493,
         -31395,  -85994, -120086, -182756, -188081, -235406, -193834, -224955,
        -189929, -184489, -131337, -125430,  -94439,  -62918,   54887,  109785,
         162304,  185332,  137028,  199335,  138759,  195390,  254373,  283379,
         295516,  358960,  369863,  404067,  -10830,  -19785,   40374,   18663,
          47104,   -6831,   -4277,   44478,   23705,   68188,   71200,  107288,
          80314,   58104,  -48894, -100213], dtype=torch.int32)
DESIRED: (shape=torch.Size([162978670, 14]), dtype=torch.int64)
First 100 elements: tensor([ -42615,  -86746,  -82570,  -40434,  -79651,  -47108,  -77534,  -48347,
           5144,   44224,    3718,   37095,   -2568,    5229,  -11560,    8003,
          33795,   82959,   92862,  149892,  201178,  230016,  250738,  297386,
         287819,  240313,  288118,  328256,   60274,   49689,   77001,  131320,
         170612,  151389,  115677,   89648,   54082,    8375,  -38135,  -15615,
          38129,   23143,  -26554,   17089,   36955,  -10866,    8125,  -26685,
         -38224,   19579,   40197,   11375,  -40191,   22374,  -24826,   -9493,
         -31395,  -85994, -120086, -182756, -188081, -235406, -193834, -224955,
        -189929, -184489, -131337, -125430,  -94439,  -62918,   54887,  109785,
         162304,  185332,  137028,  199335,  138759,  195390,  254373,  283379,
         295516,  358960,  369863,  404067,  -10830,  -19785,   40374,   18663,
          47104,   -6831,   -4277,   44478,   23705,   68188,   71200,  107288,
          80314,   58104,  -48894, -100213])
[Worker 1] Completed Task 2857

[Worker 1] Processing Task 2863: paddle.Tensor.cumsum(Tensor([285212673, 4, 2],"int64"), axis=2, )
[torch error] paddle.Tensor.cumsum(Tensor([285212673, 4, 2],"int64"), axis=2, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 7250 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 2863

[Worker 1] Processing Task 2864: paddle.Tensor.cumsum(Tensor([28521268, 10, 8],"float32"), 1, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 7250 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 2864: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 7250 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 2864: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 7250 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2876: paddle.Tensor.cumsum(Tensor([570425345, 4],"int64"), axis=1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.cumsum(Tensor([570425345, 4],"int64"), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2876

[Worker 1] Processing Task 2888: paddle.Tensor.repeat_interleave(Tensor([2281701379, 1],"int64"), 1, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.repeat_interleave(Tensor([2281701379, 1],"int64"), 1, axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_repeat_interleave(_object*, _object*, _object*)
1   repeat_interleave_ad_func(paddle::Tensor const&, int, int)
2   paddle::experimental::repeat_interleave(paddle::Tensor const&, int, int)
3   void phi::RepeatInterleaveKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, int, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 78.112305GB memory has been allocated and available memory is only 1.072571GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2888

[Worker 1] Processing Task 2891: paddle.trunc(input=Tensor([119304648, 6, 6],"float16"), )
[cuda error] paddle.trunc(input=Tensor([119304648, 6, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944146 (unix time) try "date -d @1747944146" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x125cc) received by PID 75212 (TID 0x7f2766dac740) from PID 75212 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2894: paddle.trunc(input=Tensor([3, 6, 6, 6628036, 6],"float16"), )
W0523 04:04:17.344019 75626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:04:17.345057 75626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([3, 6, 6, 6628036, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944274 (unix time) try "date -d @1747944274" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1276a) received by PID 75626 (TID 0x7f2766dac740) from PID 75626 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2897: paddle.trunc(input=Tensor([3314018, 6, 6, 6, 6],"float16"), )
W0523 04:06:37.429534 75970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:06:37.430469 75970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(input=Tensor([3314018, 6, 6, 6, 6],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944413 (unix time) try "date -d @1747944413" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x128c2) received by PID 75970 (TID 0x7f2766dac740) from PID 75970 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2902: paddle.trunc(input=Tensor([6, 6, 119304648],"float16"), )
[cuda error] paddle.trunc(input=Tensor([6, 6, 119304648],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944608 (unix time) try "date -d @1747944608" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12a2a) received by PID 76330 (TID 0x7f2766dac740) from PID 76330 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2906: paddle.trunc(Tensor([10, 228170138, 1],"float32"), )
W0523 04:11:52.331539 76787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:11:52.333022 76787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(Tensor([10, 228170138, 1],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944726 (unix time) try "date -d @1747944726" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12bf3) received by PID 76787 (TID 0x7f2766dac740) from PID 76787 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2909: paddle.trunc(Tensor([20, 114085069],"float32"), )
W0523 04:13:47.927606 77129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 04:13:47.928787 77129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.trunc(Tensor([20, 114085069],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747944841 (unix time) try "date -d @1747944841" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12d49) received by PID 77129 (TID 0x7f2766dac740) from PID 77129 ***]

[Worker 1] Started on GPU 1

[Worker 1] Processing Task 2954: paddle.argsort(Tensor([26, 87757746],"int64"), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([26, 87757746],"int64"), axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2954

[Worker 1] Processing Task 2957: paddle.argsort(Tensor([3, 4, 190141782],"int64"), axis=2, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([3, 4, 190141782],"int64"), axis=2, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2957

[Worker 1] Processing Task 2960: paddle.argsort(Tensor([5, 456340276],"int64"), axis=1, stable=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.argsort(Tensor([5, 456340276],"int64"), axis=1, stable=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_argsort(_object*, _object*, _object*)
1   argsort_ad_func(paddle::Tensor const&, int, bool, bool)
2   paddle::experimental::argsort(paddle::Tensor const&, int, bool, bool)
3   void phi::ArgsortKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, bool, phi::DenseTensor*, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 2960

[Worker 1] Processing Task 2971: paddle.chunk(Tensor([1, 1, 64, 67108865],"float16"), 2, axis=-1, )
[paddle error] paddle.chunk(Tensor([1, 1, 64, 67108865],"float16"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 1, 64, 67108865], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2971

[Worker 1] Processing Task 2973: paddle.chunk(Tensor([1, 4, 20, 28521268],"float32"), 3, axis=-1, )
[paddle error] paddle.chunk(Tensor([1, 4, 20, 28521268],"float32"), 3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [1, 4, 20, 28521268], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2973

[Worker 1] Processing Task 2975: paddle.chunk(Tensor([13, 175515491, 1],"float32"), 4, axis=1, )
[paddle error] paddle.chunk(Tensor([13, 175515491, 1],"float32"), 4, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [13, 175515491, 1], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:3 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2975

[Worker 1] Processing Task 2978: paddle.chunk(Tensor([13, 56, 3134206],"float32"), 3, axis=-1, )
[paddle error] paddle.chunk(Tensor([13, 56, 3134206],"float32"), 3, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [13, 56, 3134206], Attr(dim) = 2.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2978

[Worker 1] Processing Task 2981: paddle.chunk(Tensor([4, 139265, 64, 64],"float32"), 3, axis=1, )
[paddle error] paddle.chunk(Tensor([4, 139265, 64, 64],"float32"), 3, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [4, 139265, 64, 64], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2981

[Worker 1] Processing Task 2984: paddle.chunk(Tensor([52, 5484860, 8],"float32"), 3, axis=1, )
[paddle error] paddle.chunk(Tensor([52, 5484860, 8],"float32"), 3, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [52, 5484860, 8], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2984

[Worker 1] Processing Task 2987: paddle.chunk(x=Tensor([2281701379],"bool"), chunks=3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.chunk(x=Tensor([2281701379],"bool"), chunks=3, axis=0, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2987

[Worker 1] Processing Task 2993: paddle.chunk(x=Tensor([760567127, 3],"int32"), chunks=3, axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.chunk(x=Tensor([760567127, 3],"int32"), chunks=3, axis=0, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 3, input(X)'s shape = [760567127, 3], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 2993

[Worker 1] Processing Task 3058: paddle.flatten(Tensor([2, 512, 1, 4194304],"float32"), start_axis=1, stop_axis=-1, )
[accuracy error] paddle.flatten(Tensor([2, 512, 1, 4194304],"float32"), start_axis=1, stop_axis=-1, ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[-0.4474,  0.2424,  0.0117,  ...,  0.2795,  0.1793,  0.0170],
        [ 0.3145,  0.3383,  0.0218,  ..., -0.3380,  0.3975, -0.3524]]),
    expected=tensor([[-0.4474,  0.2424,  0.0117,  ...,  0.2795,  0.1793,  0.0170],
        [ 0.3145,  0.3383,  0.0218,  ..., -0.3380,  0.3975, -0.3524]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 1] Completed Task 3058

[Worker 1] Processing Task 3065: paddle.flatten(Tensor([214748365, 4, 5],"float32"), )
[accuracy error] paddle.flatten(Tensor([214748365, 4, 5],"float32"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([-0.4474,  0.2424,  0.0117,  ..., -0.3755,  0.2100,  0.2772]),
    expected=tensor([-0.4474,  0.2424,  0.0117,  ..., -0.3755,  0.2100,  0.2772]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 1] Completed Task 3065

[Worker 1] Processing Task 3086: paddle.fmin(Tensor([2147483649],"int64"), Tensor([1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.fmin(Tensor([2147483649],"int64"), Tensor([1],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::fmin(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::FMinKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.614258GB memory has been allocated and available memory is only 13.570618GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3086

[Worker 1] Processing Task 3087: paddle.fmin(Tensor([2281701379],"int64"), Tensor([1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.fmin(Tensor([2281701379],"int64"), Tensor([1],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::fmin(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::FMinKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.614258GB memory has been allocated and available memory is only 9.570618GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3087

[Worker 1] Processing Task 3091: paddle.gcd(Tensor([2281701379],"int64"), Tensor([1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.gcd(Tensor([2281701379],"int64"), Tensor([1],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_expand(_object*, _object*, _object*)
1   expand_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>)
2   paddle::experimental::expand(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&)
3   void phi::ExpandKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
6   paddle::memory::allocation::Allocator::Allocate(unsigned long)
7   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
11  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.614258GB memory has been allocated and available memory is only 9.570618GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3091

[Worker 1] Processing Task 3092: paddle.gcd(x=Tensor([2281701379],"int32"), y=Tensor([1],"int32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.gcd(x=Tensor([2281701379],"int32"), y=Tensor([1],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   not_equal_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::not_equal(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::NotEqualRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 2.125000GB memory on GPU 0, 78.124023GB memory has been allocated and available memory is only 1.060852GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3092

[Worker 1] Processing Task 3095: paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([253522376, 3, 3],"float32"), )
W0523 05:08:49.025331 77357 backward.cc:437] While running Node (LerpGradNode) raises an EnforceNotMet exception
[paddle error] paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), Tensor([253522376, 3, 3],"float32"), ) 
 (InvalidArgument) numel is expected to be greater than or equal 0, but received -2013265912.
  [Hint: Expected numel >= 0, but received numel:-2013265912 < 0:0.] (at /paddle/paddle/phi/backends/gpu/gpu_launch_config.h:110)

[Worker 1] Completed Task 3095

[Worker 1] Processing Task 3097: paddle.lerp(Tensor([1],"float32"), Tensor([1],"float32"), Tensor([2281701379],"float32"), )
W0523 05:09:23.796633 77357 backward.cc:437] While running Node (LerpGradNode) raises an EnforceNotMet exception
[paddle error] paddle.lerp(Tensor([1],"float32"), Tensor([1],"float32"), Tensor([2281701379],"float32"), ) 
 (InvalidArgument) numel is expected to be greater than or equal 0, but received -2013265917.
  [Hint: Expected numel >= 0, but received numel:-2013265917 < 0:0.] (at /paddle/paddle/phi/backends/gpu/gpu_launch_config.h:110)

[Worker 1] Completed Task 3097

[Worker 1] Processing Task 3100: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), "fro", )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [2, 126761188, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), "fro", ) 
 (PreconditionNotMet) For batch [95349043]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 1] Completed Task 3100

[Worker 1] Processing Task 3102: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), 1, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [2, 126761188, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), 1, ) 
 (PreconditionNotMet) For batch [95349043]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 1] Completed Task 3102

[Worker 1] Processing Task 3104: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), math.inf, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [2, 126761188, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), math.inf, ) 
 (PreconditionNotMet) For batch [95349043]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 1] Completed Task 3104

[Worker 1] Processing Task 3107: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), 1, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [63380594, 4, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), 1, ) 
 (PreconditionNotMet) For batch [95349043]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 1] Completed Task 3107

[Worker 1] Processing Task 3110: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), -math.inf, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [63380594, 4, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), -math.inf, ) 
 (PreconditionNotMet) For batch [95349043]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 1] Completed Task 3110

[Worker 1] Processing Task 3113: paddle.linalg.det(Tensor([30422686, 3, 5, 5],"float32"), )
[accuracy error] backward  paddle.linalg.det(Tensor([30422686, 3, 5, 5],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 82 / 2281701450 (0.0%)
Greatest absolute difference: 0.07311210036277771 at index (27574712, 0, 3, 0) (up to 0.01 allowed)
Greatest relative difference: 3.0429301261901855 at index (16922831, 1, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([30422686, 3, 5, 5]), dtype=torch.float32)
First 100 elements: tensor([ 2.0591e-04,  1.1940e-03, -1.0547e-04,  3.8962e-04, -6.7143e-04,
         2.3035e-03,  4.5204e-03, -8.7556e-04,  2.1910e-03, -4.3093e-03,
        -3.2514e-04, -1.7781e-03,  4.5449e-04,  1.0334e-05,  1.0978e-03,
        -3.9736e-03, -1.0020e-02,  2.8319e-03, -2.7778e-03,  7.6490e-03,
        -3.1415e-03, -8.0085e-03,  2.0008e-03, -1.9073e-03,  5.6028e-03,
         2.1610e-03, -4.2503e-03,  3.8375e-03,  1.4001e-03, -5.1688e-03,
        -1.6362e-03,  3.3786e-03, -2.6486e-03, -2.1246e-03,  5.3362e-03,
         5.5841e-03, -1.4371e-02,  8.7149e-03,  7.1306e-03, -1.8813e-02,
        -5.8223e-03,  9.5078e-03, -8.0495e-03, -4.1339e-03,  1.3978e-02,
        -1.8358e-03,  3.8296e-04, -1.9052e-03, -9.1003e-05,  9.5644e-04,
         5.8256e-03, -1.3351e-02, -8.3752e-03, -2.9169e-02,  7.1173e-04,
        -3.7489e-03, -8.5082e-03, -9.1200e-03, -8.0691e-03, -8.2300e-03,
        -3.7699e-03, -1.6969e-02,  7.8309e-03, -7.4293e-03,  1.3637e-02,
         1.1316e-02, -2.0268e-02,  8.3999e-04, -3.0595e-02,  1.1691e-03,
        -8.6459e-03,  1.8514e-05,  4.2821e-03, -2.7610e-03, -3.9178e-03,
        -1.2136e-02,  1.3188e-02, -1.3259e-02,  2.4398e-03, -1.0939e-03,
        -9.5233e-03,  3.4415e-03, -8.9531e-04,  6.6495e-03,  9.2050e-03,
         1.0688e-02, -7.6337e-03,  1.1333e-02, -7.8342e-03, -9.6289e-03,
        -4.0014e-03,  1.3027e-02, -1.0624e-02, -6.9324e-03, -1.7211e-03,
         8.1392e-03,  6.2480e-04,  5.7471e-03, -3.1821e-03, -5.2854e-03])
DESIRED: (shape=torch.Size([30422686, 3, 5, 5]), dtype=torch.float32)
First 100 elements: tensor([ 2.0591e-04,  1.1940e-03, -1.0547e-04,  3.8962e-04, -6.7143e-04,
         2.3035e-03,  4.5204e-03, -8.7555e-04,  2.1910e-03, -4.3093e-03,
        -3.2513e-04, -1.7781e-03,  4.5449e-04,  1.0335e-05,  1.0978e-03,
        -3.9736e-03, -1.0020e-02,  2.8319e-03, -2.7777e-03,  7.6489e-03,
        -3.1415e-03, -8.0085e-03,  2.0008e-03, -1.9073e-03,  5.6028e-03,
         2.1610e-03, -4.2503e-03,  3.8375e-03,  1.4001e-03, -5.1688e-03,
        -1.6362e-03,  3.3787e-03, -2.6486e-03, -2.1246e-03,  5.3362e-03,
         5.5841e-03, -1.4371e-02,  8.7149e-03,  7.1306e-03, -1.8813e-02,
        -5.8223e-03,  9.5078e-03, -8.0495e-03, -4.1339e-03,  1.3978e-02,
        -1.8358e-03,  3.8296e-04, -1.9052e-03, -9.1003e-05,  9.5644e-04,
         5.8256e-03, -1.3351e-02, -8.3751e-03, -2.9169e-02,  7.1173e-04,
        -3.7489e-03, -8.5082e-03, -9.1200e-03, -8.0691e-03, -8.2300e-03,
        -3.7699e-03, -1.6969e-02,  7.8309e-03, -7.4293e-03,  1.3637e-02,
         1.1316e-02, -2.0268e-02,  8.3999e-04, -3.0595e-02,  1.1691e-03,
        -8.6459e-03,  1.8515e-05,  4.2821e-03, -2.7610e-03, -3.9178e-03,
        -1.2136e-02,  1.3188e-02, -1.3259e-02,  2.4398e-03, -1.0939e-03,
        -9.5233e-03,  3.4415e-03, -8.9531e-04,  6.6495e-03,  9.2050e-03,
         1.0688e-02, -7.6337e-03,  1.1333e-02, -7.8342e-03, -9.6289e-03,
        -4.0014e-03,  1.3027e-02, -1.0624e-02, -6.9324e-03, -1.7211e-03,
         8.1392e-03,  6.2480e-04,  5.7471e-03, -3.1821e-03, -5.2854e-03])
[Worker 1] Completed Task 3113

[Worker 1] Processing Task 3118: paddle.maximum(Tensor([1],"float32"), Tensor([4294967295],"float32"), )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.12 GiB is free. Process 32234 has 70.06 GiB memory in use. Of the allocated memory 68.02 GiB is allocated by PyTorch, and 5.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 3118: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.12 GiB is free. Process 32234 has 70.06 GiB memory in use. Of the allocated memory 68.02 GiB is allocated by PyTorch, and 5.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 3118: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.12 GiB is free. Process 32234 has 70.06 GiB memory in use. Of the allocated memory 68.02 GiB is allocated by PyTorch, and 5.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3121: paddle.maximum(Tensor([4294967295],"float32"), Tensor([1],"float32"), )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 5979 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 3121: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 5979 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 3121: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.58 GiB is free. Process 5979 has 69.60 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3126: paddle.nanmean(Tensor([1431655765, 3],"float32"), None, True, )
W0523 05:15:16.748499 78532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:15:16.750516 78532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3130: paddle.nanmean(Tensor([2, 107374183, 4, 5],"float32"), None, False, )
W0523 05:45:36.835152 78914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:45:36.836742 78914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3134: paddle.nanmean(Tensor([2, 2147483648],"float32"), None, False, )
W0523 06:15:46.220912 79293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:15:46.221921 79293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3138: paddle.nanmean(Tensor([2, 3, 143165577, 5],"float32"), list[], False, )
W0523 06:45:54.029047 79674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:45:54.030037 79674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3142: paddle.nanmean(Tensor([2, 3, 143165577, 5],"float32"), None, True, )
W0523 07:15:58.198007 80052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:15:58.199355 80052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3146: paddle.nanmean(Tensor([2, 3, 4, 178956971],"float32"), list[0,1,2,3,], False, )
W0523 07:46:19.894599 80434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:46:19.895581 80434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3150: paddle.nanmean(Tensor([3, 1431655765],"float32"), keepdim=True, )
W0523 08:16:28.050091 80814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:16:28.051083 80814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3154: paddle.nanmean(Tensor([71582789, 3, 4, 5],"float32"), list[0,2,], False, )
W0523 08:46:33.236235 81193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:46:33.237293 81193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3158: paddle.nanmean(Tensor([858993459, 5],"float32"), axis=None, )
W0523 09:16:47.137624 81573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:16:47.138625 81573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3162: paddle.nn.functional.normalize(Tensor([2, 2147483649],"float16"), p=2, axis=-1, )
W0523 09:47:10.790751 81953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:47:10.791707 81953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(Tensor([2, 2147483649],"float16"), p=2, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4294967298 / 4294967298 (100.0%)
Greatest absolute difference: nan at index (0, 30117681) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 30117681) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 2147483649]), dtype=torch.float16)
First 100 elements: tensor([-inf, inf, -inf, -inf, inf, -inf, -inf, -inf, inf, -inf, inf, -inf, inf, -inf, -inf, inf, inf, -inf, inf, -inf, inf, inf, inf, inf,
        -inf, inf, inf, -inf, inf, inf, inf, inf, -inf, -inf, -inf, -inf, -inf, inf, inf, -inf, -inf, inf, inf, -inf, -inf, -inf, inf, -inf,
        inf, inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, inf, -inf, inf, inf, -inf, -inf, -inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, -inf,
        -inf, inf, inf, inf, -inf, -inf, inf, inf, inf, -inf, inf, -inf, inf, inf, inf, -inf, inf, inf, inf, -inf, -inf, inf, inf, inf,
        -inf, -inf, inf, inf], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 2147483649]), dtype=torch.float16)
First 100 elements: tensor([-6.5565e-06,  3.4153e-05, -2.6941e-05, -1.8835e-05,  4.8280e-06,
        -2.9862e-05, -2.4319e-05, -2.9385e-05,  1.1206e-05, -4.8280e-06,
         3.3498e-05, -1.7405e-05,  1.8716e-05, -2.2352e-05, -3.4630e-05,
         2.0683e-05,  3.8147e-06, -1.9789e-05,  2.8133e-05, -1.9073e-05,
         5.0068e-06,  3.7313e-05,  5.7817e-06,  3.2842e-05, -4.5896e-06,
         2.2113e-05,  2.9504e-05, -2.7895e-05,  1.7524e-05,  1.9073e-06,
         9.0599e-06,  1.3471e-05, -3.5763e-06, -1.3173e-05, -7.1526e-06,
        -5.3644e-06, -1.9372e-05,  8.7023e-06,  2.3007e-05, -2.3186e-05,
        -2.6882e-05,  7.5698e-06,  3.1292e-05, -3.2365e-05, -9.8348e-06,
        -3.6478e-05,  1.8477e-06, -1.9073e-06,  3.5763e-05,  2.1279e-05,
        -2.5034e-06, -3.4571e-06, -3.4928e-05,  3.4451e-05, -2.6882e-05,
        -1.2875e-05, -1.9491e-05,  2.8193e-05, -8.8811e-06,  2.9802e-07,
         1.3113e-05, -1.0490e-05, -1.8597e-05, -3.3319e-05, -1.7166e-05,
        -6.0201e-06, -6.3777e-06,  3.1292e-05, -2.1696e-05, -3.6538e-05,
        -2.3603e-05, -1.9014e-05, -2.9564e-05,  5.3048e-06,  1.3769e-05,
         3.6836e-05, -3.2187e-05, -1.1444e-05,  3.0696e-05,  1.7226e-05,
         2.5332e-05, -2.8014e-06,  3.2783e-06, -2.8968e-05,  2.0206e-05,
         1.6809e-05,  3.4273e-05, -1.2934e-05,  2.5630e-05,  1.0192e-05,
         1.0431e-05, -7.1526e-06, -2.9802e-05,  2.3007e-05,  2.1458e-06,
         2.9743e-05, -2.8908e-05, -2.0087e-05,  2.7359e-05,  6.3181e-06],
       dtype=torch.float16)
[Worker 1] Completed Task 3162

[Worker 1] Processing Task 3168: paddle.nn.functional.normalize(Tensor([4294967295],"float32"), axis=0, epsilon=1e-12, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 34090 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Error on Task 3168: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 34090 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] OOM on Task 3168: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 34090 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Started on GPU 1

[Worker 1] Processing Task 3173: paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), 0, 1e-06, False, None, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
W0523 09:49:49.534605 82505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:49:49.535794 82505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), 0, 1e-06, False, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 2 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2]), dtype=torch.float16)
All elements: tensor([0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([2]), dtype=torch.float16)
All elements: tensor([inf, inf], dtype=torch.float16)
[Worker 1] Completed Task 3173

[Worker 1] Processing Task 3175: paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), 2, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), 2, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3175

[Worker 1] Processing Task 3177: paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), -math.inf, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2, 2147483649],"float16"), Tensor([2, 2147483649],"float16"), -math.inf, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3177

[Worker 1] Processing Task 3178: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.06 GiB is free. Process 62727 has 75.12 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3178

[Worker 1] Processing Task 3181: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 1, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 1, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.06 GiB is free. Process 62727 has 75.12 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3181

[Worker 1] Processing Task 3182: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -1, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -1, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.06 GiB is free. Process 62727 has 75.12 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3182

[Worker 1] Processing Task 3184: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -1, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -1, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.06 GiB is free. Process 62727 has 75.12 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3184

[Worker 1] Processing Task 3186: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 2, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 2, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.06 GiB is free. Process 62727 has 75.12 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3186

[Worker 1] Processing Task 3188: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -math.inf, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -math.inf, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.06 GiB is free. Process 62727 has 75.12 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3188

[Worker 1] Processing Task 3190: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -math.inf, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), -math.inf, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.06 GiB is free. Process 62727 has 75.12 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3190

[Worker 1] Processing Task 3192: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 0, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 0, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3192

[Worker 1] Processing Task 3194: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -1, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -1, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3194

[Worker 1] Processing Task 3196: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -1, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -1, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3196

[Worker 1] Processing Task 3198: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 2, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 2, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3198

[Worker 1] Processing Task 3200: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -math.inf, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -math.inf, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3200

[Worker 1] Processing Task 3202: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -math.inf, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), -math.inf, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3202

[Worker 1] Processing Task 3204: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=False, reduction="none", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=False, reduction="none", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3204

[Worker 1] Processing Task 3206: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=True, reduction="mean", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3206

[Worker 1] Processing Task 3208: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=False, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=False, reduction="mean", name=None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3208

[Worker 1] Processing Task 3210: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=False, reduction="sum", name=None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3210

[Worker 1] Processing Task 3212: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([858993460, 5],"float16"), Tensor([858993460, 5],"float16"), Tensor([858993460, 5],"float16"), margin=0.3, swap=False, reduction="sum", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([858993460, 5],"float16"), Tensor([858993460, 5],"float16"), Tensor([858993460, 5],"float16"), margin=0.3, swap=False, reduction="sum", name=None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 62727 has 73.62 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 1] Completed Task 3212

[Worker 1] Processing Task 3214: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([10, 3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([10, 3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [30, 0], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:30 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 1] Completed Task 3214

[Worker 1] Processing Task 3216: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([2, 2],"float32"),Tensor([2],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([2, 2],"float32"),Tensor([2],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [4, 2], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:6 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 1] Completed Task 3216

[Worker 1] Processing Task 3219: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([3, 2, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([3, 2, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [24, 3], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:27 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 1] Completed Task 3219

[Worker 1] Processing Task 3221: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([64, 8],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),Tensor([64, 16],"float32"),Tensor([64, 16],"float32"),Tensor([64],"float32"),Tensor([64],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [512, 1024, 64, 64, 1024, 1024, 64, 64], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:3840 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 1] Completed Task 3221

[Worker 1] Processing Task 3229: paddle.sum(Tensor([1431655765, 3],"bool"), axis=-1, keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([1431655765, 3],"bool"), axis=-1, keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 52.270508GB memory has been allocated and available memory is only 26.914368GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3229

[Worker 1] Processing Task 3245: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[0,2,], keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[0,2,], keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.612305GB memory has been allocated and available memory is only 1.572571GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3245

[Worker 1] Processing Task 3250: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=tuple(0,2,), keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=tuple(0,2,), keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.612305GB memory has been allocated and available memory is only 1.572571GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3250

[Worker 1] Processing Task 3260: paddle.sum(Tensor([2, 2147483648],"bool"), axis=0, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 2147483648],"bool"), axis=0, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 57.602539GB memory has been allocated and available memory is only 21.582336GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3260

[Worker 1] Processing Task 3300: paddle.sum(Tensor([2, 3, 715827883],"int32"), axis=tuple(0,1,), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 3, 715827883],"int32"), axis=tuple(0,1,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<int, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 70.942383GB memory has been allocated and available memory is only 8.242493GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3300

[Worker 1] Processing Task 3312: paddle.sum(Tensor([3, 715827883, 2],"int32"), axis=0, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([3, 715827883, 2],"int32"), axis=0, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<int, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 76.276367GB memory has been allocated and available memory is only 2.908508GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3312

[Worker 1] Processing Task 3323: paddle.sum(Tensor([536870912, 4, 2],"int32"), axis=1, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([536870912, 4, 2],"int32"), axis=1, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<int, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 73.602539GB memory has been allocated and available memory is only 5.582336GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 1] Completed Task 3323

[Worker 1] Processing Task 3346: paddle.Tensor.chunk(Tensor([1, 1, 1, 2281701379],"float32"), 4, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 1, 1, 2281701379],"float32"), 4, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [1, 1, 1, 2281701379], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:3 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 3346

[Worker 1] Processing Task 3350: paddle.Tensor.chunk(Tensor([1, 1, 2281701379],"float32"), 2, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 1, 2281701379],"float32"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 1, 2281701379], Attr(dim) = 2.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 3350

[Worker 1] Processing Task 3354: paddle.Tensor.chunk(Tensor([1, 102, 1, 22369622],"float32"), 4, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 102, 1, 22369622],"float32"), 4, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [1, 102, 1, 22369622], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 3354

[Worker 1] Processing Task 3358: paddle.Tensor.chunk(Tensor([1901418, 300, 4],"float32"), 4, )
[paddle error] paddle.Tensor.chunk(Tensor([1901418, 300, 4],"float32"), 4, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [1901418, 300, 4], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 3358

[Worker 1] Processing Task 3362: paddle.Tensor.chunk(Tensor([950709, 300, 8],"float32"), 8, )
[paddle error] paddle.Tensor.chunk(Tensor([950709, 300, 8],"float32"), 8, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 8, input(X)'s shape = [950709, 300, 8], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:5 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 1] Completed Task 3362

[Worker 2] Processing Task 152: paddle.bucketize(Tensor([1073741825, 4],"float16"), Tensor([4],"float16"), )
[accuracy error] paddle.bucketize(Tensor([1073741825, 4],"float16"), Tensor([4],"float16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[2, 0, 2, 3],
        [3, 0, 0, 0],
        [3, 2, 2, 0],
        ...,
        [2, 3, 0, 4],
        [3, 2, 0, 2],
        [2, 2, 2, 0]]),
    expected=tensor([[2, 0, 2, 3],
        [3, 0, 0, 0],
        [3, 2, 2, 0],
        ...,
        [2, 3, 0, 4],
        [3, 2, 0, 2],
        [2, 2, 2, 0]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 152

[Worker 2] Processing Task 155: paddle.bucketize(Tensor([2, 2147483649],"float16"), Tensor([4],"float16"), )
[accuracy error] paddle.bucketize(Tensor([2, 2147483649],"float16"), Tensor([4],"float16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[2, 0, 2,  ..., 0, 3, 0],
        [0, 2, 2,  ..., 2, 2, 2]]),
    expected=tensor([[2, 0, 2,  ..., 0, 3, 0],
        [0, 2, 2,  ..., 2, 2, 2]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 155

[Worker 2] Processing Task 193: paddle.conj(Tensor([35791395, 20, 2, 3],"float32"), )
W0522 15:56:23.713701 42880 backward.cc:441] While running Node (ConjGradNode) raises a std::exception: paddle::memory::allocation::BadAlloc
[paddle error] paddle.conj(Tensor([35791395, 20, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   ConjGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::conj(paddle::Tensor const&)
4   void phi::ConjKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.610352GB memory has been allocated and available memory is only 13.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 193

[Worker 2] Processing Task 198: paddle.diff(Tensor([2, 1140850690],"float32"), n=1, axis=0, prepend=Tensor([3, 1140850690],"float32"), append=None, )
[accuracy error] paddle.diff(Tensor([2, 1140850690],"float32"), n=1, axis=0, prepend=Tensor([3, 1140850690],"float32"), append=None, ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]),
    expected=tensor([[ 0.3969, -0.2088,  0.6377,  ...,  0.1079,  0.3168, -0.1130],
        [-0.8952,  0.2140, -0.2934,  ...,  0.3115, -0.8565, -0.3990],
        [ 0.4983, -0.0052, -0.3443,  ..., -0.4194,  0.5397,  0.5120],
        [ 0.3969, -0.2088,  0.6377,  ...,  0.1079,  0.3168, -0.1130]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 198

[Worker 2] Processing Task 201: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235837850 / 2281701384 (98.0%)
Greatest absolute difference: 0.9999746084213257 at index (549500817, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425346, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425346, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.2093,  0.3196,  0.0865,  0.2890, -0.2093, -0.3196, -0.0865, -0.2890,
         0.2093,  0.3196,  0.0865,  0.2890, -0.0473,  0.2553,  0.0086,  0.0398,
        -0.1453,  0.0104,  0.3966, -0.3019,  0.3965, -0.7052, -0.2672,  0.4283,
        -0.2652, -0.1314,  0.3139, -0.2519, -0.2535,  0.0483, -0.4961, -0.4139,
         0.4759,  0.1276,  0.0207,  0.1059, -0.7802, -0.0582, -0.0432, -0.3045,
         0.0847,  0.6371,  0.0298,  0.8256,  0.4863, -0.5617,  0.3838, -0.2934,
         0.0652,  0.4282,  0.2665, -0.1076, -0.1592, -0.0023, -0.0431, -0.2054,
         0.0863, -0.5192, -0.6710,  0.1230, -0.3704,  0.2325,  0.7059,  0.2984,
         0.1406,  0.0383, -0.7280, -0.2369, -0.0967,  0.4364,  0.3426, -0.3569,
         0.1623, -0.8249, -0.1951,  0.7001,  0.2319,  0.6928,  0.6853, -0.7661,
        -0.3780, -0.0489, -0.7881,  0.8291,  0.1953, -0.2112,  0.6619, -0.2346,
        -0.2726, -0.2020, -0.4083,  0.2336,  0.5620,  0.0030, -0.1615, -0.5681,
        -0.7416,  0.2654, -0.1884,  0.2596])
[Worker 2] Completed Task 201

[Worker 2] Processing Task 205: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([570425345, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2258654641 / 2281701380 (99.0%)
Greatest absolute difference: 1.998149037361145 at index (442093111, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([-0.4185, -0.6392, -0.1730, -0.5780,  0.4185,  0.6392,  0.1730,  0.5780,
        -0.2565, -0.0643, -0.0778, -0.2493, -0.0980, -0.2449,  0.3880, -0.3417,
         0.5418, -0.7157, -0.6639,  0.7303, -0.6617,  0.5739,  0.5811, -0.6803,
         0.0116,  0.1797, -0.8100, -0.1620,  0.7295,  0.0792,  0.5168,  0.5198,
        -1.2561, -0.1858, -0.0640, -0.4104,  0.8649,  0.6953,  0.0730,  1.1300,
         0.4015, -1.1988,  0.3540, -1.1190, -0.4210,  0.9899, -0.1173,  0.1858,
        -0.2245, -0.4305, -0.3096, -0.0977,  0.2455, -0.5170, -0.6279,  0.3284,
        -0.4567,  0.7518,  1.3769,  0.1754,  0.5109, -0.1943, -1.4339, -0.5353,
        -0.2372,  0.3981,  1.0707, -0.1200,  0.2590, -1.2613, -0.5378,  1.0570,
         0.0697,  1.5178,  0.8804, -1.4661, -0.6100, -0.7417, -1.4734,  1.5952,
         0.5733, -0.1623,  1.4501, -1.0636, -0.4679,  0.0092, -1.0703,  0.4682,
         0.8346,  0.2050,  0.2469, -0.8017, -1.3036,  0.2624, -0.0270,  0.8277,
         1.3540, -0.3156,  1.0167,  0.0781])
[Worker 2] Completed Task 205

[Worker 2] Processing Task 209: paddle.diff(Tensor([2281701379],"float32"), )
[accuracy error] paddle.diff(Tensor([2281701379],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235845823 / 2281701378 (98.0%)
Greatest absolute difference: 0.9999758005142212 at index (1915220481,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([-1.4004e-01, -2.1138e-01,  2.5225e-01,  3.0844e-01, -2.9697e-02,
        -4.4451e-01,  4.5478e-01, -2.7843e-02,  2.7284e-01, -6.9113e-01,
         4.8589e-01, -2.1287e-01,  4.2852e-01, -3.0492e-01, -2.1267e-01,
         4.8556e-01, -6.7321e-01,  1.3309e-01,  4.8290e-01, -2.0795e-01,
        -5.3940e-01,  5.7835e-01, -8.2933e-02, -2.0957e-01, -2.3751e-01,
         3.3938e-02, -7.6127e-04,  6.8025e-01, -5.8585e-01, -7.2888e-02,
         8.4416e-02, -2.0584e-01,  1.3613e-01, -5.7912e-02, -1.7683e-01,
         1.8335e-01,  6.8850e-01, -6.6522e-01,  6.1895e-01, -1.5595e-01,
        -3.5951e-01,  2.8030e-01, -5.8273e-02,  2.0273e-01,  3.4587e-03,
         1.1862e-01, -4.3245e-01,  1.5112e-01,  1.6044e-01,  7.7783e-02,
        -5.9470e-01,  4.4278e-01, -4.4509e-01, -7.3992e-02,  1.9932e-01,
        -5.0604e-02,  1.5781e-01,  3.9933e-01, -2.0811e-01, -2.0846e-01,
         5.5511e-02, -3.6698e-01,  2.8300e-01, -6.8200e-02,  5.8856e-01,
        -4.6072e-01, -4.1658e-01,  4.5104e-01, -3.9866e-01,  1.6908e-01,
         4.7859e-01, -1.7057e-02,  6.2237e-02,  1.6150e-01, -9.7278e-01,
         3.7101e-01,  3.9140e-01, -5.7775e-01,  6.4441e-01, -2.6280e-01,
        -1.5039e-02,  2.9537e-01, -2.5209e-01, -3.0082e-01,  5.5527e-02,
         8.9052e-02,  3.8985e-01,  2.7616e-02, -5.0353e-01, -7.5411e-02,
        -1.6745e-02, -1.4589e-01,  5.0341e-01, -5.2922e-01,  4.3131e-01,
         2.0688e-01, -1.5921e-01,  3.4929e-01, -5.9287e-02,  1.4829e-02])
[Worker 2] Completed Task 209

[Worker 2] Processing Task 213: paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4],"float32"), )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235837846 / 2281701380 (98.0%)
Greatest absolute difference: 0.9999746084213257 at index (549500815, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([570425345, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.2093,  0.3196,  0.0865,  0.2890, -0.0473,  0.2553,  0.0086,  0.0398,
        -0.1453,  0.0104,  0.3966, -0.3019,  0.3965, -0.7052, -0.2672,  0.4283,
        -0.2652, -0.1314,  0.3139, -0.2519, -0.2535,  0.0483, -0.4961, -0.4139,
         0.4759,  0.1276,  0.0207,  0.1059, -0.7802, -0.0582, -0.0432, -0.3045,
         0.0847,  0.6371,  0.0298,  0.8256,  0.4863, -0.5617,  0.3838, -0.2934,
         0.0652,  0.4282,  0.2665, -0.1076, -0.1592, -0.0023, -0.0431, -0.2054,
         0.0863, -0.5192, -0.6710,  0.1230, -0.3704,  0.2325,  0.7059,  0.2984,
         0.1406,  0.0383, -0.7280, -0.2369, -0.0967,  0.4364,  0.3426, -0.3569,
         0.1623, -0.8249, -0.1951,  0.7001,  0.2319,  0.6928,  0.6853, -0.7661,
        -0.3780, -0.0489, -0.7881,  0.8291,  0.1953, -0.2112,  0.6619, -0.2346,
        -0.2726, -0.2020, -0.4083,  0.2336,  0.5620,  0.0030, -0.1615, -0.5681,
        -0.7416,  0.2654, -0.1884,  0.2596,  0.6124, -0.0502,  0.8283,  0.3377,
         0.1456, -0.1079, -0.9037, -0.4639])
[Worker 2] Completed Task 213

[Worker 2] Processing Task 217: paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, )
[accuracy error] paddle.diff(Tensor([570425345, 4],"float32"), n=1, axis=0, prepend=Tensor([570425345, 4],"float32"), append=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4471675688 / 4563402756 (98.0%)
Greatest absolute difference: 0.9999746084213257 at index (549500815, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1140850689, 4]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([1140850689, 4]), dtype=torch.float32)
First 100 elements: tensor([ 0.2093,  0.3196,  0.0865,  0.2890, -0.0473,  0.2553,  0.0086,  0.0398,
        -0.1453,  0.0104,  0.3966, -0.3019,  0.3965, -0.7052, -0.2672,  0.4283,
        -0.2652, -0.1314,  0.3139, -0.2519, -0.2535,  0.0483, -0.4961, -0.4139,
         0.4759,  0.1276,  0.0207,  0.1059, -0.7802, -0.0582, -0.0432, -0.3045,
         0.0847,  0.6371,  0.0298,  0.8256,  0.4863, -0.5617,  0.3838, -0.2934,
         0.0652,  0.4282,  0.2665, -0.1076, -0.1592, -0.0023, -0.0431, -0.2054,
         0.0863, -0.5192, -0.6710,  0.1230, -0.3704,  0.2325,  0.7059,  0.2984,
         0.1406,  0.0383, -0.7280, -0.2369, -0.0967,  0.4364,  0.3426, -0.3569,
         0.1623, -0.8249, -0.1951,  0.7001,  0.2319,  0.6928,  0.6853, -0.7661,
        -0.3780, -0.0489, -0.7881,  0.8291,  0.1953, -0.2112,  0.6619, -0.2346,
        -0.2726, -0.2020, -0.4083,  0.2336,  0.5620,  0.0030, -0.1615, -0.5681,
        -0.7416,  0.2654, -0.1884,  0.2596,  0.6124, -0.0502,  0.8283,  0.3377,
         0.1456, -0.1079, -0.9037, -0.4639])
[Worker 2] Completed Task 217

[Worker 2] Processing Task 226: paddle.diff(x=Tensor([10, 429496730],"float16"), axis=0, prepend=Tensor([4, 429496730],"float16"), append=Tensor([4, 429496730],"float16"), )
[accuracy error] paddle.diff(x=Tensor([10, 429496730],"float16"), axis=0, prepend=Tensor([4, 429496730],"float16"), append=Tensor([4, 429496730],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 7154578263 / 7301444410 (98.0%)
Greatest absolute difference: 1.0 at index (0, 5523968) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([17, 429496730]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([17, 429496730]), dtype=torch.float16)
First 100 elements: tensor([-5.7129e-01,  5.4150e-01, -6.5918e-01, -1.1157e-01, -3.9258e-01,
         4.7729e-01,  4.5410e-02,  7.5244e-01, -4.6509e-01,  1.2891e-01,
        -4.8828e-04, -2.5146e-02, -2.2144e-01, -2.6367e-02,  4.6936e-02,
        -2.1082e-01, -2.4268e-01,  5.7275e-01, -2.2241e-01,  3.1152e-01,
         7.3291e-01, -2.2583e-01, -8.1055e-02,  4.0039e-02, -5.9912e-01,
        -2.9541e-02,  3.7134e-01, -2.7759e-01, -4.5630e-01,  3.0054e-01,
        -4.2480e-01, -2.9297e-03, -2.4536e-02, -1.0065e-01,  6.3770e-01,
         4.0625e-01, -9.7656e-03, -5.0195e-01, -5.4565e-02, -8.0469e-01,
        -2.5464e-01,  4.3457e-01,  2.4506e-02, -3.7183e-01,  3.3911e-01,
        -5.8887e-01,  9.2480e-01, -1.7285e-01, -3.0054e-01,  6.4990e-01,
         1.6870e-01, -4.6826e-01, -1.1603e-01,  7.1094e-01, -4.1943e-01,
         7.0312e-01, -1.6394e-01, -1.0693e-01, -2.7197e-01, -7.5439e-02,
         1.2006e-01,  6.6650e-02, -9.2407e-02,  3.4570e-01,  6.2500e-02,
        -3.9062e-01, -4.8413e-01,  9.7656e-02,  2.7222e-02,  8.2886e-02,
        -7.2559e-01, -2.1387e-01, -1.7688e-01,  1.9385e-01, -1.4893e-02,
         1.2158e-01, -7.7637e-01,  5.0232e-02, -2.4976e-01,  1.2585e-01,
        -8.3740e-02,  4.0137e-01,  4.3066e-01,  5.3027e-01,  4.0015e-01,
         5.9424e-01,  1.5137e-02,  8.2520e-01,  3.1152e-01, -1.8921e-02,
         5.0537e-02,  1.8335e-01,  5.0781e-02, -2.7686e-01, -4.5557e-01,
         2.5024e-01, -5.5078e-01, -1.2085e-01, -5.5859e-01,  9.4043e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 226

[Worker 2] Processing Task 231: paddle.diff(x=Tensor([2281701379],"float32"), )
[accuracy error] paddle.diff(x=Tensor([2281701379],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2235845823 / 2281701378 (98.0%)
Greatest absolute difference: 0.9999758005142212 at index (1915220481,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.float32)
First 100 elements: tensor([-1.4004e-01, -2.1138e-01,  2.5225e-01,  3.0844e-01, -2.9697e-02,
        -4.4451e-01,  4.5478e-01, -2.7843e-02,  2.7284e-01, -6.9113e-01,
         4.8589e-01, -2.1287e-01,  4.2852e-01, -3.0492e-01, -2.1267e-01,
         4.8556e-01, -6.7321e-01,  1.3309e-01,  4.8290e-01, -2.0795e-01,
        -5.3940e-01,  5.7835e-01, -8.2933e-02, -2.0957e-01, -2.3751e-01,
         3.3938e-02, -7.6127e-04,  6.8025e-01, -5.8585e-01, -7.2888e-02,
         8.4416e-02, -2.0584e-01,  1.3613e-01, -5.7912e-02, -1.7683e-01,
         1.8335e-01,  6.8850e-01, -6.6522e-01,  6.1895e-01, -1.5595e-01,
        -3.5951e-01,  2.8030e-01, -5.8273e-02,  2.0273e-01,  3.4587e-03,
         1.1862e-01, -4.3245e-01,  1.5112e-01,  1.6044e-01,  7.7783e-02,
        -5.9470e-01,  4.4278e-01, -4.4509e-01, -7.3992e-02,  1.9932e-01,
        -5.0604e-02,  1.5781e-01,  3.9933e-01, -2.0811e-01, -2.0846e-01,
         5.5511e-02, -3.6698e-01,  2.8300e-01, -6.8200e-02,  5.8856e-01,
        -4.6072e-01, -4.1658e-01,  4.5104e-01, -3.9866e-01,  1.6908e-01,
         4.7859e-01, -1.7057e-02,  6.2237e-02,  1.6150e-01, -9.7278e-01,
         3.7101e-01,  3.9140e-01, -5.7775e-01,  6.4441e-01, -2.6280e-01,
        -1.5039e-02,  2.9537e-01, -2.5209e-01, -3.0082e-01,  5.5527e-02,
         8.9052e-02,  3.8985e-01,  2.7616e-02, -5.0353e-01, -7.5411e-02,
        -1.6745e-02, -1.4589e-01,  5.0341e-01, -5.2922e-01,  4.3131e-01,
         2.0688e-01, -1.5921e-01,  3.4929e-01, -5.9287e-02,  1.4829e-02])
[Worker 2] Completed Task 231

[Worker 2] Processing Task 235: paddle.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), )
[accuracy error] paddle.diff(x=Tensor([4294967297],"float16"), prepend=Tensor([4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208563076 / 4294967300 (98.0%)
Greatest absolute difference: 1.0 at index (1074617,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967300]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967300]), dtype=torch.float16)
First 100 elements: tensor([-0.2917,  0.3584,  0.1702, -0.2367, -0.2917,  0.3584,  0.1702, -0.0962,
        -0.6499, -0.1025,  0.0603,  0.7686, -0.3691,  0.0866, -0.5742,  0.6475,
        -0.5532,  0.3674,  0.0135, -0.0408, -0.3496,  0.6274, -0.1426, -0.4463,
         0.2390, -0.2385, -0.1282,  0.6006, -0.4492,  0.0262,  0.6392, -0.3594,
         0.1372, -0.2031, -0.0444, -0.0270,  0.2007, -0.4402, -0.1250,  0.6313,
         0.2993, -0.4490,  0.4104, -0.4351,  0.0262, -0.0999,  0.2224, -0.1462,
         0.4773, -0.8999,  0.4990,  0.0191, -0.5244,  0.1960,  0.5952, -0.3621,
        -0.2959,  0.5322, -0.5693,  0.3347,  0.4509, -0.0117, -0.4233, -0.2290,
         0.6362, -0.1482, -0.4077, -0.3398,  0.4304,  0.4958, -0.8242,  0.2216,
         0.3552,  0.0924, -0.1693, -0.0399, -0.0359,  0.2168, -0.0586,  0.2031,
        -0.5459,  0.1797,  0.0782, -0.1566, -0.0103, -0.0680, -0.1600,  0.3401,
        -0.4451,  0.7500, -0.8667,  0.1667,  0.2063,  0.1859, -0.2285, -0.1942,
         0.2323,  0.3079, -0.2554,  0.5410], dtype=torch.float16)
[Worker 2] Completed Task 235

[Worker 2] Processing Task 240: paddle.digamma(Tensor([10, 10, 42949673],"float16"), )
[accuracy error] paddle.digamma(Tensor([10, 10, 42949673],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294967300 (0.0%)
Greatest absolute difference: nan at index (0, 0, 12568207) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 12568207) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 10, 42949673]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4331e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([10, 10, 42949673]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4343e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 240

[Worker 2] Processing Task 244: paddle.digamma(Tensor([2, 1073741825, 2],"float16"), )
[accuracy error] paddle.digamma(Tensor([2, 1073741825, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294967300 (0.0%)
Greatest absolute difference: nan at index (0, 6284103, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 6284103, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1073741825, 2]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4331e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 1073741825, 2]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4343e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 244

[Worker 2] Processing Task 248: paddle.digamma(Tensor([42949673, 10, 10],"float16"), )
[accuracy error] paddle.digamma(Tensor([42949673, 10, 10],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294967300 (0.0%)
Greatest absolute difference: nan at index (125682, 0, 7) (up to 0.01 allowed)
Greatest relative difference: nan at index (125682, 0, 7) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([42949673, 10, 10]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4331e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([42949673, 10, 10]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4343e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 248

[Worker 2] Processing Task 252: paddle.digamma(Tensor([8, 524289, 32, 32],"float16"), )
[accuracy error] paddle.digamma(Tensor([8, 524289, 32, 32],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294975488 (0.0%)
Greatest absolute difference: nan at index (0, 12273, 20, 15) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 12273, 20, 15) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([8, 524289, 32, 32]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4331e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([8, 524289, 32, 32]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4343e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 252

[Worker 2] Processing Task 256: paddle.digamma(x=Tensor([3, 1431655766],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([3, 1431655766],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294967298 (0.0%)
Greatest absolute difference: nan at index (0, 12568207) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 12568207) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4331e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4343e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 256

[Worker 2] Processing Task 260: paddle.digamma(x=Tensor([3, 6628036, 6, 6, 6],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([3, 6628036, 6, 6, 6],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 58186, 0, 5, 1) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 58186, 0, 5, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 6628036, 6, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4331e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 6628036, 6, 6, 6]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4343e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 260

[Worker 2] Processing Task 264: paddle.digamma(x=Tensor([6, 6, 119304648],"float16"), )
[accuracy error] paddle.digamma(x=Tensor([6, 6, 119304648],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294967328 (0.0%)
Greatest absolute difference: nan at index (0, 0, 12568207) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 12568207) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([6, 6, 119304648]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4331e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([6, 6, 119304648]), dtype=torch.float16)
First 100 elements: tensor([-4.7773e+00,  1.3539e+01, -3.6543e+00, -2.1855e+00, -2.8633e+00,
         2.2891e+00,  1.0557e+00,  1.7217e+00, -2.3047e+00, -1.4953e+01,
        -6.7734e+00,  7.8027e-01, -4.6250e+00,  1.7910e+00, -2.3750e+01,
        -1.8188e+01, -6.4500e+01,  1.6738e+00, -3.5840e+00, -6.9805e+00,
         2.1777e+00,  1.7062e+01,  2.1855e+00,  7.3633e-01, -5.9570e+00,
         2.5371e+00,  3.0000e+00, -2.6074e+00, -2.9625e+01, -6.1523e+00,
         3.1094e+01,  1.2461e+01,  8.9609e+00, -1.0648e+01,  1.5752e+00,
         3.2959e-01, -6.4258e+00, -2.1543e+00, -6.9312e+01, -2.3887e+00,
         9.9750e+01, -6.2156e+01,  1.1227e+01, -7.5742e+00,  1.3488e+02,
        -2.1191e+00,  6.7188e-01, -1.4914e+01, -1.1766e+01,  6.1475e-01,
         3.1055e+00, -2.9238e+00,  1.4325e+02,  2.0762e+00, -4.6133e+00,
         1.6016e+00,  1.8512e+02, -2.2598e+00, -2.3320e+00, -9.6875e+01,
         3.5645e+00, -2.4375e+00, -3.9141e+00,  6.4062e+00,  2.3291e-01,
         2.0312e+01, -2.2441e+00,  1.2061e+00,  5.6211e+00, -5.2617e+00,
        -3.5840e+00, -8.4453e+00, -1.2320e+01, -2.1172e+01, -3.9805e+00,
        -5.1211e+00, -2.4922e+00,  6.5273e+00, -2.3406e+01, -8.5938e+00,
         2.8234e+01,  2.1594e+01,  8.0781e+00,  2.5176e+00, -1.5352e+01,
         1.1836e+00, -2.7754e+00,  8.6670e-02,  1.7510e+00,  7.4453e+00,
        -1.5961e+01,  5.2148e+00,  1.3955e+00,  7.1406e+00, -5.8047e+00,
         1.2945e+01, -2.1328e+00, -2.3555e+00, -2.3652e+00,  1.4343e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 264

[Worker 2] Processing Task 268: paddle.dist(Tensor([190141782, 2, 3, 2],"float32"), Tensor([190141782, 1, 3, 1],"float32"), 2, )
[accuracy error] paddle.dist(Tensor([190141782, 2, 3, 2],"float32"), Tensor([190141782, 1, 3, 1],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 19501.048828125 but got 0.0.
Absolute difference: 19501.048828125 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([19501.0488])
[Worker 2] Completed Task 268

[Worker 2] Processing Task 271: paddle.dist(Tensor([2, 2, 285212673, 2],"float32"), Tensor([1, 1, 285212673, 1],"float32"), 2, )
[accuracy error] paddle.dist(Tensor([2, 2, 285212673, 2],"float32"), Tensor([1, 1, 285212673, 1],"float32"), 2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 19501.296875 but got 0.0.
Absolute difference: 19501.296875 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([19501.2969])
[Worker 2] Completed Task 271

[Worker 2] Processing Task 275: paddle.dist(x=Tensor([10],"float16"), y=Tensor([429496730, 10],"float16"), p=4, )
[accuracy error] paddle.dist(x=Tensor([10],"float16"), y=Tensor([429496730, 10],"float16"), p=4, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 135.5 but got 0.0.
Absolute difference: 135.5 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([135.5000], dtype=torch.float16)
[Worker 2] Completed Task 275

[Worker 2] Processing Task 283: paddle.fft.ifftshift(x=Tensor([536870913, 4, 2],"float16"), )
[accuracy error] paddle.fft.ifftshift(x=Tensor([536870913, 4, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 8 / 4294967304 (0.0%)
Greatest absolute difference: 0.411376953125 at index (536870912, 0, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([536870913, 4, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4094,  0.2272,  0.0300,  0.3003, -0.3501, -0.2432,  0.0161,  0.2537,
         0.0176, -0.0956,  0.2332,  0.4084,  0.0764, -0.1406, -0.0439, -0.2057,
         0.4243, -0.2815,  0.3257,  0.4985, -0.4314, -0.4348, -0.2321,  0.3081,
         0.2942,  0.3623,  0.4429, -0.1113,  0.1536, -0.4661,  0.3894, -0.4517,
        -0.2424,  0.2791, -0.2490,  0.3035,  0.2169,  0.1526, -0.3999,  0.2275,
        -0.2205,  0.2052, -0.1727, -0.3335,  0.0463,  0.0261, -0.3298, -0.1658,
         0.1009, -0.2429,  0.0093,  0.4224, -0.4756, -0.0337,  0.2529, -0.0544,
        -0.4348,  0.0299, -0.1720, -0.0467, -0.2109, -0.2563,  0.2732,  0.0298,
        -0.0526,  0.1735,  0.4397,  0.1359,  0.1220,  0.3953,  0.4727, -0.3662,
         0.2800, -0.0738,  0.4128, -0.0201,  0.4282, -0.2581,  0.3618, -0.3958,
         0.4641, -0.0500, -0.0906,  0.3010,  0.2646,  0.2445, -0.4119, -0.4807,
        -0.4236,  0.0641,  0.3413, -0.0018, -0.0441,  0.3694,  0.2974,  0.2729,
         0.0891,  0.1181, -0.1140, -0.4866], dtype=torch.float16)
DESIRED: (shape=torch.Size([536870913, 4, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.4094,  0.2272,  0.0300,  0.3003, -0.3501, -0.2432,  0.0161,  0.2537,
         0.0176, -0.0956,  0.2332,  0.4084,  0.0764, -0.1406, -0.0439, -0.2057,
         0.4243, -0.2815,  0.3257,  0.4985, -0.4314, -0.4348, -0.2321,  0.3081,
         0.2942,  0.3623,  0.4429, -0.1113,  0.1536, -0.4661,  0.3894, -0.4517,
        -0.2424,  0.2791, -0.2490,  0.3035,  0.2169,  0.1526, -0.3999,  0.2275,
        -0.2205,  0.2052, -0.1727, -0.3335,  0.0463,  0.0261, -0.3298, -0.1658,
         0.1009, -0.2429,  0.0093,  0.4224, -0.4756, -0.0337,  0.2529, -0.0544,
        -0.4348,  0.0299, -0.1720, -0.0467, -0.2109, -0.2563,  0.2732,  0.0298,
        -0.0526,  0.1735,  0.4397,  0.1359,  0.1220,  0.3953,  0.4727, -0.3662,
         0.2800, -0.0738,  0.4128, -0.0201,  0.4282, -0.2581,  0.3618, -0.3958,
         0.4641, -0.0500, -0.0906,  0.3010,  0.2646,  0.2445, -0.4119, -0.4807,
        -0.4236,  0.0641,  0.3413, -0.0018, -0.0441,  0.3694,  0.2974,  0.2729,
         0.0891,  0.1181, -0.1140, -0.4866], dtype=torch.float16)
[Worker 2] Completed Task 283

[Worker 2] Processing Task 377: paddle.full_like(Tensor([2, 1140850690],"int64"), 151643, )
[accuracy error] paddle.full_like(Tensor([2, 1140850690],"int64"), 151643, ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[151643, 151643, 151643,  ..., 151643, 151643, 151643],
        [151643, 151643, 151643,  ..., 151643, 151643, 151643]]),
    expected=tensor([[151643, 151643, 151643,  ..., 151643, 151643, 151643],
        [151643, 151643, 151643,  ..., 151643, 151643, 151643]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 377

[Worker 2] Processing Task 496: paddle.inner(x=Tensor([2, 5, 3, 143165577],"float16"), y=Tensor([3, 2, 5, 143165577],"float16"), )
[accuracy error] paddle.inner(x=Tensor([2, 5, 3, 143165577],"float16"), y=Tensor([3, 2, 5, 143165577],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 80 / 900 (8.9%)
Greatest absolute difference: 5.25 at index (0, 2, 1, 2, 1, 1) (up to 0.01 allowed)
Greatest relative difference: 0.67626953125 at index (0, 1, 0, 0, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 5, 3, 3, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([        inf, -4.9025e+02, -8.0700e+02,  3.7675e+02, -1.2760e+03,
         1.7540e+03, -3.6625e+02,  4.9050e+02,  1.9850e+02, -3.5094e+01,
        -4.6172e+00, -4.9975e+02,  6.0500e+02, -8.6600e+02,  2.9900e+02,
        -9.2500e+02, -6.4812e+01,  1.1631e+02,  1.5450e+02, -1.4310e+03,
        -3.1350e+02,  3.9600e+02, -3.5750e+02,  9.1650e+02, -1.2760e+03,
         1.2530e+03, -8.8450e+02,  1.8238e+02,  5.2750e+02, -1.0640e+03,
        -4.9025e+02,         inf, -1.0950e+03,  2.2800e+03,  1.1160e+03,
         1.3540e+03, -2.0220e+03,  5.1133e+00, -1.0530e+03, -5.4688e+00,
         2.1962e+02, -9.1062e+01,  9.9950e+02, -9.3550e+02,  5.6850e+02,
         4.7475e+02,  5.3600e+02,  1.0638e+02, -1.4400e+03, -5.3650e+02,
         6.5150e+02,  8.1150e+02,  7.2850e+02, -1.6820e+03, -9.0150e+02,
        -9.8300e+02, -7.9875e+01,  3.0375e+02,  2.1406e+01,  2.5360e+03,
        -8.0700e+02, -1.0950e+03,         inf, -1.0450e+03,  1.2117e+01,
        -2.6150e+02, -1.7375e+02,  6.3250e+01, -2.8450e+02,  2.1738e+02,
        -1.4940e+03, -4.2800e+02, -2.1700e+03,  5.5550e+02,  6.2550e+02,
        -8.5600e+02, -5.6500e+02, -5.7050e+02,  3.8025e+02, -1.1710e+03,
        -6.4400e+02, -4.0188e+01, -2.1100e+02,  1.5840e+03,  5.0775e+02,
         1.5138e+02, -3.9150e+02, -1.2431e+02,  5.7550e+02,  7.8050e+02,
         3.7675e+02,  2.2800e+03, -1.0450e+03,         inf, -2.5775e+02,
         2.6175e+02, -1.3330e+00, -2.3260e+03, -2.2260e+03, -1.5262e+02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 5, 3, 3, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([       inf,  -490.5000,  -807.5000,   378.2500, -1272.0000,  1751.0000,
         -364.7500,   492.0000,   197.6250,   -35.0000,    -2.9121,  -498.7500,
          605.5000,  -866.5000,   299.5000,  -925.5000,   -64.6875,   116.6875,
          158.6250, -1430.0000,  -314.2500,   395.7500,  -358.2500,   917.0000,
        -1277.0000,  1250.0000,  -884.5000,   181.6250,   528.0000, -1065.0000,
         -490.5000,        inf, -1093.0000,  2270.0000,  1117.0000,  1354.0000,
        -2023.0000,     5.8242, -1052.0000,    -6.4648,   220.6250,   -90.7500,
         1000.5000,  -934.5000,   569.5000,   474.0000,   536.5000,   106.5000,
        -1441.0000,  -536.0000,   651.5000,   813.0000,   729.0000, -1680.0000,
         -901.5000,  -986.5000,   -78.6250,   302.7500,    22.8281,  2536.0000,
         -807.5000, -1093.0000,        inf, -1045.0000,    14.1406,  -261.0000,
         -174.1250,    62.5312,  -283.7500,   218.8750, -1496.0000,  -428.7500,
        -2174.0000,   553.5000,   626.5000,  -854.0000,  -566.0000,  -571.0000,
          381.5000, -1173.0000,  -643.5000,   -40.0625,  -212.3750,  1585.0000,
          506.2500,   149.0000,  -391.7500,  -123.1250,   575.5000,   782.5000,
          378.2500,  2270.0000, -1045.0000,        inf,  -257.2500,   261.2500,
           -4.1133, -2328.0000, -2230.0000,  -153.3750], dtype=torch.float16)
[Worker 2] Completed Task 496

[Worker 2] Processing Task 526: paddle.isreal(Tensor([134217728, 32],"bool"), )
[accuracy error] paddle.isreal(Tensor([134217728, 32],"bool"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    expected=tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 526

[Worker 2] Processing Task 531: paddle.isreal(Tensor([1431655765, 3],"bfloat16"), )
[accuracy error] paddle.isreal(Tensor([1431655765, 3],"bfloat16"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True],
        [True, True, True],
        [True, True, True],
        ...,
        [True, True, True],
        [True, True, True],
        [True, True, True]]),
    expected=tensor([[True, True, True],
        [True, True, True],
        [True, True, True],
        ...,
        [True, True, True],
        [True, True, True],
        [True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 531

[Worker 2] Processing Task 534: paddle.isreal(Tensor([1431655765, 3],"float32"), )
[accuracy error] paddle.isreal(Tensor([1431655765, 3],"float32"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[True, True, True],
        [True, True, True],
        [True, True, True],
        ...,
        [True, True, True],
        [True, True, True],
        [True, True, True]]),
    expected=tensor([[True, True, True],
        [True, True, True],
        [True, True, True],
        ...,
        [True, True, True],
        [True, True, True],
        [True, True, True]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 534

[Worker 2] Processing Task 562: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 27163112],"float32"), 0.36, )
[accuracy error] backward  paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 28, 27163112],"float32"), 0.36, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 24871.779296875 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([24871.7793])
[Worker 2] Completed Task 562

[Worker 2] Processing Task 564: paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 95070891, 8],"float32"), 0.3, )
[accuracy error] backward  paddle.lerp(Tensor([1, 1, 1],"float32"), Tensor([3, 95070891, 8],"float32"), 0.3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 27202.5625 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1, 1, 1]), dtype=torch.float32)
All elements: tensor([27202.5625])
[Worker 2] Completed Task 564

[Worker 2] Processing Task 568: paddle.lerp(Tensor([1, 3, 4],"float16"), Tensor([1, 3, 4],"float16"), Tensor([357913942, 3, 4],"float16"), )
[accuracy error] backward  paddle.lerp(Tensor([1, 3, 4],"float16"), Tensor([1, 3, 4],"float16"), Tensor([357913942, 3, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 12 / 12 (100.0%)
Greatest absolute difference: 8720.0 at index (0, 0, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0009765625 at index (0, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 3, 4]), dtype=torch.float16)
All elements: tensor([ 0.1528, -0.0977,  0.1853,  0.0985, -0.1201, -0.5156,  0.2299, -0.0813,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 3, 4]), dtype=torch.float16)
All elements: tensor([ 2220., -8720.,  4808., -7756.,  5296.,  1474.,  3658., -5764.,  -600.,
         6500., -2642.,   691.], dtype=torch.float16)
[Worker 2] Completed Task 568

[Worker 2] Processing Task 573: paddle.lerp(Tensor([1],"float32"), Tensor([2281701379],"float32"), Tensor([1],"float32"), )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.16 GiB is free. Process 43897 has 77.02 GiB memory in use. Of the allocated memory 51.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 573: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.16 GiB is free. Process 43897 has 77.02 GiB memory in use. Of the allocated memory 51.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 573: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.16 GiB is free. Process 43897 has 77.02 GiB memory in use. Of the allocated memory 51.02 GiB is allocated by PyTorch, and 17.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 575: paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 47535446, 8],"float32"), 0.3, )
W0522 16:45:44.316483 43614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:45:44.317365 43614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.lerp(Tensor([2, 1, 1, 1],"float32"), Tensor([2, 3, 47535446, 8],"float32"), 0.3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 2 (100.0%)
Greatest absolute difference: 3914.423828125 at index (0, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1, 1, 1]), dtype=torch.float32)
All elements: tensor([0., 0.])
DESIRED: (shape=torch.Size([2, 1, 1, 1]), dtype=torch.float32)
All elements: tensor([3914.4238,  954.9272])
[Worker 2] Completed Task 575

[Worker 2] Processing Task 579: paddle.lerp(Tensor([2, 17825793, 8, 8],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 2.1, )
[accuracy error] backward  paddle.lerp(Tensor([2, 17825793, 8, 8],"float32"), Tensor([2, 17825793, 8, 8],"float32"), 2.1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2239794911 / 2281701504 (98.2%)
Greatest absolute difference: 0.550000011920929 at index (0, 190665, 4, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 17825793, 8, 8]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2, 17825793, 8, 8]), dtype=torch.float32)
First 100 elements: tensor([-5.4712e-01,  4.1932e-01, -2.7423e-02, -3.7900e-01, -2.7705e-02,
         4.8767e-01,  3.3242e-01, -4.4555e-01,  4.2037e-01,  1.2892e-01,
         1.9488e-04,  1.5673e-01, -5.2579e-02, -2.4381e-01, -1.1966e-01,
         4.6711e-01,  3.8583e-02,  4.6881e-01, -4.9812e-01, -4.5370e-01,
         1.5477e-01,  9.3115e-02,  2.0278e-01,  1.5982e-01,  1.3808e-01,
        -3.1011e-01,  4.3055e-01, -5.0664e-01,  2.2051e-01, -9.3744e-02,
        -4.1537e-01, -1.2083e-01,  4.5876e-01,  8.7771e-02,  4.8859e-01,
         8.8699e-02, -1.1015e-01,  5.4304e-01,  4.7219e-01, -1.7776e-01,
         3.1426e-01,  4.1882e-01,  4.4095e-01,  3.8673e-01, -1.3760e-01,
        -3.1870e-01, -3.3650e-01, -4.9202e-01,  4.5951e-01, -5.2970e-01,
         3.8344e-01,  4.9196e-01, -1.7505e-02, -4.9049e-01, -1.7518e-01,
        -1.3653e-01, -1.0837e-01,  2.1730e-01, -5.2868e-01,  2.6813e-01,
        -4.3705e-01,  5.2394e-01,  4.9090e-01, -5.4245e-01, -2.4138e-01,
        -4.5700e-01, -4.3438e-01,  2.6281e-01,  1.8768e-01,  1.2458e-01,
        -2.2524e-01,  2.0481e-01, -3.9773e-01,  2.6478e-01, -2.8475e-01,
        -1.2366e-02, -1.4570e-01,  3.3509e-01,  3.4101e-01,  4.8380e-01,
        -3.7985e-02, -4.4022e-01,  5.4276e-01,  4.4866e-01, -3.3613e-01,
         2.1726e-01, -5.0544e-01, -2.4361e-01,  3.0064e-01,  2.9830e-01,
         2.5066e-01, -3.3180e-01, -2.6549e-01, -4.7766e-01,  2.3667e-01,
         4.9561e-01,  3.1672e-01,  1.3258e-01, -3.6166e-01, -3.0187e-01])
[Worker 2] Completed Task 579

[Worker 2] Processing Task 584: paddle.linalg.matrix_norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=True, )
[accuracy error] paddle.linalg.matrix_norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 2] Completed Task 584

[Worker 2] Processing Task 597: paddle.linalg.norm(Tensor([10, 11408507, 20],"float32"), p=math.inf, axis=-1, )
[accuracy error] backward  paddle.linalg.norm(Tensor([10, 11408507, 20],"float32"), p=math.inf, axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 118 / 2281701400 (0.0%)
Greatest absolute difference: 0.24626405537128448 at index (6, 4892956, 15) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 724951, 6) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 11408507, 20]), dtype=torch.float32)
First 100 elements: tensor([-0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2453, -0.0000,  0.0000,
        -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
        -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.1755, -0.0000,
        -0.4647, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.2089, -0.0000,
        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,
        -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,
        -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,
        -0.0000,  0.0000,  0.0000,  0.1518,  0.0000, -0.0000,  0.0000,  0.0000,
        -0.0000, -0.0000, -0.0000,  0.0000])
DESIRED: (shape=torch.Size([10, 11408507, 20]), dtype=torch.float32)
First 100 elements: tensor([-0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2453, -0.0000,  0.0000,
        -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
        -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.1755, -0.0000,
        -0.4647, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.2089, -0.0000,
        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,
        -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,
        -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,
        -0.0000,  0.0000,  0.0000,  0.1518,  0.0000, -0.0000,  0.0000,  0.0000,
        -0.0000, -0.0000, -0.0000,  0.0000])
[Worker 2] Completed Task 597

[Worker 2] Processing Task 600: paddle.linalg.norm(Tensor([2281701379],"float32"), )
[accuracy error] paddle.linalg.norm(Tensor([2281701379],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 13789.0029296875 but got 0.0.
Absolute difference: 13789.0029296875 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([13789.0029])
[Worker 2] Completed Task 600

[Worker 2] Processing Task 601: paddle.linalg.norm(Tensor([2281701379],"float32"), 2.0, )
[accuracy error] paddle.linalg.norm(Tensor([2281701379],"float32"), 2.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 13789.0029296875 but got 0.0.
Absolute difference: 13789.0029296875 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([13789.0029])
[Worker 2] Completed Task 601

[Worker 2] Processing Task 602: paddle.linalg.norm(Tensor([2281701379],"float32"), p=1, )
[accuracy error] paddle.linalg.norm(Tensor([2281701379],"float32"), p=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 570418368.0 but got 0.0.
Absolute difference: 570418368.0 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([5.7042e+08])
[Worker 2] Completed Task 602

[Worker 2] Processing Task 604: paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), 0.0, 2, True, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), 0.0, 2, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 60 / 60 (100.0%)
Greatest absolute difference: 21251140.0 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.5588235259056091 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 20, 1]), dtype=torch.float32)
All elements: tensor([16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.])
DESIRED: (shape=torch.Size([3, 20, 1]), dtype=torch.float32)
All elements: tensor([38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.,
        38028356., 38028356., 38028356., 38028356., 38028356., 38028356.])
[Worker 2] Completed Task 604

[Worker 2] Processing Task 605: paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), 2.0, -1, False, )
[accuracy error] paddle.linalg.norm(Tensor([3, 20, 38028357],"float32"), 2.0, -1, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 60 / 60 (100.0%)
Greatest absolute difference: 53.90283203125 at index (0, 3) (up to 0.01 allowed)
Greatest relative difference: 0.030281219631433487 at index (0, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 20]), dtype=torch.float32)
All elements: tensor([1726.4596, 1726.3718, 1726.3655, 1726.1719, 1726.2446, 1726.3314,
        1726.4528, 1726.0970, 1726.5496, 1726.0796, 1726.3612, 1726.4116,
        1726.1765, 1726.4523, 1726.3815, 1726.5470, 1726.2024, 1726.4487,
        1726.4244, 1726.1095, 1726.3289, 1726.2740, 1726.4281, 1726.3248,
        1726.5508, 1726.1876, 1726.3190, 1726.4382, 1726.4902, 1726.6283,
        1726.3910, 1726.3081, 1726.5087, 1726.6676, 1726.5389, 1726.4875,
        1726.3707, 1726.6733, 1726.5773, 1726.5459, 1726.1819, 1726.5697,
        1726.5698, 1726.3353, 1726.2639, 1726.5764, 1726.4108, 1726.4160,
        1726.5707, 1726.4489, 1726.0847, 1726.5527, 1726.5027, 1726.4120,
        1726.5211, 1726.4554, 1726.2917, 1726.5219, 1726.1199, 1726.5710])
DESIRED: (shape=torch.Size([3, 20]), dtype=torch.float32)
All elements: tensor([1780.2466, 1780.0775, 1780.0781, 1780.0747, 1780.0557, 1780.1677,
        1780.1678, 1779.8762, 1780.2980, 1779.9014, 1780.1765, 1780.2004,
        1779.9452, 1780.2587, 1779.9962, 1780.3699, 1780.0840, 1780.1716,
        1780.1621, 1779.8645, 1780.1997, 1780.0214, 1780.2234, 1780.1056,
        1780.2976, 1779.9652, 1780.0741, 1780.1071, 1780.2395, 1780.3992,
        1780.2017, 1780.0370, 1780.1674, 1780.3335, 1780.2363, 1780.3192,
        1780.0529, 1780.3518, 1780.2268, 1780.2635, 1779.9614, 1780.2062,
        1780.3092, 1780.1095, 1780.0465, 1780.2570, 1780.1079, 1780.1221,
        1780.1910, 1780.2595, 1779.9178, 1780.2528, 1780.2377, 1780.2415,
        1780.2241, 1780.1506, 1780.0160, 1780.2163, 1780.0084, 1780.3297])
[Worker 2] Completed Task 605

[Worker 2] Processing Task 608: paddle.linalg.norm(Tensor([3, 20, 71582789],"float32"), 0.0, 2, True, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.linalg.norm(Tensor([3, 20, 71582789],"float32"), 0.0, 2, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 60 / 60 (100.0%)
Greatest absolute difference: 54805576.0 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 0.765625 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 20, 1]), dtype=torch.float32)
All elements: tensor([16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.,
        16777216., 16777216., 16777216., 16777216., 16777216., 16777216.])
DESIRED: (shape=torch.Size([3, 20, 1]), dtype=torch.float32)
All elements: tensor([71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.,
        71582792., 71582792., 71582792., 71582792., 71582792., 71582792.])
[Worker 2] Completed Task 608

[Worker 2] Processing Task 610: paddle.linalg.norm(Tensor([3, 20, 71582789],"float32"), 2.0, 2, True, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 99718 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 610: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 99718 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 610: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.57 GiB is free. Process 99718 has 65.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 611: paddle.linalg.norm(Tensor([3, 253522376, 3],"float32"), math.inf, 2, True, )
W0522 16:55:53.297683 43998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:55:53.298635 43998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.linalg.norm(Tensor([3, 253522376, 3],"float32"), math.inf, 2, True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 104 / 2281701384 (0.0%)
Greatest absolute difference: 0.24504464864730835 at index (2, 235669898, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 2463052, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 253522376, 3]), dtype=torch.float32)
First 100 elements: tensor([ 0.2760, -0.0000, -0.0000, -0.0000,  0.3526,  0.0000,  0.0000, -0.0000,
         0.3792,  0.2170,  0.0000,  0.0000, -0.0000, -0.0000, -0.4720,  0.2485,
        -0.0000, -0.0000,  0.0000,  0.0000, -0.4384,  0.0000,  0.0000,  0.2605,
        -0.0000, -0.3399,  0.0000,  0.0000, -0.0000,  0.4580,  0.0000,  0.0000,
        -0.1150, -0.4269, -0.0000,  0.0000, -0.0000, -0.3058, -0.0000,  0.0000,
         0.2517,  0.0000, -0.3648,  0.0000, -0.0000,  0.0000,  0.0744,  0.0000,
        -0.0000, -0.0000, -0.3990,  0.0000,  0.4015, -0.0000,  0.2025, -0.0000,
        -0.0000,  0.0000, -0.0000, -0.0062,  0.1307, -0.0000, -0.0000,  0.1808,
        -0.0000, -0.0000, -0.0000,  0.2463,  0.0000, -0.0000, -0.4467,  0.0000,
         0.0307,  0.0000,  0.0000,  0.0000, -0.0000, -0.2256, -0.2250, -0.0000,
        -0.0000, -0.0000, -0.1673,  0.0000, -0.0000,  0.4038,  0.0000, -0.0000,
         0.0000,  0.3744, -0.0000, -0.0000, -0.1133, -0.0000, -0.2495,  0.0000,
        -0.1021, -0.0000, -0.0000, -0.2677])
DESIRED: (shape=torch.Size([3, 253522376, 3]), dtype=torch.float32)
First 100 elements: tensor([ 0.2760, -0.0000, -0.0000, -0.0000,  0.3526,  0.0000,  0.0000, -0.0000,
         0.3792,  0.2170,  0.0000,  0.0000, -0.0000, -0.0000, -0.4720,  0.2485,
        -0.0000, -0.0000,  0.0000,  0.0000, -0.4384,  0.0000,  0.0000,  0.2605,
        -0.0000, -0.3399,  0.0000,  0.0000, -0.0000,  0.4580,  0.0000,  0.0000,
        -0.1150, -0.4269, -0.0000,  0.0000, -0.0000, -0.3058, -0.0000,  0.0000,
         0.2517,  0.0000, -0.3648,  0.0000, -0.0000,  0.0000,  0.0744,  0.0000,
        -0.0000, -0.0000, -0.3990,  0.0000,  0.4015, -0.0000,  0.2025, -0.0000,
        -0.0000,  0.0000, -0.0000, -0.0062,  0.1307, -0.0000, -0.0000,  0.1808,
        -0.0000, -0.0000, -0.0000,  0.2463,  0.0000, -0.0000, -0.4467,  0.0000,
         0.0307,  0.0000,  0.0000,  0.0000, -0.0000, -0.2256, -0.2250, -0.0000,
        -0.0000, -0.0000, -0.1673,  0.0000, -0.0000,  0.4038,  0.0000, -0.0000,
         0.0000,  0.3744, -0.0000, -0.0000, -0.1133, -0.0000, -0.2495,  0.0000,
        -0.1021, -0.0000, -0.0000, -0.2677])
[Worker 2] Completed Task 611

[Worker 2] Processing Task 616: paddle.linalg.norm(Tensor([38028357, 20, 3],"float32"), -math.inf, 2, True, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.77 GiB is free. Process 85151 has 77.41 GiB memory in use. Of the allocated memory 50.29 GiB is allocated by PyTorch, and 5.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 616: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.77 GiB is free. Process 85151 has 77.41 GiB memory in use. Of the allocated memory 50.29 GiB is allocated by PyTorch, and 5.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 616: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.77 GiB is free. Process 85151 has 77.41 GiB memory in use. Of the allocated memory 50.29 GiB is allocated by PyTorch, and 5.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 617: paddle.linalg.norm(Tensor([4, 1073741824],"float32"), )
W0522 16:57:41.593426 44226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 16:57:41.594460 44226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.norm(Tensor([4, 1073741824],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18918.466796875 but got 0.0.
Absolute difference: 18918.466796875 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([18918.4668])
[Worker 2] Completed Task 617

[Worker 2] Processing Task 619: paddle.linalg.norm(Tensor([4, 570425345],"float32"), )
[accuracy error] paddle.linalg.norm(Tensor([4, 570425345],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 13789.0712890625 but got 0.0.
Absolute difference: 13789.0712890625 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([13789.0713])
[Worker 2] Completed Task 619

[Worker 2] Processing Task 620: paddle.linalg.norm(Tensor([4, 570425345],"float32"), p=-math.inf, axis=list[0,1,], )
[accuracy error] paddle.linalg.norm(Tensor([4, 570425345],"float32"), p=-math.inf, axis=list[0,1,], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 142602368.0 but got 8388607.5.
Absolute difference: 134213760.5 (up to 0.01 allowed)
Relative difference: 0.9411748372930244 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([8388607.5000])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([1.4260e+08])
[Worker 2] Completed Task 620

[Worker 2] Processing Task 635: paddle.linalg.norm(x=Tensor([2, 3, 380283564],"float32"), )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 3, 380283564],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 13789.0712890625 but got 0.0.
Absolute difference: 13789.0712890625 (up to 0.01 allowed)
Relative difference: 1.0 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([]), dtype=torch.float32)
All elements: tensor([13789.0713])
[Worker 2] Completed Task 635

[Worker 2] Processing Task 636: paddle.linalg.norm(x=Tensor([2, 3, 380283564],"float32"), p=math.inf, axis=0, keepdim=False, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 8.44 GiB is free. Process 105260 has 70.74 GiB memory in use. Of the allocated memory 48.88 GiB is allocated by PyTorch, and 4.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 636: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 8.44 GiB is free. Process 105260 has 70.74 GiB memory in use. Of the allocated memory 48.88 GiB is allocated by PyTorch, and 4.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 636: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 8.44 GiB is free. Process 105260 has 70.74 GiB memory in use. Of the allocated memory 48.88 GiB is allocated by PyTorch, and 4.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 637: paddle.linalg.norm(x=Tensor([2, 3, 380283564],"float32"), p=math.inf, axis=0, keepdim=True, )
W0522 17:03:33.252455 44435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 17:03:33.253479 44435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.linalg.norm(x=Tensor([2, 3, 380283564],"float32"), p=math.inf, axis=0, keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 88 / 2281701384 (0.0%)
Greatest absolute difference: 0.24998800456523895 at index (0, 1, 156586366) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 651634) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 380283564]), dtype=torch.float32)
First 100 elements: tensor([ 0.3615,  0.4592, -0.0000,  0.0000,  0.0000, -0.1441, -0.0000,  0.0182,
         0.2603,  0.0000, -0.3436,  0.4269, -0.3344, -0.0000, -0.4890,  0.4800,
        -0.0000, -0.0000,  0.0000, -0.0000,  0.2895,  0.0000, -0.0064, -0.0000,
         0.0000, -0.0000, -0.0000, -0.0000, -0.0510,  0.4178, -0.0000,  0.0000,
         0.3285,  0.0000, -0.0000, -0.0912, -0.1133,  0.0000, -0.0000,  0.0000,
        -0.0000, -0.0000, -0.4515, -0.0000, -0.0612,  0.3692, -0.0000, -0.0000,
        -0.0000,  0.0000, -0.0000,  0.4538,  0.0000,  0.3737,  0.0000, -0.2808,
         0.0000, -0.2330, -0.1251, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,
         0.4929, -0.0000, -0.0993,  0.0126, -0.0000, -0.0000, -0.0000, -0.0000,
         0.3898,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,
        -0.0000, -0.4759,  0.0000, -0.0000,  0.0000, -0.1875, -0.3337,  0.0000,
        -0.2437,  0.0000,  0.2219, -0.0000, -0.0000,  0.4224,  0.0000,  0.0314,
        -0.0000, -0.4048, -0.0341, -0.3055])
DESIRED: (shape=torch.Size([2, 3, 380283564]), dtype=torch.float32)
First 100 elements: tensor([ 0.3615,  0.4592, -0.0000,  0.0000,  0.0000, -0.1441, -0.0000,  0.0182,
         0.2603,  0.0000, -0.3436,  0.4269, -0.3344, -0.0000, -0.4890,  0.4800,
        -0.0000, -0.0000,  0.0000, -0.0000,  0.2895,  0.0000, -0.0064, -0.0000,
         0.0000, -0.0000, -0.0000, -0.0000, -0.0510,  0.4178, -0.0000,  0.0000,
         0.3285,  0.0000, -0.0000, -0.0912, -0.1133,  0.0000, -0.0000,  0.0000,
        -0.0000, -0.0000, -0.4515, -0.0000, -0.0612,  0.3692, -0.0000, -0.0000,
        -0.0000,  0.0000, -0.0000,  0.4538,  0.0000,  0.3737,  0.0000, -0.2808,
         0.0000, -0.2330, -0.1251, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,
         0.4929, -0.0000, -0.0993,  0.0126, -0.0000, -0.0000, -0.0000, -0.0000,
         0.3898,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,
        -0.0000, -0.4759,  0.0000, -0.0000,  0.0000, -0.1875, -0.3337,  0.0000,
        -0.2437,  0.0000,  0.2219, -0.0000, -0.0000,  0.4224,  0.0000,  0.0314,
        -0.0000, -0.4048, -0.0341, -0.3055])
[Worker 2] Completed Task 637

[Worker 2] Processing Task 640: paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=1, axis=list[0,1,], keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float16"), p=1, axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 715827883 / 715827883 (100.0%)
Greatest absolute difference: 1.0 at index (0, 0, 1508244) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 715827883]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 715827883]), dtype=torch.float16)
First 100 elements: tensor([0.8711, 0.5205, 0.4751, 0.7676, 0.5591, 0.6523, 0.8027, 0.8750, 0.8330,
        0.5332, 0.4688, 0.9697, 0.7715, 0.8560, 0.6113, 0.7539, 0.7651, 0.6167,
        0.2422, 0.6680, 0.4045, 0.6675, 0.3848, 0.7905, 0.5786, 0.7769, 0.5659,
        0.7822, 0.5039, 0.7397, 0.6255, 0.8799, 0.4380, 0.5293, 0.9111, 0.8159,
        0.3303, 0.7256, 0.7305, 0.7119, 0.8301, 0.6636, 0.6616, 0.8037, 0.8081,
        0.6406, 0.6777, 0.7393, 0.6992, 0.6963, 0.8032, 0.5264, 0.4756, 0.5088,
        0.5957, 0.6602, 0.7783, 0.3833, 0.7305, 0.6582, 0.5845, 0.8555, 0.6973,
        0.7432, 0.8989, 0.4727, 0.8257, 0.8833, 0.7363, 0.7739, 0.8184, 0.4219,
        0.9365, 0.8408, 0.9756, 0.4087, 0.5449, 0.5430, 0.6035, 0.6616, 0.8408,
        0.4556, 0.8359, 0.6836, 0.6304, 0.5063, 0.7080, 0.6934, 0.9746, 0.5566,
        0.8174, 0.7676, 0.6855, 0.5391, 0.4609, 0.6182, 0.4707, 0.6836, 0.6274,
        0.7642], dtype=torch.float16)
[Worker 2] Completed Task 640

[Worker 2] Processing Task 643: paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float32"), p=math.inf, axis=0, keepdim=False, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 11.73 GiB is free. Process 45214 has 67.45 GiB memory in use. Of the allocated memory 52.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 643: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 11.73 GiB is free. Process 45214 has 67.45 GiB memory in use. Of the allocated memory 52.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 643: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 11.73 GiB is free. Process 45214 has 67.45 GiB memory in use. Of the allocated memory 52.00 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 644: paddle.linalg.norm(x=Tensor([2, 3, 715827883],"float32"), p=math.inf, axis=0, keepdim=True, )
CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 82200 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 644: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 82200 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 644: CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 82200 has 69.61 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 647: paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), )
W0522 17:07:58.039561 44758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 17:07:58.040452 44758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.74267578125.
Absolute difference: 18911.25732421875 (up to 0.01 allowed)
Relative difference: 0.9999607299185042 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.7427], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 2] Completed Task 647

[Worker 2] Processing Task 649: paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=False, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=-math.inf, axis=list[0,1,], keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4]), dtype=torch.float16)
All elements: tensor([inf, inf, inf, inf], dtype=torch.float16)
[Worker 2] Completed Task 649

[Worker 2] Processing Task 652: paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), axis=None, p="fro", )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), axis=None, p="fro", ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Expected 18912.0 but got 0.25244140625.
Absolute difference: 18911.74755859375 (up to 0.01 allowed)
Relative difference: 0.9999866517868946 (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([0.2524], dtype=torch.float16)
DESIRED: (shape=torch.Size([]), dtype=torch.float16)
All elements: tensor([18912.], dtype=torch.float16)
[Worker 2] Completed Task 652

[Worker 2] Processing Task 653: paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=0, axis=1, keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=0, axis=1, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([2048., 2048., 2048.], dtype=torch.float16)
DESIRED: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([inf, inf, inf], dtype=torch.float16)
[Worker 2] Completed Task 653

[Worker 2] Processing Task 655: paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=1, axis=1, keepdim=False, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 1431655766],"float16"), p=1, axis=1, keepdim=False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([inf, inf, inf], dtype=torch.float16)
[Worker 2] Completed Task 655

[Worker 2] Processing Task 659: paddle.linalg.norm(x=Tensor([3, 3, 477218589],"float16"), axis=list[1,2,], p=math.inf, )
[accuracy error] paddle.linalg.norm(x=Tensor([3, 3, 477218589],"float16"), axis=list[1,2,], p=math.inf, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([inf, inf, inf], dtype=torch.float16)
[Worker 2] Completed Task 659

[Worker 2] Processing Task 667: paddle.linalg.norm(x=Tensor([477218589, 3, 3],"float16"), axis=list[0,2,], p=1, )
[accuracy error] paddle.linalg.norm(x=Tensor([477218589, 3, 3],"float16"), axis=list[0,2,], p=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: inf at index (0,) (up to 0.01 allowed)
Greatest relative difference: nan at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([1024., 1024., 1024.], dtype=torch.float16)
DESIRED: (shape=torch.Size([3]), dtype=torch.float16)
All elements: tensor([inf, inf, inf], dtype=torch.float16)
[Worker 2] Completed Task 667

[Worker 2] Processing Task 685: paddle.logsumexp(Tensor([2, 107374183, 4, 5],"float32"), list[-1,], False, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 15.17 GiB is free. Process 93800 has 64.01 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 8.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 685: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 15.17 GiB is free. Process 93800 has 64.01 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 8.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 685: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 15.17 GiB is free. Process 93800 has 64.01 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 8.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 984: paddle.nn.functional.hardshrink(Tensor([2281701379],"float32"), 0.5, None, )
[accuracy error] paddle.nn.functional.hardshrink(Tensor([2281701379],"float32"), 0.5, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 74 / 2281701379 (0.0%)
Greatest absolute difference: 0.5 at index (11435870,) (up to 0.01 allowed)
Greatest relative difference: inf at index (11435870,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
[Worker 2] Completed Task 984

[Worker 2] Processing Task 986: paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([715827883, 2, 3],"float16"), )
[accuracy error] backward  paddle.nn.functional.layer_norm(normalized_shape=tuple(2,3,), x=Tensor([715827883, 2, 3],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 13 / 4294967298 (0.0%)
Greatest absolute difference: 0.0159912109375 at index (31803105, 1, 2) (up to 0.01 allowed)
Greatest relative difference: 0.35205078125 at index (237445544, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([715827883, 2, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.3499, -0.8638,  0.2617,  0.3662, -0.8071,  0.6938,  0.0887,  0.0303,
        -0.9302,  1.1631,  0.5234, -0.8740,  1.0029,  0.4517, -0.5269, -0.4124,
        -0.9502,  0.4338, -0.9229,  0.6968,  0.9668, -1.0000,  1.1055, -0.8472,
         0.6309, -0.4204,  0.0292, -0.7285, -0.1788,  0.6680, -0.4583,  1.1924,
        -0.3630, -0.5186,  2.4941, -2.3477, -1.1768,  0.5557,  1.4512,  0.7212,
        -1.2637, -0.2859, -0.0049, -0.4746, -0.5098,  0.4036,  0.3691,  0.2175,
        -1.0859,  1.1035, -0.8311,  1.9375,  0.0179, -1.1406,  0.3689, -1.0449,
         0.4050,  0.3765, -0.0728, -0.0330, -1.4453,  2.3945, -0.7397,  1.2861,
        -0.0909, -1.4043,  0.4595,  0.0096, -2.2148, -1.3408,  1.4873,  1.5977,
         0.9883, -0.6748,  0.0280,  0.4917, -0.8286, -0.0054, -0.7207, -0.4690,
         0.5254,  1.4023, -0.8101,  0.0703,  1.0166,  1.0352, -1.1191,  1.8281,
        -3.3945,  0.6367,  0.0349,  0.2283, -0.8711, -0.2239,  1.1240, -0.2925,
        -0.5527, -0.2094,  0.5840,  0.0421], dtype=torch.float16)
DESIRED: (shape=torch.Size([715827883, 2, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.3494, -0.8638,  0.2617,  0.3662, -0.8071,  0.6938,  0.0888,  0.0303,
        -0.9302,  1.1631,  0.5229, -0.8745,  1.0029,  0.4517, -0.5264, -0.4121,
        -0.9502,  0.4338, -0.9224,  0.6968,  0.9668, -0.9995,  1.1055, -0.8467,
         0.6309, -0.4202,  0.0292, -0.7280, -0.1788,  0.6675, -0.4583,  1.1924,
        -0.3628, -0.5186,  2.4941, -2.3477, -1.1777,  0.5557,  1.4502,  0.7212,
        -1.2637, -0.2856, -0.0051, -0.4746, -0.5098,  0.4033,  0.3689,  0.2174,
        -1.0859,  1.1035, -0.8311,  1.9365,  0.0177, -1.1406,  0.3687, -1.0449,
         0.4050,  0.3767, -0.0727, -0.0329, -1.4453,  2.3945, -0.7402,  1.2861,
        -0.0913, -1.4033,  0.4597,  0.0099, -2.2129, -1.3408,  1.4873,  1.5986,
         0.9883, -0.6743,  0.0279,  0.4915, -0.8281, -0.0054, -0.7202, -0.4690,
         0.5259,  1.4023, -0.8096,  0.0705,  1.0176,  1.0332, -1.1191,  1.8281,
        -3.3965,  0.6357,  0.0350,  0.2284, -0.8711, -0.2241,  1.1240, -0.2922,
        -0.5532, -0.2101,  0.5835,  0.0417], dtype=torch.float16)
[Worker 2] Completed Task 986

[Worker 2] Processing Task 989: paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([1431655766, 3],"float16"), epsilon=1e-05, )
[accuracy error] backward  paddle.nn.functional.layer_norm(normalized_shape=tuple(3,), x=Tensor([1431655766, 3],"float16"), epsilon=1e-05, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 77176 / 4294967298 (0.0%)
Greatest absolute difference: 0.12890625 at index (1003145060, 2) (up to 0.01 allowed)
Greatest relative difference: 5460.0 at index (542495989, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.2190, -0.0552, -0.1638,  0.2192, -0.0850, -0.1343, -0.0869,  0.1185,
        -0.0319,  0.4409, -0.4270, -0.0127,  0.4563, -0.3320, -0.1240,  0.2484,
        -0.2173, -0.0312, -2.2539,  0.4954,  1.7578, -1.0371,  1.1094, -0.0723,
         1.8047, -1.8232,  0.0200, -0.7002,  0.0603,  0.6406, -0.0938,  2.3711,
        -2.2773, -6.1680,  5.4922,  0.6719, -1.1777,  0.8271,  0.3506,  0.2344,
        -1.2422,  1.0078,  0.2385, -0.0425, -0.1964,  0.1168, -0.0469, -0.0693,
        -0.3281,  0.0479,  0.2788,  0.6973, -0.8447,  0.1465,  1.0928, -0.9858,
        -0.1064,  0.1145,  0.0485, -0.1625,  0.2568,  1.3281, -1.5850, -0.0859,
         0.2617, -0.1758,  1.6309,  0.5850, -2.2168, -0.7510,  1.3408, -0.5889,
         0.7397, -1.4043,  0.6646,  1.4443, -1.5537,  0.1088, -1.7246,  0.3574,
         1.3662,  0.1367,  0.1445, -0.2808,  0.6953,  0.9326, -1.6270,  5.2773,
        -4.3594, -0.9180,  0.1221,  0.4390, -0.5620, -0.6641,  0.2529,  0.4111,
        -0.3882, -0.0919,  0.4807, -0.0298], dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.2189, -0.0551, -0.1638,  0.2195, -0.0851, -0.1343, -0.0868,  0.1186,
        -0.0318,  0.4402, -0.4270, -0.0133,  0.4561, -0.3320, -0.1240,  0.2485,
        -0.2172, -0.0313, -2.2539,  0.4951,  1.7578, -1.0371,  1.1094, -0.0721,
         1.8037, -1.8232,  0.0198, -0.7002,  0.0602,  0.6401, -0.0931,  2.3711,
        -2.2793, -6.1641,  5.4922,  0.6738, -1.1777,  0.8271,  0.3501,  0.2343,
        -1.2412,  1.0068,  0.2386, -0.0423, -0.1963,  0.1166, -0.0471, -0.0695,
        -0.3276,  0.0485,  0.2791,  0.6982, -0.8447,  0.1466,  1.0928, -0.9863,
        -0.1068,  0.1144,  0.0484, -0.1627,  0.2571,  1.3281, -1.5850, -0.0863,
         0.2617, -0.1753,  1.6309,  0.5850, -2.2148, -0.7520,  1.3408, -0.5889,
         0.7393, -1.4033,  0.6641,  1.4443, -1.5537,  0.1090, -1.7246,  0.3579,
         1.3672,  0.1367,  0.1444, -0.2810,  0.6953,  0.9316, -1.6270,  5.2734,
        -4.3555, -0.9175,  0.1224,  0.4395, -0.5620, -0.6641,  0.2529,  0.4111,
        -0.3884, -0.0921,  0.4805, -0.0292], dtype=torch.float16)
[Worker 2] Completed Task 989

[Worker 2] Processing Task 993: paddle.nn.functional.normalize(Tensor([10, 429496730],"float16"), )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.90 GiB is free. Process 112976 has 76.29 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 993: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.90 GiB is free. Process 112976 has 76.29 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 993: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.90 GiB is free. Process 112976 has 76.29 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 994: paddle.nn.functional.normalize(Tensor([1006, 4269352],"float16"), )
W0522 18:25:01.288273 46318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 18:25:01.289268 46318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(Tensor([1006, 4269352],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2271722415 / 4294968112 (52.9%)
Greatest absolute difference: 0.0212554931640625 at index (0, 299) (up to 0.01 allowed)
Greatest relative difference: 25.40625 at index (119, 8) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1006, 4269352]), dtype=torch.float16)
First 100 elements: tensor([ 2.0103e-03, -1.4862e-02,  5.2147e-03,  1.1414e-02, -5.5580e-03,
        -1.5572e-02,  1.2703e-03, -1.5717e-02,  1.2474e-03, -1.5823e-02,
         1.2596e-02,  1.5388e-02,  4.1428e-03, -4.5509e-03, -1.3542e-02,
        -1.0895e-02, -1.3779e-02,  8.0414e-03, -1.2390e-02,  1.0300e-02,
         2.1149e-02, -1.9699e-02,  1.6266e-02, -1.2009e-02, -8.1100e-03,
        -7.1449e-03, -3.6526e-03, -1.1307e-02,  1.4603e-02, -1.7288e-02,
        -6.4812e-03, -3.4504e-03, -1.5503e-02,  6.4087e-03, -2.1362e-02,
        -2.2488e-03,  5.6601e-04,  1.4008e-02, -1.4435e-02, -1.8520e-03,
         9.3689e-03,  9.2926e-03, -1.2421e-02, -2.5444e-03, -2.8014e-04,
         4.3449e-03,  5.2147e-03, -1.6129e-02, -2.2926e-03, -2.5959e-03,
        -1.6586e-02,  1.8234e-02,  8.0261e-03,  1.9424e-02,  4.7264e-03,
         2.1439e-02,  1.9485e-02, -2.1988e-02, -4.4365e-03,  1.9333e-02,
         1.4214e-02,  1.1925e-02, -5.9776e-03, -4.0779e-03, -1.5388e-02,
        -1.8661e-02,  1.6846e-02,  2.1545e-02, -2.0752e-03, -1.4900e-02,
         9.1629e-03, -1.0918e-02,  7.8964e-03,  9.4986e-03, -8.4610e-03,
        -1.4450e-02, -1.6495e-02, -2.1317e-02,  6.8855e-03,  1.4534e-02,
         6.6528e-03, -7.3318e-03, -3.8147e-03, -1.5419e-02,  1.5976e-02,
        -1.3618e-02, -7.3853e-03, -8.4221e-05,  1.2810e-02,  8.5449e-03,
        -1.7471e-02, -3.0937e-03, -1.9073e-02, -1.8463e-02,  5.3596e-03,
         1.8250e-02,  1.5900e-02,  1.4030e-02, -6.4430e-03,  1.4008e-02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1006, 4269352]), dtype=torch.float16)
First 100 elements: tensor([ 7.6234e-05, -5.6362e-04,  1.9777e-04,  4.3297e-04, -2.1076e-04,
        -5.9080e-04,  4.8161e-05, -5.9652e-04,  4.7326e-05, -6.0034e-04,
         4.7755e-04,  5.8365e-04,  1.5712e-04, -1.7262e-04, -5.1355e-04,
        -4.1318e-04, -5.2261e-04,  3.0494e-04, -4.6992e-04,  3.9077e-04,
         8.0204e-04, -7.4673e-04,  6.1703e-04, -4.5562e-04, -3.0756e-04,
        -2.7084e-04, -1.3852e-04, -4.2892e-04,  5.5361e-04, -6.5565e-04,
        -2.4581e-04, -1.3089e-04, -5.8794e-04,  2.4307e-04, -8.1015e-04,
        -8.5294e-05,  2.1458e-05,  5.3120e-04, -5.4741e-04, -7.0274e-05,
         3.5524e-04,  3.5238e-04, -4.7112e-04, -9.6500e-05, -1.0610e-05,
         1.6475e-04,  1.9777e-04, -6.1178e-04, -8.6904e-05, -9.8407e-05,
        -6.2895e-04,  6.9189e-04,  3.0446e-04,  7.3671e-04,  1.7929e-04,
         8.1348e-04,  7.3910e-04, -8.3351e-04, -1.6832e-04,  7.3338e-04,
         5.3883e-04,  4.5228e-04, -2.2674e-04, -1.5473e-04, -5.8365e-04,
        -7.0810e-04,  6.3896e-04,  8.1730e-04, -7.8678e-05, -5.6505e-04,
         3.4738e-04, -4.1413e-04,  2.9969e-04,  3.6025e-04, -3.2091e-04,
        -5.4789e-04, -6.2561e-04, -8.0872e-04,  2.6107e-04,  5.5122e-04,
         2.5225e-04, -2.7800e-04, -1.4472e-04, -5.8508e-04,  6.0558e-04,
        -5.1641e-04, -2.8014e-04, -3.2187e-06,  4.8590e-04,  3.2425e-04,
        -6.6280e-04, -1.1736e-04, -7.2384e-04, -7.0047e-04,  2.0337e-04,
         6.9189e-04,  6.0272e-04,  5.3215e-04, -2.4438e-04,  5.3120e-04],
       dtype=torch.float16)
[Worker 2] Completed Task 994

[Worker 2] Processing Task 1001: paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), p=4, )
[accuracy error] paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), p=4, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 359 / 4294967400 (0.0%)
Greatest absolute difference: inf at index (1, 0, 1, 34907780) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 0, 1, 34907780) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 5, 6, 35791395]), dtype=torch.float16)
First 100 elements: tensor([ 0.1156, -0.5835,  0.2039,  0.5825, -0.2345, -0.6929,  0.0449, -0.7329,
         0.1178, -0.7041,  0.5557,  0.8696,  0.2061, -0.2284, -0.6309, -0.5859,
        -0.9644,  0.4199, -0.5615,  0.4468,  0.7817, -0.7812,  0.7139, -0.6685,
        -0.6187, -0.3225, -0.1368, -0.4758,  0.8926, -0.7578, -0.3125, -0.1482,
        -0.6729,  0.2537, -0.9653, -0.1083,  0.0252,  0.7686, -0.6294, -0.1004,
         0.4614,  0.4387, -0.6602, -0.1282, -0.0163,  0.2190,  0.2125, -0.6929,
        -0.0867, -0.1236, -0.9155,  0.9492,  0.3970,  0.7524,  0.2306,  0.8745,
         0.8823, -0.8315, -0.2050,  0.8325,  0.6401,  0.6606, -0.5493, -0.1852,
        -0.6792, -0.9014,  0.7593,  0.8662, -0.0871, -0.6279,  0.7397, -0.5439,
         0.7456,  0.3684, -0.3596, -0.7505, -0.7739, -0.8613,  0.3354,  0.6724,
         0.3301, -0.3264, -0.1912, -0.5815,  0.7607, -0.5234, -0.4358, -0.0074,
         0.4763,  0.4763, -0.6660, -0.2046, -0.7944, -0.7905,  0.5801,  0.9360,
         0.7700,  0.5679, -0.2964,  0.6655], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 5, 6, 35791395]), dtype=torch.float16)
First 100 elements: tensor([ 0.1156, -0.5835,  0.2039,  0.5830, -0.2345, -0.6929,  0.0449, -0.7329,
         0.1178, -0.7041,  0.5557,  0.8696,  0.2062, -0.2284, -0.6309, -0.5854,
        -0.9644,  0.4199, -0.5615,  0.4468,  0.7817, -0.7808,  0.7139, -0.6685,
        -0.6187, -0.3223, -0.1368, -0.4758,  0.8926, -0.7578, -0.3125, -0.1482,
        -0.6733,  0.2537, -0.9653, -0.1083,  0.0252,  0.7686, -0.6294, -0.1004,
         0.4614,  0.4387, -0.6602, -0.1282, -0.0163,  0.2189,  0.2125, -0.6929,
        -0.0867, -0.1236, -0.9155,  0.9492,  0.3970,  0.7524,  0.2306,  0.8745,
         0.8818, -0.8315, -0.2050,  0.8325,  0.6401,  0.6606, -0.5493, -0.1852,
        -0.6792, -0.9014,  0.7593,  0.8662, -0.0871, -0.6279,  0.7388, -0.5439,
         0.7456,  0.3684, -0.3596, -0.7510, -0.7739, -0.8613,  0.3354,  0.6724,
         0.3301, -0.3264, -0.1912, -0.5815,  0.7607, -0.5234, -0.4358, -0.0074,
         0.4763,  0.4763, -0.6660, -0.2046, -0.7944, -0.7905,  0.5801,  0.9360,
         0.7700,  0.5679, -0.2964,  0.6655], dtype=torch.float16)
[Worker 2] Completed Task 1001

[Worker 2] Processing Task 1002: paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), p=4, axis=3, )
[accuracy error] paddle.nn.functional.normalize(x=Tensor([4, 5, 6, 35791395],"float16"), p=4, axis=3, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3962176749 / 4294967400 (92.3%)
Greatest absolute difference: 0.12939453125 at index (0, 0, 0, 299) (up to 0.01 allowed)
Greatest relative difference: 6.69921875 at index (1, 0, 4, 10) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 5, 6, 35791395]), dtype=torch.float16)
First 100 elements: tensor([ 0.0135, -0.1000,  0.0351,  0.0768, -0.0374, -0.1047,  0.0085, -0.1058,
         0.0084, -0.1065,  0.0847,  0.1035,  0.0279, -0.0306, -0.0911, -0.0733,
        -0.0927,  0.0541, -0.0833,  0.0693,  0.1423, -0.1324,  0.1094, -0.0808,
        -0.0546, -0.0481, -0.0246, -0.0760,  0.0982, -0.1163, -0.0436, -0.0232,
        -0.1043,  0.0431, -0.1437, -0.0151,  0.0038,  0.0942, -0.0971, -0.0125,
         0.0630,  0.0625, -0.0836, -0.0171, -0.0019,  0.0292,  0.0351, -0.1085,
        -0.0154, -0.0175, -0.1116,  0.1227,  0.0540,  0.1306,  0.0318,  0.1443,
         0.1311, -0.1478, -0.0298,  0.1301,  0.0956,  0.0802, -0.0402, -0.0274,
        -0.1035, -0.1256,  0.1133,  0.1450, -0.0140, -0.1002,  0.0616, -0.0735,
         0.0531,  0.0639, -0.0569, -0.0972, -0.1110, -0.1434,  0.0463,  0.0978,
         0.0447, -0.0493, -0.0257, -0.1038,  0.1074, -0.0916, -0.0497, -0.0006,
         0.0862,  0.0575, -0.1176, -0.0208, -0.1283, -0.1242,  0.0361,  0.1227,
         0.1069,  0.0944, -0.0433,  0.0942], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 5, 6, 35791395]), dtype=torch.float16)
First 100 elements: tensor([ 1.7586e-03, -1.3000e-02,  4.5624e-03,  9.9869e-03, -4.8637e-03,
        -1.3626e-02,  1.1110e-03, -1.3756e-02,  1.0910e-03, -1.3847e-02,
         1.1017e-02,  1.3466e-02,  3.6240e-03, -3.9825e-03, -1.1848e-02,
        -9.5291e-03, -1.2054e-02,  7.0343e-03, -1.0841e-02,  9.0103e-03,
         1.8509e-02, -1.7227e-02,  1.4236e-02, -1.0506e-02, -7.0953e-03,
        -6.2485e-03, -3.1967e-03, -9.8953e-03,  1.2772e-02, -1.5121e-02,
        -5.6686e-03, -3.0193e-03, -1.3565e-02,  5.6076e-03, -1.8677e-02,
        -1.9665e-03,  4.9543e-04,  1.2253e-02, -1.2634e-02, -1.6203e-03,
         8.1940e-03,  8.1253e-03, -1.0864e-02, -2.2259e-03, -2.4509e-04,
         3.7994e-03,  4.5624e-03, -1.4114e-02, -2.0046e-03, -2.2697e-03,
        -1.4511e-02,  1.5961e-02,  7.0229e-03,  1.6998e-02,  4.1351e-03,
         1.8753e-02,  1.7044e-02, -1.9226e-02, -3.8834e-03,  1.6922e-02,
         1.2436e-02,  1.0429e-02, -5.2299e-03, -3.5686e-03, -1.3466e-02,
        -1.6327e-02,  1.4740e-02,  1.8860e-02, -1.8148e-03, -1.3039e-02,
         8.0185e-03, -9.5520e-03,  6.9122e-03,  8.3084e-03, -7.4005e-03,
        -1.2642e-02, -1.4435e-02, -1.8661e-02,  6.0234e-03,  1.2718e-02,
         5.8212e-03, -6.4163e-03, -3.3379e-03, -1.3489e-02,  1.3969e-02,
        -1.1917e-02, -6.4621e-03, -7.3671e-05,  1.1208e-02,  7.4768e-03,
        -1.5282e-02, -2.7065e-03, -1.6693e-02, -1.6159e-02,  4.6883e-03,
         1.5961e-02,  1.3908e-02,  1.2276e-02, -5.6381e-03,  1.2253e-02],
       dtype=torch.float16)
[Worker 2] Completed Task 1002

[Worker 2] Processing Task 1006: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 1, 1e-06, False, None, )
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), 1, 1e-06, False, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 100 / 100 (100.0%)
Greatest absolute difference: 4.813709259033203 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 0.21097010374069214 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([100]), dtype=torch.float32)
All elements: tensor([27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307, 27.6307,
        27.6307, 27.6307, 27.6307, 27.6307])
DESIRED: (shape=torch.Size([100]), dtype=torch.float32)
All elements: tensor([22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170, 22.8170,
        22.8170, 22.8170, 22.8170, 22.8170])
[Worker 2] Completed Task 1006

[Worker 2] Processing Task 1020: paddle.nn.functional.rrelu(Tensor([2, 3, 76056713, 5],"float32"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([2, 3, 76056713, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2182830208 / 2281701390 (95.7%)
Greatest absolute difference: 0.5 at index (0, 0, 220435, 4) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 3, 76056713, 5]), dtype=torch.float32)
First 100 elements: tensor([ 0.3610, -0.0658,  0.2521,  0.3033,  0.1368, -0.1255, -0.1043,  0.0899,
        -0.1252, -0.0172,  0.3861,  0.4770,  0.2101, -0.1071,  0.4306,  0.3726,
        -0.0910,  0.1954, -0.0714, -0.1198,  0.0063, -0.0853, -0.0419, -0.0419,
        -0.1141, -0.0696,  0.2480, -0.0077, -0.0342,  0.4343,  0.3164,  0.4647,
         0.3063,  0.1806, -0.1256,  0.0214, -0.1069, -0.1077, -0.0356, -0.1249,
        -0.0200,  0.4542, -0.1124, -0.1040, -0.0783,  0.1354,  0.4730,  0.2370,
         0.2877, -0.0178, -0.1223, -0.0071, -0.1276,  0.0954, -0.0379, -0.0856,
         0.2623, -0.0821, -0.0567,  0.2482, -0.1264,  0.4330, -0.0879,  0.0089,
         0.3157,  0.2944, -0.0977,  0.1564, -0.0647,  0.4214, -0.1303,  0.0926,
         0.3078,  0.0390,  0.1032, -0.0570,  0.1835, -0.0182,  0.4547, -0.0903,
         0.0404,  0.2723,  0.3015,  0.3173,  0.4352, -0.1239, -0.1305, -0.0844,
         0.1402, -0.0069, -0.0121, -0.1208,  0.4347,  0.2064,  0.1290, -0.1460,
         0.4147, -0.0453,  0.1015, -0.0414])
DESIRED: (shape=torch.Size([2, 3, 76056713, 5]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
[Worker 2] Completed Task 1020

[Worker 2] Processing Task 1022: paddle.nn.functional.rrelu(Tensor([38028357, 3, 4, 5],"float32"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([38028357, 3, 4, 5],"float32"), 0.3, 0.300000009, training=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2182830237 / 2281701420 (95.7%)
Greatest absolute difference: 0.5 at index (18369, 1, 3, 4) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([38028357, 3, 4, 5]), dtype=torch.float32)
First 100 elements: tensor([ 0.3610, -0.0658,  0.2521,  0.3033,  0.1368, -0.1255, -0.1043,  0.0899,
        -0.1252, -0.0172,  0.3861,  0.4770,  0.2101, -0.1071,  0.4306,  0.3726,
        -0.0910,  0.1954, -0.0714, -0.1198,  0.0063, -0.0853, -0.0419, -0.0419,
        -0.1141, -0.0696,  0.2480, -0.0077, -0.0342,  0.4343,  0.3164,  0.4647,
         0.3063,  0.1806, -0.1256,  0.0214, -0.1069, -0.1077, -0.0356, -0.1249,
        -0.0200,  0.4542, -0.1124, -0.1040, -0.0783,  0.1354,  0.4730,  0.2370,
         0.2877, -0.0178, -0.1223, -0.0071, -0.1276,  0.0954, -0.0379, -0.0856,
         0.2623, -0.0821, -0.0567,  0.2482, -0.1264,  0.4330, -0.0879,  0.0089,
         0.3157,  0.2944, -0.0977,  0.1564, -0.0647,  0.4214, -0.1303,  0.0926,
         0.3078,  0.0390,  0.1032, -0.0570,  0.1835, -0.0182,  0.4547, -0.0903,
         0.0404,  0.2723,  0.3015,  0.3173,  0.4352, -0.1239, -0.1305, -0.0844,
         0.1402, -0.0069, -0.0121, -0.1208,  0.4347,  0.2064,  0.1290, -0.1460,
         0.4147, -0.0453,  0.1015, -0.0414])
DESIRED: (shape=torch.Size([38028357, 3, 4, 5]), dtype=torch.float32)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])
[Worker 2] Completed Task 1022

[Worker 2] Processing Task 1024: paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.3, 0.300000009, training=True, )
[accuracy error] paddle.nn.functional.rrelu(Tensor([71582789, 3, 4, 5],"float16"), 0.3, 0.300000009, training=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4108806487 / 4294967340 (95.7%)
Greatest absolute difference: 0.5 at index (4, 2, 3, 4) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 2, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float16)
First 100 elements: tensor([ 0.0455, -0.1009,  0.1180,  0.2583, -0.0377, -0.1057,  0.0287, -0.1068,
         0.0282, -0.1075,  0.2849,  0.3481,  0.0937, -0.0309, -0.0919, -0.0740,
        -0.0936,  0.1819, -0.0841,  0.2330,  0.4785, -0.1337,  0.3682, -0.0815,
        -0.0551, -0.0485, -0.0248, -0.0768,  0.3303, -0.1174, -0.0440, -0.0234,
        -0.1053,  0.1450, -0.1450, -0.0153,  0.0128,  0.3169, -0.0980, -0.0126,
         0.2119,  0.2102, -0.0843, -0.0173, -0.0019,  0.0983,  0.1180, -0.1095,
        -0.0156, -0.0176, -0.1126,  0.4126,  0.1816,  0.4395,  0.1069,  0.4851,
         0.4409, -0.1492, -0.0301,  0.4375,  0.3215,  0.2698, -0.0406, -0.0277,
        -0.1044, -0.1267,  0.3811,  0.4875, -0.0141, -0.1011,  0.2073, -0.0742,
         0.1787,  0.2148, -0.0574, -0.0981, -0.1120, -0.1448,  0.1558,  0.3289,
         0.1505, -0.0498, -0.0259, -0.1047,  0.3613, -0.0925, -0.0501, -0.0006,
         0.2898,  0.1934, -0.1186, -0.0210, -0.1295, -0.1254,  0.1213,  0.4128,
         0.3596,  0.3174, -0.0437,  0.3169], dtype=torch.float16)
DESIRED: (shape=torch.Size([71582789, 3, 4, 5]), dtype=torch.float16)
First 100 elements: tensor([ 0.0455, -0.1009,  0.1180,  0.2583, -0.0377, -0.1057,  0.0287, -0.1068,
         0.0282, -0.1075,  0.2849,  0.3481,  0.0937, -0.0309, -0.0919, -0.0740,
        -0.0936,  0.1819, -0.0841,  0.2330,  0.4785, -0.1337,  0.3682, -0.0815,
        -0.0551, -0.0485, -0.0248, -0.0768,  0.3303, -0.1174, -0.0440, -0.0234,
        -0.1053,  0.1450, -0.1450, -0.0153,  0.0128,  0.3169, -0.0980, -0.0126,
         0.2119,  0.2102, -0.0843, -0.0173,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
[Worker 2] Completed Task 1024

[Worker 2] Processing Task 1146: paddle.roll(Tensor([1, 114131, 7, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 114131, 7, 7, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 10266 / 4294977792 (0.0%)
Greatest absolute difference: 0.5 at index (0, 114130, 5, 3, 155) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 114130, 5, 0, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 114131, 7, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.1575,  0.3545, -0.4832,  0.2666,  0.4424, -0.4290,  0.0899,  0.4644,
        -0.0234,  0.3086,  0.3704, -0.0144,  0.3770,  0.3542,  0.3589,  0.1886,
        -0.2642,  0.2827,  0.3625, -0.4434,  0.1182,  0.2379,  0.1344, -0.2708,
         0.1794,  0.4111, -0.4392,  0.3455,  0.4888, -0.1724,  0.1422, -0.1821,
        -0.2720, -0.2896,  0.3347,  0.1843, -0.1125,  0.2754, -0.0982,  0.0698,
        -0.1132, -0.0748,  0.2457, -0.1104,  0.2482, -0.0724, -0.0469,  0.4592,
         0.3767, -0.0185, -0.0575, -0.0036,  0.3499, -0.2805, -0.4036,  0.1686,
        -0.3669, -0.4736,  0.2590,  0.1948, -0.2900,  0.1024, -0.2812,  0.4241,
         0.1582,  0.0583, -0.2563,  0.3318, -0.3757, -0.3318, -0.2196, -0.3726,
         0.3501,  0.4609, -0.0461,  0.4851, -0.0503,  0.0652,  0.3811, -0.4104,
         0.3452, -0.2732,  0.4971,  0.3816,  0.4866, -0.1713,  0.3228,  0.4995,
         0.4875,  0.4854, -0.1281, -0.4041, -0.2183,  0.4958, -0.3572, -0.1598,
         0.3157,  0.0392, -0.4363,  0.3721], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 114131, 7, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.1575,  0.3545, -0.4832,  0.2666,  0.4424, -0.4290,  0.0899,  0.4644,
        -0.0234,  0.3086,  0.3704, -0.0144,  0.3770,  0.3542,  0.3589,  0.1886,
        -0.2642,  0.2827,  0.3625, -0.4434,  0.1182,  0.2379,  0.1344, -0.2708,
         0.1794,  0.4111, -0.4392,  0.3455,  0.4888, -0.1724,  0.1422, -0.1821,
        -0.2720, -0.2896,  0.3347,  0.1843, -0.1125,  0.2754, -0.0982,  0.0698,
        -0.1132, -0.0748,  0.2457, -0.1104,  0.2482, -0.0724, -0.0469,  0.4592,
         0.3767, -0.0185, -0.0575, -0.0036,  0.3499, -0.2805, -0.4036,  0.1686,
        -0.3669, -0.4736,  0.2590,  0.1948, -0.2900,  0.1024, -0.2812,  0.4241,
         0.1582,  0.0583, -0.2563,  0.3318, -0.3757, -0.3318, -0.2196, -0.3726,
         0.3501,  0.4609, -0.0461,  0.4851, -0.0503,  0.0652,  0.3811, -0.4104,
         0.3452, -0.2732,  0.4971,  0.3816,  0.4866, -0.1713,  0.3228,  0.4995,
         0.4875,  0.4854, -0.1281, -0.4041, -0.2183,  0.4958, -0.3572, -0.1598,
         0.3157,  0.0392, -0.4363,  0.3721], dtype=torch.float16)
[Worker 2] Completed Task 1146

[Worker 2] Processing Task 1150: paddle.roll(Tensor([1, 16, 14, 21, 913046],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 21, 913046],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3202 / 4294968384 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 2, 2, 912304) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 2, 2, 911958) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 21, 913046]), dtype=torch.float16)
First 100 elements: tensor([ 0.4099, -0.3047, -0.4124, -0.1456, -0.2419,  0.1047,  0.3325,  0.4797,
         0.2103,  0.1294, -0.2937, -0.4951, -0.1565, -0.0626,  0.1592,  0.1265,
         0.4197, -0.3125, -0.3337,  0.0752, -0.4062,  0.4260, -0.3496, -0.2220,
         0.3005, -0.2559, -0.1932,  0.0174,  0.0300,  0.2227,  0.1494, -0.2179,
        -0.4434, -0.3091, -0.3984,  0.2935, -0.2646,  0.2229,  0.4871, -0.2230,
        -0.3750, -0.1749, -0.2639, -0.1094,  0.4050,  0.2051, -0.3445, -0.3276,
        -0.0966,  0.3162,  0.1320,  0.1538,  0.3184,  0.4094,  0.1356,  0.3381,
        -0.3357, -0.2352,  0.3638, -0.0759, -0.2607,  0.3074,  0.4385, -0.4102,
         0.4119,  0.0139,  0.3694,  0.0758, -0.3994, -0.1788, -0.4258, -0.2439,
        -0.2593,  0.0739,  0.3975,  0.3225, -0.2710,  0.1798, -0.1106,  0.3459,
         0.1735,  0.0025, -0.0045, -0.0493,  0.0828,  0.3462,  0.3789, -0.0437,
         0.1466,  0.3813,  0.1296,  0.2554,  0.0960,  0.3760,  0.3232,  0.4048,
         0.1368,  0.2296,  0.1052,  0.2842], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 21, 913046]), dtype=torch.float16)
First 100 elements: tensor([ 0.4099, -0.3047, -0.4124, -0.1456, -0.2419,  0.1047,  0.3325,  0.4797,
         0.2103,  0.1294, -0.2937, -0.4951, -0.1565, -0.0626,  0.1592,  0.1265,
         0.4197, -0.3125, -0.3337,  0.0752, -0.4062,  0.4260, -0.3496, -0.2220,
         0.3005, -0.2559, -0.1932,  0.0174,  0.0300,  0.2227,  0.1494, -0.2179,
        -0.4434, -0.3091, -0.3984,  0.2935, -0.2646,  0.2229,  0.4871, -0.2230,
        -0.3750, -0.1749, -0.2639, -0.1094,  0.4050,  0.2051, -0.3445, -0.3276,
        -0.0966,  0.3162,  0.1320,  0.1538,  0.3184,  0.4094,  0.1356,  0.3381,
        -0.3357, -0.2352,  0.3638, -0.0759, -0.2607,  0.3074,  0.4385, -0.4102,
         0.4119,  0.0139,  0.3694,  0.0758, -0.3994, -0.1788, -0.4258, -0.2439,
        -0.2593,  0.0739,  0.3975,  0.3225, -0.2710,  0.1798, -0.1106,  0.3459,
         0.1735,  0.0025, -0.0045, -0.0493,  0.0828,  0.3462,  0.3789, -0.0437,
         0.1466,  0.3813,  0.1296,  0.2554,  0.0960,  0.3760,  0.3232,  0.4048,
         0.1368,  0.2296,  0.1052,  0.2842], dtype=torch.float16)
[Worker 2] Completed Task 1150

[Worker 2] Processing Task 1154: paddle.roll(Tensor([1, 16, 14, 49933, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 14, 49933, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 137595 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 2, 2, 113) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 14, 49933, 384]), dtype=torch.float16)
First 100 elements: tensor([ 3.8306e-01,  1.1841e-01, -1.2598e-01,  1.4612e-01,  8.8577e-03,
         4.1235e-01,  3.7500e-01,  8.4412e-02, -3.2422e-01, -4.2236e-01,
         2.8906e-01,  1.2378e-01,  4.2163e-01,  2.1765e-01,  2.2278e-01,
         3.1299e-01,  1.2469e-01,  1.3672e-01,  1.4868e-01, -1.3989e-01,
         7.1167e-02, -4.3488e-02, -2.2717e-01, -4.3701e-02,  6.4087e-02,
         4.3848e-01, -2.3499e-01, -1.0175e-01,  1.3184e-01, -3.2373e-01,
         1.5833e-01, -4.9438e-01, -4.9536e-01, -5.9738e-03,  4.8901e-01,
         5.7495e-02,  9.7961e-02, -1.5393e-01,  2.6489e-01,  4.2651e-01,
        -4.6167e-01,  4.1455e-01, -2.1021e-01, -3.7915e-01,  3.7646e-01,
         2.3999e-01,  2.8857e-01, -2.0337e-01, -2.9639e-01,  3.8623e-01,
        -3.8867e-01, -4.2969e-01,  1.1843e-04,  9.0576e-02, -1.4502e-01,
        -4.9713e-02, -1.0773e-01,  1.0571e-01,  2.1240e-01,  1.6064e-01,
         2.9248e-01, -4.1504e-01,  4.6069e-01, -8.3435e-02, -2.2476e-02,
         2.4182e-01, -6.7902e-03, -3.0737e-01, -3.1152e-01, -3.2463e-03,
        -7.6416e-02,  2.1643e-01, -3.4790e-01,  1.9983e-01, -4.3488e-02,
        -1.0742e-01,  3.3340e-03, -1.3574e-01, -4.1943e-01, -2.3071e-01,
        -3.4961e-01, -2.9395e-01, -3.7451e-01, -4.5044e-01, -2.5220e-01,
         1.1603e-01,  3.3417e-02, -9.1553e-02,  2.2656e-01, -2.3352e-01,
         2.7026e-01, -3.1250e-01,  1.4429e-01,  5.0812e-03, -4.3555e-01,
        -2.3083e-01,  2.9980e-01, -4.7534e-01,  4.6021e-01,  4.2822e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 14, 49933, 384]), dtype=torch.float16)
First 100 elements: tensor([ 3.8306e-01,  1.1841e-01, -1.2598e-01,  1.4612e-01,  8.8577e-03,
         4.1235e-01,  3.7500e-01,  8.4412e-02, -3.2422e-01, -4.2236e-01,
         2.8906e-01,  1.2378e-01,  4.2163e-01,  2.1765e-01,  2.2278e-01,
         3.1299e-01,  1.2469e-01,  1.3672e-01,  1.4868e-01, -1.3989e-01,
         7.1167e-02, -4.3488e-02, -2.2717e-01, -4.3701e-02,  6.4087e-02,
         4.3848e-01, -2.3499e-01, -1.0175e-01,  1.3184e-01, -3.2373e-01,
         1.5833e-01, -4.9438e-01, -4.9536e-01, -5.9738e-03,  4.8901e-01,
         5.7495e-02,  9.7961e-02, -1.5393e-01,  2.6489e-01,  4.2651e-01,
        -4.6167e-01,  4.1455e-01, -2.1021e-01, -3.7915e-01,  3.7646e-01,
         2.3999e-01,  2.8857e-01, -2.0337e-01, -2.9639e-01,  3.8623e-01,
        -3.8867e-01, -4.2969e-01,  1.1843e-04,  9.0576e-02, -1.4502e-01,
        -4.9713e-02, -1.0773e-01,  1.0571e-01,  2.1240e-01,  1.6064e-01,
         2.9248e-01, -4.1504e-01,  4.6069e-01, -8.3435e-02, -2.2476e-02,
         2.4182e-01, -6.7902e-03, -3.0737e-01, -3.1152e-01, -3.2463e-03,
        -7.6416e-02,  2.1643e-01, -3.4790e-01,  1.9983e-01, -4.3488e-02,
        -1.0742e-01,  3.3340e-03, -1.3574e-01, -4.1943e-01, -2.3071e-01,
        -3.4961e-01, -2.9395e-01, -3.7451e-01, -4.5044e-01, -2.5220e-01,
         1.1603e-01,  3.3417e-02, -9.1553e-02,  2.2656e-01, -2.3352e-01,
         2.7026e-01, -3.1250e-01,  1.4429e-01,  5.0812e-03, -4.3555e-01,
        -2.3083e-01,  2.9980e-01, -4.7534e-01,  4.6021e-01,  4.2822e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 1154

[Worker 2] Processing Task 1158: paddle.roll(Tensor([1, 16, 21, 14, 913046],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 21, 14, 913046],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 3205 / 4294968384 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 2, 2, 912304) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 2, 2, 911958) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 21, 14, 913046]), dtype=torch.float16)
First 100 elements: tensor([-0.4609,  0.1234, -0.2896, -0.0196,  0.0058, -0.2715,  0.4763,  0.3938,
        -0.2734, -0.4336,  0.4961,  0.1022,  0.0107,  0.0313,  0.0583, -0.3569,
         0.1284,  0.0332, -0.4614, -0.3054, -0.2279,  0.1931,  0.3054,  0.2585,
        -0.2218,  0.4531,  0.4680,  0.0009, -0.0537, -0.3003, -0.3484,  0.4807,
        -0.0540,  0.3145,  0.2883, -0.4551, -0.1541, -0.1256,  0.0493,  0.4614,
         0.3708, -0.1164,  0.0815,  0.2856,  0.0475,  0.2686, -0.3477, -0.1080,
        -0.1904, -0.0909,  0.0623,  0.3745,  0.3704, -0.2115, -0.4011,  0.3875,
         0.2515,  0.1702,  0.1187,  0.3848, -0.1586,  0.0516,  0.1049, -0.0575,
         0.1052, -0.4114, -0.4634, -0.2761,  0.4507, -0.3333, -0.3796, -0.0323,
        -0.1803, -0.3247, -0.3010,  0.4421, -0.2942, -0.4976,  0.2913,  0.4705,
        -0.4756, -0.1666,  0.4805,  0.3047, -0.1135, -0.2493,  0.2971,  0.0058,
         0.2661, -0.3433, -0.4712, -0.0065, -0.4795,  0.4922, -0.0298, -0.3442,
        -0.1164,  0.2319, -0.1967,  0.1488], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 21, 14, 913046]), dtype=torch.float16)
First 100 elements: tensor([-0.4609,  0.1234, -0.2896, -0.0196,  0.0058, -0.2715,  0.4763,  0.3938,
        -0.2734, -0.4336,  0.4961,  0.1022,  0.0107,  0.0313,  0.0583, -0.3569,
         0.1284,  0.0332, -0.4614, -0.3054, -0.2279,  0.1931,  0.3054,  0.2585,
        -0.2218,  0.4531,  0.4680,  0.0009, -0.0537, -0.3003, -0.3484,  0.4807,
        -0.0540,  0.3145,  0.2883, -0.4551, -0.1541, -0.1256,  0.0493,  0.4614,
         0.3708, -0.1164,  0.0815,  0.2856,  0.0475,  0.2686, -0.3477, -0.1080,
        -0.1904, -0.0909,  0.0623,  0.3745,  0.3704, -0.2115, -0.4011,  0.3875,
         0.2515,  0.1702,  0.1187,  0.3848, -0.1586,  0.0516,  0.1049, -0.0575,
         0.1052, -0.4114, -0.4634, -0.2761,  0.4507, -0.3333, -0.3796, -0.0323,
        -0.1803, -0.3247, -0.3010,  0.4421, -0.2942, -0.4976,  0.2913,  0.4705,
        -0.4756, -0.1666,  0.4805,  0.3047, -0.1135, -0.2493,  0.2971,  0.0058,
         0.2661, -0.3433, -0.4712, -0.0065, -0.4795,  0.4922, -0.0298, -0.3442,
        -0.1164,  0.2319, -0.1967,  0.1488], dtype=torch.float16)
[Worker 2] Completed Task 1158

[Worker 2] Processing Task 1162: paddle.roll(Tensor([1, 16, 24967, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 24967, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 154772 / 4295122944 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 24952, 0, 605) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 24952, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 24967, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.2379, -0.0320,  0.3411,  0.4124,  0.2815, -0.0600,  0.3679,  0.4072,
         0.3462,  0.1669,  0.4211, -0.0815,  0.1576,  0.3149, -0.4307, -0.0791,
        -0.1390,  0.3789, -0.3901, -0.3384, -0.1555, -0.3743, -0.4011,  0.2380,
        -0.1470, -0.2625,  0.0481, -0.3684, -0.3503, -0.4702, -0.4297, -0.2961,
         0.2332,  0.0924,  0.3477, -0.2477, -0.4060,  0.3015, -0.1925,  0.4587,
        -0.2917, -0.1158,  0.4492, -0.1331,  0.0114,  0.4155,  0.3108, -0.2129,
        -0.2220,  0.3936,  0.1307, -0.1707, -0.1700,  0.1611, -0.0986,  0.2013,
        -0.2666, -0.3386,  0.2202, -0.0714,  0.4221, -0.0762,  0.3147,  0.1473,
        -0.3308,  0.3376, -0.1229, -0.0291,  0.3662, -0.0078,  0.2115, -0.3987,
         0.0121, -0.4792, -0.0852, -0.0744,  0.1765, -0.2832, -0.1887,  0.2240,
         0.1891,  0.0869, -0.0804, -0.0035, -0.3049, -0.4131,  0.0983,  0.0865,
         0.3857,  0.2395, -0.2625, -0.2559, -0.2986, -0.0574,  0.1230,  0.3938,
         0.4407,  0.2046, -0.4160,  0.3999], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 24967, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.2379, -0.0320,  0.3411,  0.4124,  0.2815, -0.0600,  0.3679,  0.4072,
         0.3462,  0.1669,  0.4211, -0.0815,  0.1576,  0.3149, -0.4307, -0.0791,
        -0.1390,  0.3789, -0.3901, -0.3384, -0.1555, -0.3743, -0.4011,  0.2380,
        -0.1470, -0.2625,  0.0481, -0.3684, -0.3503, -0.4702, -0.4297, -0.2961,
         0.2332,  0.0924,  0.3477, -0.2477, -0.4060,  0.3015, -0.1925,  0.4587,
        -0.2917, -0.1158,  0.4492, -0.1331,  0.0114,  0.4155,  0.3108, -0.2129,
        -0.2220,  0.3936,  0.1307, -0.1707, -0.1700,  0.1611, -0.0986,  0.2013,
        -0.2666, -0.3386,  0.2202, -0.0714,  0.4221, -0.0762,  0.3147,  0.1473,
        -0.3308,  0.3376, -0.1229, -0.0291,  0.3662, -0.0078,  0.2115, -0.3987,
         0.0121, -0.4792, -0.0852, -0.0744,  0.1765, -0.2832, -0.1887,  0.2240,
         0.1891,  0.0869, -0.0804, -0.0035, -0.3049, -0.4131,  0.0983,  0.0865,
         0.3857,  0.2395, -0.2625, -0.2559, -0.2986, -0.0574,  0.1230,  0.3938,
         0.4407,  0.2046, -0.4160,  0.3999], dtype=torch.float16)
[Worker 2] Completed Task 1162

[Worker 2] Processing Task 1166: paddle.roll(Tensor([1, 16, 49933, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 49933, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 84237 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 1, 1, 272) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 49933, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3225, -0.3074, -0.4429, -0.0316, -0.2356, -0.0892, -0.0164,  0.1837,
        -0.1757, -0.4607,  0.2524, -0.2969, -0.3186, -0.1642, -0.0945,  0.2334,
        -0.3669, -0.0319,  0.0847,  0.1599,  0.0665, -0.4355, -0.0088,  0.4961,
        -0.4746,  0.2125,  0.1533,  0.0213,  0.2184, -0.1184, -0.3025,  0.0093,
         0.4253,  0.4221, -0.0385,  0.0233,  0.3584,  0.3120,  0.1049,  0.2043,
         0.3760,  0.3159, -0.3044, -0.3494, -0.2284, -0.2024, -0.0519, -0.3965,
         0.3682,  0.0406, -0.4612,  0.0682,  0.0524, -0.2522, -0.3225, -0.4775,
         0.2247,  0.2019,  0.4067,  0.2544,  0.1387,  0.1104,  0.0870, -0.4160,
         0.0723,  0.2678,  0.2769, -0.1477, -0.0689,  0.1376, -0.3713, -0.2598,
         0.3552,  0.1630,  0.1371,  0.1530, -0.3230, -0.2181, -0.2974,  0.3884,
         0.2778, -0.4548, -0.2056,  0.3958,  0.0887,  0.4502, -0.2008,  0.3757,
         0.2686, -0.4990,  0.2688,  0.3999,  0.1974, -0.3354,  0.2014, -0.3447,
        -0.4600,  0.4082, -0.2759,  0.0978], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 49933, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.3225, -0.3074, -0.4429, -0.0316, -0.2356, -0.0892, -0.0164,  0.1837,
        -0.1757, -0.4607,  0.2524, -0.2969, -0.3186, -0.1642, -0.0945,  0.2334,
        -0.3669, -0.0319,  0.0847,  0.1599,  0.0665, -0.4355, -0.0088,  0.4961,
        -0.4746,  0.2125,  0.1533,  0.0213,  0.2184, -0.1184, -0.3025,  0.0093,
         0.4253,  0.4221, -0.0385,  0.0233,  0.3584,  0.3120,  0.1049,  0.2043,
         0.3760,  0.3159, -0.3044, -0.3494, -0.2284, -0.2024, -0.0519, -0.3965,
         0.3682,  0.0406, -0.4612,  0.0682,  0.0524, -0.2522, -0.3225, -0.4775,
         0.2247,  0.2019,  0.4067,  0.2544,  0.1387,  0.1104,  0.0870, -0.4160,
         0.0723,  0.2678,  0.2769, -0.1477, -0.0689,  0.1376, -0.3713, -0.2598,
         0.3552,  0.1630,  0.1371,  0.1530, -0.3230, -0.2181, -0.2974,  0.3884,
         0.2778, -0.4548, -0.2056,  0.3958,  0.0887,  0.4502, -0.2008,  0.3757,
         0.2686, -0.4990,  0.2688,  0.3999,  0.1974, -0.3354,  0.2014, -0.3447,
        -0.4600,  0.4082, -0.2759,  0.0978], dtype=torch.float16)
[Worker 2] Completed Task 1166

[Worker 2] Processing Task 1170: paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 49933, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 83988 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 1, 6, 272) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.4912, -0.3721,  0.2778,  0.3240,  0.4370,  0.0436, -0.0013,  0.4736,
         0.3811, -0.2957,  0.4038,  0.3193, -0.2988, -0.2123, -0.2722,  0.3870,
        -0.3074,  0.2737, -0.1487,  0.2683,  0.3240,  0.0337, -0.2949, -0.2052,
        -0.1010, -0.3484, -0.0996, -0.0475,  0.0424, -0.4360,  0.4502, -0.4988,
        -0.2517, -0.1982,  0.3225,  0.3547,  0.3210,  0.2408,  0.4812, -0.4705,
         0.2991, -0.2698,  0.3689, -0.1099,  0.3240, -0.2871, -0.2727,  0.4995,
        -0.3643, -0.3337, -0.0952,  0.1573, -0.2094,  0.0375,  0.0728,  0.4146,
         0.4807, -0.4158, -0.2661, -0.4648, -0.3723, -0.0218, -0.2167,  0.2776,
        -0.4790, -0.0122,  0.0959,  0.2761,  0.2927,  0.3516, -0.2644, -0.2087,
        -0.3206, -0.0045,  0.0903, -0.0030,  0.0408,  0.3250,  0.4902, -0.1318,
        -0.0838, -0.3247,  0.4622, -0.2612, -0.3540,  0.4829, -0.4001,  0.0239,
         0.1091, -0.4783,  0.0876, -0.4292, -0.4568,  0.3132, -0.4766, -0.2306,
         0.2805,  0.3530, -0.4695, -0.0911], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 49933, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.4912, -0.3721,  0.2778,  0.3240,  0.4370,  0.0436, -0.0013,  0.4736,
         0.3811, -0.2957,  0.4038,  0.3193, -0.2988, -0.2123, -0.2722,  0.3870,
        -0.3074,  0.2737, -0.1487,  0.2683,  0.3240,  0.0337, -0.2949, -0.2052,
        -0.1010, -0.3484, -0.0996, -0.0475,  0.0424, -0.4360,  0.4502, -0.4988,
        -0.2517, -0.1982,  0.3225,  0.3547,  0.3210,  0.2408,  0.4812, -0.4705,
         0.2991, -0.2698,  0.3689, -0.1099,  0.3240, -0.2871, -0.2727,  0.4995,
        -0.3643, -0.3337, -0.0952,  0.1573, -0.2094,  0.0375,  0.0728,  0.4146,
         0.4807, -0.4158, -0.2661, -0.4648, -0.3723, -0.0218, -0.2167,  0.2776,
        -0.4790, -0.0122,  0.0959,  0.2761,  0.2927,  0.3516, -0.2644, -0.2087,
        -0.3206, -0.0045,  0.0903, -0.0030,  0.0408,  0.3250,  0.4902, -0.1318,
        -0.0838, -0.3247,  0.4622, -0.2612, -0.3540,  0.4829, -0.4001,  0.0239,
         0.1091, -0.4783,  0.0876, -0.4292, -0.4568,  0.3132, -0.4766, -0.2306,
         0.2805,  0.3530, -0.4695, -0.0911], dtype=torch.float16)
[Worker 2] Completed Task 1170

[Worker 2] Processing Task 1174: paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 49933, 768],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 68191 / 4295036928 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 6, 49849, 274) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 49842, 256) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.2065, -0.3640, -0.1447, -0.0570, -0.2808, -0.4124, -0.3640,  0.4985,
        -0.0843, -0.2952,  0.4104,  0.0680,  0.1065, -0.0498, -0.1459,  0.4204,
         0.0884, -0.3647, -0.3738, -0.2400, -0.4983,  0.2505,  0.1367, -0.0487,
        -0.3938,  0.4624,  0.3835, -0.4595,  0.4736,  0.3640, -0.0635, -0.3293,
         0.3811,  0.4473,  0.3445,  0.0377, -0.3416, -0.3640, -0.4609,  0.3010,
         0.1819, -0.1547,  0.3679, -0.2544,  0.4631,  0.4985,  0.1520, -0.4529,
        -0.4780, -0.1190, -0.2737,  0.2517, -0.0851, -0.0112,  0.0644, -0.2993,
        -0.0878, -0.2490, -0.4954,  0.1254, -0.4851, -0.1843, -0.2556, -0.1006,
        -0.0699, -0.4661, -0.2135, -0.1486,  0.1744, -0.1602,  0.3447, -0.2046,
         0.0377,  0.4509,  0.2722, -0.1935, -0.4612, -0.3545, -0.2825,  0.0887,
         0.0142, -0.3979, -0.1981,  0.2140, -0.0712, -0.2754,  0.1852,  0.0756,
        -0.1371,  0.0978, -0.1689, -0.0443,  0.3074,  0.0120, -0.0485, -0.4712,
        -0.0553, -0.0696, -0.1039,  0.4458], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 49933, 768]), dtype=torch.float16)
First 100 elements: tensor([-0.2065, -0.3640, -0.1447, -0.0570, -0.2808, -0.4124, -0.3640,  0.4985,
        -0.0843, -0.2952,  0.4104,  0.0680,  0.1065, -0.0498, -0.1459,  0.4204,
         0.0884, -0.3647, -0.3738, -0.2400, -0.4983,  0.2505,  0.1367, -0.0487,
        -0.3938,  0.4624,  0.3835, -0.4595,  0.4736,  0.3640, -0.0635, -0.3293,
         0.3811,  0.4473,  0.3445,  0.0377, -0.3416, -0.3640, -0.4609,  0.3010,
         0.1819, -0.1547,  0.3679, -0.2544,  0.4631,  0.4985,  0.1520, -0.4529,
        -0.4780, -0.1190, -0.2737,  0.2517, -0.0851, -0.0112,  0.0644, -0.2993,
        -0.0878, -0.2490, -0.4954,  0.1254, -0.4851, -0.1843, -0.2556, -0.1006,
        -0.0699, -0.4661, -0.2135, -0.1486,  0.1744, -0.1602,  0.3447, -0.2046,
         0.0377,  0.4509,  0.2722, -0.1935, -0.4612, -0.3545, -0.2825,  0.0887,
         0.0142, -0.3979, -0.1981,  0.2140, -0.0712, -0.2754,  0.1852,  0.0756,
        -0.1371,  0.0978, -0.1689, -0.0443,  0.3074,  0.0120, -0.0485, -0.4712,
        -0.0553, -0.0696, -0.1039,  0.4458], dtype=torch.float16)
[Worker 2] Completed Task 1174

[Worker 2] Processing Task 1178: paddle.roll(Tensor([1, 16, 7, 7, 5478275],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 16, 7, 7, 5478275],"float16"), shifts=tuple(4,0,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 298 / 4294967600 (0.0%)
Greatest absolute difference: 0.5 at index (0, 15, 6, 6, 5478121) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 15, 6, 6, 5477971) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 16, 7, 7, 5478275]), dtype=torch.float16)
First 100 elements: tensor([ 2.3657e-01,  3.9014e-01,  3.9819e-01,  1.8384e-01,  3.3667e-01,
        -3.5889e-01, -2.0508e-01,  4.9219e-01, -4.7925e-01, -3.5986e-01,
        -2.1802e-01, -3.2056e-01,  1.1365e-01, -9.2407e-02,  2.1179e-02,
         1.1456e-01, -2.5684e-01,  1.9092e-01, -3.9038e-01,  1.8713e-01,
         3.2495e-01,  1.5717e-02, -3.8867e-01,  2.5830e-01,  4.9365e-01,
        -4.5264e-01, -3.9526e-01,  2.9770e-02, -8.5327e-02, -1.7749e-01,
         4.3481e-01,  3.3521e-01, -6.2195e-02,  1.2636e-04, -3.4607e-02,
        -1.9788e-01,  4.7217e-01, -1.6443e-01, -6.5308e-02, -1.4172e-01,
        -1.4160e-01, -2.1704e-01, -4.5563e-02, -1.2463e-01, -4.4141e-01,
         4.6777e-01, -4.8267e-01, -3.2921e-03,  4.7632e-01,  3.2568e-01,
         2.2308e-02, -9.3872e-02,  3.6108e-01, -4.1626e-01, -4.4385e-01,
         1.6956e-01, -1.2903e-01,  2.6025e-01,  3.3081e-02, -2.2827e-01,
        -3.8300e-02,  1.8201e-01, -4.0796e-01, -1.8018e-01, -1.7480e-01,
         1.3953e-01,  4.5239e-01, -3.9648e-01,  6.7444e-02,  7.7759e-02,
         2.7197e-01, -4.1089e-01, -3.5376e-01,  4.0210e-01,  3.0322e-01,
        -4.5728e-01, -1.9043e-01,  9.0088e-02,  1.2262e-01, -8.4381e-03,
         1.8628e-01,  3.9893e-01,  1.1469e-01, -3.9551e-01, -1.1609e-01,
         1.2189e-01,  2.6343e-01, -1.3416e-01, -2.0715e-01,  3.7549e-01,
         4.3018e-01,  6.7566e-02, -1.5308e-01, -2.6147e-01, -3.8843e-01,
         1.4685e-01,  2.6099e-01, -3.1567e-01,  2.3499e-01,  2.2839e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 16, 7, 7, 5478275]), dtype=torch.float16)
First 100 elements: tensor([ 2.3657e-01,  3.9014e-01,  3.9819e-01,  1.8384e-01,  3.3667e-01,
        -3.5889e-01, -2.0508e-01,  4.9219e-01, -4.7925e-01, -3.5986e-01,
        -2.1802e-01, -3.2056e-01,  1.1365e-01, -9.2407e-02,  2.1179e-02,
         1.1456e-01, -2.5684e-01,  1.9092e-01, -3.9038e-01,  1.8713e-01,
         3.2495e-01,  1.5717e-02, -3.8867e-01,  2.5830e-01,  4.9365e-01,
        -4.5264e-01, -3.9526e-01,  2.9770e-02, -8.5327e-02, -1.7749e-01,
         4.3481e-01,  3.3521e-01, -6.2195e-02,  1.2636e-04, -3.4607e-02,
        -1.9788e-01,  4.7217e-01, -1.6443e-01, -6.5308e-02, -1.4172e-01,
        -1.4160e-01, -2.1704e-01, -4.5563e-02, -1.2463e-01, -4.4141e-01,
         4.6777e-01, -4.8267e-01, -3.2921e-03,  4.7632e-01,  3.2568e-01,
         2.2308e-02, -9.3872e-02,  3.6108e-01, -4.1626e-01, -4.4385e-01,
         1.6956e-01, -1.2903e-01,  2.6025e-01,  3.3081e-02, -2.2827e-01,
        -3.8300e-02,  1.8201e-01, -4.0796e-01, -1.8018e-01, -1.7480e-01,
         1.3953e-01,  4.5239e-01, -3.9648e-01,  6.7444e-02,  7.7759e-02,
         2.7197e-01, -4.1089e-01, -3.5376e-01,  4.0210e-01,  3.0322e-01,
        -4.5728e-01, -1.9043e-01,  9.0088e-02,  1.2262e-01, -8.4381e-03,
         1.8628e-01,  3.9893e-01,  1.1469e-01, -3.9551e-01, -1.1609e-01,
         1.2189e-01,  2.6343e-01, -1.3416e-01, -2.0715e-01,  3.7549e-01,
         4.3018e-01,  6.7566e-02, -1.5308e-01, -2.6147e-01, -3.8843e-01,
         1.4685e-01,  2.6099e-01, -3.1567e-01,  2.3499e-01,  2.2839e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 1178

[Worker 2] Processing Task 1182: paddle.roll(Tensor([1, 38044, 21, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 38044, 21, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 63247 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 38043, 1, 9, 98) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 38043, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 38044, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.0657, -0.1862,  0.1918, -0.2026,  0.3201,  0.4604, -0.2124, -0.2246,
         0.3594,  0.0270, -0.1782,  0.1501, -0.0040,  0.2756, -0.3667, -0.3506,
        -0.0133, -0.1750, -0.1780, -0.4631,  0.4500, -0.2666,  0.2480, -0.4905,
         0.4412, -0.0906,  0.1191, -0.2266,  0.0826,  0.1295, -0.2440, -0.3435,
        -0.2847,  0.4492,  0.0126,  0.4016, -0.1750,  0.1552,  0.4541, -0.0182,
        -0.2035, -0.4019, -0.1328,  0.0501,  0.4683,  0.0200, -0.0499,  0.2233,
         0.2598,  0.2167,  0.2529,  0.4333,  0.2467, -0.1782,  0.0947, -0.3103,
         0.1685,  0.3804, -0.0363,  0.2866, -0.0881, -0.1393, -0.3154, -0.2047,
         0.0535,  0.2164, -0.0796, -0.0895, -0.0961,  0.4590, -0.0860, -0.4082,
        -0.4656, -0.3235, -0.0316, -0.4570, -0.4756,  0.2517, -0.3804,  0.1967,
        -0.3511, -0.0998,  0.0831, -0.0154,  0.2583, -0.0943, -0.3618, -0.0802,
         0.1008,  0.2311, -0.4414,  0.2524,  0.1085, -0.1384,  0.1591, -0.0977,
        -0.0384, -0.1403, -0.1164, -0.2297], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 38044, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([-0.0657, -0.1862,  0.1918, -0.2026,  0.3201,  0.4604, -0.2124, -0.2246,
         0.3594,  0.0270, -0.1782,  0.1501, -0.0040,  0.2756, -0.3667, -0.3506,
        -0.0133, -0.1750, -0.1780, -0.4631,  0.4500, -0.2666,  0.2480, -0.4905,
         0.4412, -0.0906,  0.1191, -0.2266,  0.0826,  0.1295, -0.2440, -0.3435,
        -0.2847,  0.4492,  0.0126,  0.4016, -0.1750,  0.1552,  0.4541, -0.0182,
        -0.2035, -0.4019, -0.1328,  0.0501,  0.4683,  0.0200, -0.0499,  0.2233,
         0.2598,  0.2167,  0.2529,  0.4333,  0.2467, -0.1782,  0.0947, -0.3103,
         0.1685,  0.3804, -0.0363,  0.2866, -0.0881, -0.1393, -0.3154, -0.2047,
         0.0535,  0.2164, -0.0796, -0.0895, -0.0961,  0.4590, -0.0860, -0.4082,
        -0.4656, -0.3235, -0.0316, -0.4570, -0.4756,  0.2517, -0.3804,  0.1967,
        -0.3511, -0.0998,  0.0831, -0.0154,  0.2583, -0.0943, -0.3618, -0.0802,
         0.1008,  0.2311, -0.4414,  0.2524,  0.1085, -0.1384,  0.1591, -0.0977,
        -0.0384, -0.1403, -0.1164, -0.2297], dtype=torch.float16)
[Worker 2] Completed Task 1182

[Worker 2] Processing Task 1186: paddle.roll(Tensor([1, 57066, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([1, 57066, 14, 7, 768],"float16"), shifts=tuple(4,3,0,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 62943 / 4295015424 (0.0%)
Greatest absolute difference: 0.5 at index (0, 57065, 0, 3, 719) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 57065, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 57066, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.3066, -0.2471,  0.4351, -0.4907, -0.4395, -0.3862,  0.4771, -0.2522,
         0.1768,  0.4136,  0.3799,  0.2428,  0.4114,  0.2898,  0.1242, -0.4543,
        -0.2362,  0.2554,  0.3254,  0.0018, -0.3765,  0.1125, -0.2086, -0.2996,
         0.2091,  0.3496, -0.0540,  0.2115, -0.3438, -0.3745,  0.2756,  0.2959,
        -0.0882,  0.2502,  0.1228, -0.3240,  0.4363,  0.0205,  0.1232,  0.1350,
         0.4727,  0.3125, -0.4854,  0.3562,  0.1909, -0.4165, -0.4036, -0.1831,
         0.4861,  0.1028,  0.2139, -0.4434,  0.0052, -0.4241,  0.4714,  0.0072,
        -0.4299,  0.2242, -0.4395, -0.3145, -0.0501,  0.3362, -0.1552,  0.1796,
        -0.3579,  0.3230, -0.1324,  0.4216,  0.3594,  0.0854,  0.4602,  0.3362,
         0.1404, -0.3350,  0.2271,  0.2148,  0.1779, -0.2354,  0.4307,  0.2048,
        -0.1812,  0.1715, -0.0655,  0.1039,  0.4707,  0.0614, -0.4214,  0.0571,
        -0.4583,  0.4368, -0.3257,  0.2998, -0.3796,  0.4519, -0.4087,  0.4741,
        -0.2057,  0.0487,  0.2456, -0.4551], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 57066, 14, 7, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.3066, -0.2471,  0.4351, -0.4907, -0.4395, -0.3862,  0.4771, -0.2522,
         0.1768,  0.4136,  0.3799,  0.2428,  0.4114,  0.2898,  0.1242, -0.4543,
        -0.2362,  0.2554,  0.3254,  0.0018, -0.3765,  0.1125, -0.2086, -0.2996,
         0.2091,  0.3496, -0.0540,  0.2115, -0.3438, -0.3745,  0.2756,  0.2959,
        -0.0882,  0.2502,  0.1228, -0.3240,  0.4363,  0.0205,  0.1232,  0.1350,
         0.4727,  0.3125, -0.4854,  0.3562,  0.1909, -0.4165, -0.4036, -0.1831,
         0.4861,  0.1028,  0.2139, -0.4434,  0.0052, -0.4241,  0.4714,  0.0072,
        -0.4299,  0.2242, -0.4395, -0.3145, -0.0501,  0.3362, -0.1552,  0.1796,
        -0.3579,  0.3230, -0.1324,  0.4216,  0.3594,  0.0854,  0.4602,  0.3362,
         0.1404, -0.3350,  0.2271,  0.2148,  0.1779, -0.2354,  0.4307,  0.2048,
        -0.1812,  0.1715, -0.0655,  0.1039,  0.4707,  0.0614, -0.4214,  0.0571,
        -0.4583,  0.4368, -0.3257,  0.2998, -0.3796,  0.4519, -0.4087,  0.4741,
        -0.2057,  0.0487,  0.2456, -0.4551], dtype=torch.float16)
[Worker 2] Completed Task 1186

[Worker 2] Processing Task 1190: paddle.roll(Tensor([1431655766, 3],"float16"), shifts=1, )
[accuracy error] paddle.roll(Tensor([1431655766, 3],"float16"), shifts=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 4294967298 (0.0%)
Greatest absolute difference: 0.279052734375 at index (1431655765, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1431655765, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.0504,  0.0455, -0.3362,  0.1180,  0.2583, -0.1257, -0.3523,  0.0287,
        -0.3557,  0.0282, -0.3582,  0.2849,  0.3481,  0.0937, -0.1030, -0.3064,
        -0.2465, -0.3118,  0.1819, -0.2803,  0.2330,  0.4785, -0.4456,  0.3682,
        -0.2717, -0.1835, -0.1616, -0.0826, -0.2559,  0.3303, -0.3911, -0.1466,
        -0.0781, -0.3508,  0.1450, -0.4832, -0.0509,  0.0128,  0.3169, -0.3267,
        -0.0419,  0.2119,  0.2102, -0.2810, -0.0576, -0.0063,  0.0983,  0.1180,
        -0.3650, -0.0518, -0.0587, -0.3752,  0.4126,  0.1816,  0.4395,  0.1069,
         0.4851,  0.4409, -0.4973, -0.1004,  0.4375,  0.3215,  0.2698, -0.1353,
        -0.0923, -0.3481, -0.4224,  0.3811,  0.4875, -0.0469, -0.3372,  0.2073,
        -0.2471,  0.1787,  0.2148, -0.1914, -0.3269, -0.3733, -0.4824,  0.1558,
         0.3289,  0.1505, -0.1659, -0.0863, -0.3489,  0.3613, -0.3081, -0.1671,
        -0.0019,  0.2898,  0.1934, -0.3953, -0.0700, -0.4316, -0.4177,  0.1213,
         0.4128,  0.3596,  0.3174, -0.1458], dtype=torch.float16)
DESIRED: (shape=torch.Size([1431655766, 3]), dtype=torch.float16)
First 100 elements: tensor([ 0.0504,  0.0455, -0.3362,  0.1180,  0.2583, -0.1257, -0.3523,  0.0287,
        -0.3557,  0.0282, -0.3582,  0.2849,  0.3481,  0.0937, -0.1030, -0.3064,
        -0.2465, -0.3118,  0.1819, -0.2803,  0.2330,  0.4785, -0.4456,  0.3682,
        -0.2717, -0.1835, -0.1616, -0.0826, -0.2559,  0.3303, -0.3911, -0.1466,
        -0.0781, -0.3508,  0.1450, -0.4832, -0.0509,  0.0128,  0.3169, -0.3267,
        -0.0419,  0.2119,  0.2102, -0.2810, -0.0576, -0.0063,  0.0983,  0.1180,
        -0.3650, -0.0518, -0.0587, -0.3752,  0.4126,  0.1816,  0.4395,  0.1069,
         0.4851,  0.4409, -0.4973, -0.1004,  0.4375,  0.3215,  0.2698, -0.1353,
        -0.0923, -0.3481, -0.4224,  0.3811,  0.4875, -0.0469, -0.3372,  0.2073,
        -0.2471,  0.1787,  0.2148, -0.1914, -0.3269, -0.3733, -0.4824,  0.1558,
         0.3289,  0.1505, -0.1659, -0.0863, -0.3489,  0.3613, -0.3081, -0.1671,
        -0.0019,  0.2898,  0.1934, -0.3953, -0.0700, -0.4316, -0.4177,  0.1213,
         0.4128,  0.3596,  0.3174, -0.1458], dtype=torch.float16)
[Worker 2] Completed Task 1190

[Worker 2] Processing Task 1194: paddle.roll(Tensor([2378, 16, 21, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([2378, 16, 21, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 505783 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (2377, 11, 1, 9, 98) (up to 0.01 allowed)
Greatest relative difference: inf at index (2377, 11, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2378, 16, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.2456,  0.2041, -0.0791, -0.4302, -0.1394,  0.3564,  0.0692,  0.0677,
        -0.1864, -0.4373, -0.3259, -0.3232,  0.0728,  0.3374, -0.1545,  0.2817,
        -0.4077, -0.1865,  0.3833, -0.1675, -0.3127,  0.4153,  0.1268, -0.1588,
        -0.0902, -0.3547,  0.1692, -0.0145, -0.0417, -0.1949, -0.2615, -0.2023,
         0.2103,  0.1333,  0.0656, -0.2302, -0.1628,  0.3750,  0.3357, -0.1164,
         0.3135,  0.4087, -0.3240,  0.4270, -0.2754,  0.1443, -0.2358, -0.1332,
        -0.3074,  0.1532, -0.3428, -0.3027, -0.4431,  0.3088,  0.1250,  0.1456,
        -0.1790,  0.0870, -0.3350,  0.3337, -0.1514, -0.1746,  0.2715, -0.0440,
         0.1656,  0.1052, -0.2668, -0.0573, -0.4124,  0.4827,  0.3062, -0.4014,
        -0.3489,  0.2852, -0.3271,  0.1956,  0.1262,  0.2428, -0.1815, -0.2854,
        -0.3040,  0.2625, -0.4478,  0.4609, -0.3142,  0.4429,  0.2651, -0.2844,
         0.1608,  0.0716, -0.0021,  0.4912, -0.3687, -0.3735,  0.3840,  0.0765,
         0.3113,  0.3271,  0.4146,  0.3289], dtype=torch.float16)
DESIRED: (shape=torch.Size([2378, 16, 21, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.2456,  0.2041, -0.0791, -0.4302, -0.1394,  0.3564,  0.0692,  0.0677,
        -0.1864, -0.4373, -0.3259, -0.3232,  0.0728,  0.3374, -0.1545,  0.2817,
        -0.4077, -0.1865,  0.3833, -0.1675, -0.3127,  0.4153,  0.1268, -0.1588,
        -0.0902, -0.3547,  0.1692, -0.0145, -0.0417, -0.1949, -0.2615, -0.2023,
         0.2103,  0.1333,  0.0656, -0.2302, -0.1628,  0.3750,  0.3357, -0.1164,
         0.3135,  0.4087, -0.3240,  0.4270, -0.2754,  0.1443, -0.2358, -0.1332,
        -0.3074,  0.1532, -0.3428, -0.3027, -0.4431,  0.3088,  0.1250,  0.1456,
        -0.1790,  0.0870, -0.3350,  0.3337, -0.1514, -0.1746,  0.2715, -0.0440,
         0.1656,  0.1052, -0.2668, -0.0573, -0.4124,  0.4827,  0.3062, -0.4014,
        -0.3489,  0.2852, -0.3271,  0.1956,  0.1262,  0.2428, -0.1815, -0.2854,
        -0.3040,  0.2625, -0.4478,  0.4609, -0.3142,  0.4429,  0.2651, -0.2844,
         0.1608,  0.0716, -0.0021,  0.4912, -0.3687, -0.3735,  0.3840,  0.0765,
         0.3113,  0.3271,  0.4146,  0.3289], dtype=torch.float16)
[Worker 2] Completed Task 1194

[Worker 2] Processing Task 1198: paddle.roll(Tensor([3567, 16, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([3567, 16, 14, 14, 384],"float16"), shifts=tuple(4,3,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 505842 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (3566, 9, 0, 10, 335) (up to 0.01 allowed)
Greatest relative difference: inf at index (3566, 9, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3567, 16, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0404, -0.2817,  0.0701, -0.2402,  0.2900, -0.3936, -0.4277, -0.4885,
         0.0953,  0.4751,  0.0233, -0.2581,  0.2595,  0.0536, -0.4060, -0.1414,
         0.0621,  0.1519, -0.2233, -0.2874, -0.0765,  0.2256,  0.4333,  0.0871,
        -0.0205,  0.1009, -0.4268, -0.0127, -0.4502,  0.1202,  0.0643,  0.0845,
         0.4573, -0.3835,  0.0806,  0.0630,  0.4724,  0.2537,  0.2271,  0.1121,
        -0.4121, -0.0492, -0.1023, -0.2874,  0.1191, -0.0324, -0.1006,  0.0300,
        -0.3979,  0.1674, -0.4370, -0.4866,  0.4092,  0.0006, -0.0858,  0.4949,
        -0.2069, -0.4150,  0.2036,  0.1163, -0.4890, -0.1975, -0.1208, -0.2208,
         0.2317,  0.2130,  0.0714,  0.1864,  0.2119,  0.2343,  0.0826, -0.2332,
        -0.4521, -0.1847,  0.1704, -0.2000, -0.2484, -0.0814, -0.1189, -0.3484,
         0.2434,  0.4238,  0.3347, -0.1953, -0.2771, -0.2610, -0.0555,  0.2700,
         0.1428,  0.4736,  0.1176,  0.2374, -0.4460, -0.2905, -0.4841, -0.3308,
        -0.4482,  0.2241,  0.4756, -0.0458], dtype=torch.float16)
DESIRED: (shape=torch.Size([3567, 16, 14, 14, 384]), dtype=torch.float16)
First 100 elements: tensor([ 0.0404, -0.2817,  0.0701, -0.2402,  0.2900, -0.3936, -0.4277, -0.4885,
         0.0953,  0.4751,  0.0233, -0.2581,  0.2595,  0.0536, -0.4060, -0.1414,
         0.0621,  0.1519, -0.2233, -0.2874, -0.0765,  0.2256,  0.4333,  0.0871,
        -0.0205,  0.1009, -0.4268, -0.0127, -0.4502,  0.1202,  0.0643,  0.0845,
         0.4573, -0.3835,  0.0806,  0.0630,  0.4724,  0.2537,  0.2271,  0.1121,
        -0.4121, -0.0492, -0.1023, -0.2874,  0.1191, -0.0324, -0.1006,  0.0300,
        -0.3979,  0.1674, -0.4370, -0.4866,  0.4092,  0.0006, -0.0858,  0.4949,
        -0.2069, -0.4150,  0.2036,  0.1163, -0.4890, -0.1975, -0.1208, -0.2208,
         0.2317,  0.2130,  0.0714,  0.1864,  0.2119,  0.2343,  0.0826, -0.2332,
        -0.4521, -0.1847,  0.1704, -0.2000, -0.2484, -0.0814, -0.1189, -0.3484,
         0.2434,  0.4238,  0.3347, -0.1953, -0.2771, -0.2610, -0.0555,  0.2700,
         0.1428,  0.4736,  0.1176,  0.2374, -0.4460, -0.2905, -0.4841, -0.3308,
        -0.4482,  0.2241,  0.4756, -0.0458], dtype=torch.float16)
[Worker 2] Completed Task 1198

[Worker 2] Processing Task 1202: paddle.roll(Tensor([3567, 16, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), )
[accuracy error] paddle.roll(Tensor([3567, 16, 7, 14, 768],"float16"), shifts=tuple(4,0,3,), axis=tuple(1,2,3,), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 492017 / 4295467008 (0.0%)
Greatest absolute difference: 0.5 at index (3566, 9, 2, 0, 272) (up to 0.01 allowed)
Greatest relative difference: inf at index (3566, 9, 2, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3567, 16, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4014,  0.3301, -0.4846, -0.4185,  0.2754,  0.2639, -0.3894, -0.3733,
        -0.2034,  0.0798,  0.3391, -0.3337,  0.1092,  0.2101,  0.0248, -0.2198,
         0.3811, -0.0032, -0.2698, -0.0817,  0.3560,  0.3115,  0.3508, -0.3633,
         0.2292, -0.2056,  0.3782, -0.0881,  0.3042,  0.4851,  0.1855,  0.3921,
        -0.2788, -0.0030, -0.2942, -0.0745,  0.2517,  0.4561, -0.4656, -0.0229,
         0.0233,  0.3284, -0.0515,  0.0035,  0.4053,  0.2710, -0.4041, -0.4133,
         0.4033,  0.0027, -0.1265, -0.0757, -0.1355, -0.2415, -0.3604, -0.4844,
         0.1469, -0.1299, -0.4851, -0.4790,  0.2952,  0.0964, -0.3425,  0.1642,
        -0.4832,  0.2849,  0.2856, -0.1351,  0.0880,  0.4768,  0.4739, -0.2739,
         0.3499,  0.1553, -0.3220, -0.4951, -0.2651, -0.2688, -0.2444,  0.4529,
         0.0517,  0.2712,  0.2847,  0.0530, -0.0872,  0.2323,  0.3750,  0.2805,
         0.4832, -0.0560, -0.2727,  0.3149,  0.4255,  0.2496, -0.1398,  0.4934,
         0.2146,  0.3267,  0.4736,  0.4902], dtype=torch.float16)
DESIRED: (shape=torch.Size([3567, 16, 7, 14, 768]), dtype=torch.float16)
First 100 elements: tensor([ 0.4014,  0.3301, -0.4846, -0.4185,  0.2754,  0.2639, -0.3894, -0.3733,
        -0.2034,  0.0798,  0.3391, -0.3337,  0.1092,  0.2101,  0.0248, -0.2198,
         0.3811, -0.0032, -0.2698, -0.0817,  0.3560,  0.3115,  0.3508, -0.3633,
         0.2292, -0.2056,  0.3782, -0.0881,  0.3042,  0.4851,  0.1855,  0.3921,
        -0.2788, -0.0030, -0.2942, -0.0745,  0.2517,  0.4561, -0.4656, -0.0229,
         0.0233,  0.3284, -0.0515,  0.0035,  0.4053,  0.2710, -0.4041, -0.4133,
         0.4033,  0.0027, -0.1265, -0.0757, -0.1355, -0.2415, -0.3604, -0.4844,
         0.1469, -0.1299, -0.4851, -0.4790,  0.2952,  0.0964, -0.3425,  0.1642,
        -0.4832,  0.2849,  0.2856, -0.1351,  0.0880,  0.4768,  0.4739, -0.2739,
         0.3499,  0.1553, -0.3220, -0.4951, -0.2651, -0.2688, -0.2444,  0.4529,
         0.0517,  0.2712,  0.2847,  0.0530, -0.0872,  0.2323,  0.3750,  0.2805,
         0.4832, -0.0560, -0.2727,  0.3149,  0.4255,  0.2496, -0.1398,  0.4934,
         0.2146,  0.3267,  0.4736,  0.4902], dtype=torch.float16)
[Worker 2] Completed Task 1202

[Worker 2] Processing Task 1206: paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=0, axis=None, )
[accuracy error] paddle.roll(x=Tensor([3, 1431655766],"float16"), shifts=0, axis=None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2 / 4294967298 (0.0%)
Greatest absolute difference: 0.05035400390625 at index (2, 1431655765) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1431655764) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([ 0.0455, -0.3362,  0.1180,  0.2583, -0.1257, -0.3523,  0.0287, -0.3557,
         0.0282, -0.3582,  0.2849,  0.3481,  0.0937, -0.1030, -0.3064, -0.2465,
        -0.3118,  0.1819, -0.2803,  0.2330,  0.4785, -0.4456,  0.3682, -0.2717,
        -0.1835, -0.1616, -0.0826, -0.2559,  0.3303, -0.3911, -0.1466, -0.0781,
        -0.3508,  0.1450, -0.4832, -0.0509,  0.0128,  0.3169, -0.3267, -0.0419,
         0.2119,  0.2102, -0.2810, -0.0576, -0.0063,  0.0983,  0.1180, -0.3650,
        -0.0518, -0.0587, -0.3752,  0.4126,  0.1816,  0.4395,  0.1069,  0.4851,
         0.4409, -0.4973, -0.1004,  0.4375,  0.3215,  0.2698, -0.1353, -0.0923,
        -0.3481, -0.4224,  0.3811,  0.4875, -0.0469, -0.3372,  0.2073, -0.2471,
         0.1787,  0.2148, -0.1914, -0.3269, -0.3733, -0.4824,  0.1558,  0.3289,
         0.1505, -0.1659, -0.0863, -0.3489,  0.3613, -0.3081, -0.1671, -0.0019,
         0.2898,  0.1934, -0.3953, -0.0700, -0.4316, -0.4177,  0.1213,  0.4128,
         0.3596,  0.3174, -0.1458,  0.3169], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 1431655766]), dtype=torch.float16)
First 100 elements: tensor([ 0.0455, -0.3362,  0.1180,  0.2583, -0.1257, -0.3523,  0.0287, -0.3557,
         0.0282, -0.3582,  0.2849,  0.3481,  0.0937, -0.1030, -0.3064, -0.2465,
        -0.3118,  0.1819, -0.2803,  0.2330,  0.4785, -0.4456,  0.3682, -0.2717,
        -0.1835, -0.1616, -0.0826, -0.2559,  0.3303, -0.3911, -0.1466, -0.0781,
        -0.3508,  0.1450, -0.4832, -0.0509,  0.0128,  0.3169, -0.3267, -0.0419,
         0.2119,  0.2102, -0.2810, -0.0576, -0.0063,  0.0983,  0.1180, -0.3650,
        -0.0518, -0.0587, -0.3752,  0.4126,  0.1816,  0.4395,  0.1069,  0.4851,
         0.4409, -0.4973, -0.1004,  0.4375,  0.3215,  0.2698, -0.1353, -0.0923,
        -0.3481, -0.4224,  0.3811,  0.4875, -0.0469, -0.3372,  0.2073, -0.2471,
         0.1787,  0.2148, -0.1914, -0.3269, -0.3733, -0.4824,  0.1558,  0.3289,
         0.1505, -0.1659, -0.0863, -0.3489,  0.3613, -0.3081, -0.1671, -0.0019,
         0.2898,  0.1934, -0.3953, -0.0700, -0.4316, -0.4177,  0.1213,  0.4128,
         0.3596,  0.3174, -0.1458,  0.3169], dtype=torch.float16)
[Worker 2] Completed Task 1206

[Worker 2] Processing Task 1211: paddle.rsqrt(x=Tensor([2, 1073741825, 2],"float16"), )
[accuracy error] backward  paddle.rsqrt(x=Tensor([2, 1073741825, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2013297 / 4294967300 (0.0%)
Greatest absolute difference: nan at index (0, 531127229, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 136, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1073741825, 2]), dtype=torch.float16)
First 100 elements: tensor([-14.4688,      nan,   2.3789,   0.5000,      nan,      nan, -10.2031,
             nan, -22.6719,      nan,  -0.3682,   0.4355,  -5.9453,      nan,
             nan,      nan,      nan,  -1.8799,      nan,   1.5469,  -0.5947,
             nan,   0.0704,      nan,      nan,      nan,      nan,      nan,
         -0.9062,      nan,      nan,      nan,      nan,   3.1855,      nan,
             nan, -29.0312,   0.4158,      nan,      nan,   0.4575,   2.4668,
             nan,      nan,      nan,   6.5195,  -4.0234,      nan,      nan,
             nan,      nan,  -0.1533,   2.7812,   0.5923,   0.6660,  -0.5283,
          0.0383,      nan,      nan,   0.6367,  -1.3145,  -0.1785,      nan,
             nan,      nan,      nan,  -0.6880,   0.6538,      nan,      nan,
          1.7441,      nan,  -0.4829,   0.7207,      nan,      nan,      nan,
             nan,  -1.4863,   0.2520,   0.5547,      nan,      nan,      nan,
         -1.0986,      nan,      nan,      nan,   1.3418,   1.4160,      nan,
             nan,      nan,      nan,   2.2461,   0.4546,   0.3347,  -0.2198,
             nan,   0.1256], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 1073741825, 2]), dtype=torch.float16)
First 100 elements: tensor([-14.4766,      nan,   2.3770,   0.5000,      nan,      nan, -10.1953,
             nan, -22.6719,      nan,  -0.3682,   0.4355,  -5.9492,      nan,
             nan,      nan,      nan,  -1.8809,      nan,   1.5469,  -0.5947,
             nan,   0.0704,      nan,      nan,      nan,      nan,      nan,
         -0.9072,      nan,      nan,      nan,      nan,   3.1875,      nan,
             nan, -29.0312,   0.4158,      nan,      nan,   0.4575,   2.4668,
             nan,      nan,      nan,   6.5195,  -4.0195,      nan,      nan,
             nan,      nan,  -0.1534,   2.7832,   0.5928,   0.6655,  -0.5283,
          0.0383,      nan,      nan,   0.6367,  -1.3154,  -0.1786,      nan,
             nan,      nan,      nan,  -0.6880,   0.6543,      nan,      nan,
          1.7441,      nan,  -0.4832,   0.7207,      nan,      nan,      nan,
             nan,  -1.4873,   0.2522,   0.5552,      nan,      nan,      nan,
         -1.0986,      nan,      nan,      nan,   1.3408,   1.4160,      nan,
             nan,      nan,      nan,   2.2461,   0.4548,   0.3347,  -0.2198,
             nan,   0.1256], dtype=torch.float16)
[Worker 2] Completed Task 1211

[Worker 2] Processing Task 1215: paddle.rsqrt(x=Tensor([715827883, 3, 2],"float16"), )
[accuracy error] backward  paddle.rsqrt(x=Tensor([715827883, 3, 2],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2013490 / 4294967298 (0.0%)
Greatest absolute difference: nan at index (570029120, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (45, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([715827883, 3, 2]), dtype=torch.float16)
First 100 elements: tensor([ 9.9453e+00,         nan,  4.4297e+00,  5.6787e-01,         nan,
                nan, -2.2062e+01,         nan, -1.1820e+01,         nan,
        -1.1201e+00,  9.2041e-01,  4.0547e+00,         nan,         nan,
                nan,         nan,  2.2441e+00,         nan,  1.6709e+00,
         4.7455e-02,         nan,  1.0684e+00,         nan,         nan,
                nan,         nan,         nan,  6.0596e-01,         nan,
                nan,         nan,         nan, -8.5107e-01,         nan,
                nan, -7.0312e+01,  4.9854e-01,         nan,         nan,
         1.9297e+00,  2.5586e+00,         nan,         nan,         nan,
        -1.2998e+00, -2.4316e+00,         nan,         nan,         nan,
                nan,  6.5039e-01,  3.0029e-01, -6.1328e-01,  3.2080e-01,
         5.9619e-01, -4.3091e-01,         nan,         nan, -8.6365e-02,
         1.2178e+00, -9.8584e-01,         nan,         nan,         nan,
                nan,  1.4270e-01,  7.2461e-01,         nan,         nan,
        -3.8721e-01,         nan,  3.5596e-01, -1.8789e+00,         nan,
                nan,         nan,         nan,  5.2637e-01, -1.8457e-01,
         2.4824e+00,         nan,         nan,         nan, -5.9277e-01,
                nan,         nan,         nan, -1.2178e+00,  1.9922e+00,
                nan,         nan,         nan,         nan,  1.7070e+00,
        -1.4819e-01,  9.8828e-01,  1.2537e-01,         nan,  5.2197e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([715827883, 3, 2]), dtype=torch.float16)
First 100 elements: tensor([ 9.9531e+00,         nan,  4.4297e+00,  5.6787e-01,         nan,
                nan, -2.2047e+01,         nan, -1.1820e+01,         nan,
        -1.1201e+00,  9.2041e-01,  4.0586e+00,         nan,         nan,
                nan,         nan,  2.2441e+00,         nan,  1.6709e+00,
         4.7455e-02,         nan,  1.0674e+00,         nan,         nan,
                nan,         nan,         nan,  6.0645e-01,         nan,
                nan,         nan,         nan, -8.5156e-01,         nan,
                nan, -7.0312e+01,  4.9854e-01,         nan,         nan,
         1.9307e+00,  2.5586e+00,         nan,         nan,         nan,
        -1.2998e+00, -2.4297e+00,         nan,         nan,         nan,
                nan,  6.5088e-01,  3.0054e-01, -6.1377e-01,  3.2080e-01,
         5.9619e-01, -4.3091e-01,         nan,         nan, -8.6365e-02,
         1.2178e+00, -9.8633e-01,         nan,         nan,         nan,
                nan,  1.4282e-01,  7.2510e-01,         nan,         nan,
        -3.8721e-01,         nan,  3.5596e-01, -1.8779e+00,         nan,
                nan,         nan,         nan,  5.2686e-01, -1.8469e-01,
         2.4844e+00,         nan,         nan,         nan, -5.9326e-01,
                nan,         nan,         nan, -1.2178e+00,  1.9922e+00,
                nan,         nan,         nan,         nan,  1.7080e+00,
        -1.4819e-01,  9.8828e-01,  1.2537e-01,         nan,  5.2197e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 1215

[Worker 2] Processing Task 1311: paddle.Tensor.bmm(Tensor([6339, 120000, 3],"float32"), Tensor([6339, 3, 2],"float32"), )
[accuracy error] backward  paddle.Tensor.bmm(Tensor([6339, 120000, 3],"float32"), Tensor([6339, 3, 2],"float32"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 133 / 38034 (0.3%)
Greatest absolute difference: 0.03696024417877197 at index (4331, 1, 1) (up to 0.01 allowed)
Greatest relative difference: 49.139225006103516 at index (232, 1, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([6339, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([ -3.7557,  12.7210,  28.0322, -14.2020, -26.3916,  -7.8578,  26.4909,
         49.2444,  60.5285,  10.9102,  -3.9293,  32.2064, -17.4103,  42.2411,
          8.9154,  10.6126, -51.2270,   4.9750,  10.0824, -20.6230, -18.1499,
        -12.9359, -71.2011,   7.5301, -17.2206,  26.2086,   0.8314,  -3.6759,
        -45.7578, -13.5129,  16.2747,  -7.0310,  -8.3117, -36.5699,  25.7883,
        -21.1488,  22.2821,  28.0251,  -1.3648, -31.5531,  67.5650,  23.2391,
         47.6498,   1.4685, -36.1983,  -2.2157,  13.8638,  15.8789,  12.9059,
        -34.1223,  19.4782, -16.1995,  35.4617,  24.0906,   4.1769, -24.5344,
         11.2576,  26.6035, -47.9392, -51.9215,  -7.2292,  60.6990, -19.4773,
        -26.5442,  15.2638, -11.6217, -21.0621, -13.9980,   3.1701,  65.2249,
        -40.6227, -28.0431, -14.7842, -41.9602,   5.8969, -46.9145,  31.4680,
         18.1530,   5.2069,  20.6794,   6.8195,  25.7415,  54.6550,  -2.6037,
         38.0042,  10.3098, -24.9308, -18.8276, -21.8077, -34.6054, -44.4818,
         30.8519,  18.2724,   7.9854, -42.1616,  -3.9540,  10.2046, -37.1184,
        -17.9781, -37.1040])
DESIRED: (shape=torch.Size([6339, 3, 2]), dtype=torch.float32)
First 100 elements: tensor([ -3.7747,  12.7182,  28.0449, -14.2033, -26.3853,  -7.8646,  26.5071,
         49.2649,  60.5420,  10.9247,  -3.9386,  32.2106, -17.4079,  42.2584,
          8.9206,  10.6160, -51.2401,   4.9893,  10.0733, -20.6286, -18.1588,
        -12.9436, -71.2176,   7.5277, -17.2289,  26.2176,   0.8325,  -3.6812,
        -45.7570, -13.5203,  16.2819,  -7.0339,  -8.3096, -36.5975,  25.8027,
        -21.1488,  22.2861,  28.0181,  -1.3677, -31.5618,  67.5838,  23.2346,
         47.6626,   1.4755, -36.2202,  -2.2217,  13.8676,  15.8782,  12.8843,
        -34.1349,  19.4825, -16.1946,  35.4715,  24.0916,   4.1693, -24.5410,
         11.2516,  26.6101, -47.9577, -51.9415,  -7.2406,  60.7060, -19.4844,
        -26.5551,  15.2648, -11.6176, -21.0585, -14.0025,   3.1668,  65.2684,
        -40.6407, -28.0407, -14.7846, -41.9915,   5.9124, -46.9332,  31.4819,
         18.1470,   5.2076,  20.6833,   6.8093,  25.7516,  54.6690,  -2.6131,
         38.0159,  10.2955, -24.9515, -18.8178, -21.8200, -34.6171, -44.5062,
         30.8732,  18.2770,   7.9834, -42.1658,  -3.9618,  10.2112, -37.1154,
        -17.9885, -37.1143])
[Worker 2] Completed Task 1311

[Worker 2] Processing Task 1326: paddle.Tensor.cumsum(Tensor([4294967297],"float16"), -1, )
[accuracy error] paddle.Tensor.cumsum(Tensor([4294967297],"float16"), -1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4294958790 / 4294967297 (100.0%)
Greatest absolute difference: 13248.0 at index (2241578588,) (up to 0.01 allowed)
Greatest relative difference: inf at index (159035,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([ 0.0455, -0.3362,  0.1180,  0.2583, -0.1257, -0.3523,  0.0287, -0.3557,
         0.0282, -0.3582,  0.2849,  0.3481,  0.0937, -0.1030, -0.3064, -0.2465,
        -0.3118,  0.1819, -0.2803,  0.2330,  0.4785, -0.4456,  0.3682, -0.2717,
        -0.1835, -0.1616, -0.0826, -0.2559,  0.3303, -0.3911, -0.1466, -0.0781,
        -0.3508,  0.1450, -0.4832, -0.0509,  0.0128,  0.3169, -0.3267, -0.0419,
         0.2119,  0.2102, -0.2810, -0.0576, -0.0063,  0.0983,  0.1180, -0.3650,
        -0.0518, -0.0587, -0.3752,  0.4126,  0.1816,  0.4395,  0.1069,  0.4851,
         0.4409, -0.4973, -0.1004,  0.4375,  0.3215,  0.2698, -0.1353, -0.0923,
        -0.3481, -0.4224,  0.3811,  0.4875, -0.0469, -0.3372,  0.2073, -0.2471,
         0.1787,  0.2148, -0.1914, -0.3269, -0.3733, -0.4824,  0.1558,  0.3289,
         0.1505, -0.1659, -0.0863, -0.3489,  0.3613, -0.3081, -0.1671, -0.0019,
         0.2898,  0.1934, -0.3953, -0.0700, -0.4316, -0.4177,  0.1213,  0.4128,
         0.3596,  0.3174, -0.1458,  0.3169], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([ 0.0455, -0.2908, -0.1729,  0.0854, -0.0403, -0.3926, -0.3638, -0.7197,
        -0.6914, -1.0498, -0.7646, -0.4165, -0.3228, -0.4258, -0.7324, -0.9790,
        -1.2910, -1.1094, -1.3896, -1.1562, -0.6777, -1.1230, -0.7549, -1.0264,
        -1.2100, -1.3711, -1.4541, -1.7100, -1.3799, -1.7715, -1.9180, -1.9961,
        -2.3477, -2.2031, -2.6855, -2.7363, -2.7227, -2.4062, -2.7324, -2.7734,
        -2.5625, -2.3516, -2.6328, -2.6895, -2.6953, -2.5977, -2.4805, -2.8457,
        -2.8984, -2.9570, -3.3320, -2.9199, -2.7383, -2.2988, -2.1914, -1.7061,
        -1.2656, -1.7627, -1.8633, -1.4258, -1.1045, -0.8350, -0.9702, -1.0625,
        -1.4102, -1.8320, -1.4512, -0.9639, -1.0107, -1.3477, -1.1406, -1.3877,
        -1.2090, -0.9941, -1.1855, -1.5127, -1.8857, -2.3672, -2.2109, -1.8818,
        -1.7314, -1.8975, -1.9834, -2.3320, -1.9707, -2.2793, -2.4473, -2.4492,
        -2.1602, -1.9668, -2.3613, -2.4316, -2.8633, -3.2812, -3.1602, -2.7480,
        -2.3887, -2.0703, -2.2168, -1.9004], dtype=torch.float16)
[Worker 2] Completed Task 1326

[Worker 2] Processing Task 1330: paddle.Tensor.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([1073741825, 4],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([10, 4],"float16"), axis=0, prepend=Tensor([4, 4],"float16"), append=Tensor([1073741825, 4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208569569 / 4294967352 (98.0%)
Greatest absolute difference: 1.0 at index (69614, 1) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741838, 4]), dtype=torch.float16)
First 100 elements: tensor([-0.1711, -0.0161, -0.0892, -0.6143,  0.1539, -0.0059,  0.2561,  0.7041,
         0.0655,  0.2551, -0.5913, -0.5947, -0.0482, -0.2332,  0.4243,  0.5049,
        -0.1711, -0.0161, -0.0892, -0.6143,  0.1539, -0.0059,  0.2561,  0.7041,
         0.0655,  0.2551, -0.5913, -0.5947, -0.4055,  0.2849,  0.0261,  0.4795,
         0.7900, -0.6274,  0.6484, -0.5049, -0.6621,  0.2839, -0.4507,  0.0159,
         0.5137, -0.2295, -0.0640,  0.1777, -0.6812,  0.5361, -0.3364,  0.0272,
         0.3635,  0.1719,  0.1565,  0.0090,  0.0327, -0.6533,  0.4446,  0.3003,
        -0.1711, -0.0161, -0.0892, -0.6143,  0.1539, -0.0059,  0.2561,  0.7041,
         0.0655,  0.2551, -0.5913, -0.5947, -0.4055,  0.2849,  0.0261,  0.4795,
         0.7900, -0.6274,  0.6484, -0.5049, -0.6621,  0.2839, -0.4507,  0.0159,
         0.5137, -0.2295, -0.0640,  0.1777, -0.6812,  0.5361, -0.3364,  0.0272,
         0.3635,  0.1719,  0.1565,  0.0090,  0.1991, -0.1067,  0.0457, -0.0157,
        -0.2183, -0.1119,  0.3989, -0.3074], dtype=torch.float16)
[Worker 2] Completed Task 1330

[Worker 2] Processing Task 1334: paddle.Tensor.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), append=Tensor([4],"float16"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([10],"float16"), prepend=Tensor([4294967297],"float16"), append=Tensor([4],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208558880 / 4294967310 (98.0%)
Greatest absolute difference: 1.0 at index (3866461,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967310]), dtype=torch.float16)
First 100 elements: tensor([-0.3816,  0.4541,  0.1404, -0.3840, -0.2266,  0.3811, -0.3845,  0.3840,
        -0.3865,  0.6431,  0.0632, -0.2544, -0.1967, -0.2034,  0.0599, -0.0653,
         0.4937, -0.4622,  0.5132,  0.2455, -0.9238,  0.8135, -0.6396,  0.0883,
         0.0219,  0.0790, -0.1732,  0.5859, -0.7217,  0.2445,  0.0685, -0.2727,
         0.4958, -0.6279,  0.4324,  0.0637,  0.3042, -0.6436,  0.2847,  0.2539,
        -0.0017, -0.4912,  0.2234,  0.0512,  0.1046,  0.0197, -0.4829,  0.3132,
        -0.0069, -0.3164,  0.7881, -0.2310,  0.2578, -0.3325,  0.3782, -0.0442,
        -0.9385,  0.3970,  0.5381, -0.1160, -0.0518, -0.4050,  0.0430, -0.2559,
        -0.0742,  0.8037,  0.1064, -0.5347, -0.2903,  0.5444, -0.4543,  0.4258,
         0.0361, -0.4062, -0.1355, -0.0464, -0.1091,  0.6382,  0.1731, -0.1783,
        -0.3164,  0.0796, -0.2627,  0.7100, -0.6694,  0.1410,  0.1652,  0.2917,
        -0.0964, -0.5889,  0.3252, -0.3616,  0.0139,  0.5391,  0.2915, -0.0532,
        -0.0422, -0.4631,  0.4626, -0.5264], dtype=torch.float16)
[Worker 2] Completed Task 1334

[Worker 2] Processing Task 1338: paddle.Tensor.diff(x=Tensor([2281701379],"int64"), )
[accuracy error] paddle.Tensor.diff(x=Tensor([2281701379],"int64"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281683971 / 2281701378 (100.0%)
Greatest absolute difference: 131068 at index (425662760,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701378]), dtype=torch.int64)
First 100 elements: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0])
DESIRED: (shape=torch.Size([2281701378]), dtype=torch.int64)
First 100 elements: tensor([ 11346, -56222,  -5548,  75870, -60811,  55149, -13622, -75425,  34410,
         25582,  39213, -97364,  -3322,  77461,  -4720, -77543,  34104, -18690,
         22636, -11470,  33470,  16307, -58377,  -4289,  -4010, -13844,  59457,
         10126, -53803, -16728, 120784,  -5847,   8975, -25238, -54857, -14372,
        -10072,  32739, -16509,  -2376,  88391, -14194, -48469,  37112,   1905,
        -63506, -20831,  52856,  -1360,  58172, -17908, -53579,    988,   4449,
        -27617,  45345, -37792, -37610,  41932,  21461,  11560, -31320, -22042,
         73448,  11362,  11594, -95360,  66261, -14597,  29183, -55505,  22928,
        -61223,  66828, -40834,  77797, -19707, -81155,  25416,  66537, -69195,
         -3008,  12571,  12349, -10351,  38600,   5388, -91760,  40400,  65363,
        -85557,  57677, -64866,  34026, -42680,  98326,   4905, -85400,   7582,
        -16935])
[Worker 2] Completed Task 1338

[Worker 2] Processing Task 1343: paddle.Tensor.inner(x=Tensor([2, 5, 3, 143165577],"float16"), y=Tensor([3, 2, 5, 143165577],"float16"), )
[accuracy error] paddle.Tensor.inner(x=Tensor([2, 5, 3, 143165577],"float16"), y=Tensor([3, 2, 5, 143165577],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 82 / 900 (9.1%)
Greatest absolute difference: 5.75 at index (0, 3, 2, 1, 1, 4) (up to 0.01 allowed)
Greatest relative difference: 0.435546875 at index (1, 0, 2, 2, 1, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 5, 3, 3, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([       inf,  1419.0000,  -378.0000,  1528.0000,   986.5000,   604.5000,
         -331.5000,  2334.0000,  1617.0000,   873.0000,   479.5000,  -699.5000,
          103.1875,  1383.0000,   355.2500, -1373.0000,  -614.5000,   362.7500,
          236.8750,  1613.0000,  -136.1250,  1258.0000, -1522.0000,  1015.5000,
         -124.3750,  -445.2500,  -905.5000,   408.0000,  -952.0000,  -397.0000,
         1419.0000,        inf,  -741.0000,  1080.0000,   317.0000, -1639.0000,
          472.2500,   573.0000,   204.3750,  1742.0000,  -462.2500,  1123.0000,
           68.0000,  1682.0000,  1120.0000,  -470.5000,  -738.5000, -1844.0000,
          617.0000,  -232.3750,  1156.0000,   808.5000,   358.2500,  -278.2500,
          215.2500,  -939.5000,  -888.5000,   202.8750,   388.7500,    98.0000,
         -378.0000,  -741.0000,        inf,   690.5000,  -646.0000,   803.5000,
         -666.0000,  -258.7500,   -19.5625,  -197.0000,  -181.6250,  -601.0000,
          556.5000,   458.0000,  -306.0000,   895.0000,   201.8750, -1281.0000,
         1155.0000,   522.5000,  -434.7500,   710.0000,  -447.2500,  -762.0000,
          817.5000,  -486.2500,  1858.0000, -1141.0000, -1269.0000,  -895.5000,
         1528.0000,  1080.0000,   690.5000,        inf,   -36.5312, -1286.0000,
           45.1250,  1091.0000,   592.0000,  -369.2500], dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 5, 3, 3, 2, 5]), dtype=torch.float16)
First 100 elements: tensor([       inf,  1413.0000,  -378.0000,  1528.0000,   985.0000,   605.0000,
         -332.0000,  2326.0000,  1616.0000,   873.0000,   480.2500,  -698.5000,
          101.4375,  1382.0000,   355.2500, -1376.0000,  -613.0000,   364.0000,
          238.1250,  1616.0000,  -136.3750,  1259.0000, -1520.0000,  1017.5000,
         -126.6875,  -442.5000,  -904.5000,   408.7500,  -951.5000,  -396.7500,
         1413.0000,        inf,  -740.0000,  1088.0000,   316.2500, -1638.0000,
          472.7500,   572.0000,   205.0000,  1742.0000,  -459.2500,  1120.0000,
           68.7500,  1681.0000,  1124.0000,  -471.0000,  -738.5000, -1844.0000,
          617.0000,  -231.7500,  1157.0000,   807.5000,   357.5000,  -277.2500,
          215.5000,  -940.0000,  -890.0000,   202.5000,   387.5000,    99.3750,
         -378.0000,  -740.0000,        inf,   689.0000,  -645.0000,   802.5000,
         -666.5000,  -258.2500,   -19.0000,  -196.3750,  -182.2500,  -602.0000,
          556.0000,   458.0000,  -305.5000,   895.5000,   202.5000, -1286.0000,
         1156.0000,   522.0000,  -436.2500,   709.5000,  -447.5000,  -759.5000,
          815.5000,  -486.2500,  1860.0000, -1140.0000, -1270.0000,  -896.0000,
         1528.0000,  1088.0000,   689.0000,        inf,   -35.6875, -1283.0000,
           45.9375,  1098.0000,   590.0000,  -370.7500], dtype=torch.float16)
[Worker 2] Completed Task 1343

[Worker 2] Processing Task 1346: paddle.Tensor.kthvalue(Tensor([2, 200, 5704254],"float32"), k=200, axis=1, )
element 1 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.kthvalue(Tensor([2, 200, 5704254],"float32"), k=200, axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 10 / 11408508 (0.0%)
Greatest absolute difference: 150 at index (0, 805827) (up to 0.01 allowed)
Greatest relative difference: 1.7391303777694702 at index (1, 5510820) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 5704254]), dtype=torch.int64)
First 100 elements: tensor([149, 102,  56,  56,  15, 105,  44, 174,  42,  80,  47,  86, 137,  84,
         83, 158, 165,  46,  82, 142, 173, 111, 195,  60, 140,  22,  76, 164,
         52, 163,   4, 107,  69, 105, 171,  22,  98, 191, 166, 118, 114,  57,
        163, 167,  55,  70,  26,  47,  53,  33,  15,   8, 192,  70, 156, 122,
          3, 152, 160,  37,  52, 134,  19,  79,  65,  50, 190, 120,  26, 176,
        179,  77, 172, 144, 134, 139, 165,   7,  13,  24, 136,  26, 100, 147,
         80,  23,  42, 161, 133, 100,  37, 106,  52, 100, 178,  38, 194, 125,
         53,  23])
DESIRED: (shape=torch.Size([2, 5704254]), dtype=torch.int64)
First 100 elements: tensor([149, 102,  56,  56,  15, 105,  44, 174,  42,  80,  47,  86, 137,  84,
         83, 158, 165,  46,  82, 142, 173, 111, 195,  60, 140,  22,  76, 164,
         52, 163,   4, 107,  69, 105, 171,  22,  98, 191, 166, 118, 114,  57,
        163, 167,  55,  70,  26,  47,  53,  33,  15,   8, 192,  70, 156, 122,
          3, 152, 160,  37,  52, 134,  19,  79,  65,  50, 190, 120,  26, 176,
        179,  77, 172, 144, 134, 139, 165,   7,  13,  24, 136,  26, 100, 147,
         80,  23,  42, 161, 133, 100,  37, 106,  52, 100, 178,  38, 194, 125,
         53,  23])
[Worker 2] Completed Task 1346

[Worker 2] Processing Task 1349: paddle.Tensor.lerp(x=Tensor([4, 1073741825],"float16"), y=Tensor([1],"float16"), weight=0.2, )
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 1073741825],"float16"), y=Tensor([1],"float16"), weight=0.2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4186471722 / 4294967300 (97.5%)
Greatest absolute difference: 0.39990234375 at index (0, 985) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 1073741825]), dtype=torch.float16)
First 100 elements: tensor([ 0.2242, -0.3403, -0.1541, -0.1050,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 1073741825]), dtype=torch.float16)
First 100 elements: tensor([ 0.2242, -0.3403, -0.1541, -0.1050, -0.2871, -0.1193,  0.0795,  0.1304,
         0.1720, -0.0387,  0.0897, -0.1433,  0.2727, -0.3027, -0.1860, -0.3267,
         0.2092,  0.2330, -0.1742, -0.2781,  0.3152, -0.3003, -0.0251,  0.2347,
        -0.3816, -0.3354, -0.1235, -0.0834,  0.2751, -0.1641, -0.1840, -0.1466,
        -0.1154, -0.2817, -0.2288,  0.0753,  0.0673, -0.1187,  0.1631, -0.1423,
        -0.0714, -0.3801, -0.3013, -0.3940,  0.2700, -0.3215,  0.2605,  0.0641,
         0.1575,  0.0329,  0.3945,  0.0651, -0.3447, -0.2759, -0.0372,  0.2856,
        -0.0179, -0.3225,  0.2019, -0.2949,  0.3833,  0.0400, -0.3550,  0.2209,
        -0.3911,  0.2649,  0.2588, -0.3560, -0.0537, -0.3943, -0.2632, -0.0128,
         0.0584, -0.1147, -0.0430,  0.2991,  0.0821, -0.1864,  0.1462, -0.0760,
        -0.0518,  0.0557, -0.2318,  0.0305,  0.3813, -0.0515,  0.2058,  0.2234,
        -0.3350, -0.1927,  0.3042, -0.2712,  0.2106,  0.2451, -0.1519, -0.1929,
        -0.1154,  0.0629, -0.3408, -0.0358], dtype=torch.float16)
[Worker 2] Completed Task 1349

[Worker 2] Processing Task 1353: paddle.Tensor.lerp(x=Tensor([4, 5, 4, 53687092],"float16"), y=Tensor([4, 5, 4, 53687092],"float16"), weight=0.0, )
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 5, 4, 53687092],"float16"), y=Tensor([4, 5, 4, 53687092],"float16"), weight=0.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208162574 / 4294967360 (98.0%)
Greatest absolute difference: 0.5 at index (0, 0, 0, 1045) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 64) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 5, 4, 53687092]), dtype=torch.float16)
First 100 elements: tensor([ 4.1382e-01, -3.9453e-01, -7.5134e-02,  2.1286e-02,  3.9502e-01,
         4.1382e-01,  4.5807e-02, -3.8940e-01, -2.4133e-01,  2.3132e-01,
         8.1604e-02,  2.6199e-02, -2.5415e-01,  4.8804e-01,  4.5044e-01,
        -1.4380e-01,  2.5537e-01,  3.8354e-01,  3.3813e-01,  1.5723e-01,
        -1.2524e-01,  4.3335e-01,  2.0251e-01, -2.4365e-01, -2.7039e-02,
         4.1577e-01, -4.1040e-01, -4.9561e-02, -1.6089e-01,  2.9395e-01,
         1.3770e-01,  8.3740e-02, -2.5439e-01,  1.2170e-01, -4.5142e-01,
        -3.3228e-01, -4.9194e-01,  3.2373e-01, -1.8213e-01, -2.0190e-01,
         5.6580e-02, -1.8542e-01, -1.7969e-01, -9.4177e-02, -3.1738e-01,
         1.7249e-01, -2.5415e-01, -1.2781e-01, -4.1016e-01, -2.6099e-01,
         3.8721e-01,  2.8174e-01,  3.5524e-04,  3.5583e-02, -4.7803e-01,
         3.7537e-02,  3.7793e-01, -4.9463e-01,  1.5601e-01,  4.7836e-03,
         2.8027e-01, -4.2554e-01, -1.9263e-01, -1.3123e-01,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 5, 4, 53687092]), dtype=torch.float16)
First 100 elements: tensor([ 4.1382e-01, -3.9453e-01, -7.5134e-02,  2.1286e-02,  3.9502e-01,
         4.1382e-01,  4.5807e-02, -3.8940e-01, -2.4133e-01,  2.3132e-01,
         8.1604e-02,  2.6199e-02, -2.5415e-01,  4.8804e-01,  4.5044e-01,
        -1.4380e-01,  2.5537e-01,  3.8354e-01,  3.3813e-01,  1.5723e-01,
        -1.2524e-01,  4.3335e-01,  2.0251e-01, -2.4365e-01, -2.7039e-02,
         4.1577e-01, -4.1040e-01, -4.9561e-02, -1.6089e-01,  2.9395e-01,
         1.3770e-01,  8.3740e-02, -2.5439e-01,  1.2170e-01, -4.5142e-01,
        -3.3228e-01, -4.9194e-01,  3.2373e-01, -1.8213e-01, -2.0190e-01,
         5.6580e-02, -1.8542e-01, -1.7969e-01, -9.4177e-02, -3.1738e-01,
         1.7249e-01, -2.5415e-01, -1.2781e-01, -4.1016e-01, -2.6099e-01,
         3.8721e-01,  2.8174e-01,  3.5524e-04,  3.5583e-02, -4.7803e-01,
         3.7537e-02,  3.7793e-01, -4.9463e-01,  1.5601e-01,  4.7836e-03,
         2.8027e-01, -4.2554e-01, -1.9263e-01, -1.3123e-01, -3.5889e-01,
        -1.4905e-01,  9.9426e-02,  1.6296e-01,  2.1497e-01, -4.8401e-02,
         1.1206e-01, -1.7908e-01,  3.4082e-01, -3.7842e-01, -2.3254e-01,
        -4.0820e-01,  2.6147e-01,  2.9126e-01, -2.1777e-01, -3.4766e-01,
         3.9404e-01, -3.7549e-01, -3.1433e-02,  2.9346e-01, -4.7705e-01,
        -4.1919e-01, -1.5442e-01, -1.0431e-01,  3.4399e-01, -2.0508e-01,
        -2.2998e-01, -1.8323e-01, -1.4417e-01, -3.5229e-01, -2.8589e-01,
         9.4116e-02,  8.4167e-02, -1.4832e-01,  2.0386e-01, -1.7786e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 1353

[Worker 2] Processing Task 1357: paddle.Tensor.lerp(x=Tensor([4, 5, 71582789, 3],"float16"), y=Tensor([4, 5, 71582789, 3],"float16"), weight=0.5, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.16 GiB is free. Process 91987 has 74.02 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 1357: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.16 GiB is free. Process 91987 has 74.02 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 1357: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.16 GiB is free. Process 91987 has 74.02 GiB memory in use. Of the allocated memory 32.02 GiB is allocated by PyTorch, and 11.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 1359: paddle.Tensor.lerp(x=Tensor([4, 89478486, 4, 3],"float16"), y=Tensor([4, 89478486, 4, 3],"float16"), weight=0.0, )
W0522 19:27:02.915968 47283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:27:02.917112 47283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([4, 89478486, 4, 3],"float16"), y=Tensor([4, 89478486, 4, 3],"float16"), weight=0.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208165685 / 4294967328 (98.0%)
Greatest absolute difference: 0.5 at index (0, 411, 2, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 2, 2, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 89478486, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.2703, -0.4609, -0.4695, -0.2820, -0.4336,  0.1622,  0.1328, -0.0384,
        -0.4153, -0.1156,  0.1149, -0.4761, -0.1649, -0.4695,  0.3948, -0.3271,
         0.1216, -0.2289, -0.4741, -0.4297, -0.3118, -0.1399, -0.1411, -0.1167,
         0.4070,  0.0546, -0.2484,  0.0856, -0.1410,  0.1348, -0.2742,  0.3582,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 89478486, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-2.7026e-01, -4.6094e-01, -4.6948e-01, -2.8198e-01, -4.3359e-01,
         1.6223e-01,  1.3281e-01, -3.8361e-02, -4.1528e-01, -1.1560e-01,
         1.1487e-01, -4.7607e-01, -1.6492e-01, -4.6948e-01,  3.9478e-01,
        -3.2715e-01,  1.2164e-01, -2.2888e-01, -4.7412e-01, -4.2969e-01,
        -3.1177e-01, -1.3989e-01, -1.4111e-01, -1.1670e-01,  4.0698e-01,
         5.4565e-02, -2.4841e-01,  8.5571e-02, -1.4099e-01,  1.3477e-01,
        -2.7417e-01,  3.5815e-01, -3.2684e-02,  1.3464e-01, -1.5637e-01,
        -3.8379e-01,  2.5659e-01, -3.7378e-01, -8.9355e-02, -1.1078e-01,
         2.1033e-01, -2.8516e-01,  3.0981e-01,  4.9170e-01,  3.0762e-01,
         4.1406e-01,  4.8730e-01, -1.0565e-01, -3.9014e-01, -4.2822e-01,
        -4.6899e-01,  1.9666e-01, -1.7334e-01,  4.9146e-01,  1.5430e-01,
         3.0078e-01, -2.0239e-01,  3.3228e-01, -2.2729e-01,  1.6724e-01,
         4.5605e-01,  1.1176e-01, -1.6541e-01, -4.0698e-01, -8.0200e-02,
        -3.6792e-01,  3.3618e-01, -3.1445e-01, -4.9170e-01, -4.0283e-01,
        -3.4937e-01, -4.6411e-01, -3.8428e-01, -1.0010e-01,  3.4692e-01,
        -7.1045e-02, -9.1736e-02, -8.0933e-02,  2.5342e-01,  2.8760e-01,
        -3.2520e-01, -4.4873e-01,  1.9910e-01,  4.8926e-01, -9.8572e-02,
        -9.5459e-02, -2.4121e-01, -1.4392e-01, -6.6528e-02, -3.3154e-01,
         2.2974e-01, -4.1797e-01,  2.3560e-01, -2.5391e-01, -3.8791e-04,
        -2.4304e-01, -3.2324e-01,  4.1040e-01,  2.9468e-01, -1.8951e-02],
       dtype=torch.float16)
[Worker 2] Completed Task 1359

[Worker 2] Processing Task 1364: paddle.Tensor.lerp(x=Tensor([71582789, 5, 4, 3],"float16"), y=Tensor([71582789, 5, 4, 3],"float16"), weight=0.5, )
CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 35888 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 1364: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 35888 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 1364: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.56 GiB is free. Process 35888 has 73.62 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 1365: paddle.Tensor.lerp(x=Tensor([71582789, 5, 4, 3],"float16"), y=Tensor([71582789, 5, 4, 3],"float16"), weight=1.0, )
W0522 19:29:27.251083 47645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 19:29:27.252815 47645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] backward  paddle.Tensor.lerp(x=Tensor([71582789, 5, 4, 3],"float16"), y=Tensor([71582789, 5, 4, 3],"float16"), weight=1.0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4208148255 / 4294967340 (98.0%)
Greatest absolute difference: 0.5 at index (68, 3, 3, 2) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 3, 2, 2) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([71582789, 5, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.4604,  0.0601,  0.2161,  0.3701,  0.3843,  0.0219,  0.2072,  0.0101,
        -0.4067, -0.0673, -0.1406, -0.0576,  0.2295,  0.2500, -0.2034,  0.0947,
         0.4980, -0.3552, -0.2035, -0.2125,  0.2410, -0.4136, -0.4956,  0.3811,
         0.2050, -0.1655,  0.2717, -0.2114,  0.4514, -0.2837, -0.1997,  0.1250,
        -0.2844,  0.4028,  0.1583, -0.3054, -0.3682,  0.0779, -0.0430,  0.3911,
        -0.4138,  0.3000, -0.0703, -0.0679,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([71582789, 5, 4, 3]), dtype=torch.float16)
First 100 elements: tensor([-0.4604,  0.0601,  0.2161,  0.3701,  0.3843,  0.0219,  0.2072,  0.0101,
        -0.4067, -0.0673, -0.1406, -0.0576,  0.2295,  0.2500, -0.2034,  0.0947,
         0.4980, -0.3552, -0.2035, -0.2125,  0.2410, -0.4136, -0.4956,  0.3811,
         0.2050, -0.1655,  0.2717, -0.2114,  0.4514, -0.2837, -0.1997,  0.1250,
        -0.2844,  0.4028,  0.1583, -0.3054, -0.3682,  0.0779, -0.0430,  0.3911,
        -0.4138,  0.3000, -0.0703, -0.0679, -0.1432, -0.0686,  0.0569,  0.4546,
        -0.2549,  0.3027, -0.2422,  0.4897,  0.3689,  0.2979, -0.1026, -0.1576,
         0.0259,  0.4353, -0.1821,  0.2482,  0.1404,  0.2151, -0.0403,  0.4805,
        -0.4702,  0.4119,  0.1788,  0.1168,  0.4863,  0.2732, -0.3628, -0.0357,
         0.1182,  0.0692,  0.1392, -0.3950,  0.3115,  0.1030,  0.4688, -0.2905,
        -0.2891, -0.4104, -0.1299,  0.0426, -0.3589,  0.1697, -0.0663,  0.1532,
         0.2966,  0.4790, -0.0109,  0.4287,  0.0251, -0.1488,  0.1044,  0.1541,
        -0.3701, -0.3452,  0.1896,  0.1451], dtype=torch.float16)
[Worker 2] Completed Task 1365

[Worker 2] Processing Task 1373: paddle.Tensor.logit(x=Tensor([4, 3, 2, 178956971],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([4, 3, 2, 178956971],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147433012 / 4294967304 (50.0%)
Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 3, 2, 178956971]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.6797, -0.2822,  0.0000,
        -0.6362, -0.3323,  0.0000,  0.0000, -2.6543,  1.7051, -1.0303,  0.0000,
         1.8418,  0.0000, -0.8076, -0.6328,  0.0000,  1.7998,  0.0000,  1.0312,
         0.5664,  0.0000, -0.3521,  1.9707, -2.4043,  0.0000,  0.7305,  0.0000,
         2.7578,  0.0000, -2.1719,  0.0000,  0.5278,  0.5176,  0.0000, -2.9336,
         1.8516,  0.0000,  0.0000,  0.0000,  0.0000, -2.7539,  0.0000,  0.0000,
        -1.4404,  3.2480, -0.5601,  0.0000,  0.0000,  2.4512, -0.8662,  2.1660,
         0.1605, -0.9487,  0.0000,  0.0000, -1.7051,  0.0000,  0.0000,  0.0000,
        -0.3142,  0.0000,  0.0000, -2.8066, -0.1141,  0.0000,  0.5542,  0.7524,
         0.0000, -1.5654, -0.1024, -0.2722, -0.1371,  0.0000, -1.5127,  0.0000,
         0.0000, -1.1104,  0.0000,  0.0000,  0.0000,  1.6074,  0.0000,  0.0000,
         0.5103,  1.4805,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.7256,
         0.0000, -6.6367,  2.2188,  1.5908], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 3, 2, 178956971]), dtype=torch.float16)
First 100 elements: tensor([    nan,     nan,     nan,     nan,     nan,  3.6797, -0.2822,     nan,
        -0.6362, -0.3323,     nan,     nan, -2.6543,  1.7051, -1.0303,     nan,
         1.8418,     nan, -0.8076, -0.6328,     nan,  1.7998,     nan,  1.0312,
         0.5664,     nan, -0.3521,  1.9707, -2.4043,     nan,  0.7305,     nan,
         2.7578,     nan, -2.1719,     nan,  0.5278,  0.5176,     nan, -2.9336,
         1.8516,     nan,     nan,     nan,     nan, -2.7539,     nan,     nan,
        -1.4404,  3.2480, -0.5601,     nan,     nan,  2.4512, -0.8662,  2.1660,
         0.1605, -0.9487,     nan,     nan, -1.7051,     nan,     nan,     nan,
        -0.3142,     nan,     nan, -2.8066, -0.1141,     nan,  0.5542,  0.7524,
            nan, -1.5654, -0.1024, -0.2722, -0.1371,     nan, -1.5127,     nan,
            nan, -1.1104,     nan,     nan,     nan,  1.6074,     nan,     nan,
         0.5103,  1.4805,     nan,     nan,     nan,     nan,     nan, -1.7256,
            nan, -6.6367,  2.2188,  1.5908], dtype=torch.float16)
[Worker 2] Completed Task 1373

[Worker 2] Processing Task 1375: paddle.Tensor.logit(x=Tensor([4, 3, 71582789, 5],"float16"), )
[accuracy error] backward  paddle.Tensor.logit(x=Tensor([4, 3, 71582789, 5],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2147433028 / 4294967340 (50.0%)
Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4, 3, 71582789, 5]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2683,  0.8320,  0.0000,
        -1.8076, -0.3257,  0.0000,  0.0000,  2.3906,  1.4082, -0.8652,  0.0000,
         2.4863,  0.0000, -1.6025, -0.8535,  0.0000, -1.7100,  0.0000,  1.5840,
         0.8267,  0.0000,  2.3730, -0.8672,  2.3086,  0.0000, -0.8159,  0.0000,
        -1.6133,  0.0000,  0.9482,  0.0000, -1.6445,  0.5825,  0.0000,  2.9043,
        -2.4590,  0.0000,  0.0000,  0.0000,  0.0000, -0.4602,  0.0000,  0.0000,
        -1.0234,  5.7969, -2.0449,  0.0000,  0.0000,  1.5244, -8.1328, -0.7964,
         0.1660,  2.7754,  0.0000,  0.0000,  0.6470,  0.0000,  0.0000,  0.0000,
        -2.3926,  0.0000,  0.0000,  0.8521,  1.9521,  0.0000, -4.4023, -0.8550,
         0.0000,  0.3289,  0.5742, -1.6016,  1.3232,  0.0000,  2.1504,  0.0000,
         0.0000, -1.7139,  0.0000,  0.0000,  0.0000,  0.7417,  0.0000,  0.0000,
         2.8359,  4.1953,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.9551,
         0.0000, -5.6953,  0.8809,  0.7422], dtype=torch.float16)
DESIRED: (shape=torch.Size([4, 3, 71582789, 5]), dtype=torch.float16)
First 100 elements: tensor([    nan,     nan,     nan,     nan,     nan,  0.2683,  0.8320,     nan,
        -1.8076, -0.3257,     nan,     nan,  2.3906,  1.4082, -0.8652,     nan,
         2.4863,     nan, -1.6025, -0.8535,     nan, -1.7100,     nan,  1.5840,
         0.8267,     nan,  2.3730, -0.8672,  2.3086,     nan, -0.8159,     nan,
        -1.6133,     nan,  0.9482,     nan, -1.6445,  0.5825,     nan,  2.9043,
        -2.4590,     nan,     nan,     nan,     nan, -0.4602,     nan,     nan,
        -1.0234,  5.7969, -2.0449,     nan,     nan,  1.5244, -8.1328, -0.7964,
         0.1660,  2.7754,     nan,     nan,  0.6470,     nan,     nan,     nan,
        -2.3926,     nan,     nan,  0.8521,  1.9521,     nan, -4.4023, -0.8550,
            nan,  0.3289,  0.5742, -1.6016,  1.3232,     nan,  2.1504,     nan,
            nan, -1.7139,     nan,     nan,     nan,  0.7417,     nan,     nan,
         2.8359,  4.1953,     nan,     nan,     nan,     nan,     nan,  1.9551,
            nan, -5.6953,  0.8809,  0.7422], dtype=torch.float16)
[Worker 2] Completed Task 1375

[Worker 2] Processing Task 1379: paddle.Tensor.nansum(Tensor([477218589, 3, 3],"float16"), )
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 1603: paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[0,1,3,2,],list[2,3,0,1,],], )
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[0,1,3,2,],list[2,3,0,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 25 (4.0%)
Greatest absolute difference: 0.3671875 at index (0, 0, 1, 4) (up to 0.01 allowed)
Greatest relative difference: 0.024658203125 at index (0, 0, 1, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float16)
All elements: tensor([  292.7500, -3664.0000,  -849.5000,   145.2500,  -131.5000,  -536.0000,
         -929.5000, -2312.0000, -2088.0000,    15.2578,  -681.5000,    95.2500,
          915.5000,  1990.0000, -2574.0000, -1271.0000,   -97.8750,   964.0000,
          356.0000,  -859.5000,   223.5000,   532.5000,  -378.7500,  -759.0000,
         -365.7500], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float16)
All elements: tensor([  292.7500, -3664.0000,  -849.5000,   145.2500,  -131.5000,  -536.0000,
         -929.5000, -2312.0000, -2088.0000,    14.8906,  -681.5000,    95.2500,
          915.5000,  1990.0000, -2574.0000, -1270.0000,   -97.8750,   964.0000,
          356.0000,  -859.5000,   223.5000,   532.5000,  -378.7500,  -759.0000,
         -365.7500], dtype=torch.float16)
[Worker 2] Completed Task 1603

[Worker 2] Processing Task 1605: paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[1,0,3,],list[2,3,0,],], )
[accuracy error] paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[1,0,3,],list[2,3,0,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 25 (4.0%)
Greatest absolute difference: 0.478515625 at index (2, 3) (up to 0.01 allowed)
Greatest relative difference: 0.705078125 at index (2, 3) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5]), dtype=torch.float16)
All elements: tensor([ 5.2640e+03,  5.8080e+03,  4.7650e+02,  1.7775e+02,  9.8050e+02,
        -2.9040e+03, -1.5330e+03, -3.0780e+03, -8.3150e+02,  5.6150e+02,
        -4.0160e+03, -2.5640e+03,  2.4280e+03, -1.1572e+00,  6.9700e+02,
        -1.6170e+03, -1.5830e+03, -2.0640e+03, -1.5760e+03, -2.6700e+02,
        -3.1380e+03, -5.4650e+02, -2.4920e+03,  3.1297e+01,  1.2269e+02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 5]), dtype=torch.float16)
All elements: tensor([ 5.2640e+03,  5.8080e+03,  4.7650e+02,  1.7750e+02,  9.8050e+02,
        -2.9040e+03, -1.5330e+03, -3.0780e+03, -8.3100e+02,  5.6150e+02,
        -4.0160e+03, -2.5640e+03,  2.4280e+03, -6.7871e-01,  6.9700e+02,
        -1.6170e+03, -1.5830e+03, -2.0640e+03, -1.5750e+03, -2.6700e+02,
        -3.1380e+03, -5.4700e+02, -2.4920e+03,  3.1000e+01,  1.2269e+02],
       dtype=torch.float16)
[Worker 2] Completed Task 1605

[Worker 2] Processing Task 1606: paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[1,0,3,2,],list[2,3,0,1,],], )
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[1,0,3,2,],list[2,3,0,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 25 (4.0%)
Greatest absolute difference: 0.3671875 at index (0, 0, 1, 4) (up to 0.01 allowed)
Greatest relative difference: 0.024658203125 at index (0, 0, 1, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float16)
All elements: tensor([  292.7500, -3664.0000,  -849.5000,   145.2500,  -131.5000,  -536.0000,
         -929.5000, -2312.0000, -2088.0000,    15.2578,  -681.5000,    95.2500,
          915.5000,  1990.0000, -2574.0000, -1271.0000,   -97.8750,   964.0000,
          356.0000,  -859.5000,   223.5000,   532.5000,  -378.7500,  -759.0000,
         -365.7500], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float16)
All elements: tensor([  292.7500, -3664.0000,  -849.5000,   145.2500,  -131.5000,  -536.0000,
         -929.5000, -2312.0000, -2088.0000,    14.8906,  -681.5000,    95.2500,
          915.5000,  1990.0000, -2574.0000, -1270.0000,   -97.8750,   964.0000,
          356.0000,  -859.5000,   223.5000,   532.5000,  -378.7500,  -759.0000,
         -365.7500], dtype=torch.float16)
[Worker 2] Completed Task 1606

[Worker 2] Processing Task 1609: paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[1,3,2,0,],list[2,1,0,3,],], )
[accuracy error] backward  paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[1,3,2,0,],list[2,1,0,3,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 25 (4.0%)
Greatest absolute difference: 0.3671875 at index (0, 0, 4, 1) (up to 0.01 allowed)
Greatest relative difference: 0.024658203125 at index (0, 0, 4, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float16)
All elements: tensor([  292.7500,  -536.0000,  -681.5000, -1271.0000,   223.5000, -3664.0000,
         -929.5000,    95.2500,   -97.8750,   532.5000,  -849.5000, -2312.0000,
          915.5000,   964.0000,  -378.7500,   145.2500, -2088.0000,  1990.0000,
          356.0000,  -759.0000,  -131.5000,    15.2578, -2574.0000,  -859.5000,
         -365.7500], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 5, 5]), dtype=torch.float16)
All elements: tensor([  292.7500,  -536.0000,  -681.5000, -1270.0000,   223.5000, -3664.0000,
         -929.5000,    95.2500,   -97.8750,   532.5000,  -849.5000, -2312.0000,
          915.5000,   964.0000,  -378.7500,   145.2500, -2088.0000,  1990.0000,
          356.0000,  -759.0000,  -131.5000,    14.8906, -2574.0000,  -859.5000,
         -365.7500], dtype=torch.float16)
[Worker 2] Completed Task 1609

[Worker 2] Processing Task 1615: paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[3,1,0,],list[3,2,1,],], )
[accuracy error] paddle.tensordot(Tensor([1, 1, 5, 5],"float16"), Tensor([5, 5, 34359739, 5],"float16"), list[list[3,1,0,],list[3,2,1,],], ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 25 (4.0%)
Greatest absolute difference: 0.484375 at index (2, 0) (up to 0.01 allowed)
Greatest relative difference: 0.0237884521484375 at index (2, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([5, 5]), dtype=torch.float16)
All elements: tensor([ 1.4770e+03,  2.5680e+03,  2.3080e+03, -2.6475e+02,  3.1440e+03,
        -4.3600e+03,  6.9438e+01, -3.4920e+03, -5.9650e+02, -1.5560e+03,
         1.9875e+01,  1.4150e+00,  1.3480e+03,  8.2600e+02, -1.0225e+03,
        -1.1270e+03, -2.4220e+03, -8.9450e+02, -1.3860e+03, -1.5810e+03,
        -1.8620e+03,  1.7610e+03, -2.6580e+03,  7.1750e+01,  1.3888e+02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([5, 5]), dtype=torch.float16)
All elements: tensor([ 1.4770e+03,  2.5680e+03,  2.3080e+03, -2.6475e+02,  3.1440e+03,
        -4.3600e+03,  6.9438e+01, -3.4920e+03, -5.9650e+02, -1.5560e+03,
         2.0359e+01,  1.4150e+00,  1.3480e+03,  8.2600e+02, -1.0225e+03,
        -1.1270e+03, -2.4220e+03, -8.9450e+02, -1.3860e+03, -1.5810e+03,
        -1.8620e+03,  1.7610e+03, -2.6580e+03,  7.1750e+01,  1.3888e+02],
       dtype=torch.float16)
[Worker 2] Completed Task 1615

[Worker 2] Processing Task 1665: paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([171798692, 5, 1, 5],"float16"), list[list[1,3,],list[1,0,],], )
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 1686: paddle.tensordot(Tensor([171798692, 5, 5, 1],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[3,2,1,],list[2,0,1,],], )
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 1775: paddle.tensordot(Tensor([5, 171798692, 5, 1],"float16"), Tensor([5, 5, 1, 5],"float16"), list[list[2,3,0,],list[3,1,0,],], )
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2105: paddle.tril(Tensor([10, 228170138, 1],"float32"), 0, )
[accuracy error] paddle.tril(Tensor([10, 228170138, 1],"float32"), 0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 131535417 / 2281701380 (5.8%)
Greatest absolute difference: 0.5 at index (9, 103686553, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (9, 93952406, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([10, 228170138, 1]), dtype=torch.float32)
First 100 elements: tensor([-0.0847,  0.3579, -0.2406,  0.0635,  0.3035,  0.4905,  0.0449,  0.4943,
        -0.4343, -0.1650,  0.0427, -0.4921,  0.1020,  0.1313, -0.0704,  0.4371,
        -0.2017,  0.2901, -0.4193, -0.2092,  0.2381,  0.2883,  0.0065, -0.0427,
        -0.2314, -0.1220, -0.1804, -0.4008,  0.4987,  0.4339, -0.4636,  0.3895,
        -0.0782,  0.3763,  0.0996,  0.1735, -0.1056,  0.2507, -0.1741, -0.0410,
         0.4222,  0.3409, -0.1956,  0.0604, -0.3221, -0.2260,  0.3213, -0.4612,
         0.4659,  0.2592,  0.3086,  0.0474, -0.4625,  0.0743, -0.0519, -0.4072,
         0.0814, -0.1086,  0.2782, -0.3541, -0.1738,  0.4620, -0.2919, -0.4164,
        -0.3000,  0.4412, -0.0815,  0.0055,  0.4748,  0.4083,  0.1486, -0.0129,
        -0.3701,  0.0644, -0.0810, -0.1795, -0.4422, -0.3852,  0.1974, -0.1776,
        -0.0840, -0.4505, -0.0974, -0.1322, -0.3245, -0.4002,  0.2007,  0.1704,
        -0.3610, -0.1211,  0.2422,  0.2474,  0.3481, -0.4094, -0.3948, -0.4489,
         0.4182, -0.1106,  0.3086,  0.3515])
DESIRED: (shape=torch.Size([10, 228170138, 1]), dtype=torch.float32)
First 100 elements: tensor([-0.0847,  0.3579, -0.2406,  0.0635,  0.3035,  0.4905,  0.0449,  0.4943,
        -0.4343, -0.1650,  0.0427, -0.4921,  0.1020,  0.1313, -0.0704,  0.4371,
        -0.2017,  0.2901, -0.4193, -0.2092,  0.2381,  0.2883,  0.0065, -0.0427,
        -0.2314, -0.1220, -0.1804, -0.4008,  0.4987,  0.4339, -0.4636,  0.3895,
        -0.0782,  0.3763,  0.0996,  0.1735, -0.1056,  0.2507, -0.1741, -0.0410,
         0.4222,  0.3409, -0.1956,  0.0604, -0.3221, -0.2260,  0.3213, -0.4612,
         0.4659,  0.2592,  0.3086,  0.0474, -0.4625,  0.0743, -0.0519, -0.4072,
         0.0814, -0.1086,  0.2782, -0.3541, -0.1738,  0.4620, -0.2919, -0.4164,
        -0.3000,  0.4412, -0.0815,  0.0055,  0.4748,  0.4083,  0.1486, -0.0129,
        -0.3701,  0.0644, -0.0810, -0.1795, -0.4422, -0.3852,  0.1974, -0.1776,
        -0.0840, -0.4505, -0.0974, -0.1322, -0.3245, -0.4002,  0.2007,  0.1704,
        -0.3610, -0.1211,  0.2422,  0.2474,  0.3481, -0.4094, -0.3948, -0.4489,
         0.4182, -0.1106,  0.3086,  0.3515])
[Worker 2] Completed Task 2105

[Worker 2] Processing Task 2108: paddle.tril(Tensor([2281701379, 1],"float32"), diagonal=0, )
[accuracy error] paddle.tril(Tensor([2281701379, 1],"float32"), diagonal=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 131535416 / 2281701379 (5.8%)
Greatest absolute difference: 0.5 at index (2157217795, 0) (up to 0.01 allowed)
Greatest relative difference: inf at index (2147483648, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379, 1]), dtype=torch.float32)
First 100 elements: tensor([-0.0847,  0.3579, -0.2406,  0.0635,  0.3035,  0.4905,  0.0449,  0.4943,
        -0.4343, -0.1650,  0.0427, -0.4921,  0.1020,  0.1313, -0.0704,  0.4371,
        -0.2017,  0.2901, -0.4193, -0.2092,  0.2381,  0.2883,  0.0065, -0.0427,
        -0.2314, -0.1220, -0.1804, -0.4008,  0.4987,  0.4339, -0.4636,  0.3895,
        -0.0782,  0.3763,  0.0996,  0.1735, -0.1056,  0.2507, -0.1741, -0.0410,
         0.4222,  0.3409, -0.1956,  0.0604, -0.3221, -0.2260,  0.3213, -0.4612,
         0.4659,  0.2592,  0.3086,  0.0474, -0.4625,  0.0743, -0.0519, -0.4072,
         0.0814, -0.1086,  0.2782, -0.3541, -0.1738,  0.4620, -0.2919, -0.4164,
        -0.3000,  0.4412, -0.0815,  0.0055,  0.4748,  0.4083,  0.1486, -0.0129,
        -0.3701,  0.0644, -0.0810, -0.1795, -0.4422, -0.3852,  0.1974, -0.1776,
        -0.0840, -0.4505, -0.0974, -0.1322, -0.3245, -0.4002,  0.2007,  0.1704,
        -0.3610, -0.1211,  0.2422,  0.2474,  0.3481, -0.4094, -0.3948, -0.4489,
         0.4182, -0.1106,  0.3086,  0.3515])
DESIRED: (shape=torch.Size([2281701379, 1]), dtype=torch.float32)
First 100 elements: tensor([-0.0847,  0.3579, -0.2406,  0.0635,  0.3035,  0.4905,  0.0449,  0.4943,
        -0.4343, -0.1650,  0.0427, -0.4921,  0.1020,  0.1313, -0.0704,  0.4371,
        -0.2017,  0.2901, -0.4193, -0.2092,  0.2381,  0.2883,  0.0065, -0.0427,
        -0.2314, -0.1220, -0.1804, -0.4008,  0.4987,  0.4339, -0.4636,  0.3895,
        -0.0782,  0.3763,  0.0996,  0.1735, -0.1056,  0.2507, -0.1741, -0.0410,
         0.4222,  0.3409, -0.1956,  0.0604, -0.3221, -0.2260,  0.3213, -0.4612,
         0.4659,  0.2592,  0.3086,  0.0474, -0.4625,  0.0743, -0.0519, -0.4072,
         0.0814, -0.1086,  0.2782, -0.3541, -0.1738,  0.4620, -0.2919, -0.4164,
        -0.3000,  0.4412, -0.0815,  0.0055,  0.4748,  0.4083,  0.1486, -0.0129,
        -0.3701,  0.0644, -0.0810, -0.1795, -0.4422, -0.3852,  0.1974, -0.1776,
        -0.0840, -0.4505, -0.0974, -0.1322, -0.3245, -0.4002,  0.2007,  0.1704,
        -0.3610, -0.1211,  0.2422,  0.2474,  0.3481, -0.4094, -0.3948, -0.4489,
         0.4182, -0.1106,  0.3086,  0.3515])
[Worker 2] Completed Task 2108

[Worker 2] Processing Task 2111: paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=1, )
[accuracy error] paddle.tril(x=Tensor([1073741825, 2, 2],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104510008 / 4294967300 (49.0%)
Greatest absolute difference: 0.5 at index (536871633, 0, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 2111

[Worker 2] Processing Task 2114: paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=0, )
[accuracy error] paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104510005 / 4294967298 (49.0%)
Greatest absolute difference: 0.5 at index (1, 357915383, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 357913941, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01,  0.0000e+00, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01,  0.0000e+00, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 2114

[Worker 2] Processing Task 2117: paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=5, )
[accuracy error] paddle.tril(x=Tensor([3, 715827883, 2],"float16"), diagonal=5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2104510006 / 4294967298 (49.0%)
Greatest absolute difference: 0.5 at index (1, 357915383, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 357913941, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 2117

[Worker 2] Processing Task 2120: paddle.triu(Tensor([1, 390451573, 1, 11],"float16"), diagonal=1, )
[accuracy error] paddle.triu(Tensor([1, 390451573, 1, 11],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 318866072 / 4294967303 (7.4%)
Greatest absolute difference: 0.5 at index (0, 357914037, 0, 7) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 357913941, 0, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 390451573, 1, 11]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000e+00, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  0.0000e+00,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02,  0.0000e+00, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  0.0000e+00, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01,  0.0000e+00,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
         0.0000e+00,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  0.0000e+00, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03,  0.0000e+00,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  0.0000e+00, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01,  0.0000e+00],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 390451573, 1, 11]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000e+00, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  0.0000e+00,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02,  0.0000e+00, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  0.0000e+00, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01,  0.0000e+00,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
         0.0000e+00,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  0.0000e+00, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03,  0.0000e+00,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  0.0000e+00, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01,  0.0000e+00],
       dtype=torch.float16)
[Worker 2] Completed Task 2120

[Worker 2] Processing Task 2123: paddle.triu(Tensor([2, 1, 1, 2147483649],"float16"), )
[accuracy error] paddle.triu(Tensor([2, 1, 1, 2147483649],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 5 / 4294967298 (0.0%)
Greatest absolute difference: 0.407470703125 at index (1, 0, 0, 2147483647) (up to 0.01 allowed)
Greatest relative difference: inf at index (1, 0, 0, 2147483644) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2, 1, 1, 2147483649]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([2, 1, 1, 2147483649]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 2123

[Worker 2] Processing Task 2126: paddle.triu(Tensor([42524429, 1, 1, 101],"float16"), )
[accuracy error] paddle.triu(Tensor([42524429, 1, 1, 101],"float16"), ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 121414715 / 4294967329 (2.8%)
Greatest absolute difference: 0.5 at index (41297801, 0, 0, 87) (up to 0.01 allowed)
Greatest relative difference: inf at index (41297762, 0, 0, 48) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([42524429, 1, 1, 101]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([42524429, 1, 1, 101]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 2126

[Worker 2] Processing Task 2129: paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=1, )
[accuracy error] paddle.triu(x=Tensor([1073741825, 2, 2],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 526129233 / 4294967300 (12.2%)
Greatest absolute difference: 0.5 at index (536871633, 0, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (536870912, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000, -0.0681,  0.0000,  0.0000,  0.0000,  0.2661,  0.0000,  0.0000,
         0.0000,  0.2130,  0.0000,  0.0000,  0.0000, -0.4749,  0.0000,  0.0000,
         0.0000, -0.0547,  0.0000,  0.0000,  0.0000,  0.0616,  0.0000,  0.0000,
         0.0000, -0.3533,  0.0000,  0.0000,  0.0000, -0.1001,  0.0000,  0.0000,
         0.0000,  0.3811,  0.0000,  0.0000,  0.0000, -0.4329,  0.0000,  0.0000,
         0.0000, -0.1483,  0.0000,  0.0000,  0.0000,  0.4055,  0.0000,  0.0000,
         0.0000,  0.4734,  0.0000,  0.0000,  0.0000,  0.0313,  0.0000,  0.0000,
         0.0000, -0.0096,  0.0000,  0.0000,  0.0000, -0.1124,  0.0000,  0.0000,
         0.0000,  0.3789,  0.0000,  0.0000,  0.0000, -0.0392,  0.0000,  0.0000,
         0.0000,  0.2469,  0.0000,  0.0000,  0.0000, -0.1234,  0.0000,  0.0000,
         0.0000,  0.2727,  0.0000,  0.0000,  0.0000, -0.4602,  0.0000,  0.0000,
         0.0000, -0.2496,  0.0000,  0.0000,  0.0000,  0.4587,  0.0000,  0.0000,
         0.0000, -0.0701,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([1073741825, 2, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000, -0.0681,  0.0000,  0.0000,  0.0000,  0.2661,  0.0000,  0.0000,
         0.0000,  0.2130,  0.0000,  0.0000,  0.0000, -0.4749,  0.0000,  0.0000,
         0.0000, -0.0547,  0.0000,  0.0000,  0.0000,  0.0616,  0.0000,  0.0000,
         0.0000, -0.3533,  0.0000,  0.0000,  0.0000, -0.1001,  0.0000,  0.0000,
         0.0000,  0.3811,  0.0000,  0.0000,  0.0000, -0.4329,  0.0000,  0.0000,
         0.0000, -0.1483,  0.0000,  0.0000,  0.0000,  0.4055,  0.0000,  0.0000,
         0.0000,  0.4734,  0.0000,  0.0000,  0.0000,  0.0313,  0.0000,  0.0000,
         0.0000, -0.0096,  0.0000,  0.0000,  0.0000, -0.1124,  0.0000,  0.0000,
         0.0000,  0.3789,  0.0000,  0.0000,  0.0000, -0.0392,  0.0000,  0.0000,
         0.0000,  0.2469,  0.0000,  0.0000,  0.0000, -0.1234,  0.0000,  0.0000,
         0.0000,  0.2727,  0.0000,  0.0000,  0.0000, -0.4602,  0.0000,  0.0000,
         0.0000, -0.2496,  0.0000,  0.0000,  0.0000,  0.4587,  0.0000,  0.0000,
         0.0000, -0.0701,  0.0000,  0.0000], dtype=torch.float16)
[Worker 2] Completed Task 2129

[Worker 2] Processing Task 2132: paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=0, )
[accuracy error] paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 7 / 4294967298 (0.0%)
Greatest absolute difference: 0.407470703125 at index (2, 1, 715827881) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1, 715827876) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 2.7051e-01, -6.8115e-02, -4.7656e-01,  7.3425e-02, -2.7100e-01,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 2132

[Worker 2] Processing Task 2135: paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=5, )
[accuracy error] paddle.triu(x=Tensor([3, 2, 715827883],"float16"), diagonal=5, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 7 / 4294967298 (0.0%)
Greatest absolute difference: 0.407470703125 at index (2, 1, 715827881) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 1, 715827876) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 2, 715827883]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         2.6611e-01,  2.0251e-01, -4.7095e-01,  3.3667e-01,  2.1301e-01,
        -3.7891e-01,  2.5742e-02,  4.3970e-01, -4.7485e-01,  2.4402e-01,
        -9.9731e-02, -3.3667e-01, -5.4749e-02,  4.8853e-01,  1.3623e-01,
         2.2620e-01,  6.1615e-02, -1.0089e-01, -3.1982e-01,  3.4790e-02,
        -3.5327e-01, -4.3604e-01,  5.4970e-03, -1.5417e-01, -1.0010e-01,
        -4.1699e-01, -6.5491e-02, -1.7798e-01,  3.8110e-01, -1.7053e-01,
        -4.9390e-01, -3.4326e-01, -4.3286e-01, -1.7310e-01,  3.0933e-01,
        -3.2617e-01, -1.4832e-01, -1.5967e-01, -2.4048e-01, -3.0566e-01,
         4.0552e-01, -1.2268e-01,  4.1870e-01, -3.9380e-01,  4.7339e-01,
        -4.2407e-01, -6.3599e-02, -8.3252e-02,  3.1281e-02,  3.3423e-01,
        -2.8979e-01,  1.4343e-01, -9.6207e-03, -7.5439e-02, -2.2827e-01,
         1.6150e-01, -1.1237e-01, -2.2388e-01,  3.0457e-02,  1.2250e-01,
         3.7891e-01,  2.7271e-01, -4.6973e-01,  1.2225e-01, -3.9215e-02,
         6.8703e-03, -5.8197e-02,  4.2041e-01,  2.4695e-01,  3.2227e-01,
        -6.0089e-02, -2.0905e-03, -1.2335e-01,  2.1777e-01, -4.7510e-01,
         5.3704e-05,  2.7271e-01, -4.6265e-01,  7.5928e-02, -1.0632e-01,
        -4.6021e-01, -3.5645e-01,  4.7974e-01,  2.8198e-01, -2.4963e-01,
        -3.1372e-01, -3.3203e-01, -2.7222e-01,  4.5874e-01,  3.4619e-01,
         3.2007e-01, -1.1426e-01, -7.0129e-02,  4.6582e-01, -1.5405e-01],
       dtype=torch.float16)
[Worker 2] Completed Task 2135

[Worker 2] Processing Task 2138: paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=1, )
[accuracy error] paddle.triu(x=Tensor([3, 715827883, 2],"float16"), diagonal=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 4294967298 (0.0%)
Greatest absolute difference: 0.433837890625 at index (2, 0, 1) (up to 0.01 allowed)
Greatest relative difference: inf at index (2, 0, 1) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000, -0.0681,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 715827883, 2]), dtype=torch.float16)
First 100 elements: tensor([ 0.0000, -0.0681,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], dtype=torch.float16)
[Worker 2] Completed Task 2138

[Worker 2] Processing Task 2200: paddle.argmax(Tensor([13, 2, 4, 10969719, 2],"float32"), axis=-1, )
[cuda error] paddle.argmax(Tensor([13, 2, 4, 10969719, 2],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927345 (unix time) try "date -d @1747927345" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc13f) received by PID 49471 (TID 0x7f2766dac740) from PID 49471 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2204: paddle.argmax(Tensor([3, 17674763, 3, 3, 3, 3],"float16"), axis=0, )
[cuda error] paddle.argmax(Tensor([3, 17674763, 3, 3, 3, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927489 (unix time) try "date -d @1747927489" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc294) received by PID 49812 (TID 0x7f2766dac740) from PID 49812 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2208: paddle.argmax(Tensor([3, 3, 3, 3, 3, 17674763],"float16"), axis=0, )
W0522 23:26:42.876953 50188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:26:42.877725 50188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmax(Tensor([3, 3, 3, 3, 3, 17674763],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927604 (unix time) try "date -d @1747927604" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc40c) received by PID 50188 (TID 0x7f2766dac740) from PID 50188 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2213: paddle.argmax(Tensor([4, 4, 16777217, 4, 4],"float16"), axis=0, )
[cuda error] paddle.argmax(Tensor([4, 4, 16777217, 4, 4],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927736 (unix time) try "date -d @1747927736" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc4c8) received by PID 50376 (TID 0x7f2766dac740) from PID 50376 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2218: paddle.argmax(Tensor([8912897, 2, 4, 16, 2],"float32"), axis=-1, )
[cuda error] paddle.argmax(Tensor([8912897, 2, 4, 16, 2],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747927840 (unix time) try "date -d @1747927840" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc640) received by PID 50752 (TID 0x7f2766dac740) from PID 50752 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2229: paddle.argmin(Tensor([3, 3, 17674763, 3, 3, 3],"float16"), axis=0, )
[cuda error] paddle.argmin(Tensor([3, 3, 17674763, 3, 3, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928008 (unix time) try "date -d @1747928008" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc7b7) received by PID 51127 (TID 0x7f2766dac740) from PID 51127 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2230: paddle.argmin(Tensor([3, 3, 3, 17674763, 3, 3],"float16"), axis=0, )
W0522 23:34:44.808415 51316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:34:44.809171 51316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmin(Tensor([3, 3, 3, 17674763, 3, 3],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928086 (unix time) try "date -d @1747928086" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xc874) received by PID 51316 (TID 0x7f2766dac740) from PID 51316 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2238: paddle.argmin(Tensor([4, 4, 4, 4, 16777217],"float16"), axis=0, )
W0522 23:36:31.127794 51785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:36:31.128568 51785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.argmin(Tensor([4, 4, 4, 4, 16777217],"float16"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928192 (unix time) try "date -d @1747928192" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xca49) received by PID 51785 (TID 0x7f2766dac740) from PID 51785 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2245: paddle.argmin(x=Tensor([357913942, 3, 4],"float16"), axis=1, keepdim=False, )
[cuda error] paddle.argmin(x=Tensor([357913942, 3, 4],"float16"), axis=1, keepdim=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928328 (unix time) try "date -d @1747928328" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcb63) received by PID 52067 (TID 0x7f2766dac740) from PID 52067 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2254: paddle.copysign(Tensor([107374183, 20, 2],"float16"), Tensor([107374183, 20, 2],"float16"), )
[cuda error] paddle.copysign(Tensor([107374183, 20, 2],"float16"), Tensor([107374183, 20, 2],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928509 (unix time) try "date -d @1747928509" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcc93) received by PID 52371 (TID 0x7f2766dac740) from PID 52371 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2260: paddle.copysign(Tensor([1203073, 17, 5, 6, 7],"float16"), Tensor([1203073, 17, 5, 6, 7],"float16"), )
W0522 23:43:49.282413 53032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:43:49.283830 53032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([1203073, 17, 5, 6, 7],"float16"), Tensor([1203073, 17, 5, 6, 7],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928645 (unix time) try "date -d @1747928645" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xcf28) received by PID 53032 (TID 0x7f2766dac740) from PID 53032 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2263: paddle.copysign(Tensor([2, 3, 4, 178956971],"float16"), Tensor([2, 3, 4, 178956971],"float16"), )
W0522 23:45:34.162509 53395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:45:34.163707 53395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([2, 3, 4, 178956971],"float16"), Tensor([2, 3, 4, 178956971],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928753 (unix time) try "date -d @1747928753" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd093) received by PID 53395 (TID 0x7f2766dac740) from PID 53395 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2266: paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([5],"float16"), )
W0522 23:47:19.780701 53739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:47:19.781785 53739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([5],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928855 (unix time) try "date -d @1747928855" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd1eb) received by PID 53739 (TID 0x7f2766dac740) from PID 53739 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2271: paddle.copysign(Tensor([71582789, 3, 4, 5],"float16"), Tensor([71582789, 3, 4, 5],"float16"), )
W0522 23:49:40.162189 54288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:49:40.163214 54288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([71582789, 3, 4, 5],"float16"), Tensor([71582789, 3, 4, 5],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747928996 (unix time) try "date -d @1747928996" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd410) received by PID 54288 (TID 0x7f2766dac740) from PID 54288 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2275: paddle.copysign(Tensor([8, 2556529, 5, 6, 7],"float16"), Tensor([8, 2556529, 5, 6, 7],"float16"), )
W0522 23:51:54.694464 54744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0522 23:51:54.695842 54744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.copysign(Tensor([8, 2556529, 5, 6, 7],"float16"), Tensor([8, 2556529, 5, 6, 7],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747929131 (unix time) try "date -d @1747929131" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd5d8) received by PID 54744 (TID 0x7f2766dac740) from PID 54744 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2295: paddle.cumsum(Tensor([114085069, 20],"int64"), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.cumsum(Tensor([114085069, 20],"int64"), axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cumsum(_object*, _object*, _object*)
1   cumsum_ad_func(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor>, bool, bool, bool)
2   paddle::experimental::cumsum(paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, bool, bool, bool)
3   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 17.000000GB memory on GPU 0, 69.610352GB memory has been allocated and available memory is only 9.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 2295

[Worker 2] Processing Task 2298: paddle.cumsum(Tensor([16, 142606337],"int32"), axis=0, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.cumsum(Tensor([16, 142606337],"int32"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01

ACTUAL: (shape=torch.Size([16, 142606337]), dtype=torch.int32)
First 100 elements: tensor([-26668, -27293, -30621,  37160, -45225,  36266,  11812,  26592, -53212,
        -52870,  29693,  -5254,  32086,  41964,  17648,  27056,  15223,  45779,
        -47045, -53714,  21714,   -595, -24686,   8115, -28972, -25943,  11858,
        -28906,  45420,  19658, -32827,  23241, -37610,  46040,  -6863,  58480,
        -37299,  12549,  -3013,  62141, -47709,   -356, -32403,  32630, -21540,
        -21304,  57040, -20830, -57696,   6206,  44261, -52567, -47840, -36822,
         14522,  49175, -55787,  12764, -20460,  51044, -10418,  58897, -53707,
         57936, -61755,  32057,  58847,   6266, -55804, -43047, -32901,  20639,
        -52836,  49958, -30405, -18281, -62198,  26428,  13096,  19856, -50249,
        -46589, -29424,  38632, -44533,  15083, -17099, -54269,  29432, -15258,
        -65383, -38540, -14951,  59774,  37751, -25725, -62029,   8941, -29844,
         15691], dtype=torch.int32)
DESIRED: (shape=torch.Size([16, 142606337]), dtype=torch.int64)
First 100 elements: tensor([-26668, -27293, -30621,  37160, -45225,  36266,  11812,  26592, -53212,
        -52870,  29693,  -5254,  32086,  41964,  17648,  27056,  15223,  45779,
        -47045, -53714,  21714,   -595, -24686,   8115, -28972, -25943,  11858,
        -28906,  45420,  19658, -32827,  23241, -37610,  46040,  -6863,  58480,
        -37299,  12549,  -3013,  62141, -47709,   -356, -32403,  32630, -21540,
        -21304,  57040, -20830, -57696,   6206,  44261, -52567, -47840, -36822,
         14522,  49175, -55787,  12764, -20460,  51044, -10418,  58897, -53707,
         57936, -61755,  32057,  58847,   6266, -55804, -43047, -32901,  20639,
        -52836,  49958, -30405, -18281, -62198,  26428,  13096,  19856, -50249,
        -46589, -29424,  38632, -44533,  15083, -17099, -54269,  29432, -15258,
        -65383, -38540, -14951,  59774,  37751, -25725, -62029,   8941, -29844,
         15691])
[Worker 2] Completed Task 2298

[Worker 2] Processing Task 2303: paddle.cumsum(Tensor([22591103, 101],"int64"), 1, )
[torch error] paddle.cumsum(Tensor([22591103, 101],"int64"), 1, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 67193 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2303

[Worker 2] Processing Task 2305: paddle.cumsum(Tensor([24, 95070891],"int32"), axis=0, )
[torch error] paddle.cumsum(Tensor([24, 95070891],"int32"), axis=0, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 9.57 GiB is free. Process 67193 has 69.61 GiB memory in use. Of the allocated memory 51.00 GiB is allocated by PyTorch, and 8.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2305

[Worker 2] Processing Task 2306: paddle.cumsum(Tensor([285212673, 2, 4],"float32"), axis=1, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 67193 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 2306: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 67193 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 2306: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 67193 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2320: paddle.cumsum(x=Tensor([1, 1398102, 96, 32],"float16"), axis=2, )
[accuracy error] paddle.cumsum(x=Tensor([1, 1398102, 96, 32],"float16"), axis=2, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 54748 / 4294969344 (0.0%)
Greatest absolute difference: 0.03515625 at index (0, 259294, 86, 31) (up to 0.01 allowed)
Greatest relative difference: inf at index (0, 33249, 56, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1398102, 96, 32]), dtype=torch.float16)
First 100 elements: tensor([-0.2864, -0.2344, -0.0211, -0.3079, -0.2708, -0.1338, -0.1681, -0.2196,
         0.1093, -0.3245,  0.1827,  0.0175,  0.2952, -0.4465,  0.2839, -0.3608,
         0.0083,  0.0676,  0.0596,  0.3557,  0.4250,  0.4565, -0.1361, -0.3389,
         0.0890, -0.2498,  0.3450, -0.4539, -0.0555,  0.4790, -0.4084, -0.0227,
        -0.5625, -0.4822,  0.4214, -0.3704, -0.6431, -0.1564, -0.3828,  0.2120,
         0.0995,  0.0522,  0.6318,  0.1055,  0.6562, -0.1167,  0.1246, -0.4475,
         0.1692, -0.3567,  0.2969,  0.6904,  0.4956,  0.2190, -0.1736, -0.8027,
        -0.2529,  0.1975, -0.0647, -0.6797,  0.1183, -0.0159, -0.8086,  0.0662,
        -0.5571, -0.0801,  0.1190, -0.0794, -0.5732,  0.3042, -0.3955,  0.2944,
         0.1410, -0.0450,  1.0039,  0.4895,  0.4961, -0.2300, -0.2096, -0.6514,
         0.1076, -0.3721,  0.2764,  0.8452,  0.2822,  0.1448,  0.2466, -1.2568,
        -0.1973,  0.1027, -0.1066, -0.2844, -0.3650, -0.1140, -0.9746, -0.0296,
        -0.6055, -0.5566,  0.4072,  0.0610], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1398102, 96, 32]), dtype=torch.float16)
First 100 elements: tensor([-0.2864, -0.2344, -0.0211, -0.3079, -0.2708, -0.1338, -0.1681, -0.2196,
         0.1093, -0.3245,  0.1827,  0.0175,  0.2952, -0.4465,  0.2839, -0.3608,
         0.0083,  0.0676,  0.0596,  0.3557,  0.4250,  0.4565, -0.1361, -0.3389,
         0.0890, -0.2498,  0.3450, -0.4539, -0.0555,  0.4790, -0.4084, -0.0227,
        -0.5625, -0.4822,  0.4214, -0.3704, -0.6431, -0.1564, -0.3828,  0.2120,
         0.0995,  0.0522,  0.6318,  0.1055,  0.6562, -0.1167,  0.1246, -0.4475,
         0.1692, -0.3567,  0.2969,  0.6904,  0.4956,  0.2190, -0.1736, -0.8027,
        -0.2529,  0.1975, -0.0647, -0.6797,  0.1183, -0.0159, -0.8086,  0.0662,
        -0.5566, -0.0801,  0.1191, -0.0793, -0.5732,  0.3042, -0.3955,  0.2944,
         0.1410, -0.0450,  1.0039,  0.4895,  0.4961, -0.2300, -0.2096, -0.6514,
         0.1075, -0.3721,  0.2764,  0.8452,  0.2825,  0.1448,  0.2466, -1.2568,
        -0.1971,  0.1027, -0.1066, -0.2842, -0.3650, -0.1140, -0.9746, -0.0295,
        -0.6050, -0.5566,  0.4075,  0.0610], dtype=torch.float16)
[Worker 2] Completed Task 2320

[Worker 2] Processing Task 2328: paddle.cumulative_trapezoid(y=Tensor([1073741825, 4],"float16"), x=Tensor([1073741825, 4],"float16"), )
W0523 00:07:30.223179 55469 backward.cc:441] While running Node (GatherGradNode) raises a std::exception: paddle::memory::allocation::BadAlloc
[paddle error] paddle.cumulative_trapezoid(y=Tensor([1073741825, 4],"float16"), x=Tensor([1073741825, 4],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Grad(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
1   egr::RunBackward(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, bool, std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&)
2   GatherGradNode::operator()(paddle::small_vector<std::vector<paddle::Tensor, std::allocator<paddle::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::gather_grad(paddle::Tensor const&, paddle::Tensor const&, paddle::Tensor const&, paddle::experimental::ScalarBase<paddle::Tensor> const&, paddle::Tensor*)
4   void phi::funcs::GatherV2GradCUDAFunction<phi::dtype::float16, long>(phi::DenseTensor const*, phi::DenseTensor const*, int, phi::DenseTensor*, phi::GPUContext const&)
5   phi::dtype::float16* phi::DeviceContext::Alloc<phi::dtype::float16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
12  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 77.625977GB memory has been allocated and available memory is only 1.558899GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930055 (unix time) try "date -d @1747930055" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xd8ad) received by PID 55469 (TID 0x7f2766dac740) from PID 55469 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2343: paddle.dist(x=Tensor([1073741825, 4],"float16"), y=Tensor([1073741825, 4],"float16"), p=1, )
[cuda error] paddle.dist(x=Tensor([1073741825, 4],"float16"), y=Tensor([1073741825, 4],"float16"), p=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930215 (unix time) try "date -d @1747930215" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xda75) received by PID 55925 (TID 0x7f2766dac740) from PID 55925 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2346: paddle.dist(x=Tensor([4, 1073741825],"float16"), y=Tensor([4, 1073741825],"float16"), )
W0523 00:11:35.576550 56133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:11:35.577574 56133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.dist(x=Tensor([4, 1073741825],"float16"), y=Tensor([4, 1073741825],"float16"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930301 (unix time) try "date -d @1747930301" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdb45) received by PID 56133 (TID 0x7f2766dac740) from PID 56133 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2350: paddle.dist(x=Tensor([570425345, 4],"float32"), y=Tensor([570425345, 4],"float32"), )
W0523 00:13:26.265482 56605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:13:26.266573 56605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.dist(x=Tensor([570425345, 4],"float32"), y=Tensor([570425345, 4],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930408 (unix time) try "date -d @1747930408" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xdd1d) received by PID 56605 (TID 0x7f2766dac740) from PID 56605 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2353: paddle.frac(Tensor([114085069, 20, 1],"float32"), )
W0523 00:14:39.516139 56890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 00:14:39.517091 56890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.frac(Tensor([114085069, 20, 1],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747930493 (unix time) try "date -d @1747930493" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xde3a) received by PID 56890 (TID 0x7f2766dac740) from PID 56890 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2510: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), "nuc", )
[torch error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), "nuc", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Error on Task 2510: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] OOM on Task 2510: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2512: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), -2, )
[torch error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), -2, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Error on Task 2512: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] OOM on Task 2512: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2517: paddle.linalg.matrix_rank(Tensor([114085069, 4, 5],"float32"), )
[torch error] paddle.linalg.matrix_rank(Tensor([114085069, 4, 5],"float32"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Error on Task 2517: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] OOM on Task 2517: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2525: paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=1, axis=list[0,1,], keepdim=True, )
[accuracy error] paddle.linalg.norm(x=Tensor([2, 536870913, 4],"float16"), p=1, axis=list[0,1,], keepdim=True, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([0., 0., 0., 0.], dtype=torch.float16)
DESIRED: (shape=torch.Size([1, 1, 4]), dtype=torch.float16)
All elements: tensor([1., 1., 1., 1.], dtype=torch.float16)
[Worker 2] Completed Task 2525

[Worker 2] Processing Task 2625: paddle.nansum(Tensor([1073741824, 4],"float32"), )
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2629: paddle.nansum(Tensor([3, 1431655765],"float32"), axis=None, )
W0523 01:26:16.236505 59142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:26:16.237474 59142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2633: paddle.nansum(Tensor([858993459, 5],"float32"), axis=None, )
W0523 01:56:19.288378 59522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 01:56:19.289389 59522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2637: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 67108864, 32],"float32"), 16, False, None, )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 2] Error on Task 2637: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 2] OOM on Task 2637: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2641: paddle.nn.functional.adaptive_max_pool2d(Tensor([29217465, 3, 7, 7],"float32"), output_size=list[None,3,], return_mask=False, name=None, )
(External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 2] Error on Task 2641: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 2] OOM on Task 2641: (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2645: paddle.nn.functional.grid_sample(Tensor([56, 3, 6790778, 2],"float32"), Tensor([56, 2, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
W0523 02:28:38.487059 60659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:28:38.488054 60659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 3, 6790778, 2],"float32"), Tensor([56, 2, 2, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938519 (unix time) try "date -d @1747938519" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xecf3) received by PID 60659 (TID 0x7f2766dac740) from PID 60659 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2650: paddle.nn.functional.grid_sample(Tensor([56, 9948, 64, 64],"float32"), Tensor([56, 64, 64, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, )
W0523 02:30:23.039438 61192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:30:23.040663 61192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([56, 9948, 64, 64],"float32"), Tensor([56, 64, 64, 2],"float32"), mode="bilinear", padding_mode="border", align_corners=True, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938638 (unix time) try "date -d @1747938638" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xef08) received by PID 61192 (TID 0x7f2766dac740) from PID 61192 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2655: paddle.nn.functional.grid_sample(Tensor([727584, 4, 28, 28],"float32"), Tensor([727584, 34, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )
W0523 02:32:28.027319 61722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:32:28.028342 61722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.grid_sample(Tensor([727584, 4, 28, 28],"float32"), Tensor([727584, 34, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938770 (unix time) try "date -d @1747938770" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf11a) received by PID 61722 (TID 0x7f2766dac740) from PID 61722 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2659: paddle.nn.functional.layer_norm(Tensor([69633, 128, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, )
W0523 02:34:35.858220 62199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:34:35.859227 62199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.layer_norm(Tensor([69633, 128, 256],"float32"), list[256,], weight=Tensor([256],"float32"), bias=Tensor([256],"float32"), epsilon=1e-05, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747938889 (unix time) try "date -d @1747938889" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf2f7) received by PID 62199 (TID 0x7f2766dac740) from PID 62199 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2663: paddle.nn.functional.normalize(Tensor([1, 2228225, 32, 32],"float32"), axis=1, )
W0523 02:36:39.828438 62636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:36:39.829416 62636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 2228225, 32, 32],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939017 (unix time) try "date -d @1747939017" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf4ac) received by PID 62636 (TID 0x7f2766dac740) from PID 62636 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2669: paddle.nn.functional.normalize(Tensor([1, 8912897, 16, 16],"float32"), axis=1, )
W0523 02:38:50.633070 63298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:38:50.634037 63298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1, 8912897, 16, 16],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939152 (unix time) try "date -d @1747939152" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf742) received by PID 63298 (TID 0x7f2766dac740) from PID 63298 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2673: paddle.nn.functional.normalize(Tensor([1006, 2268093],"float32"), )
W0523 02:40:54.653458 63756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:40:54.654412 63756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([1006, 2268093],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939272 (unix time) try "date -d @1747939272" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xf90c) received by PID 63756 (TID 0x7f2766dac740) from PID 63756 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2675: paddle.nn.functional.normalize(Tensor([12, 190141782],"float32"), axis=-1, )
W0523 02:42:54.490744 64005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:42:54.491660 64005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([12, 190141782],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939487 (unix time) try "date -d @1747939487" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfa05) received by PID 64005 (TID 0x7f2766dac740) from PID 64005 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2682: paddle.nn.functional.normalize(Tensor([228170138, 10],"float32"), axis=0, )
W0523 02:46:30.898027 64802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:46:30.899055 64802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([228170138, 10],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939743 (unix time) try "date -d @1747939743" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xfd22) received by PID 64802 (TID 0x7f2766dac740) from PID 64802 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2690: paddle.nn.functional.normalize(Tensor([35651585, 64],"float32"), axis=-1, )
W0523 02:50:44.909379 65714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:50:44.910351 65714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([35651585, 64],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939858 (unix time) try "date -d @1747939858" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x100b2) received by PID 65714 (TID 0x7f2766dac740) from PID 65714 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2692: paddle.nn.functional.normalize(Tensor([4074467, 8, 7, 10],"float32"), axis=1, )
W0523 02:52:10.869840 65942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:52:10.870848 65942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([4074467, 8, 7, 10],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747939944 (unix time) try "date -d @1747939944" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10196) received by PID 65942 (TID 0x7f2766dac740) from PID 65942 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2696: paddle.nn.functional.normalize(Tensor([456340276, 5],"float32"), axis=0, )
W0523 02:54:16.117751 66396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:54:16.119220 66396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([456340276, 5],"float32"), axis=0, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940287 (unix time) try "date -d @1747940287" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1035c) received by PID 66396 (TID 0x7f2766dac740) from PID 66396 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2702: paddle.nn.functional.normalize(Tensor([8705, 64, 64, 64],"float32"), axis=1, )
W0523 02:59:55.569181 67082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 02:59:55.570266 67082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(Tensor([8705, 64, 64, 64],"float32"), axis=1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940410 (unix time) try "date -d @1747940410" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1060a) received by PID 67082 (TID 0x7f2766dac740) from PID 67082 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2705: paddle.nn.functional.normalize(x=Tensor([2, 1140850690],"float32"), )
W0523 03:02:27.781159 67424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:02:27.782089 67424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([2, 1140850690],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747940995 (unix time) try "date -d @1747940995" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10760) received by PID 67424 (TID 0x7f2766dac740) from PID 67424 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2718: paddle.nn.functional.normalize(x=Tensor([570425345, 4],"float32"), )
W0523 03:11:38.494426 68906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:11:38.495426 68906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.normalize(x=Tensor([570425345, 4],"float32"), ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941112 (unix time) try "date -d @1747941112" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10d2a) received by PID 68906 (TID 0x7f2766dac740) from PID 68906 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2720: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -1, 1e-06, True, None, )
W0523 03:13:05.994515 69153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:13:05.995514 69153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -1, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941200 (unix time) try "date -d @1747941200" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10e21) received by PID 69153 (TID 0x7f2766dac740) from PID 69153 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2725: paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -math.inf, 1e-06, False, None, )
W0523 03:15:01.784161 69626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:15:01.785257 69626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 22817014],"float32"), Tensor([100, 22817014],"float32"), -math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941305 (unix time) try "date -d @1747941305" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10ffa) received by PID 69626 (TID 0x7f2766dac740) from PID 69626 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2729: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -1, 1e-06, True, None, )
W0523 03:17:05.482167 70006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:17:05.483160 70006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), -1, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941462 (unix time) try "date -d @1747941462" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11176) received by PID 70006 (TID 0x7f2766dac740) from PID 70006 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2734: paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), math.inf, 1e-06, True, None, )
W0523 03:19:31.712471 70481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:19:31.713501 70481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([100, 42949673],"float16"), Tensor([100, 42949673],"float16"), math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941580 (unix time) try "date -d @1747941580" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11351) received by PID 70481 (TID 0x7f2766dac740) from PID 70481 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2739: paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), -math.inf, 1e-06, False, None, )
W0523 03:21:33.735883 70954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:21:33.736860 70954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([2, 1140850690],"float32"), Tensor([2, 1140850690],"float32"), -math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941755 (unix time) try "date -d @1747941755" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1152a) received by PID 70954 (TID 0x7f2766dac740) from PID 70954 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2746: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 2, 1e-06, False, None, )
W0523 03:24:31.571128 71507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:24:31.572510 71507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), 2, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941873 (unix time) try "date -d @1747941873" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11753) received by PID 71507 (TID 0x7f2766dac740) from PID 71507 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2751: paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -math.inf, 1e-06, True, None, )
W0523 03:26:17.790973 71965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:26:17.791957 71965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([22817014, 100],"float32"), Tensor([22817014, 100],"float32"), -math.inf, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747941980 (unix time) try "date -d @1747941980" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1191d) received by PID 71965 (TID 0x7f2766dac740) from PID 71965 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2754: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 1, 1e-06, True, None, )
W0523 03:27:42.603735 72419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:27:42.604730 72419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), 1, 1e-06, True, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942068 (unix time) try "date -d @1747942068" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11ae3) received by PID 72419 (TID 0x7f2766dac740) from PID 72419 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2758: paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), math.inf, 1e-06, False, None, )
W0523 03:29:33.934213 72875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:29:33.935220 72875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([42949673, 100],"float16"), Tensor([42949673, 100],"float16"), math.inf, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942179 (unix time) try "date -d @1747942179" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11cab) received by PID 72875 (TID 0x7f2766dac740) from PID 72875 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2762: paddle.nn.functional.pairwise_distance(Tensor([760567127, 3],"float32"), Tensor([760567127, 3],"float32"), 1, 1e-06, False, None, )
W0523 03:31:28.774602 73313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:31:28.775635 73313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.nn.functional.pairwise_distance(Tensor([760567127, 3],"float32"), Tensor([760567127, 3],"float32"), 1, 1e-06, False, None, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747942295 (unix time) try "date -d @1747942295" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x11e61) received by PID 73313 (TID 0x7f2766dac740) from PID 73313 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2770: paddle.nn.functional.rrelu(Tensor([2, 57042535, 4, 5],"float32"), 0.1, 0.3, training=False, )
[cuda error] paddle.nn.functional.rrelu(Tensor([2, 57042535, 4, 5],"float32"), 0.1, 0.3, training=False, ) 
 (External) CUDA error(9), invalid configuration argument. 
  [Hint: 'cudaErrorInvalidConfiguration'. This indicates that a kernel launch is requesting resources that can never be satisfied by the current device. Requestingmore shared memory per block than the device supports will trigger this error, as will requesting too many threads or blocks.See cudaDeviceProp for more device limitations.] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1384)

[Worker 2] Completed Task 2770

[Worker 2] Processing Task 2777: paddle.std(Tensor([35791395, 3, 4, 10],"float16"), 2, True, False, )
[accuracy error] backward  paddle.std(Tensor([35791395, 3, 4, 10],"float16"), 2, True, False, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 50 / 4294967400 (0.0%)
Greatest absolute difference: 0.0533447265625 at index (1468315, 2, 2, 6) (up to 0.01 allowed)
Greatest relative difference: inf at index (1309982, 1, 2, 4) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([35791395, 3, 4, 10]), dtype=torch.float16)
First 100 elements: tensor([-0.0309, -0.0014,  0.0703,  0.1320,  0.1764, -0.0179, -0.0817,  0.0207,
        -0.0269, -0.1108, -0.0635,  0.0461, -0.0513, -0.1207, -0.0936,  0.0048,
        -0.0417, -0.0247, -0.0078, -0.0980,  0.0475,  0.0594, -0.0570,  0.1370,
        -0.1456,  0.0201,  0.0900, -0.0190, -0.0411,  0.1074,  0.0469, -0.1042,
         0.0380, -0.1482,  0.0627, -0.0070,  0.0334,  0.0230,  0.0759,  0.1014,
        -0.0112, -0.0147,  0.0571, -0.1863, -0.0031, -0.0250,  0.0486, -0.2357,
         0.0062, -0.0522,  0.1350,  0.0251, -0.0938, -0.0024,  0.0128,  0.0105,
        -0.0566,  0.0365,  0.0017, -0.0907, -0.1436, -0.0078, -0.0462,  0.0459,
         0.0003,  0.0043, -0.0302,  0.1257,  0.0116, -0.0468,  0.0197, -0.0027,
         0.0829,  0.1427, -0.0100,  0.0102,  0.0382,  0.0736, -0.0195,  0.1897,
         0.0105, -0.0599, -0.0133,  0.1001,  0.0831, -0.0224,  0.0008, -0.0141,
         0.0415,  0.0388,  0.0661, -0.0271, -0.0377, -0.1813,  0.0204,  0.0211,
         0.0056, -0.0165, -0.1115,  0.0117], dtype=torch.float16)
DESIRED: (shape=torch.Size([35791395, 3, 4, 10]), dtype=torch.float16)
First 100 elements: tensor([-0.0309, -0.0014,  0.0703,  0.1320,  0.1764, -0.0179, -0.0817,  0.0207,
        -0.0269, -0.1108, -0.0636,  0.0461, -0.0512, -0.1207, -0.0936,  0.0048,
        -0.0417, -0.0247, -0.0078, -0.0980,  0.0475,  0.0594, -0.0569,  0.1370,
        -0.1456,  0.0201,  0.0899, -0.0190, -0.0411,  0.1074,  0.0469, -0.1042,
         0.0379, -0.1482,  0.0627, -0.0070,  0.0334,  0.0230,  0.0759,  0.1014,
        -0.0113, -0.0147,  0.0572, -0.1863, -0.0031, -0.0250,  0.0486, -0.2357,
         0.0062, -0.0522,  0.1350,  0.0251, -0.0938, -0.0025,  0.0128,  0.0105,
        -0.0566,  0.0365,  0.0017, -0.0907, -0.1436, -0.0078, -0.0463,  0.0459,
         0.0003,  0.0043, -0.0302,  0.1257,  0.0116, -0.0468,  0.0197, -0.0027,
         0.0829,  0.1427, -0.0100,  0.0102,  0.0382,  0.0736, -0.0195,  0.1897,
         0.0105, -0.0599, -0.0133,  0.1001,  0.0829, -0.0224,  0.0008, -0.0141,
         0.0415,  0.0388,  0.0661, -0.0271, -0.0377, -0.1813,  0.0202,  0.0211,
         0.0056, -0.0165, -0.1115,  0.0117], dtype=torch.float16)
[Worker 2] Completed Task 2777

[Worker 2] Processing Task 2782: paddle.std(x=Tensor([3, 3, 477218589],"float16"), axis=0, )
[accuracy error] backward  paddle.std(x=Tensor([3, 3, 477218589],"float16"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 20619 / 4294967301 (0.0%)
Greatest absolute difference: nan at index (0, 0, 789123) (up to 0.01 allowed)
Greatest relative difference: nan at index (0, 0, 789123) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([3, 3, 477218589]), dtype=torch.float16)
First 100 elements: tensor([-7.3303e-02, -9.0942e-02,  1.4001e-01,  1.1670e-01, -4.8065e-02,
         1.0986e-01, -3.1128e-02, -2.4658e-02, -1.4236e-02, -1.0498e-01,
        -2.0850e-01,  2.3572e-01,  4.3907e-03, -1.0522e-01, -9.6008e-02,
        -1.3501e-01,  1.7993e-01, -1.6235e-01, -1.3977e-01, -1.6272e-01,
         7.5867e-02,  5.2094e-02,  5.6274e-02,  9.7534e-02,  1.2891e-01,
         2.3346e-02,  2.6562e-01, -6.2073e-02,  2.0117e-01, -1.6626e-01,
         2.0642e-01, -2.6627e-03,  2.4139e-02, -2.3486e-01,  2.4023e-01,
         2.6382e-02, -2.3758e-02,  3.2654e-02,  7.6294e-02, -4.3610e-02,
         6.4011e-03,  1.2337e-02, -7.2021e-02, -1.8408e-01,  2.4207e-01,
        -2.2070e-01,  1.6739e-02, -2.2375e-01, -7.8674e-02, -1.5710e-01,
        -7.9468e-02, -2.7832e-01, -7.5317e-02,  2.0645e-02,  2.3279e-01,
        -7.7881e-02, -5.8136e-02, -1.2073e-01, -1.0521e-02,  2.4548e-01,
        -1.2048e-01, -1.2189e-01,  2.3712e-02,  2.8052e-01, -2.5955e-02,
         3.5076e-03, -3.4084e-03,  2.5635e-01, -1.1029e-01, -2.0349e-01,
        -1.1664e-01, -2.5803e-02,  2.9449e-02, -1.6708e-02, -1.1633e-01,
        -2.6413e-02,  2.9800e-02,  1.5479e-01,  4.8409e-03,  5.0751e-02,
         1.7380e-02, -9.1797e-02,  7.1777e-02, -9.0179e-03,  3.1158e-02,
         4.2114e-02,  1.1139e-01,  3.6102e-02, -4.9896e-02,  1.3000e-01,
         6.7688e-02,  6.8054e-02, -1.8066e-01, -1.8262e-01, -5.0690e-02,
        -6.7472e-05,  1.1975e-01,  1.4026e-01, -2.7393e-01, -1.5541e-02],
       dtype=torch.float16)
DESIRED: (shape=torch.Size([3, 3, 477218589]), dtype=torch.float16)
First 100 elements: tensor([-7.3425e-02, -9.1003e-02,  1.4001e-01,  1.1664e-01, -4.8035e-02,
         1.0986e-01, -3.1128e-02, -2.4673e-02, -1.4221e-02, -1.0492e-01,
        -2.0874e-01,  2.3584e-01,  4.4022e-03, -1.0535e-01, -9.6008e-02,
        -1.3489e-01,  1.7993e-01, -1.6235e-01, -1.3965e-01, -1.6272e-01,
         7.5928e-02,  5.2063e-02,  5.6396e-02,  9.7534e-02,  1.2915e-01,
         2.3346e-02,  2.6562e-01, -6.2073e-02,  2.0105e-01, -1.6626e-01,
         2.0630e-01, -2.6627e-03,  2.4124e-02, -2.3486e-01,  2.4023e-01,
         2.6367e-02, -2.3788e-02,  3.2776e-02,  7.6233e-02, -4.3610e-02,
         6.4278e-03,  1.2321e-02, -7.2021e-02, -1.8408e-01,  2.4207e-01,
        -2.2070e-01,  1.6754e-02, -2.2351e-01, -7.8674e-02, -1.5710e-01,
        -7.9529e-02, -2.7808e-01, -7.5378e-02,  2.0615e-02,  2.3279e-01,
        -7.7820e-02, -5.8136e-02, -1.2073e-01, -1.0513e-02,  2.4573e-01,
        -1.2048e-01, -1.2189e-01,  2.3697e-02,  2.8076e-01, -2.5940e-02,
         3.5229e-03, -3.4027e-03,  2.5635e-01, -1.1029e-01, -2.0349e-01,
        -1.1658e-01, -2.5833e-02,  2.9465e-02, -1.6708e-02, -1.1633e-01,
        -2.6505e-02,  2.9800e-02,  1.5479e-01,  4.8409e-03,  5.0781e-02,
         1.7395e-02, -9.1797e-02,  7.1716e-02, -8.9493e-03,  3.1158e-02,
         4.2114e-02,  1.1139e-01,  3.6102e-02, -4.9896e-02,  1.3000e-01,
         6.7749e-02,  6.8115e-02, -1.8079e-01, -1.8274e-01, -5.0690e-02,
        -6.7830e-05,  1.1975e-01,  1.4026e-01, -2.7417e-01, -1.5533e-02],
       dtype=torch.float16)
[Worker 2] Completed Task 2782

[Worker 2] Processing Task 2830: paddle.Tensor.argmax(Tensor([221848, 1, 10285],"float32"), axis=-2, )
[cuda error] paddle.Tensor.argmax(Tensor([221848, 1, 10285],"float32"), axis=-2, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943156 (unix time) try "date -d @1747943156" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x12099) received by PID 73881 (TID 0x7f2766dac740) from PID 73881 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2833: paddle.Tensor.argmax(Tensor([7225, 157920, 2],"float32"), axis=-1, )
W0523 03:47:04.781311 74473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 03:47:04.782088 74473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[cuda error] paddle.Tensor.argmax(Tensor([7225, 157920, 2],"float32"), axis=-1, ) 
 (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/fluid/pybind/eager_functions.cc:1381)

terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at /paddle/paddle/phi/core/platform/device/gpu/gpu_info.cc:348)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1747943226 (unix time) try "date -d @1747943226" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x122e9) received by PID 74473 (TID 0x7f2766dac740) from PID 74473 ***]

[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2843: paddle.Tensor.cumsum(Tensor([1, 15845149, 144],"float32"), 1, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 15845149, 144],"float32"), 1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1874821 / 2281701456 (0.1%)
Greatest absolute difference: 0.13698959350585938 at index (0, 11221760, 39) (up to 0.01 allowed)
Greatest relative difference: 30411.77734375 at index (0, 14311025, 16) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 15845149, 144]), dtype=torch.float32)
First 100 elements: tensor([-0.2392, -0.0237, -0.4806, -0.4563, -0.4921, -0.1715,  0.0992, -0.1599,
        -0.3210, -0.2047,  0.2163, -0.4631,  0.4330,  0.0386,  0.2331,  0.4673,
        -0.2215, -0.2261,  0.3090,  0.3476, -0.0277, -0.1935,  0.2064, -0.4919,
         0.1562,  0.4067, -0.4372, -0.1540, -0.3855,  0.4501, -0.0273, -0.4967,
        -0.2986,  0.2318, -0.2164,  0.2272, -0.1468,  0.1709,  0.0846, -0.4013,
         0.2282, -0.1863,  0.2318,  0.3565,  0.2092,  0.3758,  0.2564, -0.2761,
        -0.2779, -0.1677,  0.2695,  0.2857, -0.4389, -0.1845,  0.2629,  0.4553,
        -0.2825, -0.4137, -0.0918,  0.4561,  0.4272, -0.0897, -0.2125,  0.3329,
         0.2079,  0.3654,  0.0099, -0.0615, -0.4467,  0.3218,  0.0926,  0.1050,
         0.3636,  0.3221, -0.2747,  0.3747,  0.2578, -0.1018, -0.4006,  0.4998,
         0.4388, -0.1258,  0.2038,  0.3524,  0.1552, -0.3675,  0.4531,  0.3112,
        -0.1317, -0.0497, -0.2290, -0.1337, -0.4865,  0.2926,  0.1374, -0.2492,
         0.0732,  0.2829, -0.3500,  0.0563])
DESIRED: (shape=torch.Size([1, 15845149, 144]), dtype=torch.float32)
First 100 elements: tensor([-0.2392, -0.0237, -0.4806, -0.4563, -0.4921, -0.1715,  0.0992, -0.1599,
        -0.3210, -0.2047,  0.2163, -0.4631,  0.4330,  0.0386,  0.2331,  0.4673,
        -0.2215, -0.2261,  0.3090,  0.3476, -0.0277, -0.1935,  0.2064, -0.4919,
         0.1562,  0.4067, -0.4372, -0.1540, -0.3855,  0.4501, -0.0273, -0.4967,
        -0.2986,  0.2318, -0.2164,  0.2272, -0.1468,  0.1709,  0.0846, -0.4013,
         0.2282, -0.1863,  0.2318,  0.3565,  0.2092,  0.3758,  0.2564, -0.2761,
        -0.2779, -0.1677,  0.2695,  0.2857, -0.4389, -0.1845,  0.2629,  0.4553,
        -0.2825, -0.4137, -0.0918,  0.4561,  0.4272, -0.0897, -0.2125,  0.3329,
         0.2079,  0.3654,  0.0099, -0.0615, -0.4467,  0.3218,  0.0926,  0.1050,
         0.3636,  0.3221, -0.2747,  0.3747,  0.2578, -0.1018, -0.4006,  0.4998,
         0.4388, -0.1258,  0.2038,  0.3524,  0.1552, -0.3675,  0.4531,  0.3112,
        -0.1317, -0.0497, -0.2290, -0.1337, -0.4865,  0.2926,  0.1374, -0.2492,
         0.0732,  0.2829, -0.3500,  0.0563])
[Worker 2] Completed Task 2843

[Worker 2] Processing Task 2853: paddle.Tensor.cumsum(Tensor([1, 91268056, 25],"float32"), 1, )
[accuracy error] paddle.Tensor.cumsum(Tensor([1, 91268056, 25],"float32"), 1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 6475524 / 2281701400 (0.3%)
Greatest absolute difference: 0.7942543029785156 at index (0, 67415319, 20) (up to 0.01 allowed)
Greatest relative difference: 12671.599609375 at index (0, 73861195, 24) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 91268056, 25]), dtype=torch.float32)
First 100 elements: tensor([-0.2392, -0.0237, -0.4806, -0.4563, -0.4921, -0.1715,  0.0992, -0.1599,
        -0.3210, -0.2047,  0.2163, -0.4631,  0.4330,  0.0386,  0.2331,  0.4673,
        -0.2215, -0.2261,  0.3090,  0.3476, -0.0277, -0.1935,  0.2064, -0.4919,
         0.1562,  0.1675, -0.4609, -0.6346, -0.8418, -0.0421, -0.1988, -0.3975,
        -0.4586, -0.0892, -0.4211,  0.4435, -0.6099,  0.6038,  0.1232, -0.1682,
         0.6955, -0.4078,  0.0057,  0.6656,  0.5568,  0.3481,  0.0629, -0.0697,
        -0.7698, -0.0115,  0.4371, -0.1752, -1.0736, -1.0263,  0.2209,  0.2565,
        -0.6800, -0.8723, -0.1810,  0.0350,  0.8707, -0.6996,  0.3913,  0.4560,
         0.0397,  1.0608, -0.3979, -0.0558,  0.2189,  0.8786,  0.4407,  0.1679,
         0.2939, -0.4477, -0.2862,  0.8117,  0.0826, -1.1753, -1.4269,  0.7207,
         0.6953, -0.8057, -0.6685,  0.1713,  0.1902,  0.5032, -0.2465,  0.7025,
         0.3243, -0.0099,  0.8318, -0.5316, -0.5423,  0.5115,  1.0160,  0.1915,
         0.2411,  0.5768, -0.7976, -0.2299])
DESIRED: (shape=torch.Size([1, 91268056, 25]), dtype=torch.float32)
First 100 elements: tensor([-0.2392, -0.0237, -0.4806, -0.4563, -0.4921, -0.1715,  0.0992, -0.1599,
        -0.3210, -0.2047,  0.2163, -0.4631,  0.4330,  0.0386,  0.2331,  0.4673,
        -0.2215, -0.2261,  0.3090,  0.3476, -0.0277, -0.1935,  0.2064, -0.4919,
         0.1562,  0.1675, -0.4609, -0.6346, -0.8418, -0.0421, -0.1988, -0.3975,
        -0.4586, -0.0892, -0.4211,  0.4435, -0.6099,  0.6038,  0.1232, -0.1682,
         0.6955, -0.4078,  0.0057,  0.6656,  0.5568,  0.3481,  0.0629, -0.0697,
        -0.7698, -0.0115,  0.4371, -0.1752, -1.0736, -1.0263,  0.2209,  0.2565,
        -0.6800, -0.8723, -0.1810,  0.0350,  0.8707, -0.6996,  0.3913,  0.4560,
         0.0397,  1.0608, -0.3979, -0.0558,  0.2189,  0.8786,  0.4407,  0.1679,
         0.2939, -0.4477, -0.2862,  0.8117,  0.0826, -1.1753, -1.4269,  0.7207,
         0.6953, -0.8057, -0.6685,  0.1713,  0.1902,  0.5032, -0.2465,  0.7025,
         0.3243, -0.0099,  0.8318, -0.5316, -0.5423,  0.5115,  1.0160,  0.1915,
         0.2411,  0.5768, -0.7976, -0.2299])
[Worker 2] Completed Task 2853

[Worker 2] Processing Task 2860: paddle.Tensor.cumsum(Tensor([2228225, 1024],"int32"), axis=-1, )
element 0 of tensors does not require grad and does not have a grad_fn
[accuracy error] paddle.Tensor.cumsum(Tensor([2228225, 1024],"int32"), axis=-1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01

ACTUAL: (shape=torch.Size([2228225, 1024]), dtype=torch.int32)
First 100 elements: tensor([   197, -30831,   5514,  63043,  83776, 127402, 174567, 218062, 165089,
        203417, 140583, 180008, 125590, 136254, 104941, 139716, 198657, 256034,
        292540, 313771, 308800, 324363, 300014, 326837, 329492, 347302, 362262,
        353216, 371659, 352761, 381301, 408672, 344487, 354619, 309124, 330392,
        376304, 359985, 357139, 401873, 409683, 373434, 351051, 401492, 408623,
        372366, 354958, 417439, 377888, 384290, 396557, 461109, 469807, 466454,
        473807, 437742, 421711, 452468, 390308, 435321, 463071, 475819, 482270,
        532321, 475782, 414234, 465372, 443837, 434945, 425298, 415317, 393270,
        407585, 417426, 438616, 449778, 397234, 438694, 398808, 415430, 453053,
        390045, 393446, 369703, 306718, 366160, 301067, 358180, 394554, 355151,
        294291, 324523, 292194, 299804, 354765, 362630, 313210, 338304, 395976,
        454435], dtype=torch.int32)
DESIRED: (shape=torch.Size([2228225, 1024]), dtype=torch.int64)
First 100 elements: tensor([   197, -30831,   5514,  63043,  83776, 127402, 174567, 218062, 165089,
        203417, 140583, 180008, 125590, 136254, 104941, 139716, 198657, 256034,
        292540, 313771, 308800, 324363, 300014, 326837, 329492, 347302, 362262,
        353216, 371659, 352761, 381301, 408672, 344487, 354619, 309124, 330392,
        376304, 359985, 357139, 401873, 409683, 373434, 351051, 401492, 408623,
        372366, 354958, 417439, 377888, 384290, 396557, 461109, 469807, 466454,
        473807, 437742, 421711, 452468, 390308, 435321, 463071, 475819, 482270,
        532321, 475782, 414234, 465372, 443837, 434945, 425298, 415317, 393270,
        407585, 417426, 438616, 449778, 397234, 438694, 398808, 415430, 453053,
        390045, 393446, 369703, 306718, 366160, 301067, 358180, 394554, 355151,
        294291, 324523, 292194, 299804, 354765, 362630, 313210, 338304, 395976,
        454435])
[Worker 2] Completed Task 2860

[Worker 2] Processing Task 2866: paddle.Tensor.cumsum(Tensor([3, 380283564, 2],"int64"), axis=0, )
[torch error] paddle.Tensor.cumsum(Tensor([3, 380283564, 2],"int64"), axis=0, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 7.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2866

[Worker 2] Processing Task 2867: paddle.Tensor.cumsum(Tensor([3, 380283564, 2],"int64"), axis=1, )
[torch error] paddle.Tensor.cumsum(Tensor([3, 380283564, 2],"int64"), axis=1, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 7.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2867

[Worker 2] Processing Task 2868: paddle.Tensor.cumsum(Tensor([3, 380283564, 2],"int64"), axis=2, )
[torch error] paddle.Tensor.cumsum(Tensor([3, 380283564, 2],"int64"), axis=2, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 7.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2868

[Worker 2] Processing Task 2869: paddle.Tensor.cumsum(Tensor([3, 4, 190141782],"int64"), axis=0, )
[torch error] paddle.Tensor.cumsum(Tensor([3, 4, 190141782],"int64"), axis=0, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 7.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2869

[Worker 2] Processing Task 2870: paddle.Tensor.cumsum(Tensor([3, 4, 190141782],"int64"), axis=1, )
[torch error] paddle.Tensor.cumsum(Tensor([3, 4, 190141782],"int64"), axis=1, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 7.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2870

[Worker 2] Processing Task 2872: paddle.Tensor.cumsum(Tensor([5, 456340276],"int64"), axis=0, )
[torch error] paddle.Tensor.cumsum(Tensor([5, 456340276],"int64"), axis=0, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 7.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 2872

[Worker 2] Processing Task 2873: paddle.Tensor.cumsum(Tensor([5070448, 18, 25],"float32"), 1, )
CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 9.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 2873: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 9.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 2873: CUDA out of memory. Tried to allocate 8.50 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.07 GiB is free. Process 127560 has 78.11 GiB memory in use. Of the allocated memory 59.50 GiB is allocated by PyTorch, and 9.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 2887: paddle.Tensor.nansum(Tensor([477218589, 3, 3],"float16"), axis=-1, )
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3059: paddle.flatten(Tensor([2, 512, 4194304, 1],"float32"), 1, )
[accuracy error] paddle.flatten(Tensor([2, 512, 4194304, 1],"float32"), 1, ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([[ 0.1803,  0.4866,  0.1554,  ..., -0.2604, -0.2660, -0.0108],
        [-0.1649,  0.4389,  0.0276,  ...,  0.1641,  0.4209,  0.4643]]),
    expected=tensor([[ 0.1803,  0.4866,  0.1554,  ..., -0.2604, -0.2660, -0.0108],
        [-0.1649,  0.4389,  0.0276,  ...,  0.1641,  0.4209,  0.4643]]),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 3059

[Worker 2] Processing Task 3080: paddle.flatten(Tensor([5, 429496730],"float64"), )
[accuracy error] paddle.flatten(Tensor([5, 429496730],"float64"), ) 
 Comparing

TensorLikePair(
    id=(),
    actual=tensor([-0.4283, -0.3376,  0.4297,  ...,  0.0300,  0.4776, -0.0422],
       dtype=torch.float64),
    expected=tensor([-0.4283, -0.3376,  0.4297,  ...,  0.0300,  0.4776, -0.0422],
       dtype=torch.float64),
    rtol=0.01,
    atol=0.01,
    equal_nan=True,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.
[Worker 2] Completed Task 3080

[Worker 2] Processing Task 3090: paddle.gcd(Tensor([2281701379],"int32"), Tensor([1],"int32"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.gcd(Tensor([2281701379],"int32"), Tensor([1],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   not_equal_ad_func(paddle::Tensor const&, paddle::Tensor const&)
1   paddle::experimental::not_equal(paddle::Tensor const&, paddle::Tensor const&)
2   void phi::NotEqualRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
4   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
5   paddle::memory::allocation::Allocator::Allocate(unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
10  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 2.125000GB memory on GPU 0, 78.124023GB memory has been allocated and available memory is only 1.060852GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 3090

[Worker 2] Processing Task 3096: paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([253522376, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), )
W0523 05:08:52.710134 77700 backward.cc:437] While running Node (LerpGradNode) raises an EnforceNotMet exception
[paddle error] paddle.lerp(Tensor([1, 3, 3],"float32"), Tensor([253522376, 3, 3],"float32"), Tensor([1, 3, 3],"float32"), ) 
 (InvalidArgument) numel is expected to be greater than or equal 0, but received -2013265912.
  [Hint: Expected numel >= 0, but received numel:-2013265912 < 0:0.] (at /paddle/paddle/phi/backends/gpu/gpu_launch_config.h:110)

[Worker 2] Completed Task 3096

[Worker 2] Processing Task 3098: paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), Tensor([2, 1140850690],"float32"), )
W0523 05:09:22.649993 77700 backward.cc:437] While running Node (LerpGradNode) raises an EnforceNotMet exception
[paddle error] paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 1],"float32"), Tensor([2, 1140850690],"float32"), ) 
 (InvalidArgument) numel is expected to be greater than or equal 0, but received -2013265916.
  [Hint: Expected numel >= 0, but received numel:-2013265916 < 0:0.] (at /paddle/paddle/phi/backends/gpu/gpu_launch_config.h:110)

[Worker 2] Completed Task 3098

[Worker 2] Processing Task 3099: paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 1140850690],"float32"), Tensor([2, 1],"float32"), )
W0523 05:09:55.703547 77700 backward.cc:437] While running Node (LerpGradNode) raises an EnforceNotMet exception
[paddle error] paddle.lerp(Tensor([2, 1],"float32"), Tensor([2, 1140850690],"float32"), Tensor([2, 1],"float32"), ) 
 (InvalidArgument) numel is expected to be greater than or equal 0, but received -2013265916.
  [Hint: Expected numel >= 0, but received numel:-2013265916 < 0:0.] (at /paddle/paddle/phi/backends/gpu/gpu_launch_config.h:110)

[Worker 2] Completed Task 3099

[Worker 2] Processing Task 3103: paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), -1, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [2, 126761188, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([2, 126761188, 3, 3],"float32"), -1, ) 
 (PreconditionNotMet) For batch [62761710]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 2] Completed Task 3103

[Worker 2] Processing Task 3106: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), "fro", )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [63380594, 4, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), "fro", ) 
 (PreconditionNotMet) For batch [62761710]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 2] Completed Task 3106

[Worker 2] Processing Task 3109: paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), math.inf, )
one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [63380594, 4, 3, 3]], which is output 0 of LinalgInvExBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
[paddle error] paddle.linalg.cond(Tensor([63380594, 4, 3, 3],"float32"), math.inf, ) 
 (PreconditionNotMet) For batch [62761710]: U(3, 3) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:3 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 2] Completed Task 3109

[Worker 2] Processing Task 3112: paddle.linalg.det(Tensor([3, 30422686, 5, 5],"float32"), )
W0523 05:11:33.028273 77700 backward.cc:437] While running Node (DetGradNode) raises an EnforceNotMet exception
[paddle error] paddle.linalg.det(Tensor([3, 30422686, 5, 5],"float32"), ) 
 (PreconditionNotMet) For batch [1319315]: U(5, 5) is zero, singular U. Please check the matrix value and change it to a non-singular matrix
  [Hint: Expected info[i] == 0, but received info[i]:5 != 0:0.] (at /paddle/paddle/phi/kernels/funcs/matrix_inverse.cu:117)

[Worker 2] Completed Task 3112

[Worker 2] Processing Task 3120: paddle.maximum(Tensor([2147483649],"float64"), Tensor([1],"float64"), )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.27 GiB is free. Process 80397 has 76.91 GiB memory in use. Of the allocated memory 66.02 GiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 3120: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.27 GiB is free. Process 80397 has 76.91 GiB memory in use. Of the allocated memory 66.02 GiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 3120: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.27 GiB is free. Process 80397 has 76.91 GiB memory in use. Of the allocated memory 66.02 GiB is allocated by PyTorch, and 15.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3124: paddle.nanmean(Tensor([1431655765, 3],"float32"), 0, True, )
W0523 05:14:20.467372 78341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:14:20.468670 78341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3128: paddle.nanmean(Tensor([2, 107374183, 4, 5],"float32"), list[], False, )
W0523 05:44:28.239005 78726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 05:44:28.240023 78726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3132: paddle.nanmean(Tensor([2, 2147483648],"float32"), 1, False, )
W0523 06:14:41.694625 79106 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:14:41.695673 79106 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3136: paddle.nanmean(Tensor([2, 2147483648],"float32"), tuple(0,1,), False, )
W0523 06:44:50.729507 79486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 06:44:50.730973 79486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3140: paddle.nanmean(Tensor([2, 3, 143165577, 5],"float32"), list[0,2,], False, )
W0523 07:15:16.316218 79866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:15:16.317209 79866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3144: paddle.nanmean(Tensor([2, 3, 4, 178956971],"float32"), -1, False, )
W0523 07:45:10.029017 80246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 07:45:10.030321 80246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3148: paddle.nanmean(Tensor([2, 3, 4, 178956971],"float32"), None, True, )
W0523 08:15:22.501649 80626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:15:22.502696 80626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3152: paddle.nanmean(Tensor([71582789, 3, 4, 5],"float32"), list[], False, )
W0523 08:45:33.905231 81006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 08:45:33.906289 81006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3156: paddle.nanmean(Tensor([71582789, 3, 4, 5],"float32"), None, True, )
W0523 09:15:48.881028 81386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:15:48.882030 81386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3160: paddle.nn.functional.normalize(Tensor([1, 2281701379],"float32"), axis=1, )
W0523 09:46:01.767956 81766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:46:01.768918 81766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(Tensor([1, 2281701379],"float32"), axis=1, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281701379 / 2281701379 (100.0%)
Greatest absolute difference: 499999997952.0 at index (0, 36051979) (up to 0.01 allowed)
Greatest relative difference: 1.3789275971649536e+16 at index (0, 124) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 2.1643e+10, -2.5866e+11, -4.2262e+11,  2.4642e+11,  7.4123e+10,
         3.5889e+10, -2.8275e+11, -3.9419e+11,  1.8775e+11,  4.4827e+11,
         3.3210e+11,  3.7081e+11, -2.9466e+11, -4.1487e+09, -1.2461e+11,
         4.6334e+11, -1.5692e+11, -2.3535e+11,  2.0404e+11,  1.7636e+10,
        -2.6876e+11,  2.4107e+10,  3.4868e+11, -2.8580e+11, -4.7098e+11,
        -3.8499e+11, -1.0029e+11,  4.1899e+11,  4.9273e+11, -3.8842e+11,
         4.3012e+11, -6.8716e+10, -3.3990e+11, -2.2177e+11,  5.6577e+10,
         2.1431e+11,  3.2957e+10,  2.6338e+11,  1.1776e+11, -3.4605e+11,
        -4.5410e+11,  9.9662e+10, -2.4866e+11, -3.0363e+11,  1.8180e+11,
         1.8805e+11, -2.4757e+11,  1.0217e+11, -1.7391e+11,  2.8825e+11,
         3.2696e+11, -4.3656e+11, -6.3621e+10, -3.6783e+11, -2.2133e+11,
        -3.9542e+11, -3.2947e+11, -3.1119e+11,  8.5787e+10, -2.4886e+11,
         2.0062e+11, -2.1848e+11, -4.2070e+11,  1.2250e+11,  9.4049e+10,
        -2.2316e+11,  3.0656e+11, -4.4868e+11,  1.8773e+11, -4.9815e+11,
         3.7822e+11, -4.8369e+11,  1.6961e+11,  1.7686e+11, -3.2526e+11,
         3.1517e+10, -3.5926e+11, -2.6855e+10, -2.4400e+11, -1.3372e+11,
        -9.0010e+10,  4.8534e+11, -2.0518e+11,  1.4139e+11,  4.2797e+11,
        -3.7007e+11, -3.5067e+11, -2.6157e+11,  9.4327e+10, -2.6225e+11,
         1.0264e+11, -6.8808e+10,  9.1293e+10, -3.4577e+11,  5.1908e+10,
         2.2181e+11, -1.1602e+11,  4.0458e+11,  4.7495e+11,  1.5268e+11])
DESIRED: (shape=torch.Size([1, 2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 1.5695e-06, -1.8758e-05, -3.0648e-05,  1.7870e-05,  5.3754e-06,
         2.6026e-06, -2.0505e-05, -2.8587e-05,  1.3616e-05,  3.2508e-05,
         2.4084e-05,  2.6891e-05, -2.1369e-05, -3.0087e-07, -9.0364e-06,
         3.3602e-05, -1.1380e-05, -1.7068e-05,  1.4797e-05,  1.2789e-06,
        -1.9490e-05,  1.7483e-06,  2.5286e-05, -2.0726e-05, -3.4155e-05,
        -2.7920e-05, -7.2731e-06,  3.0386e-05,  3.5733e-05, -2.8168e-05,
         3.1192e-05, -4.9833e-06, -2.4650e-05, -1.6083e-05,  4.1029e-06,
         1.5541e-05,  2.3900e-06,  1.9100e-05,  8.5401e-06, -2.5096e-05,
        -3.2932e-05,  7.2275e-06, -1.8033e-05, -2.2019e-05,  1.3184e-05,
         1.3637e-05, -1.7953e-05,  7.4092e-06, -1.2612e-05,  2.0904e-05,
         2.3712e-05, -3.1659e-05, -4.6138e-06, -2.6675e-05, -1.6051e-05,
        -2.8676e-05, -2.3893e-05, -2.2568e-05,  6.2213e-06, -1.8047e-05,
         1.4549e-05, -1.5844e-05, -3.0509e-05,  8.8840e-06,  6.8204e-06,
        -1.6184e-05,  2.2232e-05, -3.2538e-05,  1.3614e-05, -3.6126e-05,
         2.7429e-05, -3.5077e-05,  1.2300e-05,  1.2826e-05, -2.3588e-05,
         2.2856e-06, -2.6054e-05, -1.9475e-06, -1.7695e-05, -9.6973e-06,
        -6.5276e-06,  3.5197e-05, -1.4880e-05,  1.0253e-05,  3.1037e-05,
        -2.6838e-05, -2.5431e-05, -1.8969e-05,  6.8406e-06, -1.9019e-05,
         7.4433e-06, -4.9900e-06,  6.6206e-06, -2.5075e-05,  3.7644e-06,
         1.6086e-05, -8.4141e-06,  2.9340e-05,  3.4443e-05,  1.1072e-05])
[Worker 2] Completed Task 3160

[Worker 2] Processing Task 3164: paddle.nn.functional.normalize(Tensor([2281701379],"float32"), axis=0, epsilon=1e-10, )
[accuracy error] paddle.nn.functional.normalize(Tensor([2281701379],"float32"), axis=0, epsilon=1e-10, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 2281701379 / 2281701379 (100.0%)
Greatest absolute difference: 5000000000.0 at index (36051979,) (up to 0.01 allowed)
Greatest relative difference: 137892760387584.0 at index (966,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 2.1643e+08, -2.5866e+09, -4.2262e+09,  2.4642e+09,  7.4123e+08,
         3.5889e+08, -2.8275e+09, -3.9419e+09,  1.8775e+09,  4.4827e+09,
         3.3210e+09,  3.7081e+09, -2.9466e+09, -4.1487e+07, -1.2461e+09,
         4.6334e+09, -1.5692e+09, -2.3535e+09,  2.0404e+09,  1.7636e+08,
        -2.6876e+09,  2.4107e+08,  3.4868e+09, -2.8580e+09, -4.7098e+09,
        -3.8499e+09, -1.0029e+09,  4.1899e+09,  4.9273e+09, -3.8842e+09,
         4.3012e+09, -6.8716e+08, -3.3990e+09, -2.2177e+09,  5.6577e+08,
         2.1431e+09,  3.2957e+08,  2.6338e+09,  1.1776e+09, -3.4605e+09,
        -4.5410e+09,  9.9662e+08, -2.4866e+09, -3.0363e+09,  1.8180e+09,
         1.8805e+09, -2.4757e+09,  1.0217e+09, -1.7391e+09,  2.8825e+09,
         3.2696e+09, -4.3656e+09, -6.3621e+08, -3.6783e+09, -2.2133e+09,
        -3.9542e+09, -3.2947e+09, -3.1119e+09,  8.5787e+08, -2.4886e+09,
         2.0062e+09, -2.1848e+09, -4.2070e+09,  1.2250e+09,  9.4049e+08,
        -2.2316e+09,  3.0656e+09, -4.4868e+09,  1.8773e+09, -4.9815e+09,
         3.7822e+09, -4.8369e+09,  1.6961e+09,  1.7686e+09, -3.2526e+09,
         3.1517e+08, -3.5926e+09, -2.6855e+08, -2.4400e+09, -1.3372e+09,
        -9.0010e+08,  4.8534e+09, -2.0518e+09,  1.4139e+09,  4.2797e+09,
        -3.7007e+09, -3.5067e+09, -2.6157e+09,  9.4327e+08, -2.6225e+09,
         1.0264e+09, -6.8808e+08,  9.1293e+08, -3.4577e+09,  5.1908e+08,
         2.2181e+09, -1.1602e+09,  4.0458e+09,  4.7495e+09,  1.5268e+09])
DESIRED: (shape=torch.Size([2281701379]), dtype=torch.float32)
First 100 elements: tensor([ 1.5695e-06, -1.8758e-05, -3.0648e-05,  1.7870e-05,  5.3754e-06,
         2.6026e-06, -2.0505e-05, -2.8587e-05,  1.3616e-05,  3.2508e-05,
         2.4084e-05,  2.6891e-05, -2.1369e-05, -3.0087e-07, -9.0364e-06,
         3.3602e-05, -1.1380e-05, -1.7068e-05,  1.4797e-05,  1.2789e-06,
        -1.9490e-05,  1.7483e-06,  2.5286e-05, -2.0726e-05, -3.4155e-05,
        -2.7920e-05, -7.2731e-06,  3.0386e-05,  3.5733e-05, -2.8168e-05,
         3.1192e-05, -4.9833e-06, -2.4650e-05, -1.6083e-05,  4.1029e-06,
         1.5541e-05,  2.3900e-06,  1.9100e-05,  8.5401e-06, -2.5096e-05,
        -3.2932e-05,  7.2275e-06, -1.8033e-05, -2.2019e-05,  1.3184e-05,
         1.3637e-05, -1.7953e-05,  7.4092e-06, -1.2612e-05,  2.0904e-05,
         2.3712e-05, -3.1659e-05, -4.6138e-06, -2.6675e-05, -1.6051e-05,
        -2.8676e-05, -2.3893e-05, -2.2568e-05,  6.2213e-06, -1.8047e-05,
         1.4549e-05, -1.5844e-05, -3.0509e-05,  8.8840e-06,  6.8204e-06,
        -1.6184e-05,  2.2232e-05, -3.2538e-05,  1.3614e-05, -3.6126e-05,
         2.7429e-05, -3.5077e-05,  1.2300e-05,  1.2826e-05, -2.3588e-05,
         2.2856e-06, -2.6054e-05, -1.9475e-06, -1.7695e-05, -9.6973e-06,
        -6.5276e-06,  3.5197e-05, -1.4880e-05,  1.0253e-05,  3.1037e-05,
        -2.6838e-05, -2.5431e-05, -1.8969e-05,  6.8406e-06, -1.9019e-05,
         7.4433e-06, -4.9900e-06,  6.6206e-06, -2.5075e-05,  3.7644e-06,
         1.6086e-05, -8.4141e-06,  2.9340e-05,  3.4443e-05,  1.1072e-05])
[Worker 2] Completed Task 3164

[Worker 2] Processing Task 3166: paddle.nn.functional.normalize(Tensor([4294967295],"float32"), axis=0, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.57 GiB is free. Process 21577 has 66.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 3166: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.57 GiB is free. Process 21577 has 66.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 3166: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.57 GiB is free. Process 21577 has 66.61 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3167: paddle.nn.functional.normalize(Tensor([4294967295],"float32"), axis=0, epsilon=1e-10, )
CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.58 GiB is free. Process 45832 has 65.60 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Error on Task 3167: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.58 GiB is free. Process 45832 has 65.60 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] OOM on Task 3167: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.58 GiB is free. Process 45832 has 65.60 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Started on GPU 2

[Worker 2] Processing Task 3172: paddle.nn.functional.normalize(x=Tensor([4294967297],"float16"), axis=0, )
W0523 09:49:53.563097 82412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0523 09:49:53.564052 82412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
[accuracy error] paddle.nn.functional.normalize(x=Tensor([4294967297],"float16"), axis=0, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 4255620541 / 4294967297 (99.1%)
Greatest absolute difference: 1.0927734375 at index (2588,) (up to 0.01 allowed)
Greatest relative difference: 46464.0 at index (347895,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([ 1.0000, -0.4753,  0.0576,  0.8301,  0.5029, -0.9863, -0.7588,  0.8252,
         0.8711, -0.5615, -1.0312, -0.3662, -0.2416, -0.3164, -0.3015,  0.7539,
        -0.0461, -0.7466,  0.8315, -0.6196, -0.6577, -0.3772, -0.0557, -0.6069,
         0.1312,  0.2751,  0.1063,  0.1572, -0.3152,  0.3584,  0.1869, -0.1229,
         0.9502, -0.3428,  0.4453, -0.9287,  0.3560,  0.0070, -0.4980,  0.2874,
         0.7407,  0.8833, -0.9214,  0.8311, -0.2130, -1.0244, -0.4436,  1.0020,
         0.9189, -0.6318, -0.8174,  0.7480, -0.5068, -1.0195,  0.4155, -0.7695,
        -0.1853, -0.5664, -0.5806, -0.2756, -0.7456, -0.3813,  0.0994, -1.0322,
        -0.7578, -0.0852,  1.0586,  1.0762,  0.2196,  0.9268,  0.6665,  0.0172,
         0.3467,  0.5825, -0.9263, -0.0575,  0.8159, -0.7666,  0.2311, -0.8301,
        -0.5024,  0.4436, -0.9805,  0.9810, -0.7261,  0.1376,  0.8242, -0.9194,
         0.8901,  0.9048, -0.5728, -0.8408, -0.9482,  1.0547,  0.7886,  0.4272,
         0.3994, -0.9473, -1.0098,  0.6855], dtype=torch.float16)
DESIRED: (shape=torch.Size([4294967297]), dtype=torch.float16)
First 100 elements: tensor([ 2.4199e-05, -1.1504e-05,  1.3709e-06,  2.0087e-05,  1.2159e-05,
        -2.3842e-05, -1.8358e-05,  1.9968e-05,  2.1040e-05, -1.3590e-05,
        -2.4915e-05, -8.8811e-06, -5.8413e-06, -7.6294e-06, -7.2718e-06,
         1.8239e-05, -1.1325e-06, -1.8060e-05,  2.0087e-05, -1.4961e-05,
        -1.5914e-05, -9.1195e-06, -1.3709e-06, -1.4663e-05,  3.1590e-06,
         6.6757e-06,  2.5630e-06,  3.8147e-06, -7.6294e-06,  8.6427e-06,
         4.5300e-06, -2.9802e-06,  2.3007e-05, -8.2850e-06,  1.0788e-05,
        -2.2471e-05,  8.5831e-06,  1.7881e-07, -1.2040e-05,  6.9737e-06,
         1.7941e-05,  2.1338e-05, -2.2292e-05,  2.0087e-05, -5.1260e-06,
        -2.4796e-05, -1.0729e-05,  2.4259e-05,  2.2233e-05, -1.5259e-05,
        -1.9789e-05,  1.8120e-05, -1.2279e-05, -2.4676e-05,  1.0073e-05,
        -1.8597e-05, -4.4703e-06, -1.3709e-05, -1.4067e-05, -6.6757e-06,
        -1.8060e-05, -9.2387e-06,  2.3842e-06, -2.4974e-05, -1.8358e-05,
        -2.0862e-06,  2.5570e-05,  2.6047e-05,  5.3048e-06,  2.2411e-05,
         1.6153e-05,  4.1723e-07,  8.4043e-06,  1.4126e-05, -2.2411e-05,
        -1.3709e-06,  1.9729e-05, -1.8537e-05,  5.6028e-06, -2.0087e-05,
        -1.2159e-05,  1.0729e-05, -2.3723e-05,  2.3723e-05, -1.7583e-05,
         3.3379e-06,  1.9968e-05, -2.2233e-05,  2.1517e-05,  2.1875e-05,
        -1.3828e-05, -2.0325e-05, -2.2948e-05,  2.5511e-05,  1.9073e-05,
         1.0312e-05,  9.6560e-06, -2.2888e-05, -2.4438e-05,  1.6570e-05],
       dtype=torch.float16)
[Worker 2] Completed Task 3172

[Worker 2] Processing Task 3180: paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 0, 1e-06, True, None, )
One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.
[accuracy error] paddle.nn.functional.pairwise_distance(Tensor([2281701379],"float32"), Tensor([2281701379],"float32"), 0, 1e-06, True, None, ) 
 Not equal to tolerance rtol=0.01, atol=0.01
Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 2281701376.0 at index (0,) (up to 0.01 allowed)
Greatest relative difference: 1.0 at index (0,) (up to 0.01 allowed)
ACTUAL: (shape=torch.Size([1]), dtype=torch.float32)
All elements: tensor([0.])
DESIRED: (shape=torch.Size([1]), dtype=torch.float32)
All elements: tensor([2.2817e+09])
[Worker 2] Completed Task 3180

[Worker 2] Processing Task 3193: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 1, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 1, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3193

[Worker 2] Processing Task 3195: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 1, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 1, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3195

[Worker 2] Processing Task 3197: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 2, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), 2, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3197

[Worker 2] Processing Task 3199: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), math.inf, 1e-06, False, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), math.inf, 1e-06, False, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3199

[Worker 2] Processing Task 3201: paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), math.inf, 1e-06, True, None, )
[torch error] paddle.nn.functional.pairwise_distance(Tensor([4294967297],"float16"), Tensor([4294967297],"float16"), math.inf, 1e-06, True, None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3201

[Worker 2] Processing Task 3203: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=False, reduction="mean", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3203

[Worker 2] Processing Task 3205: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([5, 858993460],"float16"), positive=Tensor([5, 858993460],"float16"), negative=Tensor([5, 858993460],"float16"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3205

[Worker 2] Processing Task 3207: paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([858993460, 5],"float16"), positive=Tensor([858993460, 5],"float16"), negative=Tensor([858993460, 5],"float16"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(input=Tensor([858993460, 5],"float16"), positive=Tensor([858993460, 5],"float16"), negative=Tensor([858993460, 5],"float16"), distance_function=None, margin=0.3, swap=False, reduction="sum", )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3207

[Worker 2] Processing Task 3209: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=False, reduction="none", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=False, reduction="none", name=None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3209

[Worker 2] Processing Task 3211: paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=True, reduction="mean", name=None, )
[torch error] paddle.nn.functional.triplet_margin_with_distance_loss(Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), Tensor([5, 858993460],"float16"), margin=0.3, swap=True, reduction="mean", name=None, )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5400, in triplet_margin_with_distance_loss
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 5435, in triplet_margin_with_distance_loss
    dist_pos = distance_function(anchor, positive)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.56 GiB is free. Process 59458 has 76.62 GiB memory in use. Of the allocated memory 41.00 GiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[Worker 2] Completed Task 3211

[Worker 2] Processing Task 3213: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([10, 15],"float32"),Tensor([15],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([10, 15],"float32"),Tensor([15],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [150, 15], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:165 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 2] Completed Task 3213

[Worker 2] Processing Task 3215: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([16, 8],"float32"),Tensor([16, 16],"float32"),Tensor([16],"float32"),Tensor([16],"float32"),Tensor([16, 16],"float32"),Tensor([16, 16],"float32"),Tensor([16],"float32"),Tensor([16],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([16, 8],"float32"),Tensor([16, 16],"float32"),Tensor([16],"float32"),Tensor([16],"float32"),Tensor([16, 16],"float32"),Tensor([16, 16],"float32"),Tensor([16],"float32"),Tensor([16],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [128, 256, 16, 16, 256, 256, 16, 16], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:960 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 2] Completed Task 3215

[Worker 2] Processing Task 3217: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([3, 2, 4, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([3, 2, 4, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 3], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:387 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 2] Completed Task 3217

[Worker 2] Processing Task 3218: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([3, 2, 4, 4],"float32"),Tensor([3],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([3, 2, 4, 4],"float32"),Tensor([3],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [96, 3], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:99 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 2] Completed Task 3218

[Worker 2] Processing Task 3220: paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], )
[paddle error] paddle.nn.utils.vector_to_parameters(Tensor([2281701379],"float32"), list[Tensor([48, 8],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),Tensor([48, 16],"float32"),Tensor([48, 16],"float32"),Tensor([48],"float32"),Tensor([48],"float32"),], ) 
 (InvalidArgument) Sum of Attr(num_or_sections) must be equal to the input's size along the split dimension. But received Attr(num_or_sections) = [384, 768, 48, 48, 768, 768, 48, 48], input(X)'s shape = [2281701379], Attr(dim) = 0.
  [Hint: Expected sum_of_section == input_axis_dim, but received sum_of_section:2880 != input_axis_dim:2281701379.] (at /paddle/paddle/phi/infermeta/unary.cc:4453)

[Worker 2] Completed Task 3220

[Worker 2] Processing Task 3222: paddle.outer(Tensor([2281701379],"float32"), Tensor([1],"float32"), )
[paddle error] paddle.outer(Tensor([2281701379],"float32"), Tensor([1],"float32"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at /paddle/paddle/phi/core/dense_tensor.cc:113)

[Worker 2] Completed Task 3222

[Worker 2] Processing Task 3242: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=2, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=2, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 49.610352GB memory has been allocated and available memory is only 29.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 3242

[Worker 2] Processing Task 3247: paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[2,], keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 107374183, 4, 5],"bool"), axis=list[2,], keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 49.610352GB memory has been allocated and available memory is only 29.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 3247

[Worker 2] Processing Task 3288: paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[2,], keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([2, 3, 4, 178956971],"bool"), axis=list[2,], keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 49.610352GB memory has been allocated and available memory is only 29.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 3288

[Worker 2] Processing Task 3310: paddle.sum(Tensor([3, 4, 357913942],"int32"), axis=1, keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([3, 4, 357913942],"int32"), axis=1, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<int, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<int, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 73.610352GB memory has been allocated and available memory is only 5.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 3310

[Worker 2] Processing Task 3324: paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=-1, keepdim=False, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=-1, keepdim=False, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 48.008789GB memory has been allocated and available memory is only 31.176086GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 3324

[Worker 2] Processing Task 3330: paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=list[2,], keepdim=True, )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.sum(Tensor([71582789, 3, 4, 5],"bool"), axis=list[2,], keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_sum(_object*, _object*, _object*)
1   sum_ad_func(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor>, phi::DataType, bool)
2   paddle::experimental::sum(paddle::Tensor const&, paddle::experimental::IntArrayBase<paddle::Tensor> const&, phi::DataType, bool)
3   void phi::SumKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, phi::DataType, bool, phi::DenseTensor*)
4   void phi::SumRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, paddle::experimental::IntArrayBase<phi::DenseTensor> const&, bool, bool, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<bool, long>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
13  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 32.000000GB memory on GPU 0, 49.610352GB memory has been allocated and available memory is only 29.574524GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at /paddle/paddle/phi/core/memory/allocation/cuda_allocator.cc:71)

[Worker 2] Completed Task 3330

[Worker 2] Processing Task 3349: paddle.Tensor.chunk(Tensor([1, 1, 12096, 188633],"float32"), 2, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 1, 12096, 188633],"float32"), 2, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 1, 12096, 188633], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 2] Completed Task 3349

[Worker 2] Processing Task 3352: paddle.Tensor.chunk(Tensor([1, 101, 1, 22591103],"float32"), 4, axis=-1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 101, 1, 22591103],"float32"), 4, axis=-1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [1, 101, 1, 22591103], Attr(dim) = 3.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:3 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 2] Completed Task 3352

[Worker 2] Processing Task 3356: paddle.Tensor.chunk(Tensor([1, 2281701379],"float32"), 2, axis=1, )
[paddle error] paddle.Tensor.chunk(Tensor([1, 2281701379],"float32"), 2, axis=1, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 2, input(X)'s shape = [1, 2281701379], Attr(dim) = 1.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:1 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 2] Completed Task 3356

[Worker 2] Processing Task 3360: paddle.Tensor.chunk(Tensor([5704254, 100, 4],"float32"), 4, )
[paddle error] paddle.Tensor.chunk(Tensor([5704254, 100, 4],"float32"), 4, ) 
 (InvalidArgument) The input's size along the split dimension must be evenly divisible by Attr(num_or_sections). But received Attr(num_or_sections) = 4, input(X)'s shape = [5704254, 100, 4], Attr(dim) = 0.
  [Hint: Expected input_axis_dim % num == 0, but received input_axis_dim % num:2 != 0:0.] (at /paddle/paddle/phi/infermeta/unary.cc:4506)

[Worker 2] Completed Task 3360

[Worker 2] Processing Task 3363: paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([2281701379, 1],"int64"), )
element 0 of tensors does not require grad and does not have a grad_fn
[paddle error] paddle.Tensor.expand_as(Tensor([1, 1],"int32"), Tensor([2281701379, 1],"int64"), ) 
 (InvalidArgument) When the value in shape is negative for expand_as_v2 op, only -1 is supported, but the value received is -2013265917.
  [Hint: Expected target_shape[i] == -1, but received target_shape[i]:-2013265917 != -1:-1.] (at /paddle/paddle/phi/kernels/gpu/expand_as_kernel.cu:70)

[Worker 2] Completed Task 3363

[Worker 2] Processing Task 3440: paddle.Tensor.lu(Tensor([3, 760567127],"float32"), )
=========================================================================================
   WARNING batched routines are designed for small sizes. It might be better to use the
   Native/Hybrid classical routines if you want good performance.
=========================================================================================
CUDA runtime error: an illegal memory access was encountered (700) in magma_sgetrf_batched at /builder/magma/magma-cuda118/magma-2.6.1/src/sgetrf_batched.cpp:217
CUDA runtime error: an illegal memory access was encountered (700) in magma_sgetrf_batched at /builder/magma/magma-cuda118/magma-2.6.1/src/sgetrf_batched.cpp:218
CUDA runtime error: an illegal memory access was encountered (700) in magma_sgetrf_batched at /builder/magma/magma-cuda118/magma-2.6.1/src/sgetrf_batched.cpp:219
/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:902: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2053.)
  LU, pivots, infos = torch._lu_with_info(
[torch error] paddle.Tensor.lu(Tensor([3, 760567127],"float32"), )
Traceback (most recent call last):
  File "/luozeyu01_api_test/PaddleAPITest/tester/accuracy.py", line 84, in test
    exec(code.core_compiled, exec_globals, exec_locals)
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py", line 898, in lu
    return handle_torch_function(
  File "/usr/local/lib/python3.10/dist-packages/torch/overrides.py", line 1720, in handle_torch_function
    result = mode.__torch_function__(public_api, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py", line 104, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py", line 902, in lu
    LU, pivots, infos = torch._lu_with_info(
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Error on Task 3440: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] OOM on Task 3440: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[Worker 2] Started on GPU 2

