paddle.Tensor.coalesce(Tensor([2, 3],"float16"), )
paddle.Tensor.coalesce(Tensor([2, 3],"float32"), )
paddle.Tensor.coalesce(Tensor([2, 3],"int32"), )
paddle.Tensor.coalesce(Tensor([3, 3, 2],"int16"), )
paddle.Tensor.coalesce(Tensor([3, 3, 3],"complex64"), )
paddle.Tensor.is_coalesced(Tensor([2, 3],"float16"), )
paddle.Tensor.is_coalesced(Tensor([2, 3],"float32"), )
paddle.Tensor.is_coalesced(Tensor([2, 3],"int32"), )
paddle.Tensor.is_coalesced(Tensor([2, 3],"int64"), )
paddle.Tensor.is_coalesced(Tensor([2, 3],"uint8"), )
paddle.Tensor.is_coalesced(Tensor([3, 3, 2],"int16"), )
paddle.Tensor.is_coalesced(Tensor([3, 3, 3],"complex128"), )
paddle.Tensor.is_coalesced(Tensor([3, 3, 3],"complex64"), )
paddle.Tensor.is_coalesced(Tensor([3, 3],"float64"), )
paddle.nn.functional.sparse_attention(Tensor([2, 2, 64, 32],"float64"), Tensor([2, 2, 64, 32],"float64"), Tensor([2, 2, 64, 32],"float64"), Tensor([2, 2, 65],"int32"), Tensor([2, 2, 128],"int32"), )
paddle.nn.functional.sparse_attention(Tensor([2, 2, 8, 4],"float32"), Tensor([2, 2, 8, 4],"float32"), Tensor([2, 2, 8, 4],"float32"), Tensor([2, 2, 9],"int32"), Tensor([2, 2, 16],"int32"), )
paddle.nn.functional.sparse_attention(Tensor([3, 3, 35, 15],"float64"), Tensor([3, 3, 35, 15],"float64"), Tensor([3, 3, 35, 15],"float64"), Tensor([3, 3, 36],"int32"), Tensor([3, 3, 109],"int32"), )
paddle.nn.functional.sparse_attention(Tensor([4, 4, 128, 32],"float64"), Tensor([4, 4, 128, 32],"float64"), Tensor([4, 4, 128, 32],"float64"), Tensor([4, 4, 129],"int32"), Tensor([4, 4, 1024],"int32"), )
paddle.sparse.abs(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.abs(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.abs(Tensor([8, 16, 32],"float16"), )
paddle.sparse.abs(Tensor([8, 16, 32],"float32"), )
paddle.sparse.abs(Tensor([8, 16, 32],"float64"), )
paddle.sparse.add(Tensor([2, 4, 2],"complex64"), Tensor([2, 4, 2],"complex64"), )
paddle.sparse.add(Tensor([2, 4, 2],"complex64"), Tensor([2],"complex64"), )
paddle.sparse.add(Tensor([2, 4, 2],"float32"), Tensor([2, 4, 2],"float32"), )
paddle.sparse.add(Tensor([2, 4, 2],"float32"), Tensor([2],"float32"), )
paddle.sparse.add(Tensor([3, 7, 2, 9],"complex128"), Tensor([3, 7, 2, 9],"complex128"), )
paddle.sparse.add(Tensor([3, 7, 2, 9],"complex64"), Tensor([3, 7, 2, 9],"complex64"), )
paddle.sparse.add(Tensor([4, 8, 3, 5],"float32"), Tensor([4, 8, 3, 5],"float32"), )
paddle.sparse.add(Tensor([4, 8, 3, 5],"float64"), Tensor([4, 8, 3, 5],"float64"), )
paddle.sparse.add(Tensor([4, 8, 3, 5],"int32"), Tensor([4, 8, 3, 5],"int32"), )
paddle.sparse.add(Tensor([4, 8, 3, 5],"int64"), Tensor([4, 8, 3, 5],"int64"), )
paddle.sparse.add(Tensor([8, 10],"complex128"), Tensor([8, 10],"complex128"), )
paddle.sparse.add(Tensor([8, 10],"complex64"), Tensor([8, 10],"complex64"), )
paddle.sparse.add(Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), )
paddle.sparse.add(Tensor([8, 8],"float64"), Tensor([8, 8],"float64"), )
paddle.sparse.add(Tensor([8, 8],"int32"), Tensor([8, 8],"int32"), )
paddle.sparse.add(Tensor([8, 8],"int64"), Tensor([8, 8],"int64"), )
paddle.sparse.addmm(Tensor([16, 10],"float64"), Tensor([16, 12],"float64"), Tensor([12, 10],"float64"), 3.0, 2.0, )
paddle.sparse.addmm(Tensor([8, 16, 10],"float64"), Tensor([8, 16, 12],"float64"), Tensor([8, 12, 10],"float64"), 3.0, 2.0, )
paddle.sparse.asin(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.asin(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.asin(Tensor([8, 16, 32],"float16"), )
paddle.sparse.asin(Tensor([8, 16, 32],"float32"), )
paddle.sparse.asin(Tensor([8, 16, 32],"float64"), )
paddle.sparse.asinh(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.asinh(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.asinh(Tensor([8, 16, 32],"float16"), )
paddle.sparse.asinh(Tensor([8, 16, 32],"float32"), )
paddle.sparse.asinh(Tensor([8, 16, 32],"float64"), )
paddle.sparse.atan(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.atan(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.atan(Tensor([8, 16, 32],"float16"), )
paddle.sparse.atan(Tensor([8, 16, 32],"float32"), )
paddle.sparse.atan(Tensor([8, 16, 32],"float64"), )
paddle.sparse.atanh(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.atanh(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.atanh(Tensor([8, 16, 32],"float16"), )
paddle.sparse.atanh(Tensor([8, 16, 32],"float32"), )
paddle.sparse.atanh(Tensor([8, 16, 32],"float64"), )
paddle.sparse.cast(Tensor([8, 16, 32],"float32"), "int32", "float32", )
paddle.sparse.cast(Tensor([8, 16, 32],"float32"), "int32", "float64", )
paddle.sparse.coalesce(Tensor([1, 1, 1, 2, 1],"float32"), )
paddle.sparse.coalesce(Tensor([1, 1, 2, 1],"float32"), )
paddle.sparse.coalesce(Tensor([100, 40],"float64"), )
paddle.sparse.coalesce(Tensor([17, 17],"float64"), )
paddle.sparse.coalesce(Tensor([17, 4],"float64"), )
paddle.sparse.coalesce(Tensor([4, 17],"float64"), )
paddle.sparse.coalesce(Tensor([1358, 1358],"float32"), )
paddle.sparse.coalesce(Tensor([3029, 3029],"float32"), )
paddle.sparse.coalesce(Tensor([3029, 458],"float32"), )
paddle.sparse.coalesce(Tensor([3886, 1358],"float32"), )
paddle.sparse.coalesce(Tensor([3887, 1358],"float32"), )
paddle.sparse.coalesce(Tensor([3887, 3887],"float32"), )
paddle.sparse.coalesce(Tensor([458, 458],"float32"), )
paddle.sparse.coalesce(Tensor([6683, 3029],"float32"), )
paddle.sparse.coalesce(Tensor([6684, 3029],"float32"), )
paddle.sparse.coalesce(Tensor([6684, 6684],"float32"), )
paddle.sparse.deg2rad(Tensor([8, 16, 32],"float32"), )
paddle.sparse.divide(Tensor([3, 7, 2, 9],"complex128"), Tensor([3, 7, 2, 9],"complex128"), )
paddle.sparse.divide(Tensor([3, 7, 2, 9],"complex64"), Tensor([3, 7, 2, 9],"complex64"), )
paddle.sparse.divide(Tensor([4, 8, 3, 5],"float32"), Tensor([4, 8, 3, 5],"float32"), )
paddle.sparse.divide(Tensor([4, 8, 3, 5],"float64"), Tensor([4, 8, 3, 5],"float64"), )
paddle.sparse.divide(Tensor([4, 8, 3, 5],"int32"), Tensor([4, 8, 3, 5],"int32"), )
paddle.sparse.divide(Tensor([4, 8, 3, 5],"int64"), Tensor([4, 8, 3, 5],"int64"), )
paddle.sparse.divide(Tensor([8, 10],"complex128"), Tensor([8, 10],"complex128"), )
paddle.sparse.divide(Tensor([8, 10],"complex64"), Tensor([8, 10],"complex64"), )
paddle.sparse.divide(Tensor([8, 16, 32],"float32"), 2, )
paddle.sparse.divide(Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), )
paddle.sparse.divide(Tensor([8, 8],"float64"), Tensor([8, 8],"float64"), )
paddle.sparse.divide(Tensor([8, 8],"int32"), Tensor([8, 8],"int32"), )
paddle.sparse.divide(Tensor([8, 8],"int64"), Tensor([8, 8],"int64"), )
paddle.sparse.expm1(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.expm1(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.expm1(Tensor([8, 16, 32],"float16"), )
paddle.sparse.expm1(Tensor([8, 16, 32],"float32"), )
paddle.sparse.expm1(Tensor([8, 16, 32],"float64"), )
paddle.sparse.isnan(Tensor([20],"float32"), )
paddle.sparse.isnan(Tensor([4, 5],"float32"), )
paddle.sparse.isnan(Tensor([8, 16, 32],"float32"), )
paddle.sparse.isnan(Tensor([8, 16, 32],"float64"), )
paddle.sparse.log1p(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.log1p(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.log1p(Tensor([8, 16, 32],"float16"), )
paddle.sparse.log1p(Tensor([8, 16, 32],"float32"), )
paddle.sparse.log1p(Tensor([8, 16, 32],"float64"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"complex128"), Tensor([5, 3, 4, 2],"complex128"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"complex64"), Tensor([5, 3, 4, 2],"complex64"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"float16"), Tensor([5, 3, 4, 2],"float16"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"float32"), Tensor([5, 3, 4, 2],"float32"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"float64"), Tensor([5, 3, 4, 2],"float64"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"int16"), Tensor([5, 3, 4, 2],"int16"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"int32"), Tensor([5, 3, 4, 2],"int32"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"int64"), Tensor([5, 3, 4, 2],"int64"), )
paddle.sparse.mask_as(Tensor([5, 3, 4, 2],"int8"), Tensor([5, 3, 4, 2],"int8"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"complex128"), Tensor([5, 3, 4],"complex128"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"complex64"), Tensor([5, 3, 4],"complex64"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"float16"), Tensor([5, 3, 4],"float16"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"float32"), Tensor([5, 3, 4],"float32"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"float64"), Tensor([5, 3, 4],"float64"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"int16"), Tensor([5, 3, 4],"int16"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"int32"), Tensor([5, 3, 4],"int32"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"int64"), Tensor([5, 3, 4],"int64"), )
paddle.sparse.mask_as(Tensor([5, 3, 4],"int8"), Tensor([5, 3, 4],"int8"), )
paddle.sparse.mask_as(Tensor([5, 3],"complex128"), Tensor([5, 3],"complex128"), )
paddle.sparse.mask_as(Tensor([5, 3],"complex64"), Tensor([5, 3],"complex64"), )
paddle.sparse.mask_as(Tensor([5, 3],"float16"), Tensor([5, 3],"float16"), )
paddle.sparse.mask_as(Tensor([5, 3],"float32"), Tensor([5, 3],"float32"), )
paddle.sparse.mask_as(Tensor([5, 3],"float64"), Tensor([5, 3],"float64"), )
paddle.sparse.mask_as(Tensor([5, 3],"int16"), Tensor([5, 3],"int16"), )
paddle.sparse.mask_as(Tensor([5, 3],"int32"), Tensor([5, 3],"int32"), )
paddle.sparse.mask_as(Tensor([5, 3],"int64"), Tensor([5, 3],"int64"), )
paddle.sparse.mask_as(Tensor([5, 3],"int8"), Tensor([5, 3],"int8"), )
paddle.sparse.mask_as(Tensor([5],"complex128"), Tensor([5],"complex128"), )
paddle.sparse.mask_as(Tensor([5],"complex64"), Tensor([5],"complex64"), )
paddle.sparse.mask_as(Tensor([5],"float16"), Tensor([5],"float16"), )
paddle.sparse.mask_as(Tensor([5],"float32"), Tensor([5],"float32"), )
paddle.sparse.mask_as(Tensor([5],"float64"), Tensor([5],"float64"), )
paddle.sparse.mask_as(Tensor([5],"int16"), Tensor([5],"int16"), )
paddle.sparse.mask_as(Tensor([5],"int32"), Tensor([5],"int32"), )
paddle.sparse.mask_as(Tensor([5],"int64"), Tensor([5],"int64"), )
paddle.sparse.mask_as(Tensor([5],"int8"), Tensor([5],"int8"), )
paddle.sparse.masked_matmul(Tensor([10, 12],"float64"), Tensor([12, 6],"float64"), Tensor([10, 6],"float64"), )
paddle.sparse.matmul(Tensor([100, 40],"float64"), Tensor([40, 21],"float64"), )
paddle.sparse.matmul(Tensor([16, 12],"float32"), Tensor([12, 10],"float32"), )
paddle.sparse.matmul(Tensor([16, 16, 12],"float32"), Tensor([16, 12, 10],"float32"), )
paddle.sparse.matmul(Tensor([17, 17],"float64"), Tensor([17, 16],"float64"), )
paddle.sparse.matmul(Tensor([17, 4],"float64"), Tensor([4, 4],"float64"), )
paddle.sparse.matmul(Tensor([4, 17],"float64"), Tensor([17, 4],"float64"), )
paddle.sparse.matmul(Tensor([40, 100],"float64"), Tensor([100, 21],"float64"), )
paddle.sparse.matmul(Tensor([8, 16, 12],"float32"), Tensor([8, 12, 10],"float32"), )
paddle.sparse.matmul(Tensor([100, 69278],"float32"), Tensor([69278, 1],"float32"), )
paddle.sparse.multiply(Tensor([3, 7, 2, 9],"complex128"), Tensor([3, 7, 2, 9],"complex128"), )
paddle.sparse.multiply(Tensor([3, 7, 2, 9],"complex64"), Tensor([3, 7, 2, 9],"complex64"), )
paddle.sparse.multiply(Tensor([4, 8, 3, 5],"float32"), Tensor([4, 8, 3, 5],"float32"), )
paddle.sparse.multiply(Tensor([4, 8, 3, 5],"float64"), Tensor([4, 8, 3, 5],"float64"), )
paddle.sparse.multiply(Tensor([4, 8, 3, 5],"int32"), Tensor([4, 8, 3, 5],"int32"), )
paddle.sparse.multiply(Tensor([4, 8, 3, 5],"int64"), Tensor([4, 8, 3, 5],"int64"), )
paddle.sparse.multiply(Tensor([8, 10],"complex128"), Tensor([8, 10],"complex128"), )
paddle.sparse.multiply(Tensor([8, 10],"complex64"), Tensor([8, 10],"complex64"), )
paddle.sparse.multiply(Tensor([8, 16, 32],"float32"), 3, )
paddle.sparse.multiply(Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), )
paddle.sparse.multiply(Tensor([8, 8],"float64"), Tensor([8, 8],"float64"), )
paddle.sparse.multiply(Tensor([8, 8],"int32"), Tensor([8, 8],"int32"), )
paddle.sparse.multiply(Tensor([8, 8],"int64"), Tensor([8, 8],"int64"), )
paddle.sparse.mv(Tensor([64, 32],"float64"), Tensor([32],"float64"), )
paddle.sparse.neg(Tensor([8, 16, 32],"float32"), )
paddle.sparse.nn.functional.attention(Tensor([16, 16, 128, 16],"float64"), Tensor([16, 16, 128, 16],"float64"), Tensor([16, 16, 128, 16],"float64"), Tensor([256, 128, 128],"float32"), Tensor([16, 128],"float64"), Tensor([128, 128],"float64"), )
paddle.sparse.nn.functional.attention(Tensor([16, 16, 128, 32],"float64"), Tensor([16, 16, 128, 32],"float64"), Tensor([16, 16, 128, 32],"float64"), Tensor([256, 128, 128],"float32"), )
paddle.sparse.nn.functional.attention(Tensor([16, 16, 512, 16],"float64"), Tensor([16, 16, 512, 16],"float64"), Tensor([16, 16, 512, 16],"float64"), Tensor([256, 512, 512],"float32"), Tensor([16, 512],"float64"), Tensor([512, 512],"float64"), )
paddle.sparse.nn.functional.attention(Tensor([16, 16, 512, 32],"float64"), Tensor([16, 16, 512, 32],"float64"), Tensor([16, 16, 512, 32],"float64"), Tensor([256, 512, 512],"float32"), )
paddle.sparse.nn.functional.attention(Tensor([16, 16, 512, 64],"float64"), Tensor([16, 16, 512, 64],"float64"), Tensor([16, 16, 512, 64],"float64"), Tensor([256, 512, 512],"float32"), Tensor([16, 512],"float64"), Tensor([512, 512],"float64"), )
paddle.sparse.nn.functional.conv2d(Tensor([1, 3, 4, 1],"float32"), Tensor([3, 3, 1, 1],"float32"), bias=Tensor([1],"float32"), stride=list[1,1,], padding=list[0,0,], dilation=list[1,1,], groups=1, data_format="NHWC", )
paddle.sparse.nn.functional.conv3d(Tensor([1, 1, 3, 4, 1],"float32"), Tensor([1, 3, 3, 1, 1],"float32"), bias=Tensor([1],"float32"), stride=list[1,1,1,], padding=list[0,0,0,], dilation=list[1,1,1,], groups=1, data_format="NDHWC", )
paddle.sparse.nn.functional.leaky_relu(Tensor([8, 16, 32],"float32"), 0.1, None, )
paddle.sparse.nn.functional.max_pool3d(Tensor([1, 4, 4, 4, 4],"float32"), list[3,3,3,], stride=1, padding=list[0,0,0,], )
paddle.sparse.nn.functional.max_pool3d(Tensor([1, 4, 4, 4, 4],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.sparse.nn.functional.max_pool3d(Tensor([1, 5, 6, 8, 3],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=1, )
paddle.sparse.nn.functional.max_pool3d(Tensor([1, 6, 9, 6, 3],"float32"), list[5,5,5,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.sparse.nn.functional.max_pool3d(Tensor([2, 3, 6, 6, 3],"float32"), kernel_size=3, stride=None, padding=0, ceil_mode=False, data_format="NDHWC", name=None, )
paddle.sparse.nn.functional.max_pool3d(Tensor([2, 6, 7, 9, 3],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.sparse.nn.functional.relu(Tensor([3, 3],"float32"), )
paddle.sparse.nn.functional.relu(Tensor([8, 16, 32],"float32"), None, )
paddle.sparse.nn.functional.relu6(Tensor([8, 16, 32],"float32"), None, )
paddle.sparse.nn.functional.softmax(Tensor([16, 128],"float64"), -1, None, )
paddle.sparse.nn.functional.softmax(Tensor([16, 128],"float64"), 0, None, )
paddle.sparse.nn.functional.softmax(Tensor([16, 128],"float64"), 1, None, )
paddle.sparse.nn.functional.softmax(Tensor([16, 16, 128],"float64"), -1, None, )
paddle.sparse.nn.functional.softmax(Tensor([16, 16, 128],"float64"), 0, None, )
paddle.sparse.nn.functional.softmax(Tensor([16, 16, 128],"float64"), 1, None, )
paddle.sparse.nn.functional.softmax(Tensor([16, 16, 128],"float64"), 2, None, )
paddle.sparse.nn.functional.softmax(Tensor([2, 5],"float32"), -1, None, )
paddle.sparse.nn.functional.subm_conv2d(Tensor([1, 3, 4, 1],"float32"), Tensor([1, 3, 3, 1],"float32"), key="subm_conv", )
paddle.sparse.nn.functional.subm_conv2d_igemm(Tensor([1, 3, 4, 1],"float32"), Tensor([3, 3, 1, 1],"float32"), Tensor([1],"float32"), stride=1, padding=1, dilation=1, groups=1, data_format="NHWC", key="subm_conv_2d", )
paddle.sparse.nn.functional.subm_conv3d(Tensor([1, 1, 3, 4, 1],"float32"), Tensor([1, 3, 3, 1, 1],"float32"), key="subm_conv", )
paddle.sparse.nn.functional.subm_conv3d_igemm(Tensor([1, 1, 3, 4, 1],"float32"), Tensor([1, 3, 3, 1, 1],"float32"), Tensor([1],"float32"), stride=1, padding=1, dilation=1, groups=1, data_format="NDHWC", key="subm_conv_3d", )
paddle.sparse.pca_lowrank(Tensor([100, 40],"float64"), q=21, )
paddle.sparse.pca_lowrank(Tensor([17, 17],"float64"), q=16, )
paddle.sparse.pca_lowrank(Tensor([17, 4],"float64"), q=4, )
paddle.sparse.pca_lowrank(Tensor([4, 17],"float64"), q=4, )
paddle.sparse.pow(Tensor([8, 16, 32],"float32"), 3, )
paddle.sparse.rad2deg(Tensor([8, 16, 32],"float32"), )
paddle.sparse.reshape(Tensor([10, 5],"int64"), list[2,25,], )
paddle.sparse.reshape(Tensor([12, 5],"int64"), list[15,4,], )
paddle.sparse.reshape(Tensor([2, 5],"int64"), list[10,], )
paddle.sparse.reshape(Tensor([3, 4, 4, 5, 7],"int64"), list[1,12,2,5,14,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[-1,0,3,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[-1,1,3,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[-1,3,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[-1,6,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[-1,9,1,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[-1,9,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[0,0,-1,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[1,-1,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[1,0,2,-1,3,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[1,18,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[1,2,2,3,3,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[12,1,3,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[2,-1,0,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[2,-1,18,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[2,1,18,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[2,3,0,-1,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[2,3,3,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[2,6,3,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[2,9,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[3,6,2,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[4,9,1,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[6,2,3,], )
paddle.sparse.reshape(Tensor([6, 2, 3],"int64"), list[6,3,2,], )
paddle.sparse.reshape(Tensor([8, 3, 4, 4, 5, 3],"int64"), list[24,8,10,3,], )
paddle.sparse.reshape(Tensor([9, 8],"int64"), list[18,4,], )
paddle.sparse.sin(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.sin(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.sin(Tensor([8, 16, 32],"float16"), )
paddle.sparse.sin(Tensor([8, 16, 32],"float32"), )
paddle.sparse.sin(Tensor([8, 16, 32],"float64"), )
paddle.sparse.sinh(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.sinh(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.sinh(Tensor([8, 16, 32],"float16"), )
paddle.sparse.sinh(Tensor([8, 16, 32],"float32"), )
paddle.sparse.sinh(Tensor([8, 16, 32],"float64"), )
paddle.sparse.slice(Tensor([1, 2, 4],"int64"), list[1,2,], list[0,0,], list[2,2,], )
paddle.sparse.slice(Tensor([12],"int64"), list[0,], list[-3,], list[-1,], )
paddle.sparse.slice(Tensor([12],"int64"), list[0,], list[3,], list[5,], )
paddle.sparse.slice(Tensor([2, 3, 4, 5, 6],"int64"), list[0,1,2,4,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.sparse.slice(Tensor([2, 3, 4, 5],"int64"), list[0,1,2,3,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.sparse.slice(Tensor([2, 4],"int64"), list[0,1,], list[0,0,], list[2,2,], )
paddle.sparse.slice(Tensor([2, 4],"int64"), list[0,1,], list[0,1,], list[2,3,], )
paddle.sparse.slice(Tensor([3, 4],"int64"), list[-2,-1,], list[-3,0,], list[2,-1,], )
paddle.sparse.slice(Tensor([3, 4],"int64"), list[0,], list[0,], list[2,], )
paddle.sparse.slice(Tensor([3, 4],"int64"), list[1,], list[-3,], list[2,], )
paddle.sparse.slice(Tensor([4, 4, 5],"int64"), list[-1,], list[0,], list[2,], )
paddle.sparse.slice(Tensor([4, 4, 5],"int64"), list[-3,-2,-1,], list[1,-3,2,], list[3,3,4,], )
paddle.sparse.slice(Tensor([4, 4, 5],"int64"), list[0,1,2,], list[0,1,2,], list[3,3,4,], )
paddle.sparse.slice(Tensor([4, 4, 5],"int64"), list[0,2,], list[2,2,], list[3,4,], )
paddle.sparse.slice(Tensor([4, 4, 5],"int64"), list[0,], list[1,], list[2,], )
paddle.sparse.slice(Tensor([4, 4, 5],"int64"), list[1,2,], list[2,2,], list[3,4,], )
paddle.sparse.slice(Tensor([4, 4, 5],"int64"), list[1,], list[2,], list[3,], )
paddle.sparse.slice(Tensor([78, 78],"int64"), list[0,-1,], list[32,58,], list[-2,-1,], )
paddle.sparse.sqrt(Tensor([8, 16, 32],"float32"), )
paddle.sparse.square(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.square(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.square(Tensor([8, 16, 32],"float16"), )
paddle.sparse.square(Tensor([8, 16, 32],"float32"), )
paddle.sparse.square(Tensor([8, 16, 32],"float64"), )
paddle.sparse.subtract(Tensor([3, 7, 2, 9],"complex128"), Tensor([3, 7, 2, 9],"complex128"), )
paddle.sparse.subtract(Tensor([3, 7, 2, 9],"complex64"), Tensor([3, 7, 2, 9],"complex64"), )
paddle.sparse.subtract(Tensor([4, 8, 3, 5],"float32"), Tensor([4, 8, 3, 5],"float32"), )
paddle.sparse.subtract(Tensor([4, 8, 3, 5],"float64"), Tensor([4, 8, 3, 5],"float64"), )
paddle.sparse.subtract(Tensor([4, 8, 3, 5],"int32"), Tensor([4, 8, 3, 5],"int32"), )
paddle.sparse.subtract(Tensor([4, 8, 3, 5],"int64"), Tensor([4, 8, 3, 5],"int64"), )
paddle.sparse.subtract(Tensor([8, 10],"complex128"), Tensor([8, 10],"complex128"), )
paddle.sparse.subtract(Tensor([8, 10],"complex64"), Tensor([8, 10],"complex64"), )
paddle.sparse.subtract(Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), )
paddle.sparse.subtract(Tensor([8, 8],"float64"), Tensor([8, 8],"float64"), )
paddle.sparse.subtract(Tensor([8, 8],"int32"), Tensor([8, 8],"int32"), )
paddle.sparse.subtract(Tensor([8, 8],"int64"), Tensor([8, 8],"int64"), )
paddle.sparse.sum(Tensor([100, 40],"float64"), axis=-2, )
paddle.sparse.sum(Tensor([17, 17],"float64"), axis=-2, )
paddle.sparse.sum(Tensor([17, 4],"float64"), axis=-2, )
paddle.sparse.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 4],"float64"), 0, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 4],"float64"), 1, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 4],"float64"), 2, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 4],"float64"), 3, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 4],"float64"), 4, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 4],"float64"), 5, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 5],"float64"), -1, keepdim=True, dtype="float32", )
paddle.sparse.sum(Tensor([2, 5],"float64"), -1, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([2, 5],"float64"), 0, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 5],"float64"), 0, keepdim=True, dtype="float32", )
paddle.sparse.sum(Tensor([2, 5],"float64"), 1, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([2, 5],"float64"), None, keepdim=False, dtype="float32", )
paddle.sparse.sum(Tensor([2, 5],"float64"), None, keepdim=True, dtype="float32", )
paddle.sparse.sum(Tensor([2, 5],"float64"), None, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([4, 17],"float64"), axis=-2, )
paddle.sparse.sum(Tensor([5],"float64"), 0, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([5],"float64"), 0, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([5],"float64"), None, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([5],"float64"), None, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), -1, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), -2, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), -2, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), 0, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), 0, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), 1, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), 1, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), None, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([6, 2, 3],"float64"), None, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 0, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 0, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 1, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 1, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 2, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 2, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 3, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 3, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 4, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 4, keepdim=True, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 5, keepdim=False, dtype=None, )
paddle.sparse.sum(Tensor([8, 3, 4, 4, 5, 3],"float64"), 5, keepdim=True, dtype=None, )
paddle.sparse.tan(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.tan(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.tan(Tensor([8, 16, 32],"float16"), )
paddle.sparse.tan(Tensor([8, 16, 32],"float32"), )
paddle.sparse.tan(Tensor([8, 16, 32],"float64"), )
paddle.sparse.tanh(Tensor([8, 16, 32],"complex128"), )
paddle.sparse.tanh(Tensor([8, 16, 32],"complex64"), )
paddle.sparse.tanh(Tensor([8, 16, 32],"float16"), )
paddle.sparse.tanh(Tensor([8, 16, 32],"float32"), )
paddle.sparse.tanh(Tensor([8, 16, 32],"float64"), )
paddle.sparse.transpose(Tensor([100, 40],"float64"), list[1,0,], )
paddle.sparse.transpose(Tensor([17, 17],"float64"), list[1,0,], )
paddle.sparse.transpose(Tensor([17, 4],"float64"), list[1,0,], )
paddle.sparse.transpose(Tensor([2, 3, 4, 2, 3, 4, 2, 3, 4],"float32"), list[2,3,4,5,6,7,8,0,1,], )
paddle.sparse.transpose(Tensor([2, 5],"float32"), list[0,1,], )
paddle.sparse.transpose(Tensor([2, 5],"float32"), list[1,0,], )
paddle.sparse.transpose(Tensor([4, 17],"float64"), list[1,0,], )
paddle.sparse.transpose(Tensor([40, 100],"float64"), list[1,0,], )
paddle.sparse.transpose(Tensor([6, 2, 3],"float32"), list[0,1,2,], )
paddle.sparse.transpose(Tensor([6, 2, 3],"float32"), list[0,2,1,], )
paddle.sparse.transpose(Tensor([6, 2, 3],"float32"), list[1,0,2,], )
paddle.sparse.transpose(Tensor([6, 2, 3],"float32"), list[1,2,0,], )
paddle.sparse.transpose(Tensor([6, 2, 3],"float32"), list[2,0,1,], )
paddle.sparse.transpose(Tensor([6, 2, 3],"float32"), list[2,1,0,], )
paddle.sparse.transpose(Tensor([3029, 458],"float32"), list[1,0,], )
paddle.sparse.transpose(Tensor([3886, 1358],"float32"), list[1,0,], )
paddle.sparse.transpose(Tensor([6683, 3029],"float32"), list[1,0,], )
paddle.sparse.transpose(Tensor([8, 3, 4, 4, 5, 3],"float32"), list[5,3,4,1,0,2,], )
paddle.nn.functional.sparse_attention(Tensor([1, 1, 8, 4],"float64"), Tensor([1, 1, 8, 4],"float64"), Tensor([1, 1, 8, 4],"float64"), Tensor([1, 1, 9],"int32"), Tensor([1, 1, 16],"int32"), key_padding_mask=Tensor([1, 8],"float64"), attn_mask=Tensor([8, 8],"float64"), )
paddle.nn.functional.sparse_attention(Tensor([2, 1, 64, 32],"float64"), Tensor([2, 1, 64, 32],"float64"), Tensor([2, 1, 64, 32],"float64"), Tensor([2, 1, 65],"int32"), Tensor([2, 1, 128],"int32"), )
