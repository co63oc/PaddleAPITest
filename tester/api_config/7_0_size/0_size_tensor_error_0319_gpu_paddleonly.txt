paddle.allclose(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), rtol=1e-05, atol=1e-08, )
paddle.allclose(Tensor([0, 13, 128],"float32"), Tensor([0, 13, 128],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([0, 13, 32],"float32"), Tensor([0, 13, 32],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([0, 13],"float32"), Tensor([0, 13],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([0, 16],"float32"), Tensor([0, 16],"float32"), )
paddle.allclose(Tensor([0, 16],"float32"), Tensor([0, 16],"float32"), atol=1e-05, rtol=1e-05, )
paddle.allclose(Tensor([0, 2],"float32"), Tensor([0, 2],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([0, 20, 200],"float32"), Tensor([0, 20, 200],"float32"), )
paddle.allclose(Tensor([0, 20, 32],"float32"), Tensor([0, 20, 32],"float32"), )
paddle.allclose(Tensor([0, 3, 8, 8],"float32"), Tensor([0, 3, 8, 8],"float32"), )
paddle.allclose(Tensor([0, 3],"float32"), Tensor([0, 3],"float32"), atol=0.0001, )
paddle.allclose(Tensor([0, 3],"float32"), Tensor([0, 3],"float32"), atol=0.001, )
paddle.allclose(Tensor([0, 3],"float32"), Tensor([0, 3],"float32"), atol=0.01, )
paddle.allclose(Tensor([0, 32],"float32"), Tensor([0, 32],"float32"), )
paddle.allclose(Tensor([0, 5, 32],"float32"), Tensor([0, 5, 32],"float32"), atol=1e-05, )
paddle.allclose(Tensor([0, 5],"float32"), Tensor([0, 5],"float32"), atol=1e-06, )
paddle.allclose(Tensor([0, 64, 16],"float32"), Tensor([0, 64, 16],"float32"), atol=1e-05, )
paddle.allclose(Tensor([0, 8, 32],"float32"), Tensor([0, 8, 32],"float32"), atol=0.0001, )
paddle.allclose(Tensor([0, 8],"float32"), Tensor([0, 8],"float32"), atol=1e-06, )
paddle.allclose(Tensor([0, 8],"float32"), Tensor([0, 8],"float32"), atol=1e-06, rtol=1e-06, )
paddle.allclose(Tensor([0],"bool"), Tensor([0],"bool"), 0.0, 0.0, False, )
paddle.allclose(Tensor([0],"float16"), Tensor([0],"float16"), atol=0.001, )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), atol=0.0001, )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), atol=0.001, )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), atol=0.5, )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), atol=1e-05, rtol=1e-05, )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), atol=1e-06, )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), atol=1e-06, rtol=1e-06, )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), rtol=0.01, atol=0.0, name="test_7", )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), rtol=1e-05, atol=1e-08, equal_nan=False, name="test_1", )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), rtol=1e-05, atol=1e-08, equal_nan=False, name="test_3", )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), rtol=1e-05, atol=1e-08, equal_nan=False, name="test_5", )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), rtol=1e-05, atol=1e-08, equal_nan=True, name="test_2", )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), rtol=1e-05, atol=1e-08, equal_nan=True, name="test_4", )
paddle.allclose(Tensor([0],"float32"), Tensor([0],"float32"), rtol=1e-05, atol=1e-08, equal_nan=True, name="test_6", )
paddle.allclose(Tensor([0],"float64"), Tensor([0],"float64"), atol=0.0001, rtol=0.0001, )
paddle.allclose(Tensor([0],"float64"), Tensor([0],"float64"), rtol=0.015, atol=0.0, name="test_8", )
paddle.allclose(Tensor([0],"int32"), Tensor([0],"int32"), 50.0, 48.0, False, )
paddle.allclose(Tensor([0],"int32"), Tensor([0],"int32"), 50.0, 49.0, False, )
paddle.allclose(Tensor([0],"int64"), Tensor([0],"int64"), 50.0, 48.0, False, )
paddle.allclose(Tensor([0],"int64"), Tensor([0],"int64"), 50.0, 49.0, False, )
paddle.allclose(Tensor([1, 0, 200],"float32"), Tensor([1, 0, 200],"float32"), )
paddle.allclose(Tensor([1, 0, 32],"float32"), Tensor([1, 0, 32],"float32"), )
paddle.allclose(Tensor([1, 0, 32],"float32"), Tensor([1, 0, 32],"float32"), atol=1e-05, )
paddle.allclose(Tensor([1, 0],"float32"), Tensor([1, 0],"float32"), atol=1e-06, rtol=1e-06, )
paddle.allclose(Tensor([1, 20, 0],"float32"), Tensor([1, 20, 0],"float32"), )
paddle.allclose(Tensor([1, 5, 0],"float32"), Tensor([1, 5, 0],"float32"), atol=1e-05, )
paddle.allclose(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), rtol=1e-05, atol=1e-08, )
paddle.allclose(Tensor([1124, 0],"float32"), Tensor([1124, 0],"float32"), )
paddle.allclose(Tensor([13, 0, 128],"float32"), Tensor([13, 0, 128],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([13, 0, 32],"float32"), Tensor([13, 0, 32],"float32"), atol=0.0001, )
paddle.allclose(Tensor([13, 0, 32],"float32"), Tensor([13, 0, 32],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([13, 0],"float32"), Tensor([13, 0],"float32"), atol=0.001, )
paddle.allclose(Tensor([13, 0],"float32"), Tensor([13, 0],"float32"), atol=0.01, )
paddle.allclose(Tensor([13, 0],"float32"), Tensor([13, 0],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([13, 13, 0],"float32"), Tensor([13, 13, 0],"float32"), rtol=0.0001, atol=0.0001, )
paddle.allclose(Tensor([13, 8, 0],"float32"), Tensor([13, 8, 0],"float32"), atol=0.0001, )
paddle.allclose(Tensor([14, 0, 16],"float32"), Tensor([14, 0, 16],"float32"), atol=1e-05, )
paddle.allclose(Tensor([14, 0],"float32"), Tensor([14, 0],"float32"), atol=0.001, )
paddle.allclose(Tensor([14, 64, 0],"float32"), Tensor([14, 64, 0],"float32"), atol=1e-05, )
paddle.allclose(Tensor([16, 0],"float32"), Tensor([16, 0],"float32"), )
paddle.allclose(Tensor([2, 0, 8, 8],"float32"), Tensor([2, 0, 8, 8],"float32"), )
paddle.allclose(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), atol=0.0001, )
paddle.allclose(Tensor([2, 0],"float32"), Tensor([2, 0],"float32"), atol=1e-06, )
paddle.allclose(Tensor([2, 3, 0, 8],"float32"), Tensor([2, 3, 0, 8],"float32"), )
paddle.allclose(Tensor([2, 3, 8, 0],"float32"), Tensor([2, 3, 8, 0],"float32"), )
paddle.allclose(Tensor([4, 0],"float32"), Tensor([4, 0],"float32"), atol=1e-06, )
paddle.allclose(Tensor([64, 0],"float32"), Tensor([64, 0],"float32"), atol=1e-05, rtol=1e-05, )
paddle.allclose(tuple(Tensor([0, 20, 100],"float32"),), tuple(Tensor([0, 20, 100],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([0, 20, 32],"float32"),), tuple(Tensor([0, 20, 32],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([0, 3],"float32"),), tuple(Tensor([0, 3],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([0, 7, 16],"float32"),Tensor([0, 7, 16],"float32"),), tuple(Tensor([0, 7, 16],"float32"),Tensor([0, 7, 16],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([0, 7],"float32"),Tensor([0, 7],"float32"),), tuple(Tensor([0, 7],"float32"),Tensor([0, 7],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([13, 0, 16],"float32"),Tensor([13, 0, 16],"float32"),), tuple(Tensor([13, 0, 16],"float32"),Tensor([13, 0, 16],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([13, 0],"float32"),Tensor([13, 0],"float32"),), tuple(Tensor([13, 0],"float32"),Tensor([13, 0],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([13, 7, 0],"float32"),Tensor([13, 7, 0],"float32"),), tuple(Tensor([13, 7, 0],"float32"),Tensor([13, 7, 0],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([2, 0, 100],"float32"),), tuple(Tensor([2, 0, 100],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([2, 0, 32],"float32"),), tuple(Tensor([2, 0, 32],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([2, 0],"float32"),), tuple(Tensor([2, 0],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(tuple(Tensor([2, 20, 0],"float32"),), tuple(Tensor([2, 20, 0],"float32"),), rtol=0.0001, atol=0.0001, )
paddle.allclose(x=Tensor([0, 2, 2, 3],"float64"), y=Tensor([0, 2, 2, 3],"float64"), )
paddle.allclose(x=Tensor([0, 2, 2, 3],"float64"), y=Tensor([0, 2, 2, 3],"float64"), rtol=-3.0, atol=-2.0, )
paddle.allclose(x=Tensor([0],"float32"), y=Tensor([0],"float32"), rtol=0.01, atol=0.01, equal_nan=False, )
paddle.allclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), rtol=0.01, atol=0.0, equal_nan=False, )
paddle.allclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), rtol=0.01, atol=0.01, equal_nan=False, )
paddle.allclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), rtol=1e-05, atol=0.001, equal_nan=False, )
paddle.allclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), rtol=1e-05, atol=0.001, equal_nan=True, )
paddle.allclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), rtol=1e-06, atol=0.001, equal_nan=False, )
paddle.allclose(x=Tensor([0],"float64"), y=Tensor([0],"float64"), rtol=1e-06, atol=0.001, equal_nan=True, )
paddle.allclose(x=Tensor([2, 0, 2, 3],"float64"), y=Tensor([2, 0, 2, 3],"float64"), )
paddle.allclose(x=Tensor([2, 0, 2, 3],"float64"), y=Tensor([2, 0, 2, 3],"float64"), rtol=-3.0, atol=-2.0, )
paddle.allclose(x=Tensor([2, 2, 0, 3],"float64"), y=Tensor([2, 2, 0, 3],"float64"), )
paddle.allclose(x=Tensor([2, 2, 0, 3],"float64"), y=Tensor([2, 2, 0, 3],"float64"), rtol=-3.0, atol=-2.0, )
paddle.allclose(x=Tensor([2, 2, 2, 0],"float64"), y=Tensor([2, 2, 2, 0],"float64"), )
paddle.allclose(x=Tensor([2, 2, 2, 0],"float64"), y=Tensor([2, 2, 2, 0],"float64"), rtol=-3.0, atol=-2.0, )
paddle.bitwise_invert(Tensor([0, 3, 4, 5],"int32"), )
paddle.bitwise_invert(Tensor([0, 4, 1],"int32"), )
paddle.bitwise_invert(Tensor([2, 0, 4, 5],"int32"), )
paddle.bitwise_invert(Tensor([2, 3, 0, 5],"int32"), )
paddle.bitwise_invert(Tensor([2, 3, 4, 0],"int32"), )
paddle.bitwise_invert(Tensor([3, 0, 1],"int32"), )
paddle.bitwise_invert(Tensor([3, 4, 0],"int32"), )
paddle.bitwise_not(Tensor([0, 4, 1],"int64"), out=Tensor([0, 4, 1],"int64"), )
paddle.bitwise_not(Tensor([0, 4, 1],"int64"), out=Tensor([3, 4, 1],"int64"), )
paddle.bitwise_not(Tensor([3, 0, 1],"int64"), out=Tensor([3, 0, 1],"int64"), )
paddle.bitwise_not(Tensor([3, 0, 1],"int64"), out=Tensor([3, 4, 1],"int64"), )
paddle.bitwise_not(Tensor([3, 4, 0],"int64"), out=Tensor([3, 4, 0],"int64"), )
paddle.bitwise_not(Tensor([3, 4, 0],"int64"), out=Tensor([3, 4, 1],"int64"), )
paddle.cartesian_prod(list[Tensor([0],"complex128"),Tensor([0],"complex128"),Tensor([0],"complex128"),], )
paddle.cartesian_prod(list[Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),], )
paddle.cartesian_prod(list[Tensor([1],"float32"),Tensor([0],"float32"),Tensor([1],"float32"),], )
paddle.cartesian_prod(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.cartesian_prod(list[Tensor([2],"complex128"),Tensor([0],"complex128"),Tensor([3],"complex128"),], )
paddle.cartesian_prod(list[Tensor([2],"complex128"),Tensor([1],"complex128"),Tensor([0],"complex128"),], )
paddle.clip(x=Tensor([0],"float64"), )
paddle.cummax(Tensor([0, 100],"float32"), )
paddle.cummax(Tensor([0, 100],"float32"), axis=-1, )
paddle.cummax(Tensor([100, 0],"float32"), )
paddle.cummax(Tensor([100, 0],"float32"), axis=0, )
paddle.cummax(Tensor([100, 0],"float32"), axis=-1, )
paddle.cummax(Tensor([100, 0],"float32"), axis=-2, )
paddle.cummax(Tensor([100, 0],"float32"), axis=-2, dtype="int32", )
paddle.cummax(Tensor([100, 0],"int32"), axis=0, )
paddle.cummin(Tensor([0, 100],"float32"), )
paddle.cummin(Tensor([0, 100],"float32"), axis=-1, )
paddle.cummin(Tensor([100, 0],"float32"), )
paddle.cummin(Tensor([100, 0],"float32"), axis=0, )
paddle.cummin(Tensor([100, 0],"float32"), axis=-1, )
paddle.cummin(Tensor([100, 0],"float32"), axis=-2, )
paddle.cummin(Tensor([100, 0],"float32"), axis=-2, dtype="int32", )
paddle.cummin(Tensor([100, 0],"int32"), axis=0, )
paddle.cumsum(Tensor([0, 12],"float16"), dtype="float16", )
paddle.cumsum(Tensor([10, 0],"float16"), dtype="float16", )
paddle.cumsum(x=Tensor([1, 0, 1, 3],"float64"), axis=Tensor([1],"float64"), )
paddle.cumsum(x=Tensor([1, 2, 0, 3],"float64"), axis=Tensor([1],"float64"), )
paddle.cumsum(x=Tensor([1, 2, 1, 0],"float64"), axis=Tensor([1],"float64"), )
paddle.dsplit(Tensor([0, 2, 6],"bool"), 3, )
paddle.dsplit(Tensor([0, 2, 6],"float16"), 3, )
paddle.dsplit(Tensor([0, 3, 6],"int64"), 2, )
paddle.dsplit(Tensor([4, 0, 6],"bool"), 3, )
paddle.dsplit(Tensor([4, 0, 6],"float16"), 3, )
paddle.dsplit(Tensor([4, 0, 6],"int64"), 2, )
paddle.dsplit(Tensor([4, 2, 0],"bool"), 3, )
paddle.dsplit(Tensor([4, 2, 0],"float16"), 3, )
paddle.dsplit(Tensor([4, 3, 0],"int64"), 2, )
paddle.einsum("..., ...", Tensor([0, 10],"float64"), Tensor([2, 3, 10],"float64"), )
paddle.einsum("..., ...", Tensor([0, 11],"float64"), Tensor([2, 3, 11],"float64"), )
paddle.einsum("..., ...", Tensor([3, 0],"float64"), Tensor([2, 3, 10],"float64"), )
paddle.einsum("..., ...", Tensor([3, 0],"float64"), Tensor([2, 3, 11],"float64"), )
paddle.einsum("..., f -> ... f", Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.einsum("..., f -> ... f", Tensor([0],"float32"), Tensor([16],"float32"), )
paddle.einsum("..., f -> ... f", Tensor([16],"float32"), Tensor([0],"float32"), )
paddle.einsum("..., f -> ... f", Tensor([24],"float32"), Tensor([0],"float32"), )
paddle.einsum("...,...", Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.einsum("...,...", Tensor([0],"float64"), Tensor([10],"float64"), )
paddle.einsum("...,...", Tensor([0],"float64"), Tensor([11],"float64"), )
paddle.einsum("...,...->...", Tensor([0, 5, 5],"float64"), Tensor([0, 5, 5],"float64"), )
paddle.einsum("...,...->...", Tensor([0, 5, 5],"float64"), Tensor([5, 5, 5],"float64"), )
paddle.einsum("...,...->...", Tensor([5, 0, 5],"float64"), Tensor([5, 0, 5],"float64"), )
paddle.einsum("...,...->...", Tensor([5, 0, 5],"float64"), Tensor([5, 5, 5],"float64"), )
paddle.einsum("...,...->...", Tensor([5, 5, 0],"float64"), Tensor([5, 5, 0],"float64"), )
paddle.einsum("...,...->...", Tensor([5, 5, 0],"float64"), Tensor([5, 5, 5],"float64"), )
paddle.einsum("...->...", Tensor([0, 5, 5],"float64"), )
paddle.einsum("...->...", Tensor([5, 0, 5],"float64"), )
paddle.einsum("...->...", Tensor([5, 5, 0],"float64"), )
paddle.einsum("...a,a...->...", Tensor([0, 2, 2, 10],"float64"), Tensor([10, 3, 2, 2],"float64"), )
paddle.einsum("...a,a...->...", Tensor([3, 0, 2, 10],"float64"), Tensor([10, 3, 2, 2],"float64"), )
paddle.einsum("...a,a...->...", Tensor([3, 2, 0, 10],"float64"), Tensor([10, 3, 2, 2],"float64"), )
paddle.einsum("...a,a...->...", Tensor([3, 2, 2, 0],"float64"), Tensor([10, 3, 2, 2],"float64"), )
paddle.einsum("...i, ...i", Tensor([0, 3, 10],"float64"), Tensor([10],"float64"), )
paddle.einsum("...i, ...i", Tensor([0, 3, 11],"float64"), Tensor([11],"float64"), )
paddle.einsum("...i, ...i", Tensor([2, 0, 10],"float64"), Tensor([10],"float64"), )
paddle.einsum("...i, ...i", Tensor([2, 0, 11],"float64"), Tensor([11],"float64"), )
paddle.einsum("...i, ...i", Tensor([2, 3, 0],"float64"), Tensor([10],"float64"), )
paddle.einsum("...i, ...i", Tensor([2, 3, 0],"float64"), Tensor([11],"float64"), )
paddle.einsum("...i->...", Tensor([0, 3, 10],"float64"), )
paddle.einsum("...i->...", Tensor([0, 3, 11],"float64"), )
paddle.einsum("...i->...", Tensor([2, 0, 10],"float64"), )
paddle.einsum("...i->...", Tensor([2, 0, 11],"float64"), )
paddle.einsum("...i->...", Tensor([2, 3, 0],"float64"), )
paddle.einsum("...ii,...i->...i", Tensor([0, 13, 13, 12, 12],"float64"), Tensor([1, 12],"float64"), )
paddle.einsum("...ii,...i->...i", Tensor([32, 0, 13, 12, 12],"float64"), Tensor([1, 12],"float64"), )
paddle.einsum("...ii,...i->...i", Tensor([32, 13, 0, 12, 12],"float64"), Tensor([1, 12],"float64"), )
paddle.einsum("...ii,...i->...i", Tensor([32, 13, 13, 0, 12],"float64"), Tensor([1, 12],"float64"), )
paddle.einsum("...ij,...i->j...", Tensor([0, 11],"float64"), Tensor([3, 4, 5, 10],"float64"), )
paddle.einsum("...ij,...i->j...", Tensor([10, 0],"float64"), Tensor([3, 4, 5, 10],"float64"), )
paddle.einsum("...ij,...jk->...ik", Tensor([0, 5],"float64"), Tensor([5, 1],"float64"), )
paddle.einsum("...ij,...jk->...ik", Tensor([0, 5],"float64"), Tensor([5, 5],"float64"), )
paddle.einsum("...ij,...jk->...ik", Tensor([1, 0],"float64"), Tensor([5, 0],"float64"), )
paddle.einsum("...ij,...jk->...ik", Tensor([1, 0],"float64"), Tensor([5, 1],"float64"), )
paddle.einsum("...ij,...jk->...ik", Tensor([1, 0],"float64"), Tensor([5, 5],"float64"), )
paddle.einsum("...ij,...jk->...ik", Tensor([1, 5],"float64"), Tensor([5, 0],"float64"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([0, 28, 28],"float32"), Tensor([3, 6, 28, 28],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([0, 6, 8, 8],"float32"), Tensor([2, 3, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([0, 8, 8],"float32"), Tensor([3, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([2, 0, 8, 8],"float32"), Tensor([2, 3, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([2, 6, 0, 8],"float32"), Tensor([2, 3, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([2, 6, 8, 0],"float32"), Tensor([2, 3, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([2, 6, 8, 8],"float32"), Tensor([2, 0, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([6, 0, 28],"float32"), Tensor([3, 6, 28, 28],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([6, 0, 8],"float32"), Tensor([3, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([6, 28, 0],"float32"), Tensor([3, 6, 28, 28],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([6, 28, 28],"float32"), Tensor([0, 6, 28, 28],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([6, 8, 0],"float32"), Tensor([3, 6, 8, 8],"float32"), )
paddle.einsum("...ijk, ...xijk -> ...xjk", Tensor([6, 8, 8],"float32"), Tensor([0, 6, 8, 8],"float32"), )
paddle.einsum("...jk, ...kl->...jl", Tensor([0, 10, 3],"float64"), Tensor([0, 3, 10],"float64"), )
paddle.einsum("...jk, ...kl->...jl", Tensor([0, 10, 3],"float64"), Tensor([3, 3, 10],"float64"), )
paddle.einsum("...jk, ...kl->...jl", Tensor([3, 0, 3],"float64"), Tensor([3, 3, 10],"float64"), )
paddle.einsum("...jk, ...kl->...jl", Tensor([3, 10, 0],"float64"), Tensor([3, 3, 0],"float64"), )
paddle.einsum("...jk, ...kl->...jl", Tensor([3, 10, 0],"float64"), Tensor([3, 3, 10],"float64"), )
paddle.einsum("...jk, ...kl->...jl", Tensor([3, 10, 3],"float64"), Tensor([3, 3, 0],"float64"), )
paddle.einsum("...jk->...kj", Tensor([0, 10, 3],"float64"), )
paddle.einsum("...jk->...kj", Tensor([3, 0, 3],"float64"), )
paddle.einsum("...jk->...kj", Tensor([3, 10, 0],"float64"), )
paddle.einsum("...qk,...kd->...qd", Tensor([0, 4, 3, 1, 2],"float32"), Tensor([0, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([0, 4, 3, 1, 2],"float32"), Tensor([13, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([0, 4, 3, 1, 2],"float32"), Tensor([52, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 0, 3, 1, 2],"float32"), Tensor([13, 0, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 0, 3, 1, 2],"float32"), Tensor([13, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 4, 0, 1, 2],"float32"), Tensor([13, 4, 0, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 4, 0, 1, 2],"float32"), Tensor([13, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 4, 3, 0, 2],"float32"), Tensor([13, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 4, 3, 1, 0],"float32"), Tensor([13, 4, 3, 2, 0],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 4, 3, 1, 0],"float32"), Tensor([13, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([13, 4, 3, 1, 2],"float32"), Tensor([13, 4, 3, 2, 0],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 0, 3, 1, 2],"float32"), Tensor([52, 0, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 0, 3, 1, 2],"float32"), Tensor([52, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 4, 0, 1, 2],"float32"), Tensor([52, 4, 0, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 4, 0, 1, 2],"float32"), Tensor([52, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 4, 3, 0, 2],"float32"), Tensor([52, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 4, 3, 1, 0],"float32"), Tensor([52, 4, 3, 2, 0],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 4, 3, 1, 0],"float32"), Tensor([52, 4, 3, 2, 8],"float32"), )
paddle.einsum("...qk,...kd->...qd", Tensor([52, 4, 3, 1, 2],"float32"), Tensor([52, 4, 3, 2, 0],"float32"), )
paddle.einsum("a...a->...", Tensor([0, 3, 2, 1, 4, 5],"float64"), )
paddle.einsum("a...a->...", Tensor([5, 0, 2, 1, 4, 5],"float64"), )
paddle.einsum("a...a->...", Tensor([5, 3, 0, 1, 4, 5],"float64"), )
paddle.einsum("a...a->...", Tensor([5, 3, 2, 0, 4, 5],"float64"), )
paddle.einsum("a...a->...", Tensor([5, 3, 2, 1, 0, 5],"float64"), )
paddle.einsum("a...a->a...", Tensor([0, 3, 2, 1, 4, 5],"float64"), )
paddle.einsum("a...a->a...", Tensor([5, 0, 2, 1, 4, 5],"float64"), )
paddle.einsum("a...a->a...", Tensor([5, 3, 0, 1, 4, 5],"float64"), )
paddle.einsum("a...a->a...", Tensor([5, 3, 2, 0, 4, 5],"float64"), )
paddle.einsum("a...a->a...", Tensor([5, 3, 2, 1, 0, 5],"float64"), )
paddle.einsum("a...b,b...c,c...a", Tensor([4, 0, 1, 4],"float64"), Tensor([4, 0, 1, 4],"float64"), Tensor([4, 0, 1, 4],"float64"), )
paddle.einsum("a...b,b...c,c...a", Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), )
paddle.einsum("a...b,b...c,c...a", Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), )
paddle.einsum("a...b,b...c,c...d", Tensor([0, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), )
paddle.einsum("a...b,b...c,c...d", Tensor([4, 0, 1, 4],"float64"), Tensor([4, 0, 1, 4],"float64"), Tensor([4, 0, 1, 4],"float64"), )
paddle.einsum("a...b,b...c,c...d", Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), )
paddle.einsum("a...b,b...c,c...d", Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), )
paddle.einsum("a...b,b...c,c...d", Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 4],"float64"), Tensor([4, 3, 1, 0],"float64"), )
paddle.einsum("a...d,...cb->...abcd", Tensor([0, 3, 2, 3, 4],"float64"), Tensor([12, 10],"float64"), )
paddle.einsum("a...d,...cb->...abcd", Tensor([10, 0, 2, 3, 4],"float64"), Tensor([12, 10],"float64"), )
paddle.einsum("a...d,...cb->...abcd", Tensor([10, 3, 0, 3, 4],"float64"), Tensor([12, 10],"float64"), )
paddle.einsum("a...d,...cb->...abcd", Tensor([10, 3, 2, 0, 4],"float64"), Tensor([12, 10],"float64"), )
paddle.einsum("a...d,...cb->...abcd", Tensor([10, 3, 2, 3, 0],"float64"), Tensor([12, 10],"float64"), )
paddle.einsum("a...d,...cb->...abcd", Tensor([10, 3, 2, 3, 4],"float64"), Tensor([0, 10],"float64"), )
paddle.einsum("a...d,...cb->...abcd", Tensor([10, 3, 2, 3, 4],"float64"), Tensor([12, 0],"float64"), )
paddle.einsum("aaa->a", Tensor([0, 5, 5],"float64"), )
paddle.einsum("abcd,dfg->abcfg", Tensor([0, 4, 5, 3],"float64"), Tensor([3, 4, 5],"float64"), )
paddle.einsum("abcd,dfg->abcfg", Tensor([2, 0, 5, 3],"float64"), Tensor([3, 4, 5],"float64"), )
paddle.einsum("abcd,dfg->abcfg", Tensor([2, 4, 0, 3],"float64"), Tensor([3, 4, 5],"float64"), )
paddle.einsum("abcd,dfg->abcfg", Tensor([2, 4, 5, 0],"float64"), Tensor([3, 4, 5],"float64"), )
paddle.einsum("abcd,dfg->abcfg", Tensor([2, 4, 5, 3],"float64"), Tensor([3, 0, 5],"float64"), )
paddle.einsum("abcd,dfg->abcfg", Tensor([2, 4, 5, 3],"float64"), Tensor([3, 4, 0],"float64"), )
paddle.einsum("ak, kn-> an", Tensor([0, 11],"float32"), Tensor([11, 50],"float32"), )
paddle.einsum("ak, kn-> an", Tensor([15000, 0],"float32"), Tensor([11, 0],"float32"), )
paddle.einsum("ak, kn-> an", Tensor([15000, 0],"float32"), Tensor([11, 50],"float32"), )
paddle.einsum("ak, kn-> an", Tensor([15000, 11],"float32"), Tensor([11, 0],"float32"), )
paddle.einsum("ak, kn-> an", Tensor([60000, 0],"float32"), Tensor([11, 0],"float32"), )
paddle.einsum("ak, kn-> an", Tensor([60000, 0],"float32"), Tensor([11, 50],"float32"), )
paddle.einsum("ak, kn-> an", Tensor([60000, 11],"float32"), Tensor([11, 0],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([0, 8, 1, 64],"float32"), Tensor([0, 8, 1, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([0, 8, 1, 64],"float32"), Tensor([0, 8, 109, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([0, 8, 1, 64],"float32"), Tensor([1, 8, 1, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([0, 8, 1, 64],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 0, 1, 64],"float32"), Tensor([1, 0, 1, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 0, 1, 64],"float32"), Tensor([1, 0, 109, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 0, 1, 64],"float32"), Tensor([1, 8, 1, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 0, 1, 64],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 0, 64],"float32"), Tensor([1, 8, 0, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 0, 64],"float32"), Tensor([1, 8, 1, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 0, 64],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 1, 0],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 1, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 109, 0],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i d, b h j d -> b h i j", Tensor([1, 8, 1, 64],"float32"), Tensor([1, 8, 0, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([0, 8, 1, 109],"float32"), Tensor([0, 8, 109, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([0, 8, 1, 109],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([0, 8, 1, 113],"float32"), Tensor([0, 8, 113, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([0, 8, 1, 113],"float32"), Tensor([1, 8, 113, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 0, 1, 109],"float32"), Tensor([1, 0, 109, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 0, 1, 109],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 0, 1, 113],"float32"), Tensor([1, 0, 113, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 0, 1, 113],"float32"), Tensor([1, 8, 113, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 0, 109],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 0, 113],"float32"), Tensor([1, 8, 113, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 109, 0],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 109, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 113, 0],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 1, 0],"float32"), Tensor([1, 8, 113, 64],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 1, 109],"float32"), Tensor([1, 8, 109, 0],"float32"), )
paddle.einsum("b h i j, b h j d -> b h i d", Tensor([1, 8, 1, 113],"float32"), Tensor([1, 8, 113, 0],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([0, 4, 5, 1, 8],"float32"), Tensor([0, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([0, 4, 5, 1, 8],"float32"), Tensor([13, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([0, 4, 5, 1, 8],"float32"), Tensor([52, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 0, 5, 1, 8],"float32"), Tensor([13, 0, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 0, 5, 1, 8],"float32"), Tensor([13, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 4, 0, 1, 8],"float32"), Tensor([13, 4, 0, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 4, 0, 1, 8],"float32"), Tensor([13, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 4, 5, 0, 8],"float32"), Tensor([13, 4, 5, 0, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 4, 5, 0, 8],"float32"), Tensor([13, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 4, 5, 1, 0],"float32"), Tensor([13, 4, 5, 7, 0],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 4, 5, 1, 0],"float32"), Tensor([13, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([13, 4, 5, 1, 8],"float32"), Tensor([13, 4, 5, 0, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 0, 5, 1, 8],"float32"), Tensor([52, 0, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 0, 5, 1, 8],"float32"), Tensor([52, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 4, 0, 1, 8],"float32"), Tensor([52, 4, 0, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 4, 0, 1, 8],"float32"), Tensor([52, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 4, 5, 0, 8],"float32"), Tensor([52, 4, 5, 0, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 4, 5, 0, 8],"float32"), Tensor([52, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 4, 5, 1, 0],"float32"), Tensor([52, 4, 5, 7, 0],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 4, 5, 1, 0],"float32"), Tensor([52, 4, 5, 7, 8],"float32"), )
paddle.einsum("bhlqd,bhlkd->bhlqk", Tensor([52, 4, 5, 1, 8],"float32"), Tensor([52, 4, 5, 0, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([0, 4, 3, 1, 1],"float32"), Tensor([13, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([0, 4, 3, 1, 1],"float32"), Tensor([52, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([13, 0, 3, 1, 1],"float32"), Tensor([13, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([13, 4, 0, 1, 1],"float32"), Tensor([13, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([13, 4, 3, 0, 1],"float32"), Tensor([13, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([13, 4, 3, 1, 0],"float32"), Tensor([13, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([13, 4, 3, 1, 1],"float32"), Tensor([13, 4, 1, 0],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([52, 0, 3, 1, 1],"float32"), Tensor([52, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([52, 4, 0, 1, 1],"float32"), Tensor([52, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([52, 4, 3, 0, 1],"float32"), Tensor([52, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([52, 4, 3, 1, 0],"float32"), Tensor([52, 4, 1, 8],"float32"), )
paddle.einsum("bhlqk,bhkd->bhlqd", Tensor([52, 4, 3, 1, 1],"float32"), Tensor([52, 4, 1, 0],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([0, 4, 1, 1, 7],"float32"), Tensor([0, 4, 1, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([0, 4, 1, 1, 7],"float32"), Tensor([13, 4, 1, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([0, 4, 3, 1, 3],"float32"), Tensor([0, 4, 3, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([0, 4, 3, 1, 3],"float32"), Tensor([13, 4, 3, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 0, 1, 1, 7],"float32"), Tensor([13, 0, 1, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 0, 1, 1, 7],"float32"), Tensor([13, 4, 1, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 0, 3, 1, 3],"float32"), Tensor([13, 0, 3, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 0, 3, 1, 3],"float32"), Tensor([13, 4, 3, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 0, 1, 3],"float32"), Tensor([13, 4, 0, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 0, 1, 3],"float32"), Tensor([13, 4, 3, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 0, 1, 7],"float32"), Tensor([13, 4, 0, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 0, 1, 7],"float32"), Tensor([13, 4, 1, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 1, 0, 7],"float32"), Tensor([13, 4, 1, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 1, 1, 0],"float32"), Tensor([13, 4, 1, 7, 0],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 1, 1, 0],"float32"), Tensor([13, 4, 1, 7, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 1, 1, 7],"float32"), Tensor([13, 4, 1, 7, 0],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 3, 0, 3],"float32"), Tensor([13, 4, 3, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 3, 1, 0],"float32"), Tensor([13, 4, 3, 3, 0],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 3, 1, 0],"float32"), Tensor([13, 4, 3, 3, 8],"float32"), )
paddle.einsum("bhlqk,bhlkd->bhlqd", Tensor([13, 4, 3, 1, 3],"float32"), Tensor([13, 4, 3, 3, 0],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([0, 14, 14, 64],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([0, 32, 32, 64],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([432, 0, 14, 64],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([432, 14, 0, 64],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([432, 14, 14, 0],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([432, 14, 14, 64],"float32"), Tensor([14, 0, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([48, 0, 32, 64],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([48, 32, 0, 64],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([48, 32, 32, 0],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,hkc->bhwk", Tensor([48, 32, 32, 64],"float32"), Tensor([32, 0, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([0, 14, 14, 64],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([0, 32, 32, 64],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([432, 0, 14, 64],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([432, 14, 0, 64],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([432, 14, 14, 0],"float32"), Tensor([14, 14, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([432, 14, 14, 64],"float32"), Tensor([14, 0, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([48, 0, 32, 64],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([48, 32, 0, 64],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([48, 32, 32, 0],"float32"), Tensor([32, 32, 64],"float32"), )
paddle.einsum("bhwc,wkc->bhwk", Tensor([48, 32, 32, 64],"float32"), Tensor([32, 0, 64],"float32"), )
paddle.einsum("bij,bjk->bik", Tensor([0, 4, 5],"float64"), Tensor([0, 5, 2],"float64"), )
paddle.einsum("bij,bjk->bik", Tensor([0, 4, 5],"float64"), Tensor([3, 5, 2],"float64"), )
paddle.einsum("bij,bjk->bik", Tensor([3, 0, 5],"float64"), Tensor([3, 5, 2],"float64"), )
paddle.einsum("bij,bjk->bik", Tensor([3, 4, 0],"float64"), Tensor([3, 5, 0],"float64"), )
paddle.einsum("bij,bjk->bik", Tensor([3, 4, 0],"float64"), Tensor([3, 5, 2],"float64"), )
paddle.einsum("bij,bjk->bik", Tensor([3, 4, 5],"float64"), Tensor([3, 5, 0],"float64"), )
paddle.einsum("bind,bjnd->bnij", Tensor([0, 2, 4, 4],"float32"), Tensor([0, 2, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([0, 2, 4, 4],"float32"), Tensor([0, 4, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([0, 2, 4, 4],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([0, 2, 4, 4],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 0, 4, 4],"float32"), Tensor([13, 0, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 0, 4, 4],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 0, 4, 4],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 0, 4],"float32"), Tensor([13, 2, 0, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 0, 4],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 0, 4],"float32"), Tensor([13, 4, 0, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 0, 4],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 4, 0],"float32"), Tensor([13, 2, 4, 0],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 4, 0],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 4, 0],"float32"), Tensor([13, 4, 4, 0],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 4, 0],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bind,bjnd->bnij", Tensor([13, 2, 4, 4],"float32"), Tensor([13, 0, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([0, 2, 4, 4],"float32"), Tensor([2, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([0, 4, 4, 4],"float32"), Tensor([2, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([13, 0, 4, 4],"float32"), Tensor([2, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([13, 2, 0, 4],"float32"), Tensor([2, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([13, 2, 4, 0],"float32"), Tensor([2, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([13, 2, 4, 4],"float32"), Tensor([0, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([13, 4, 0, 4],"float32"), Tensor([2, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([13, 4, 4, 0],"float32"), Tensor([2, 4, 4],"float32"), )
paddle.einsum("bind,snd->bnis", Tensor([13, 4, 4, 4],"float32"), Tensor([0, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([0, 2, 4, 4],"float32"), Tensor([4, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([0, 2, 4, 4],"float32"), Tensor([8, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([13, 0, 4, 4],"float32"), Tensor([4, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([13, 0, 4, 4],"float32"), Tensor([8, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([13, 2, 0, 4],"float32"), Tensor([4, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([13, 2, 0, 4],"float32"), Tensor([8, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([13, 2, 4, 0],"float32"), Tensor([4, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([13, 2, 4, 0],"float32"), Tensor([8, 4, 4],"float32"), )
paddle.einsum("binh,tnh->bnit", Tensor([13, 2, 4, 4],"float32"), Tensor([0, 4, 4],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([0, 5, 1, 1],"float32"), Tensor([0, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([0, 5, 1, 1],"float32"), Tensor([13, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([0, 5, 1, 1],"float32"), Tensor([52, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([13, 0, 1, 1],"float32"), Tensor([13, 0, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([13, 0, 1, 1],"float32"), Tensor([13, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([13, 5, 0, 1],"float32"), Tensor([13, 5, 0, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([13, 5, 0, 1],"float32"), Tensor([13, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([13, 5, 1, 0],"float32"), Tensor([13, 5, 1, 0],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([13, 5, 1, 0],"float32"), Tensor([13, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([13, 5, 1, 1],"float32"), Tensor([13, 5, 1, 0],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([52, 0, 1, 1],"float32"), Tensor([52, 0, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([52, 0, 1, 1],"float32"), Tensor([52, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([52, 5, 0, 1],"float32"), Tensor([52, 5, 0, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([52, 5, 0, 1],"float32"), Tensor([52, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([52, 5, 1, 0],"float32"), Tensor([52, 5, 1, 0],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([52, 5, 1, 0],"float32"), Tensor([52, 5, 1, 3],"float32"), )
paddle.einsum("blkd,bldq->blkq", Tensor([52, 5, 1, 1],"float32"), Tensor([52, 5, 1, 0],"float32"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([0, 3, 5],"float64"), Tensor([1, 2, 3, 4],"float64"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([0, 5, 1],"float32"), Tensor([13, 4, 5, 2],"float32"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([1, 0, 5],"float64"), Tensor([1, 2, 3, 4],"float64"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([1, 3, 0],"float64"), Tensor([1, 2, 3, 4],"float64"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([1, 3, 5],"float64"), Tensor([1, 0, 3, 4],"float64"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([1, 3, 5],"float64"), Tensor([1, 2, 3, 0],"float64"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([13, 0, 1],"float32"), Tensor([13, 4, 5, 2],"float32"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([13, 5, 0],"float32"), Tensor([13, 4, 5, 2],"float32"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([13, 5, 1],"float32"), Tensor([13, 0, 5, 2],"float32"), )
paddle.einsum("blq,bhlk->bhlqk", Tensor([13, 5, 1],"float32"), Tensor([13, 4, 5, 0],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([0, 5, 1, 1],"float32"), Tensor([0, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([0, 5, 1, 1],"float32"), Tensor([13, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([0, 5, 1, 1],"float32"), Tensor([52, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 0, 1, 1],"float32"), Tensor([13, 0, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 0, 1, 1],"float32"), Tensor([13, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 5, 0, 1],"float32"), Tensor([13, 1, 0, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 5, 0, 1],"float32"), Tensor([13, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 5, 1, 0],"float32"), Tensor([13, 1, 1, 0],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 5, 1, 0],"float32"), Tensor([13, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 5, 1, 1],"float32"), Tensor([13, 0, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([13, 5, 1, 1],"float32"), Tensor([13, 1, 1, 0],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 0, 1, 1],"float32"), Tensor([52, 0, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 0, 1, 1],"float32"), Tensor([52, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 5, 0, 1],"float32"), Tensor([52, 1, 0, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 5, 0, 1],"float32"), Tensor([52, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 5, 1, 0],"float32"), Tensor([52, 1, 1, 0],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 5, 1, 0],"float32"), Tensor([52, 1, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 5, 1, 1],"float32"), Tensor([52, 0, 1, 1],"float32"), )
paddle.einsum("blqd,bmdk->blqk", Tensor([52, 5, 1, 1],"float32"), Tensor([52, 1, 1, 0],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([0, 2, 16, 16],"float32"), Tensor([2, 16, 4, 1],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([13, 0, 16, 16],"float32"), Tensor([2, 16, 4, 1],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([13, 2, 0, 16],"float32"), Tensor([2, 16, 0, 1],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([13, 2, 0, 16],"float32"), Tensor([2, 16, 4, 1],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([13, 2, 16, 0],"float32"), Tensor([2, 16, 4, 0],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([13, 2, 16, 0],"float32"), Tensor([2, 16, 4, 1],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([13, 2, 16, 16],"float32"), Tensor([2, 16, 0, 1],"float32"), )
paddle.einsum("bmtd,mdhr->bmhtr", Tensor([13, 2, 16, 16],"float32"), Tensor([2, 16, 4, 0],"float32"), )
paddle.einsum("bn,anm,bm->ba", Tensor([2, 5],"float64"), Tensor([0, 5, 2],"float64"), Tensor([2, 2],"float64"), )
paddle.einsum("bnij,bjnd->bind", Tensor([0, 4, 2, 2],"float32"), Tensor([0, 2, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([0, 4, 2, 2],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([0, 4, 2, 4],"float32"), Tensor([0, 4, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([0, 4, 2, 4],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 0, 2, 2],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 0, 2, 4],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 0, 2],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 0, 4],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 2, 0],"float32"), Tensor([13, 2, 4, 0],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 2, 0],"float32"), Tensor([13, 2, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 2, 0],"float32"), Tensor([13, 4, 4, 0],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 2, 0],"float32"), Tensor([13, 4, 4, 4],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 2, 2],"float32"), Tensor([13, 2, 4, 0],"float32"), )
paddle.einsum("bnij,bjnd->bind", Tensor([13, 4, 2, 4],"float32"), Tensor([13, 4, 4, 0],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([0, 4, 7, 7],"float32"), Tensor([7, 10, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([0, 4, 7, 7],"float32"), Tensor([7, 11, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([10, 0, 7, 7],"float32"), Tensor([7, 10, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([10, 4, 0, 7],"float32"), Tensor([7, 10, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([10, 4, 7, 0],"float32"), Tensor([7, 10, 4, 0],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([10, 4, 7, 0],"float32"), Tensor([7, 10, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([10, 4, 7, 7],"float32"), Tensor([7, 10, 4, 0],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([11, 0, 7, 7],"float32"), Tensor([7, 11, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([11, 4, 0, 7],"float32"), Tensor([7, 11, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([11, 4, 7, 0],"float32"), Tensor([7, 11, 4, 0],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([11, 4, 7, 0],"float32"), Tensor([7, 11, 4, 8],"float32"), )
paddle.einsum("bnij,jbnd->ibnd", Tensor([11, 4, 7, 7],"float32"), Tensor([7, 11, 4, 0],"float32"), )
paddle.einsum("i , j -> i j", Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.einsum("i , j -> i j", Tensor([0],"float32"), Tensor([2],"float32"), )
paddle.einsum("i , j -> i j", Tensor([1],"float32"), Tensor([0],"float32"), )
paddle.einsum("i , j -> i j", Tensor([10],"float32"), Tensor([0],"float32"), )
paddle.einsum("i, i", Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.einsum("i, i", Tensor([0],"float64"), Tensor([1],"float64"), )
paddle.einsum("i,d->id", Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.einsum("i,d->id", Tensor([0],"float32"), Tensor([16],"float32"), )
paddle.einsum("i,d->id", Tensor([14],"float32"), Tensor([0],"float32"), )
paddle.einsum("i,d->id", Tensor([16],"float32"), Tensor([0],"float32"), )
paddle.einsum("i,i", Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.einsum("i,i", Tensor([0],"float64"), Tensor([10],"float64"), )
paddle.einsum("i,i", Tensor([0],"float64"), Tensor([11],"float64"), )
paddle.einsum("i,i->", Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.einsum("i,i->", Tensor([0],"float32"), Tensor([5],"float32"), )
paddle.einsum("i,i->", Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.einsum("i,i->", Tensor([0],"float64"), Tensor([10],"float64"), )
paddle.einsum("i,i->i", Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.einsum("i,i->i", Tensor([0],"float64"), Tensor([5],"float64"), )
paddle.einsum("i,ij->", Tensor([0],"float64"), Tensor([2, 2],"float64"), )
paddle.einsum("i,ij->", Tensor([2],"float64"), Tensor([2, 0],"float64"), )
paddle.einsum("i,j", Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.einsum("i,j", Tensor([0],"float64"), Tensor([10],"float64"), )
paddle.einsum("i,j", Tensor([0],"float64"), Tensor([11],"float64"), )
paddle.einsum("i,j", Tensor([3],"float64"), Tensor([0],"float64"), )
paddle.einsum("i,j->ii", Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.einsum("i,j->ii", Tensor([0],"float64"), Tensor([2],"float64"), )
paddle.einsum("i,j->ii", Tensor([2],"float64"), Tensor([0],"float64"), )
paddle.einsum("i,j->ij", Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.einsum("i,j->ij", Tensor([0],"float32"), Tensor([128],"float32"), )
paddle.einsum("i,j->ij", Tensor([0],"float32"), Tensor([2],"float32"), )
paddle.einsum("i,j->ij", Tensor([10],"float32"), Tensor([0],"float32"), )
paddle.einsum("i..., i...", Tensor([0, 3, 2],"float64"), Tensor([1],"float64"), )
paddle.einsum("i..., i...", Tensor([0, 3, 2],"float64"), Tensor([10],"float64"), )
paddle.einsum("i..., i...", Tensor([1, 0, 2],"float64"), Tensor([1],"float64"), )
paddle.einsum("i..., i...", Tensor([1, 3, 0],"float64"), Tensor([1],"float64"), )
paddle.einsum("i->", Tensor([0],"float64"), )
paddle.einsum("i->ii", Tensor([0],"float64"), )
paddle.expand(x=Tensor([1, 1, 1],"int64"), shape=Tensor([0],"int32"), )
paddle.flip(Tensor([0, 3, 112, 112],"float32"), axis=-1, )
paddle.flip(Tensor([0, 3],"float32"), 1, )
paddle.flip(Tensor([2, 0],"float32"), 1, )
paddle.flip(Tensor([20, 0, 112, 112],"float32"), axis=-1, )
paddle.flip(Tensor([20, 3, 0, 112],"float32"), axis=-1, )
paddle.flip(Tensor([20, 3, 112, 0],"float32"), axis=-1, )
paddle.flip(Tensor([32, 0, 112, 112],"float32"), axis=-1, )
paddle.flip(Tensor([32, 3, 0, 112],"float32"), axis=-1, )
paddle.flip(Tensor([32, 3, 112, 0],"float32"), axis=-1, )
paddle.frac(Tensor([0, 3],"int32"), )
paddle.frac(Tensor([0, 3],"int64"), )
paddle.frac(Tensor([2, 0],"int32"), )
paddle.frac(Tensor([2, 0],"int64"), )
paddle.frexp(Tensor([0, 12],"float32"), )
paddle.frexp(Tensor([0, 12],"float64"), )
paddle.frexp(Tensor([0, 5, 2],"float32"), )
paddle.frexp(Tensor([0, 5, 2],"float64"), )
paddle.frexp(Tensor([10, 0],"float32"), )
paddle.frexp(Tensor([10, 0],"float64"), )
paddle.frexp(Tensor([4, 0, 2],"float32"), )
paddle.frexp(Tensor([4, 0, 2],"float64"), )
paddle.frexp(Tensor([4, 5, 0],"float32"), )
paddle.frexp(Tensor([4, 5, 0],"float64"), )
paddle.gammaln(Tensor([0, 20, 1],"float32"), )
paddle.gammaln(Tensor([0, 3, 4, 5],"float32"), )
paddle.gammaln(Tensor([0, 3, 4, 5],"float64"), )
paddle.gammaln(Tensor([10, 0, 1],"float32"), )
paddle.gammaln(Tensor([10, 20, 0],"float32"), )
paddle.gammaln(Tensor([2, 0, 4, 5],"float32"), )
paddle.gammaln(Tensor([2, 0, 4, 5],"float64"), )
paddle.gammaln(Tensor([2, 3, 0, 5],"float32"), )
paddle.gammaln(Tensor([2, 3, 0, 5],"float64"), )
paddle.gammaln(Tensor([2, 3, 4, 0],"float32"), )
paddle.gammaln(Tensor([2, 3, 4, 0],"float64"), )
paddle.hsplit(Tensor([0, 6, 3],"int64"), 2, )
paddle.hsplit(Tensor([0, 6, 3],"int64"), 3, )
paddle.hsplit(Tensor([0, 6],"int64"), 2, )
paddle.hsplit(Tensor([0, 6],"int64"), 3, )
paddle.hsplit(Tensor([4, 0, 3],"int64"), 2, )
paddle.hsplit(Tensor([4, 0, 3],"int64"), 3, )
paddle.hsplit(Tensor([4, 0],"int64"), 2, )
paddle.hsplit(Tensor([4, 0],"int64"), 3, )
paddle.hsplit(Tensor([4, 6, 0],"int64"), 2, )
paddle.hsplit(Tensor([4, 6, 0],"int64"), 3, )
paddle.incubate.nn.functional.blha_get_max_len(Tensor([0],"int32"), Tensor([10],"int32"), Tensor([10],"float32"), )
paddle.incubate.nn.functional.blha_get_max_len(Tensor([10],"int32"), Tensor([0],"int32"), Tensor([10],"float32"), )
paddle.incubate.nn.functional.fused_bias_act(Tensor([1, 0],"float16"), None, act_method="swiglu", )
paddle.incubate.nn.functional.fused_bias_act(Tensor([100, 0],"float16"), None, act_method="swiglu", )
paddle.incubate.nn.functional.fused_bias_act(Tensor([101, 0],"float16"), Tensor([256],"float16"), act_method="gelu", )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"float16"), Tensor([256],"float16"), act_method="gelu", )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([2, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0014022786635905504, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.001479289960116148, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 0],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([22016],"float32"), shift=None, smooth=None, quant_scale=0.0016999575309455395, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0009313154732808471, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0009654839523136616, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0009928022045642138, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0010831302497535944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_bias_act(Tensor([464, 22016],"int32"), None, act_method="swiglu", compute_dtype="fp16", dequant_scales=Tensor([0],"float32"), shift=None, smooth=None, quant_scale=0.0010981468949466944, quant_round_type=0, quant_max_bound=127.0, quant_min_bound=-127.0, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 1, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 128, 768],"float16"), Tensor([768, 3072],"float16"), Tensor([3072, 768],"float16"), Tensor([3072],"float16"), Tensor([768],"float16"), None, None, Tensor([768],"float32"), Tensor([768],"float32"), dropout1_rate=0.0, dropout2_rate=0.1, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 128, 768],"float32"), Tensor([768, 3072],"float32"), Tensor([3072, 768],"float32"), Tensor([3072],"float32"), Tensor([768],"float32"), None, None, Tensor([768],"float32"), Tensor([768],"float32"), dropout1_rate=0.0, dropout2_rate=0.1, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, Tensor([4],"float32"), Tensor([4],"float32"), dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 2, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 98, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="relu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([0, 98, 508],"float64"), Tensor([508, 130],"float64"), Tensor([130, 508],"float64"), Tensor([130],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 0, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, Tensor([4],"float32"), Tensor([4],"float32"), dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 0, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 0, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4, 4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), Tensor([4],"float32"), None, None, dropout1_rate=0, dropout2_rate=0, activation="relu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=True, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([1, 0, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8, 8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 0, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 0, 508],"float32"), Tensor([508, 130],"float32"), Tensor([130, 508],"float32"), Tensor([130],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), Tensor([508],"float32"), 0.0, 0.0, activation="relu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([31, 0, 508],"float64"), Tensor([508, 130],"float64"), Tensor([130, 508],"float64"), Tensor([130],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), Tensor([508],"float64"), 0.0, 0.0, activation="gelu", pre_layer_norm=False, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([32, 0, 768],"float16"), Tensor([768, 3072],"float16"), Tensor([3072, 768],"float16"), Tensor([3072],"float16"), Tensor([768],"float16"), None, None, Tensor([768],"float32"), Tensor([768],"float32"), dropout1_rate=0.0, dropout2_rate=0.1, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(Tensor([32, 0, 768],"float32"), Tensor([768, 3072],"float32"), Tensor([3072, 768],"float32"), Tensor([3072],"float32"), Tensor([768],"float32"), None, None, Tensor([768],"float32"), Tensor([768],"float32"), dropout1_rate=0.0, dropout2_rate=0.1, activation="gelu", ln1_epsilon=1e-05, ln2_epsilon=1e-05, pre_layer_norm=False, training=True, ring_id=-1, name=None, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([0, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), activation="gelu", dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([0, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([0, 2, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([0, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([0, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln1_scale=Tensor([2],"float32"), ln1_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([0, 2, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln2_scale=Tensor([2],"float32"), ln2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 0, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), activation="gelu", dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 0, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 0, 2],"float32"), linear1_weight=Tensor([2, 2],"float32"), linear2_weight=Tensor([2, 2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 0, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 0, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln1_scale=Tensor([2],"float32"), ln1_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, pre_layer_norm=True, )
paddle.incubate.nn.functional.fused_feedforward(x=Tensor([1, 0, 2],"float32"), linear1_weight=Tensor([2, 4],"float32"), linear2_weight=Tensor([4, 2],"float32"), linear1_bias=Tensor([4],"float32"), linear2_bias=Tensor([2],"float32"), ln2_scale=Tensor([2],"float32"), ln2_bias=Tensor([2],"float32"), dropout1_rate=0, dropout2_rate=0, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 1, 64],"float16"), Tensor([64],"float32"), Tensor([64],"float32"), 1e-05, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 256],"float16"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 256],"float16"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([16, 256],"float16"), residual_alpha=0.69204696, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float32"), residual=Tensor([16, 256],"float32"), residual_alpha=0.69204696, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 64],"float16"), norm_weight=Tensor([64],"float32"), norm_bias=Tensor([64],"float32"), epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([101, 64],"float16"), )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 64],"float16"), norm_weight=Tensor([64],"float32"), norm_bias=Tensor([64],"float32"), epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([2, 1, 64],"float16"), )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 64],"float16"), norm_weight=Tensor([64],"float32"), norm_bias=Tensor([64],"float32"), epsilon=1e-05, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([59, 64],"float16"), )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 64],"float16"), norm_weight=Tensor([64],"float32"), norm_bias=Tensor([64],"float32"), epsilon=1e-05, residual_alpha=1.4142135623730951, begin_norm_axis=1, bias=Tensor([64],"float16"), residual=Tensor([58, 64],"float16"), )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([0, 64],"float16"), Tensor([64],"float32"), Tensor([64],"float32"), 1e-05, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 256],"float16"), Tensor([256],"float32"), Tensor([0],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([16, 256],"float16"), residual_alpha=0.69204696, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 256],"float16"), Tensor([256],"float32"), Tensor([0],"float32"), 1e-05, begin_norm_axis=1, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 256],"float16"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([0],"float16"), residual=Tensor([16, 256],"float16"), residual_alpha=0.69204696, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 256],"float16"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([0, 256],"float16"), residual_alpha=0.69204696, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_layer_norm(Tensor([16, 256],"float16"), Tensor([256],"float32"), Tensor([256],"float32"), 1e-05, begin_norm_axis=1, bias=Tensor([256],"float16"), residual=Tensor([16, 0],"float16"), residual_alpha=0.69204696, quant_scale=0.15, quant_round_type=1, quant_max_bound=127, quant_min_bound=-127, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([0, 1, 512],"float16"), Tensor([512],"float16"), None, 1e-05, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([0, 1, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([0, 512],"float16"), Tensor([512],"float16"), None, 1e-05, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rms_norm(Tensor([0, 64],"float16"), Tensor([64],"float16"), None, 1e-06, begin_norm_axis=1, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([0, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([0, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([0, 8, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 0, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 0, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 0, 2, 8],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=Tensor([1, 8],"int64"), use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 0],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=False, time_major=False, )
paddle.incubate.nn.functional.fused_rotary_position_embedding(Tensor([1, 8, 4, 8],"float32"), Tensor([1, 8, 2, 0],"float32"), Tensor([1, 8, 2, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), Tensor([1, 8, 1, 8],"float32"), position_ids=None, use_neox_rotary_style=True, time_major=False, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 0, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1],"int32"), Tensor([1, 1],"int32"), mask=Tensor([1, 1, 50, 50],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 0],"float16"), Tensor([1, 1],"int32"), Tensor([1, 1],"int32"), mask=Tensor([1, 1, 50, 50],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([0, 1],"int32"), Tensor([1, 1],"int32"), mask=Tensor([1, 1, 50, 50],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 0],"int32"), Tensor([1, 1],"int32"), mask=Tensor([1, 1, 50, 50],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1],"int32"), Tensor([0, 1],"int32"), mask=Tensor([1, 1, 50, 50],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1],"int32"), Tensor([1, 0],"int32"), mask=Tensor([1, 1, 50, 50],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1],"int32"), Tensor([1, 1],"int32"), mask=Tensor([0, 1, 50, 50],"float16"), scale=0.125, )
paddle.incubate.nn.functional.variable_length_memory_efficient_attention(Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1, 31, 64],"float16"), Tensor([1, 1],"int32"), Tensor([1, 1],"int32"), mask=Tensor([1, 0, 50, 50],"float16"), scale=0.125, )
paddle.incubate.softmax_mask_fuse(Tensor([0, 1, 8, 32],"float32"), Tensor([0, 1, 8, 32],"float32"), )
paddle.incubate.softmax_mask_fuse(Tensor([1, 0, 8, 32],"float32"), Tensor([1, 1, 8, 32],"float32"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([0, 8, 8, 1020],"float16"), mask=Tensor([0, 1, 8, 1020],"float16"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([0, 8, 8, 32],"float16"), mask=Tensor([0, 1, 8, 32],"float16"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([2, 0, 8, 1020],"float16"), mask=Tensor([2, 1, 8, 1020],"float16"), )
paddle.incubate.softmax_mask_fuse(x=Tensor([2, 0, 8, 32],"float16"), mask=Tensor([2, 1, 8, 32],"float16"), )
paddle.index_fill(Tensor([0, 40],"float32"), Tensor([2],"int64"), 1, -1, )
paddle.index_fill(Tensor([0],"int64"), Tensor([0],"int64"), 0, 2, )
paddle.index_fill(Tensor([0],"int64"), Tensor([0],"int64"), 0, 5, )
paddle.index_fill(Tensor([0],"int64"), Tensor([0],"int64"), 0, 6, )
paddle.index_fill(Tensor([0],"int64"), Tensor([0],"int64"), 0, 7, )
paddle.index_fill(Tensor([0],"int64"), Tensor([28],"int64"), 0, 5, )
paddle.index_fill(Tensor([0],"int64"), Tensor([30],"int64"), 0, 7, )
paddle.index_fill(Tensor([0],"int64"), Tensor([38],"int64"), 0, 6, )
paddle.index_fill(Tensor([0],"int64"), Tensor([4],"int64"), 0, 2, )
paddle.index_fill(Tensor([0],"int64"), Tensor([5],"int64"), 0, 2, )
paddle.index_fill(Tensor([128],"int64"), Tensor([0],"int64"), 0, 5, )
paddle.index_fill(Tensor([128],"int64"), Tensor([0],"int64"), 0, 6, )
paddle.index_fill(Tensor([128],"int64"), Tensor([0],"int64"), 0, 7, )
paddle.index_fill(Tensor([20, 0],"float32"), Tensor([2],"int64"), 1, -1, )
paddle.index_fill(Tensor([20, 40],"float32"), Tensor([0],"int64"), 1, -1, )
paddle.index_fill(Tensor([4],"int64"), Tensor([0],"int64"), 0, 2, )
paddle.index_fill(Tensor([8],"int64"), Tensor([0],"int64"), 0, 2, )
paddle.isin(Tensor([0, 64],"bfloat16"), Tensor([0, 256],"bfloat16"), False, False, )
paddle.isin(Tensor([0, 64],"bfloat16"), Tensor([0, 256],"bfloat16"), False, True, )
paddle.isin(Tensor([0, 64],"bfloat16"), Tensor([4, 256],"bfloat16"), False, False, )
paddle.isin(Tensor([0, 64],"bfloat16"), Tensor([4, 256],"bfloat16"), False, True, )
paddle.isin(Tensor([0, 8],"bfloat16"), Tensor([0, 3],"bfloat16"), False, False, )
paddle.isin(Tensor([0, 8],"bfloat16"), Tensor([0, 3],"bfloat16"), False, True, )
paddle.isin(Tensor([0, 8],"bfloat16"), Tensor([2, 3],"bfloat16"), False, False, )
paddle.isin(Tensor([0, 8],"bfloat16"), Tensor([2, 3],"bfloat16"), False, True, )
paddle.isin(Tensor([4, 0],"bfloat16"), Tensor([2, 0],"bfloat16"), False, False, )
paddle.isin(Tensor([4, 0],"bfloat16"), Tensor([2, 0],"bfloat16"), False, True, )
paddle.isin(Tensor([4, 0],"bfloat16"), Tensor([2, 3],"bfloat16"), False, False, )
paddle.isin(Tensor([4, 0],"bfloat16"), Tensor([2, 3],"bfloat16"), False, True, )
paddle.isin(Tensor([8, 0],"bfloat16"), Tensor([4, 0],"bfloat16"), False, False, )
paddle.isin(Tensor([8, 0],"bfloat16"), Tensor([4, 0],"bfloat16"), False, True, )
paddle.isin(Tensor([8, 0],"bfloat16"), Tensor([4, 256],"bfloat16"), False, False, )
paddle.isin(Tensor([8, 0],"bfloat16"), Tensor([4, 256],"bfloat16"), False, True, )
paddle.kthvalue(Tensor([0, 128, 10],"float64"), 2, -1, )
paddle.kthvalue(Tensor([0, 128, 10],"float64"), 2, 2, )
paddle.kthvalue(Tensor([0, 200, 40],"float32"), k=1, axis=1, )
paddle.kthvalue(Tensor([0, 200, 40],"float32"), k=1, axis=1, keepdim=True, )
paddle.kthvalue(Tensor([0, 200, 40],"float32"), k=2, )
paddle.kthvalue(Tensor([0, 30, 250],"float64"), 244, -1, )
paddle.kthvalue(Tensor([0, 30, 250],"float64"), 244, 2, )
paddle.kthvalue(Tensor([2, 0, 10],"float64"), 2, -1, )
paddle.kthvalue(Tensor([2, 0, 10],"float64"), 2, 2, )
paddle.kthvalue(Tensor([2, 0, 250],"float64"), 244, -1, )
paddle.kthvalue(Tensor([2, 0, 250],"float64"), 244, 2, )
paddle.kthvalue(Tensor([30, 0, 40],"float32"), k=2, )
paddle.kthvalue(Tensor([30, 200, 0],"float32"), k=1, axis=1, )
paddle.kthvalue(Tensor([30, 200, 0],"float32"), k=1, axis=1, keepdim=True, )
paddle.kthvalue(x=Tensor([0, 2, 4],"float64"), k=4, axis=2, keepdim=False, )
paddle.kthvalue(x=Tensor([0, 2, 4],"float64"), k=4, axis=2, keepdim=True, )
paddle.kthvalue(x=Tensor([3, 0, 4],"float32"), k=3, axis=0, )
paddle.kthvalue(x=Tensor([3, 0, 4],"float64"), k=3, axis=0, )
paddle.kthvalue(x=Tensor([3, 0, 4],"float64"), k=4, axis=2, keepdim=False, )
paddle.kthvalue(x=Tensor([3, 0, 4],"float64"), k=4, axis=2, keepdim=True, )
paddle.kthvalue(x=Tensor([3, 2, 0],"float32"), k=3, axis=0, )
paddle.kthvalue(x=Tensor([3, 2, 0],"float64"), k=3, axis=0, )
paddle.ldexp(Tensor([0],"float32"), Tensor([0],"int32"), )
paddle.ldexp(Tensor([0],"int64"), Tensor([0],"int32"), )
paddle.ldexp(Tensor([10, 20, 1],"float32"), Tensor([0],"int32"), )
paddle.linalg.slogdet(Tensor([0, 3, 3],"float32"), )
paddle.linalg.slogdet(Tensor([0, 3, 5, 5],"complex64"), )
paddle.linalg.slogdet(Tensor([0, 3, 5, 5],"float32"), )
paddle.linalg.slogdet(Tensor([0, 5, 5],"complex128"), )
paddle.linalg.slogdet(x=Tensor([0, 4, 4],"float64"), )
paddle.logaddexp(Tensor([0, 2, 3, 4],"float64"), Tensor([0, 2, 3, 4],"float64"), )
paddle.logaddexp(Tensor([0, 200, 300],"float32"), Tensor([0, 200, 300],"float32"), )
paddle.logaddexp(Tensor([0, 3, 2],"float16"), Tensor([0, 3, 2],"float32"), )
paddle.logaddexp(Tensor([1, 0, 3, 4],"float64"), Tensor([1, 0, 3, 4],"float64"), )
paddle.logaddexp(Tensor([1, 2, 0, 4],"float64"), Tensor([1, 2, 0, 4],"float64"), )
paddle.logaddexp(Tensor([1, 2, 3, 0],"float32"), Tensor([1, 2, 3, 0],"float32"), )
paddle.logaddexp(Tensor([1, 2, 3, 0],"float64"), Tensor([1, 2, 3, 0],"float64"), )
paddle.logaddexp(Tensor([1, 2, 3, 4],"float64"), Tensor([0, 2, 3, 4],"float64"), )
paddle.logaddexp(Tensor([10, 0, 300],"float32"), Tensor([10, 0, 300],"float32"), )
paddle.logaddexp(Tensor([10, 200, 0],"float32"), Tensor([10, 200, 0],"float32"), )
paddle.logaddexp(Tensor([4, 0, 2],"float16"), Tensor([4, 0, 2],"float32"), )
paddle.logaddexp(Tensor([4, 3, 0],"float16"), Tensor([4, 3, 0],"float32"), )
paddle.logcumsumexp(Tensor([0, 10, 10],"float32"), )
paddle.logcumsumexp(Tensor([0, 12],"float16"), dtype="float16", axis=1, )
paddle.logcumsumexp(Tensor([0, 12],"float16"), dtype="float16", axis=None, )
paddle.logcumsumexp(Tensor([0, 12],"float32"), dtype="float32", axis=1, )
paddle.logcumsumexp(Tensor([0, 12],"float32"), dtype="float32", axis=None, )
paddle.logcumsumexp(Tensor([0, 4],"float32"), )
paddle.logcumsumexp(Tensor([0, 4],"float32"), dtype="float32", )
paddle.logcumsumexp(Tensor([0],"float32"), )
paddle.logcumsumexp(Tensor([10, 0, 10],"float32"), )
paddle.logcumsumexp(Tensor([10, 0],"float16"), dtype="float16", axis=1, )
paddle.logcumsumexp(Tensor([10, 0],"float16"), dtype="float16", axis=None, )
paddle.logcumsumexp(Tensor([10, 0],"float32"), dtype="float32", axis=1, )
paddle.logcumsumexp(Tensor([10, 0],"float32"), dtype="float32", axis=None, )
paddle.logcumsumexp(Tensor([10, 10, 0],"float32"), )
paddle.logcumsumexp(Tensor([3, 0],"float32"), )
paddle.logcumsumexp(Tensor([3, 0],"float32"), dtype="float32", )
paddle.masked_fill(Tensor([0, 3],"float32"), Tensor([1, 3],"bool"), Tensor([1],"float32"), )
paddle.masked_fill(Tensor([0, 40],"float32"), Tensor([40],"bool"), Tensor([1],"float32"), )
paddle.masked_fill(Tensor([0],"float16"), Tensor([0],"bool"), Tensor([0],"float16"), )
paddle.masked_fill(Tensor([0],"float32"), Tensor([0],"bool"), Tensor([0],"float32"), )
paddle.masked_fill(Tensor([120],"float32"), Tensor([0, 120],"bool"), Tensor([1],"float32"), )
paddle.masked_fill(Tensor([3, 0],"float16"), Tensor([3, 1],"bool"), Tensor([1],"float16"), )
paddle.matmul(Tensor([0],"float16"), Tensor([2],"float16"), False, False, )
paddle.matmul(Tensor([0],"float32"), Tensor([1],"float32"), )
paddle.matmul(Tensor([0],"float32"), Tensor([10],"float32"), )
paddle.matmul(Tensor([0],"float32"), Tensor([10],"float32"), True, True, )
paddle.matmul(Tensor([0],"float32"), Tensor([2],"float32"), False, False, )
paddle.matmul(Tensor([1, 3, 2, 5, 5],"float16"), Tensor([0, 3, 2, 5, 4],"float16"), )
paddle.matmul(Tensor([1],"float32"), Tensor([0],"float32"), )
paddle.matmul(Tensor([10],"float32"), Tensor([0],"float32"), )
paddle.matmul(Tensor([10],"float32"), Tensor([0],"float32"), True, True, )
paddle.matmul(Tensor([2, 2],"float32"), Tensor([50000, 2, 0],"float32"), )
paddle.matmul(Tensor([2],"float16"), Tensor([0],"float16"), False, False, )
paddle.matmul(Tensor([2],"float32"), Tensor([0],"float32"), False, False, )
paddle.matmul(Tensor([23, 23],"float16"), Tensor([512, 23, 0],"float16"), )
paddle.matmul(Tensor([3, 3],"float64"), Tensor([50000, 2, 3, 0],"float64"), )
paddle.matmul(x=Tensor([0],"float32"), y=Tensor([10],"float32"), )
paddle.matmul(x=Tensor([0],"float64"), y=Tensor([10],"float64"), )
paddle.matmul(x=Tensor([10],"float32"), y=Tensor([0],"float32"), )
paddle.matmul(x=Tensor([10],"float64"), y=Tensor([0],"float64"), )
paddle.meshgrid(list[Tensor([0],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([0],"float32"),Tensor([0],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([0],"int64"),Tensor([0],"int64"),], indexing="ij", )
paddle.meshgrid(list[Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),Tensor([0],"int64"),], )
paddle.meshgrid(list[Tensor([1],"float32"),Tensor([0],"float32"),Tensor([1],"float32"),], )
paddle.meshgrid(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([10],"float64"),Tensor([0],"float64"),Tensor([10],"float64"),Tensor([10],"float64"),Tensor([10],"float64"),], )
paddle.meshgrid(list[Tensor([10],"float64"),Tensor([10],"float64"),Tensor([0],"float64"),Tensor([10],"float64"),Tensor([10],"float64"),], )
paddle.meshgrid(list[Tensor([10],"float64"),Tensor([10],"float64"),Tensor([10],"float64"),Tensor([0],"float64"),Tensor([10],"float64"),], )
paddle.meshgrid(list[Tensor([10],"float64"),Tensor([10],"float64"),Tensor([10],"float64"),Tensor([10],"float64"),Tensor([0],"float64"),], )
paddle.meshgrid(list[Tensor([10],"int64"),Tensor([0],"int64"),Tensor([10],"int64"),Tensor([10],"int64"),Tensor([10],"int64"),], )
paddle.meshgrid(list[Tensor([10],"int64"),Tensor([10],"int64"),Tensor([0],"int64"),Tensor([10],"int64"),Tensor([10],"int64"),], )
paddle.meshgrid(list[Tensor([10],"int64"),Tensor([10],"int64"),Tensor([10],"int64"),Tensor([0],"int64"),Tensor([10],"int64"),], )
paddle.meshgrid(list[Tensor([10],"int64"),Tensor([10],"int64"),Tensor([10],"int64"),Tensor([10],"int64"),Tensor([0],"int64"),], )
paddle.meshgrid(list[Tensor([100],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([140],"float32"),Tensor([0],"float32"),Tensor([1],"float32"),], )
paddle.meshgrid(list[Tensor([140],"float32"),Tensor([188],"float32"),Tensor([0],"float32"),], )
paddle.meshgrid(list[Tensor([4],"int64"),Tensor([0],"int64"),], indexing="ij", )
paddle.meshgrid(Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.meshgrid(Tensor([0],"float32"), Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.meshgrid(Tensor([0],"float32"), Tensor([0],"float32"), Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.meshgrid(Tensor([0],"float64"), Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.meshgrid(Tensor([0],"int64"), Tensor([0],"int64"), indexing="ij", )
paddle.meshgrid(Tensor([100],"float32"), Tensor([0],"float32"), )
paddle.meshgrid(Tensor([2],"float32"), Tensor([0],"float32"), Tensor([6],"float32"), )
paddle.meshgrid(Tensor([2],"float32"), Tensor([4],"float32"), Tensor([0],"float32"), )
paddle.meshgrid(Tensor([2],"float64"), Tensor([0],"float64"), Tensor([6],"float64"), )
paddle.meshgrid(Tensor([2],"float64"), Tensor([4],"float64"), Tensor([0],"float64"), )
paddle.meshgrid(Tensor([216],"float32"), Tensor([0],"float32"), Tensor([1],"float32"), Tensor([2],"float32"), )
paddle.meshgrid(Tensor([216],"float32"), Tensor([248],"float32"), Tensor([0],"float32"), Tensor([2],"float32"), )
paddle.meshgrid(Tensor([216],"float32"), Tensor([248],"float32"), Tensor([1],"float32"), Tensor([0],"float32"), )
paddle.meshgrid(Tensor([5],"int64"), Tensor([0],"int64"), indexing="ij", )
paddle.mm(input=Tensor([0],"float64"), mat2=Tensor([7],"float64"), )
paddle.mm(input=Tensor([7],"float64"), mat2=Tensor([0],"float64"), )
paddle.nanmedian(Tensor([0, 100],"float32"), axis=1, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=0, keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=0, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=-1, keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=-1, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=2, keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=-2, keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=2, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=-2, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=list[0,-1,], keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=list[0,-1,], keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=list[0,1,3,], keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=list[0,1,3,], keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=list[0,3,], keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=list[0,3,], keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=tuple(1,2,), keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=tuple(1,2,), keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=tuple(1,2,3,), keepdim=False, )
paddle.nanmedian(Tensor([0, 3, 4, 5],"float32"), axis=tuple(1,2,3,), keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 3],"float64"), axis=1, keepdim=False, )
paddle.nanmedian(Tensor([0, 3],"float64"), axis=1, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([0, 5],"float64"), axis=1, )
paddle.nanmedian(Tensor([0, 5],"float64"), axis=1, mode="min", )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=0, keepdim=False, )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=0, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=-1, keepdim=False, )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=-1, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=2, keepdim=False, )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=-2, keepdim=False, )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=2, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=-2, keepdim=False, mode="min", )
paddle.nanmedian(Tensor([2, 0, 4, 5],"float32"), axis=list[0,-1,], keepdim=False, )
paddle.nanquantile(Tensor([0, 3],"float32"), list[0.3,0.7,], 1, )
paddle.nanquantile(Tensor([0, 7, 6],"float64"), q=0.1, axis=list[1,2,], keepdim=True, )
paddle.nanquantile(Tensor([4, 0, 6],"float64"), q=0.75, axis=list[0,2,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 1024, 4, 80],"float16"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 1024, 4, 80],"float32"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 128, 28, 28],"float16"), output_size=7, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 128, 28, 28],"float32"), output_size=7, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 128, 32, 32],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 128, 32, 32],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 128, 32, 32],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 160, 16, 32],"float16"), output_size=2, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 160, 16, 32],"float16"), output_size=4, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 160, 16, 32],"float32"), output_size=2, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 160, 16, 32],"float32"), output_size=4, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 256, 2, 25],"float16"), output_size=list[1,25,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 256, 2, 25],"float32"), output_size=list[1,25,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 256, 56, 56],"float32"), output_size=list[7,7,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 4, 4],"float32"), output_size=list[3,3,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 4, 4],"float64"), output_size=list[1,4,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 4, 4],"float64"), output_size=list[2,3,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 4, 4],"float64"), output_size=list[3,3,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 7, 7],"float32"), list[2,5,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=5, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[2,5,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[3,3,], data_format="NHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[None,3,], data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 4, 4, 3],"float64"), output_size=3, data_format="NHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 4, 4, 3],"float64"), output_size=list[3,3,], data_format="NHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 4, 4, 3],"float64"), output_size=tuple(3,3,), data_format="NHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 512, 128, 128],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 512, 128, 128],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 512, 128, 128],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 512, 2, 2],"float32"), output_size=tuple(7,7,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([0, 512, 7, 7],"float32"), output_size=tuple(7,7,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 128, 128],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 128, 128],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 128, 128],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 16, 32],"float32"), output_size=2, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 16, 32],"float32"), output_size=4, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 2, 2],"float32"), output_size=tuple(7,7,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 32, 32],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 32, 32],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 0, 32, 32],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 1024, 0, 14],"float32"), output_size=1, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 1024, 0, 18],"float32"), output_size=1, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 1024, 14, 0],"float32"), output_size=1, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 1024, 18, 0],"float32"), output_size=1, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 0, 32],"float32"), output_size=tuple(1,1,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 0, 32],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 0, 32],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 0, 32],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 32, 0],"float32"), output_size=tuple(1,1,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 32, 0],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 32, 0],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 128, 32, 0],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 0, 10],"float32"), tuple(1,1,), )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 0, 11],"float32"), tuple(1,1,), )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 0, 32],"float32"), output_size=2, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 0, 32],"float32"), output_size=4, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 10, 0],"float32"), tuple(1,1,), )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 11, 0],"float32"), tuple(1,1,), )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 16, 0],"float32"), output_size=2, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 160, 16, 0],"float32"), output_size=4, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 2048, 0, 64],"float32"), output_size=tuple(1,1,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 2048, 62, 0],"float32"), output_size=tuple(1,1,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 0, 128],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 0, 128],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 0, 128],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 0, 2],"float32"), output_size=tuple(7,7,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 128, 0],"float32"), output_size=tuple(2,2,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 128, 0],"float32"), output_size=tuple(3,3,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 128, 0],"float32"), output_size=tuple(6,6,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1, 512, 2, 0],"float32"), output_size=tuple(7,7,), data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1024, 2048, 0, 7],"float32"), output_size=1, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([1024, 2048, 7, 0],"float32"), output_size=1, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 0, 28, 28],"float16"), output_size=7, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 0, 28, 28],"float32"), output_size=7, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 0, 4, 80],"float16"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 0, 4, 80],"float32"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 1024, 0, 80],"float16"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 1024, 0, 80],"float32"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 1024, 4, 0],"float16"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 1024, 4, 0],"float32"), list[1,40,], )
paddle.nn.functional.adaptive_avg_pool2d(Tensor([128, 128, 0, 28],"float16"), output_size=7, data_format="NCHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float64"), output_size=3, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[1,1,1,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[1,3,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[2,2,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[2,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 3, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 768, 16, 7, 10],"float16"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([0, 768, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 0, 16, 7, 10],"float16"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 0, 16, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 0, 7, 10],"float16"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 0, 7, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 0, 10],"float16"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 0, 10],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 0],"float16"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([1, 768, 16, 7, 0],"float32"), output_size=tuple(1,1,1,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 5, 7, 7],"float32"), list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 5, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[None,3,None,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float64"), output_size=3, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[1,1,1,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[1,3,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[2,2,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[2,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 0, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float64"), output_size=3, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[1,1,1,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[1,3,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[2,2,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[2,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 7, 7],"float32"), list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 7, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[None,3,None,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 0, 7],"float32"), list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 0, 7],"float32"), output_size=5, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[None,3,None,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 0],"float32"), list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 0],"float32"), output_size=5, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[2,3,5,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[3,3,3,], data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[None,3,None,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float64"), output_size=3, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[1,1,1,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[1,3,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[2,2,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[2,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 0, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float32"), output_size=list[3,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float64"), output_size=3, data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[1,1,1,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[1,3,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[2,2,2,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[2,3,3,], data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(Tensor([2, 3, 8, 32, 0],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", name=None, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=5, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=3, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[1,1,1,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[1,3,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[2,2,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=list[2,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([0, 3, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 5, 7, 7],"float32"), output_size=5, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 5, 7, 7],"float32"), output_size=list[None,3,None,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=3, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[1,1,1,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[1,3,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[2,2,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=list[2,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 0, 8, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=3, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[1,1,1,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[1,3,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[2,2,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=list[2,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=tuple(3,3,3,), )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 32, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 7, 7],"float32"), output_size=5, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[None,3,None,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 0, 7],"float32"), output_size=5, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 0, 7],"float32"), output_size=list[None,3,None,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 0],"float32"), output_size=5, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[2,3,5,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[3,3,3,], data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 5, 7, 0],"float32"), output_size=list[None,3,None,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=3, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[1,1,1,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[1,3,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[2,2,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=list[2,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=tuple(3,3,3,), )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 0, 32],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float32"), output_size=list[3,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=3, )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[1,1,1,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[1,3,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[2,2,2,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=list[2,3,3,], )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=tuple(3,3,3,), )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=tuple(3,3,3,), data_format="NCDHW", )
paddle.nn.functional.adaptive_avg_pool3d(x=Tensor([2, 3, 8, 32, 0],"float64"), output_size=tuple(3,3,3,), data_format="NDHWC", )
paddle.nn.functional.avg_pool1d(Tensor([0, 1, 120],"float32"), 25, 1, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 32],"float32"), 2, None, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 32],"float32"), kernel_size=2, stride=2, padding=list[0,], )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 8],"float32"), 2, 2, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 8],"float64"), 1, 1, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 8],"float64"), 2, 1, 0, True, True, None, )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 8],"float64"), 2, 1, 1, False, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 8],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([0, 3, 8],"float64"), 3, 4, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([13, 0, 120],"float32"), 25, 1, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([16, 0, 120],"float32"), 25, 1, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 32],"float32"), 2, None, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 32],"float32"), kernel_size=2, stride=2, padding=list[0,], )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 8],"float32"), 2, 2, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 8],"float64"), 1, 1, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 8],"float64"), 2, 1, 0, True, True, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 8],"float64"), 2, 1, 1, False, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 8],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 0, 8],"float64"), 3, 4, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 3, 0],"float64"), 2, 1, 1, False, False, None, )
paddle.nn.functional.avg_pool1d(Tensor([2, 3, 0],"float64"), 3, 4, 0, True, False, None, )
paddle.nn.functional.avg_pool1d(x=Tensor([0, 3, 8],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=1, stride=1, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=1, padding=0, ceil_mode=True, )
paddle.nn.functional.avg_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=1, padding=1, exclusive=False, )
paddle.nn.functional.avg_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=3, stride=4, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 0, 8],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=1, stride=1, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=1, padding=0, ceil_mode=True, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=1, padding=1, exclusive=False, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=3, stride=4, padding=0, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=2, stride=1, padding=1, exclusive=False, )
paddle.nn.functional.avg_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=3, stride=4, padding=0, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1, 4, 32],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1, 40, 44],"float32"), kernel_size=tuple(1,5,), stride=1, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1, 44, 40],"float32"), kernel_size=tuple(5,1,), stride=1, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1, 7, 32],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1024, 14, 14],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1024, 17, 17],"float16"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1024, 17, 17],"float32"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1024, 4, 4],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1024, 40, 54],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1024, 40, 60],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1024, 8, 8],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 104, 28, 28],"float16"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 104, 28, 28],"float32"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 128, 20, 20],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 128, 64, 64],"float16"), kernel_size=1, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 128, 64, 64],"float32"), kernel_size=1, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 128, 8, 50],"float16"), kernel_size=tuple(2,1,), stride=tuple(2,1,), padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 128, 8, 50],"float32"), kernel_size=tuple(2,1,), stride=tuple(2,1,), padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1280, 5, 5],"float32"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1536, 7, 7],"float16"), kernel_size=7, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 1536, 7, 7],"float32"), kernel_size=7, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 192, 25, 25],"float32"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 2, 4, 4],"float32"), kernel_size=2, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 256, 10, 10],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 256, 56, 56],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 16, 16],"float32"), kernel_size=2, stride=2, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[list[0,0,],list[0,0,],list[0,0,],list[0,0,],], divisor_override=4, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=list[2,2,], stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[2,2,], stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[1,1,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=True, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=list[0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=tuple(0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 384, 4, 80],"float32"), list[4,2,], )
paddle.nn.functional.avg_pool2d(Tensor([0, 4, 3, 3],"float32"), kernel_size=2, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 512, 13, 13],"float32"), kernel_size=5, stride=3, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 512, 3, 80],"float16"), kernel_size=list[3,2,], stride=list[3,2,], padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 512, 3, 80],"float32"), kernel_size=list[2,2,], stride=list[2,2,], padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 512, 3, 80],"float32"), kernel_size=list[3,2,], stride=list[3,2,], padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([0, 528, 13, 13],"float32"), kernel_size=5, stride=3, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 0, 10, 10],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 0, 20, 20],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 0, 3, 3],"float32"), kernel_size=2, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 0, 4, 4],"float32"), kernel_size=2, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 0, 40, 54],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 0, 40, 60],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 1024, 0, 54],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 1024, 0, 60],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([1, 1024, 40, 0],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([13, 0, 4, 32],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.avg_pool2d(Tensor([13, 0, 7, 32],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.avg_pool2d(Tensor([13, 1, 0, 32],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.avg_pool2d(Tensor([16, 0, 4, 4],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([16, 0, 8, 8],"float32"), kernel_size=tuple(2,2,), stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 13, 13],"float32"), kernel_size=5, stride=3, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 25, 25],"float32"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[list[0,0,],list[0,0,],list[0,0,],list[0,0,],], divisor_override=4, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=list[2,2,], stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[2,2,], stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[1,1,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=True, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=list[0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=tuple(0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 0, 5, 5],"float32"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 3, 0, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=True, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([2, 3, 4, 0],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=True, exclusive=False, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([256, 0, 8, 50],"float16"), kernel_size=tuple(2,1,), stride=tuple(2,1,), padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([256, 0, 8, 50],"float32"), kernel_size=tuple(2,1,), stride=tuple(2,1,), padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([256, 128, 0, 50],"float16"), kernel_size=tuple(2,1,), stride=tuple(2,1,), padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([256, 128, 0, 50],"float32"), kernel_size=tuple(2,1,), stride=tuple(2,1,), padding=0, ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([3, 0, 40, 44],"float32"), kernel_size=tuple(1,5,), stride=1, )
paddle.nn.functional.avg_pool2d(Tensor([3, 0, 44, 40],"float32"), kernel_size=tuple(5,1,), stride=1, )
paddle.nn.functional.avg_pool2d(Tensor([32, 0, 14, 14],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([32, 0, 56, 56],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([32, 1024, 0, 14],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([32, 1024, 14, 0],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([32, 256, 0, 56],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([32, 256, 56, 0],"float32"), kernel_size=2, stride=2, padding="SAME", ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([4, 0, 4, 80],"float32"), list[4,2,], )
paddle.nn.functional.avg_pool2d(Tensor([56, 0, 16, 16],"float32"), kernel_size=2, stride=2, )
paddle.nn.functional.avg_pool2d(Tensor([56, 0, 32, 32],"float32"), kernel_size=2, stride=2, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 17, 17],"float16"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 17, 17],"float32"), kernel_size=3, stride=1, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 28, 28],"float16"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 28, 28],"float32"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 3, 80],"float16"), kernel_size=list[3,2,], stride=list[3,2,], padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 3, 80],"float32"), kernel_size=list[3,2,], stride=list[3,2,], padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 64, 64],"float16"), kernel_size=1, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 64, 64],"float32"), kernel_size=1, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 7, 7],"float16"), kernel_size=7, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 0, 7, 7],"float32"), kernel_size=7, stride=1, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 104, 0, 28],"float16"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 104, 0, 28],"float32"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 104, 28, 0],"float16"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([64, 104, 28, 0],"float32"), kernel_size=3, stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(Tensor([8, 0, 3, 80],"float32"), kernel_size=list[2,2,], stride=list[2,2,], padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCHW", name=None, )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 32, 32],"float32"), kernel_size=list[2,2,], )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[2,2,], )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[0,0,], )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[1,1,], exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,], ceil_mode=True, exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=False, exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=list[0,0,], )
paddle.nn.functional.avg_pool2d(x=Tensor([0, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=tuple(0,0,), )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 32, 32],"float32"), kernel_size=list[2,2,], )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[2,2,], )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[0,0,], )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[1,1,], exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,], ceil_mode=True, exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=False, exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=list[0,0,], )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 0, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=tuple(0,0,), )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 3, 0, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,], ceil_mode=True, exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([2, 3, 4, 0],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,], ceil_mode=True, exclusive=False, )
paddle.nn.functional.avg_pool3d(Tensor([0, 1, 3, 1600, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([0, 1, 40, 40, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([0, 1, 7, 3, 1600],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([0, 1, 7, 40, 40],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([0, 8, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NDHWC", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 8, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NDHWC", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([3, 0, 3, 1600, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 0, 40, 40, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 0, 7, 3, 1600],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 0, 7, 40, 40],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([0, 8, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NDHWC", exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 8, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NDHWC", exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 0, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 0, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.binary_cross_entropy_with_logits(logit=Tensor([0, 19],"float32"), label=Tensor([0, 19],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(logit=Tensor([0, 26],"float32"), label=Tensor([0, 26],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(logit=Tensor([0],"float32"), label=Tensor([0],"float32"), reduction="sum", )
paddle.nn.functional.binary_cross_entropy_with_logits(logit=Tensor([64, 0],"float32"), label=Tensor([64, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 100, 2],"float32"), Tensor([0, 100, 2],"float32"), weight=Tensor([0, 100, 2],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 1000],"float32"), Tensor([0, 1000],"float32"), weight=None, reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 1000],"float32"), Tensor([0, 1000],"float32"), weight=Tensor([0, 1000],"float32"), reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 12544],"float32"), Tensor([0, 12544],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 160, 160],"float32"), Tensor([0, 160, 160],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 192, 11],"float32"), Tensor([0, 192, 11],"float32"), weight=Tensor([0, 192, 11],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 200, 80],"float32"), Tensor([0, 200, 80],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 3, 10, 10, 1],"float32"), Tensor([0, 3, 10, 10, 1],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 3, 10, 10, 80],"float32"), Tensor([0, 3, 10, 10, 80],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), "none", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), "sum", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), weight=Tensor([0, 3, 4, 10],"float64"), reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), weight=Tensor([0, 3, 4, 10],"float64"), reduction="sum", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 30],"float64"), Tensor([0, 30],"float64"), None, "none", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 30],"float64"), Tensor([0, 30],"float64"), None, "sum", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 30],"float64"), Tensor([0, 30],"float64"), weight=None, reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0, 30],"float64"), Tensor([0, 30],"float64"), weight=None, reduction="sum", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0],"float32"), Tensor([0],"float32"), None, "sum", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([0],"float32"), Tensor([0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 0, 11],"float32"), Tensor([1, 0, 11],"float32"), weight=Tensor([1, 0, 11],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 0, 2],"float32"), Tensor([1, 0, 2],"float32"), weight=Tensor([1, 0, 2],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 0],"float32"), Tensor([1, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 100, 0],"float32"), Tensor([1, 100, 0],"float32"), weight=Tensor([1, 100, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([1, 192, 0],"float32"), Tensor([1, 192, 0],"float32"), weight=Tensor([1, 192, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([12, 0, 10, 10, 1],"float32"), Tensor([12, 0, 10, 10, 1],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([12, 0, 10, 10, 80],"float32"), Tensor([12, 0, 10, 10, 80],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([12, 3, 0, 10, 1],"float32"), Tensor([12, 3, 0, 10, 1],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([12, 3, 0, 10, 80],"float32"), Tensor([12, 3, 0, 10, 80],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([12, 3, 10, 0, 1],"float32"), Tensor([12, 3, 10, 0, 1],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([12, 3, 10, 0, 80],"float32"), Tensor([12, 3, 10, 0, 80],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([12, 3, 10, 10, 0],"float32"), Tensor([12, 3, 10, 10, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([13, 0, 160],"float32"), Tensor([13, 0, 160],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([13, 160, 0],"float32"), Tensor([13, 160, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), "none", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), "sum", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), weight=Tensor([2, 0, 4, 10],"float64"), reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), weight=Tensor([2, 0, 4, 10],"float64"), reduction="sum", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 0, 80],"float32"), Tensor([2, 0, 80],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 200, 0],"float32"), Tensor([2, 200, 0],"float32"), reduction="none", )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), "none", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), "sum", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), weight=Tensor([2, 3, 0, 10],"float64"), reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), weight=Tensor([2, 3, 0, 10],"float64"), reduction="sum", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), "none", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), "sum", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), weight=Tensor([2, 3, 4, 0],"float64"), reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), weight=Tensor([2, 3, 4, 0],"float64"), reduction="sum", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([20, 0],"float64"), Tensor([20, 0],"float64"), None, "none", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([20, 0],"float64"), Tensor([20, 0],"float64"), None, "sum", None, None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([20, 0],"float64"), Tensor([20, 0],"float64"), weight=None, reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([20, 0],"float64"), Tensor([20, 0],"float64"), weight=None, reduction="sum", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 0],"float32"), Tensor([300, 0],"float32"), weight=None, reduction="none", pos_weight=None, )
paddle.nn.functional.binary_cross_entropy_with_logits(Tensor([300, 0],"float32"), Tensor([300, 0],"float32"), weight=Tensor([300, 0],"float32"), reduction="none", pos_weight=None, )
paddle.nn.functional.channel_shuffle(Tensor([2, 0, 4, 4],"float64"), 3, "NCHW", )
paddle.nn.functional.channel_shuffle(Tensor([2, 0, 4, 4],"float64"), 3, "NCHW", None, )
paddle.nn.functional.channel_shuffle(Tensor([2, 0, 4, 9],"float64"), 3, "NHWC", )
paddle.nn.functional.channel_shuffle(Tensor([2, 0, 4, 9],"float64"), 3, "NHWC", None, )
paddle.nn.functional.channel_shuffle(Tensor([2, 4, 0, 9],"float64"), 3, "NHWC", )
paddle.nn.functional.channel_shuffle(Tensor([2, 4, 0, 9],"float64"), 3, "NHWC", None, )
paddle.nn.functional.channel_shuffle(Tensor([2, 4, 4, 0],"float64"), 3, "NHWC", )
paddle.nn.functional.channel_shuffle(Tensor([2, 4, 4, 0],"float64"), 3, "NHWC", None, )
paddle.nn.functional.channel_shuffle(Tensor([2, 9, 0, 4],"float64"), 3, "NCHW", )
paddle.nn.functional.channel_shuffle(Tensor([2, 9, 0, 4],"float64"), 3, "NCHW", None, )
paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 0],"float64"), 3, "NCHW", )
paddle.nn.functional.channel_shuffle(Tensor([2, 9, 4, 0],"float64"), 3, "NCHW", None, )
paddle.nn.functional.conv1d(Tensor([1, 1024, 0],"float32"), Tensor([1024, 1024, 3],"float32"), bias=Tensor([1024],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 1024, 3000],"float32"), Tensor([1024, 1024, 0],"float32"), bias=Tensor([1024],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 0],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([128, 128, 0],"float32"), bias=Tensor([128],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 1280, 0],"float32"), Tensor([1280, 1280, 3],"float32"), bias=Tensor([1280],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 1280, 3000],"float32"), Tensor([1280, 1280, 0],"float32"), bias=Tensor([1280],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 20, 0],"float32"), Tensor([512, 20, 7],"float32"), bias=Tensor([512],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 20, 7],"float32"), Tensor([512, 20, 0],"float32"), bias=Tensor([512],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 0],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([256, 256, 0],"float32"), bias=Tensor([256],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 3, 5],"float32"), Tensor([4, 3, 0],"float32"), bias=Tensor([4],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 0, 32],"float32"), Tensor([16, 32, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([13, 0, 32],"float32"), Tensor([32, 1, 3],"float32"), bias=None, padding=1, stride=list[1,], dilation=list[1,], groups=32, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([13, 1, 0],"float32"), Tensor([32, 1, 0],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 1, 1024],"float32"), Tensor([32, 1, 0],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 20, 0],"float32"), Tensor([256, 20, 0],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 20, 0],"float32"), Tensor([256, 20, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 20, 2048],"float32"), Tensor([256, 20, 0],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 24, 0],"float32"), Tensor([24, 12, 16],"float32"), bias=Tensor([24],"float32"), padding=8, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 24, 14],"float32"), Tensor([24, 12, 0],"float32"), bias=Tensor([24],"float32"), padding=8, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 256, 0],"float32"), Tensor([20, 256, 0],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 256, 0],"float32"), Tensor([20, 256, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 256, 2048],"float32"), Tensor([20, 256, 0],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 0],"float32"), Tensor([32, 16, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 0],"float32"), Tensor([32, 32, 0],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 0],"float32"), Tensor([64, 8, 1],"float32"), bias=Tensor([64],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 255],"float32"), Tensor([32, 32, 0],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 7],"float32"), Tensor([32, 16, 0],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 7],"float32"), Tensor([64, 8, 0],"float32"), bias=Tensor([64],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 64, 0],"float32"), Tensor([32, 64, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 64, 0],"float32"), Tensor([64, 1, 4],"float32"), bias=Tensor([64],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=64, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 64, 10],"float32"), Tensor([64, 1, 0],"float32"), bias=Tensor([64],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=64, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 64, 1007],"float32"), Tensor([64, 1, 0],"float32"), bias=Tensor([64],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=64, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 64, 7],"float32"), Tensor([32, 64, 0],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 7, 32],"float32"), Tensor([16, 32, 0],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([13, 7, 32],"float32"), Tensor([32, 1, 0],"float32"), bias=None, padding=1, stride=list[1,], dilation=list[1,], groups=32, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=128, stride=list[1,], dilation=list[128,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=16, stride=list[1,], dilation=list[16,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=2, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=256, stride=list[1,], dilation=list[256,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=32, stride=list[1,], dilation=list[32,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=4, stride=list[1,], dilation=list[4,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=512, stride=list[1,], dilation=list[512,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=64, stride=list[1,], dilation=list[64,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 0],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=8, stride=list[1,], dilation=list[8,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=128, stride=list[1,], dilation=list[128,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=16, stride=list[1,], dilation=list[16,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=2, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=256, stride=list[1,], dilation=list[256,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=32, stride=list[1,], dilation=list[32,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=4, stride=list[1,], dilation=list[4,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=512, stride=list[1,], dilation=list[512,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 25500],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([128],"float32"), padding=64, stride=list[1,], dilation=list[64,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 80, 0],"float32"), Tensor([128, 80, 0],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 80, 0],"float32"), Tensor([128, 80, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 80, 0],"float32"), Tensor([80, 80, 0],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 80, 25500],"float32"), Tensor([128, 80, 0],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 80, 89],"float32"), Tensor([80, 80, 0],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 0],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 0],"float32"), Tensor([6, 1, 3],"float32"), bias=Tensor([6],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 0],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 0],"float64"), Tensor([6, 1, 3],"float64"), bias=Tensor([6],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([6, 1, 0],"float32"), bias=Tensor([6],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([6, 1, 0],"float64"), bias=Tensor([6],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 4, 3],"float32"), Tensor([2, 3, 0],"float32"), bias=Tensor([2],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([2, 4, 3],"float64"), Tensor([2, 3, 0],"float64"), bias=Tensor([2],"float64"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([4, 0, 6],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([4, 0, 6],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([4, 16, 3],"float32"), Tensor([6, 1, 0],"float32"), bias=Tensor([6],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([4, 16, 6],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([4, 16, 6],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([4, 6, 0],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding="same", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 0],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 0],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([512, 6, 0],"float32"), bias=Tensor([512],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([512, 6, 0],"float32"), bias=Tensor([512],"float32"), padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding="same", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding=0, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding=list[1,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 6, 0],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([52, 0, 32],"float32"), Tensor([16, 32, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([52, 0, 32],"float32"), Tensor([32, 1, 3],"float32"), bias=None, padding=1, stride=list[1,], dilation=list[1,], groups=32, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([52, 7, 32],"float32"), Tensor([16, 32, 0],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([52, 7, 32],"float32"), Tensor([32, 1, 0],"float32"), bias=None, padding=1, stride=list[1,], dilation=list[1,], groups=32, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([8, 256, 0],"float16"), Tensor([256, 64, 3],"float16"), bias=Tensor([256],"float16"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([8, 256, 0],"float32"), Tensor([256, 64, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([8, 256, 100],"float16"), Tensor([256, 64, 0],"float16"), bias=Tensor([256],"float16"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([8, 256, 100],"float32"), Tensor([256, 64, 0],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 0],"float32"), weight=Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 0],"float32"), weight=Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 0],"float32"), weight=Tensor([6, 1, 3],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 0],"float64"), weight=Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 0],"float64"), weight=Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 0],"float64"), weight=Tensor([6, 1, 3],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=list[1,], padding=1, dilation=2, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=list[1,], padding=list[1,], dilation=tuple(2,), )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 2],"float32"), bias=Tensor([0],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=list[1,], padding=1, dilation=2, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=list[1,], padding=list[1,], dilation=tuple(2,), )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float32"), weight=Tensor([6, 1, 0],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=list[1,], padding=1, dilation=2, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=list[1,], padding=list[1,], dilation=tuple(2,), )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=list[1,], padding=1, dilation=2, )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=list[1,], padding=list[1,], dilation=tuple(2,), )
paddle.nn.functional.conv1d(x=Tensor([2, 3, 4],"float64"), weight=Tensor([6, 1, 0],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv1d(x=Tensor([2, 4, 3],"float32"), weight=Tensor([2, 3, 0],"float32"), bias=Tensor([2],"float32"), stride=1, padding=0, data_format="NLC", )
paddle.nn.functional.conv1d(x=Tensor([2, 4, 3],"float64"), weight=Tensor([2, 3, 0],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 128, 112],"float32"), Tensor([128, 64, 8],"float32"), bias=Tensor([64],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 16, 6],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=18, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 16, 6],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 16, 6],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=2, padding=0, stride=list[3,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 2, 3],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 2, 3],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 2, 3],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 2, 3],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 256, 28],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 16],"float32"), Tensor([3, 2, 3],"float32"), bias=Tensor([6],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float32"), Tensor([3, 2, 3],"float32"), bias=Tensor([2],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 3, 2],"float64"), Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 6, 16],"float32"), Tensor([6, 4, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 6, 16],"float32"), Tensor([6, 8, 1],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 6, 16],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=list[36,], output_padding=0, padding=0, stride=list[2,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 6, 16],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 6, 16],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[2,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 6, 16],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([0, 6, 16],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=list[2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([1, 128, 0],"float32"), Tensor([128, 64, 8],"float32"), bias=Tensor([64],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([1, 128, 112],"float32"), Tensor([128, 0, 8],"float32"), bias=Tensor([64],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([1, 128, 112],"float32"), Tensor([128, 64, 0],"float32"), bias=Tensor([64],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([1, 256, 0],"float32"), Tensor([256, 128, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([1, 256, 28],"float32"), Tensor([256, 0, 8],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([1, 256, 28],"float32"), Tensor([256, 128, 0],"float32"), bias=Tensor([128],"float32"), output_size=None, output_padding=0, padding=2, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 0, 3],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 0, 3],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 0, 3],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 0, 3],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 2, 3],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 2, 3],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 2, 3],"float32"), Tensor([3, 1, 0],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 2, 3],"float64"), Tensor([3, 0, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 2, 3],"float64"), Tensor([3, 0, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 2, 3],"float64"), Tensor([3, 1, 0],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=1, padding=list[1,], stride=list[2,], dilation=list[1,], groups=3, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float32"), Tensor([3, 2, 3],"float32"), bias=Tensor([2],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 0],"float64"), Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([2],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([3],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 1, 0],"float32"), bias=Tensor([1],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([0],"float32"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([0],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 1, 3],"float32"), bias=Tensor([0],"float32"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float32"), Tensor([3, 2, 0],"float32"), bias=Tensor([2],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 0, 3],"float64"), bias=Tensor([2],"float64"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 0, 3],"float64"), bias=Tensor([3],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 1, 0],"float64"), bias=Tensor([1],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), output_size=None, output_padding=0, padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), output_size=None, output_padding=0, padding=list[1,], stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([2, 3, 2],"float64"), Tensor([3, 2, 0],"float64"), bias=Tensor([2],"float64"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 0, 6],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 0, 6],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=2, padding=0, stride=list[3,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 16, 6],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=18, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 16, 6],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 16, 6],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=2, padding=0, stride=list[3,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 16, 6],"float32"), Tensor([6, 8, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 16, 6],"float32"), Tensor([6, 8, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=2, padding=0, stride=list[3,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 3, 0],"float32"), Tensor([3, 2, 3],"float32"), bias=Tensor([6],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 3, 16],"float32"), Tensor([3, 0, 3],"float32"), bias=Tensor([6],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 3, 16],"float32"), Tensor([3, 2, 0],"float32"), bias=Tensor([6],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 0],"float32"), Tensor([6, 4, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 0],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 0],"float32"), Tensor([6, 8, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[2,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 0, 1],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=list[36,], output_padding=0, padding=0, stride=list[2,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[2,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 0, 3],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=list[2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 4, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 8, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 8, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=0, stride=list[2,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 8, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 8, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(Tensor([4, 6, 16],"float32"), Tensor([6, 8, 0],"float32"), bias=Tensor([8],"float32"), output_size=None, output_padding=0, padding=list[2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 2, 3],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=3, dilation=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 2, 3],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 2, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=3, dilation=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 2, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 2, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,], output_padding=0, groups=3, dilation=1, output_size=None, data_format="NLC", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 2, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,], output_padding=1, groups=3, dilation=1, output_size=None, data_format="NLC", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=3, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float32"), weight=Tensor([3, 2, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=3, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], output_padding=0, groups=1, dilation=2, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,], output_padding=0, groups=3, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 2],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 5],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding="SaME", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 5],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding="vALiD", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 8],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[4,4,], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 3, 8],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[3,4,],], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([0, 8, 3],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[list[0,0,],list[3,4,],list[0,0,],], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 0, 3],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=3, dilation=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 0, 3],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 0, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=3, dilation=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 0, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 0, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,], output_padding=0, groups=3, dilation=1, output_size=None, data_format="NLC", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 0, 3],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,], output_padding=1, groups=3, dilation=1, output_size=None, data_format="NLC", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=3, dilation=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float32"), weight=Tensor([3, 1, 0],"float32"), bias=Tensor([1],"float32"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=3, dilation=1, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,], output_padding=0, groups=3, dilation=1, output_size=None, data_format="NLC", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,], output_padding=1, groups=3, dilation=1, output_size=None, data_format="NLC", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float64"), weight=Tensor([3, 1, 0],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], groups=3, dilation=1, data_format="NLC", output_padding=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 2, 3],"float64"), weight=Tensor([3, 1, 0],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,], output_padding=1, groups=3, dilation=1, output_size=None, data_format="NLC", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=3, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float32"), weight=Tensor([3, 2, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=3, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], output_padding=0, groups=1, dilation=2, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,], output_padding=0, groups=3, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding="SaME", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding="vALiD", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 0],"float64"), weight=Tensor([3, 2, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,], groups=3, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 1, 0],"float32"), bias=Tensor([1],"float32"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 1, 3],"float32"), bias=Tensor([0],"float32"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float32"), weight=Tensor([3, 2, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], groups=3, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,], output_padding=0, groups=1, dilation=2, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,], output_padding=0, groups=3, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 0],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 0],"float64"), bias=Tensor([1],"float64"), stride=2, padding=list[1,], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=1, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,], groups=1, dilation=2, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,], output_padding=0, groups=1, dilation=2, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), stride=2, padding=list[1,], groups=1, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 1, 3],"float64"), bias=Tensor([0],"float64"), stride=2, padding=list[1,], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 2, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 2],"float64"), weight=Tensor([3, 2, 0],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", name=None, )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 5],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding="SaME", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 5],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding="vALiD", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 5],"float64"), weight=Tensor([3, 2, 0],"float64"), bias=Tensor([2],"float64"), stride=1, padding="SaME", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 5],"float64"), weight=Tensor([3, 2, 0],"float64"), bias=Tensor([2],"float64"), stride=1, padding="vALiD", output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 8],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[4,4,], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 8],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[3,4,],], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 3, 8],"float64"), weight=Tensor([3, 2, 0],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[3,4,],], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NCL", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 8, 3],"float64"), weight=Tensor([3, 0, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[list[0,0,],list[3,4,],list[0,0,],], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NLC", )
paddle.nn.functional.conv1d_transpose(x=Tensor([2, 8, 3],"float64"), weight=Tensor([3, 2, 0],"float64"), bias=Tensor([2],"float64"), stride=1, padding=list[list[0,0,],list[3,4,],list[0,0,],], output_padding=0, groups=1, dilation=1, output_size=None, data_format="NLC", )
paddle.nn.functional.conv2d(Tensor([1, 1, 0, 165],"float32"), Tensor([64, 1, 0, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1, 0, 261],"float32"), Tensor([64, 1, 0, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1, 0, 32],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([6],"float32"), padding=1, stride=list[1,1,], dilation=list[1,1,], groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 1, 101, 0],"float32"), Tensor([64, 1, 7, 0],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1, 101, 165],"float32"), Tensor([64, 1, 0, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1, 101, 165],"float32"), Tensor([64, 1, 7, 0],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1, 101, 261],"float32"), Tensor([64, 1, 0, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1, 101, 261],"float32"), Tensor([64, 1, 7, 0],"float32"), None, list[2,2,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1, 32, 0],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([6],"float32"), padding=1, stride=list[1,1,], dilation=list[1,1,], groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 1, 32, 32],"float32"), Tensor([6, 1, 0, 3],"float32"), bias=Tensor([6],"float32"), padding=1, stride=list[1,1,], dilation=list[1,1,], groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 1, 32, 32],"float32"), Tensor([6, 1, 3, 0],"float32"), bias=Tensor([6],"float32"), padding=1, stride=list[1,1,], dilation=list[1,1,], groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 128],"float32"), Tensor([1024, 256, 0, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 128],"float32"), Tensor([1024, 256, 3, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 128],"float32"), Tensor([12, 256, 0, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 128],"float32"), Tensor([12, 256, 1, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 256],"float32"), Tensor([1024, 128, 0, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 256],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 256],"float32"), Tensor([24, 128, 0, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 256],"float32"), Tensor([24, 128, 1, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 26],"float32"), Tensor([256, 1024, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 26],"float32"), Tensor([256, 1024, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 32],"float32"), Tensor([256, 1024, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 0, 32],"float32"), Tensor([256, 1024, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 10, 0],"float32"), Tensor([256, 1024, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 10, 0],"float32"), Tensor([256, 1024, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 10, 26],"float32"), Tensor([256, 1024, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 10, 26],"float32"), Tensor([256, 1024, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 12, 0],"float32"), Tensor([256, 1024, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 12, 0],"float32"), Tensor([256, 1024, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 12, 32],"float32"), Tensor([256, 1024, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 12, 32],"float32"), Tensor([256, 1024, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 0],"float32"), Tensor([1024, 256, 3, 0],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 0],"float32"), Tensor([1024, 256, 3, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 0],"float32"), Tensor([12, 256, 1, 0],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 0],"float32"), Tensor([12, 256, 1, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 128],"float32"), Tensor([1024, 256, 0, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 128],"float32"), Tensor([1024, 256, 3, 0],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 128],"float32"), Tensor([12, 256, 0, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 128, 128],"float32"), Tensor([12, 256, 1, 0],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 0],"float32"), Tensor([1024, 128, 3, 0],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 0],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 0],"float32"), Tensor([24, 128, 1, 0],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 0],"float32"), Tensor([24, 128, 1, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([1024, 128, 0, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([1024, 128, 3, 0],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([24, 128, 0, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 1024, 256, 256],"float32"), Tensor([24, 128, 1, 0],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 20],"float32"), Tensor([128, 128, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 20],"float32"), Tensor([128, 128, 3, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 256],"float32"), Tensor([128, 128, 0, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 256],"float32"), Tensor([128, 128, 3, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 256],"float32"), Tensor([3, 128, 0, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 256],"float32"), Tensor([3, 128, 1, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 32],"float32"), Tensor([128, 128, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 0, 32],"float32"), Tensor([128, 128, 3, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 12, 0],"float32"), Tensor([128, 128, 3, 0],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 12, 0],"float32"), Tensor([128, 128, 3, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 12, 20],"float32"), Tensor([128, 128, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 12, 20],"float32"), Tensor([128, 128, 3, 0],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 12, 32],"float32"), Tensor([128, 128, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 12, 32],"float32"), Tensor([128, 128, 3, 0],"float32"), None, list[1,1,], 1, list[1,1,], 1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 0],"float32"), Tensor([128, 128, 3, 0],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 0],"float32"), Tensor([128, 128, 3, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 0],"float32"), Tensor([3, 128, 1, 0],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 0],"float32"), Tensor([3, 128, 1, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 256],"float32"), Tensor([128, 128, 0, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 256],"float32"), Tensor([128, 128, 3, 0],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 256],"float32"), Tensor([3, 128, 0, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 128, 256, 256],"float32"), Tensor([3, 128, 1, 0],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 128],"float32"), Tensor([2048, 256, 0, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 128],"float32"), Tensor([2048, 256, 3, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 128],"float32"), Tensor([24, 256, 0, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 128],"float32"), Tensor([24, 256, 1, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 16],"float32"), Tensor([12, 512, 0, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 16],"float32"), Tensor([12, 512, 1, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 16],"float32"), Tensor([2048, 512, 0, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 0, 16],"float32"), Tensor([2048, 512, 3, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 0],"float32"), Tensor([2048, 256, 3, 0],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 0],"float32"), Tensor([2048, 256, 3, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 0],"float32"), Tensor([24, 256, 1, 0],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 0],"float32"), Tensor([24, 256, 1, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 128],"float32"), Tensor([2048, 256, 0, 3],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 128],"float32"), Tensor([2048, 256, 3, 0],"float32"), padding=1, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 128],"float32"), Tensor([24, 256, 0, 1],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 128, 128],"float32"), Tensor([24, 256, 1, 0],"float32"), padding=0, groups=8, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 0],"float32"), Tensor([12, 512, 1, 0],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 0],"float32"), Tensor([12, 512, 1, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 0],"float32"), Tensor([2048, 512, 3, 0],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 0],"float32"), Tensor([2048, 512, 3, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 16],"float32"), Tensor([12, 512, 0, 1],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 16],"float32"), Tensor([12, 512, 1, 0],"float32"), padding=0, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 16],"float32"), Tensor([2048, 512, 0, 3],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 2048, 16, 16],"float32"), Tensor([2048, 512, 3, 0],"float32"), padding=1, groups=4, )
paddle.nn.functional.conv2d(Tensor([1, 256, 0, 128],"float32"), Tensor([256, 256, 0, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 0, 128],"float32"), Tensor([256, 256, 3, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 0, 128],"float32"), Tensor([3, 256, 0, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 0, 128],"float32"), Tensor([3, 256, 1, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 0],"float32"), Tensor([256, 256, 3, 0],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 0],"float32"), Tensor([256, 256, 3, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 0],"float32"), Tensor([3, 256, 1, 0],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 0],"float32"), Tensor([3, 256, 1, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 128],"float32"), Tensor([256, 256, 0, 3],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 128],"float32"), Tensor([256, 256, 3, 0],"float32"), padding=1, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 128],"float32"), Tensor([3, 256, 0, 1],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 256, 128, 128],"float32"), Tensor([3, 256, 1, 0],"float32"), padding=0, groups=1, )
paddle.nn.functional.conv2d(Tensor([1, 3, 0, 224],"float32"), Tensor([3, 3, 3, 3],"float32"), Tensor([3],"float32"), list[3,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 3, 0, 224],"float32"), Tensor([3, 3, 3, 3],"float32"), Tensor([3],"float32"), list[4,3,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 3, 224, 0],"float32"), Tensor([3, 3, 3, 3],"float32"), Tensor([3],"float32"), list[3,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 3, 224, 0],"float32"), Tensor([3, 3, 3, 3],"float32"), Tensor([3],"float32"), list[4,3,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 3, 224, 224],"float32"), Tensor([3, 3, 0, 3],"float32"), Tensor([3],"float32"), list[3,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 3, 224, 224],"float32"), Tensor([3, 3, 0, 3],"float32"), Tensor([3],"float32"), list[4,3,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 3, 224, 224],"float32"), Tensor([3, 3, 3, 0],"float32"), Tensor([3],"float32"), list[3,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 3, 224, 224],"float32"), Tensor([3, 3, 3, 0],"float32"), Tensor([3],"float32"), list[4,3,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 6, 16, 16],"float32"), Tensor([16, 6, 0, 5],"float32"), bias=Tensor([16],"float32"), padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([1, 6, 16, 16],"float32"), Tensor([16, 6, 5, 0],"float32"), bias=Tensor([16],"float32"), padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([1024, 1, 0, 131],"float32"), Tensor([1, 1, 0, 4],"float32"), )
paddle.nn.functional.conv2d(Tensor([1024, 1, 0, 258],"float32"), Tensor([1, 1, 0, 4],"float32"), )
paddle.nn.functional.conv2d(Tensor([1024, 1, 131, 0],"float32"), Tensor([1, 1, 4, 0],"float32"), )
paddle.nn.functional.conv2d(Tensor([1024, 1, 131, 131],"float32"), Tensor([1, 1, 0, 4],"float32"), )
paddle.nn.functional.conv2d(Tensor([1024, 1, 131, 131],"float32"), Tensor([1, 1, 4, 0],"float32"), )
paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 0],"float32"), Tensor([1, 1, 4, 0],"float32"), )
paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 0, 4],"float32"), )
paddle.nn.functional.conv2d(Tensor([1024, 1, 258, 258],"float32"), Tensor([1, 1, 4, 0],"float32"), )
paddle.nn.functional.conv2d(Tensor([16, 3, 0, 260],"float32"), weight=Tensor([3, 1, 0, 5],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([16, 3, 0, 268],"float32"), weight=Tensor([3, 1, 0, 13],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([16, 3, 260, 0],"float32"), weight=Tensor([3, 1, 5, 0],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([16, 3, 260, 260],"float32"), weight=Tensor([3, 1, 0, 5],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([16, 3, 260, 260],"float32"), weight=Tensor([3, 1, 5, 0],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([16, 3, 268, 0],"float32"), weight=Tensor([3, 1, 13, 0],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([16, 3, 268, 268],"float32"), weight=Tensor([3, 1, 0, 13],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([16, 3, 268, 268],"float32"), weight=Tensor([3, 1, 13, 0],"float32"), groups=3, )
paddle.nn.functional.conv2d(Tensor([2, 192, 0, 4],"float32"), Tensor([384, 192, 0, 1],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 0, 4],"float32"), Tensor([384, 192, 1, 1],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 0, 4],"float32"), Tensor([48, 192, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 0, 4],"float32"), Tensor([48, 192, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 0, 4],"float32"), Tensor([96, 192, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 0, 4],"float32"), Tensor([96, 192, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 0],"float32"), Tensor([384, 192, 1, 0],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 0],"float32"), Tensor([384, 192, 1, 1],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 0],"float32"), Tensor([48, 192, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 0],"float32"), Tensor([48, 192, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 0],"float32"), Tensor([96, 192, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 0],"float32"), Tensor([96, 192, 1, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 4],"float32"), Tensor([384, 192, 0, 1],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 4],"float32"), Tensor([384, 192, 1, 0],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 4],"float32"), Tensor([48, 192, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 4],"float32"), Tensor([48, 192, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 4],"float32"), Tensor([96, 192, 0, 1],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 192, 4, 4],"float32"), Tensor([96, 192, 1, 0],"float32"), None, list[1,1,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 24, 0, 8],"float32"), Tensor([24, 24, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 24, 0, 8],"float32"), Tensor([24, 24, 3, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 24, 8, 0],"float32"), Tensor([24, 24, 3, 0],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 24, 8, 0],"float32"), Tensor([24, 24, 3, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 24, 8, 8],"float32"), Tensor([24, 24, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 24, 8, 8],"float32"), Tensor([24, 24, 3, 0],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 3, 0, 37],"float32"), Tensor([64, 3, 0, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 3, 37, 0],"float32"), Tensor([64, 3, 7, 0],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 3, 37, 37],"float32"), Tensor([64, 3, 0, 7],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 3, 37, 37],"float32"), Tensor([64, 3, 7, 0],"float32"), None, list[2,2,], 0, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 48, 0, 4],"float32"), Tensor([48, 48, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 48, 0, 4],"float32"), Tensor([48, 48, 3, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 48, 4, 0],"float32"), Tensor([48, 48, 3, 0],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 48, 4, 0],"float32"), Tensor([48, 48, 3, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 48, 4, 4],"float32"), Tensor([48, 48, 0, 3],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([2, 48, 4, 4],"float32"), Tensor([48, 48, 3, 0],"float32"), None, list[1,1,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 16, 0, 2],"float32"), Tensor([16, 16, 0, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 16, 0, 2],"float32"), Tensor([16, 16, 3, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 16, 2, 0],"float32"), Tensor([16, 16, 3, 0],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 16, 2, 0],"float32"), Tensor([16, 16, 3, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 16, 2, 2],"float32"), Tensor([16, 16, 0, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 16, 2, 2],"float32"), Tensor([16, 16, 3, 0],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 3, 0, 32],"float32"), Tensor([64, 3, 0, 7],"float32"), None, list[2,2,], 3, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 3, 0, 32],"float32"), Tensor([64, 3, 7, 7],"float32"), None, list[2,2,], 3, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 3, 32, 0],"float32"), Tensor([64, 3, 7, 0],"float32"), None, list[2,2,], 3, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 3, 32, 0],"float32"), Tensor([64, 3, 7, 7],"float32"), None, list[2,2,], 3, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 3, 32, 32],"float32"), Tensor([64, 3, 0, 7],"float32"), None, list[2,2,], 3, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 3, 32, 32],"float32"), Tensor([64, 3, 7, 0],"float32"), None, list[2,2,], 3, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 8, 0, 4],"float32"), Tensor([8, 8, 0, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 8, 0, 4],"float32"), Tensor([8, 8, 3, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 8, 4, 0],"float32"), Tensor([8, 8, 3, 0],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 8, 4, 0],"float32"), Tensor([8, 8, 3, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 8, 4, 4],"float32"), Tensor([8, 8, 0, 3],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([3, 8, 4, 4],"float32"), Tensor([8, 8, 3, 0],"float32"), None, list[2,2,], 1, list[1,1,], 1, "NCHW", )
paddle.nn.functional.conv2d(Tensor([4, 16, 0, 3],"float32"), Tensor([5, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,], stride=1, dilation=2, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 0, 3],"float32"), Tensor([5, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,], stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 0, 3],"float32"), Tensor([5, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,], stride=2, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 0, 3],"float32"), Tensor([5, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,], stride=1, dilation=2, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,], stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,], stride=2, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,], stride=1, dilation=2, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[1,2,], stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,], stride=2, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 16, 16, 3],"float32"), Tensor([5, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d(Tensor([4, 3, 0, 16],"float32"), Tensor([5, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([4, 3, 16, 0],"float32"), Tensor([5, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([4, 3, 16, 16],"float32"), Tensor([5, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([4, 3, 16, 16],"float32"), Tensor([5, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([4, 6, 0, 16],"float32"), Tensor([12, 1, 0, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([4, 6, 0, 16],"float32"), Tensor([8, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d(Tensor([4, 6, 16, 0],"float32"), Tensor([12, 1, 3, 0],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 1024, 128, 128],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([0, 1024, 16, 16],"float32"), Tensor([1024, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1024, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 1024, 16, 16],"float32"), Tensor([1024, 256, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 1024, 2, 2],"float32"), Tensor([1024, 512, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 128, 124, 108],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 128, 128, 128],"float32"), Tensor([128, 3, 4, 4],"float32"), bias=Tensor([3],"float32"), padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 128, 128, 128],"float32"), Tensor([128, 64, 3, 3],"float32"), bias=Tensor([64],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 128, 32, 32],"float32"), Tensor([128, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 128, 38, 68],"float32"), Tensor([128, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 128, 80, 80],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=Tensor([128],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 128, 94, 70],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 3],"float32"), Tensor([3, 5, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 4],"float32"), Tensor([4, 1, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=1, groups=4, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=tuple(2,1,), groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 6],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 16, 16, 6],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 2, 6],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 2, 6],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 3, 3],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding="SAME", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 3, 3],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding="VALID", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2, 3, 3],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding=list[1,0,0,1,], )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2048, 128, 128],"float32"), Tensor([2048, 128, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([0, 2048, 16, 16],"float32"), Tensor([2048, 512, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 128, 128],"float32"), Tensor([256, 128, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 14, 14],"float32"), Tensor([256, 256, 2, 2],"float32"), bias=Tensor([256],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 16, 16],"float32"), Tensor([256, 1, 16, 16],"float32"), bias=None, padding=4, output_padding=0, stride=list[8,8,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 16, 16],"float32"), Tensor([256, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 19, 34],"float32"), Tensor([256, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 32, 32],"float32"), Tensor([256, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 47, 35],"float32"), Tensor([256, 128, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 62, 54],"float32"), Tensor([256, 128, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 256, 64, 64],"float32"), Tensor([256, 128, 3, 3],"float32"), bias=Tensor([128],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 16, 16],"float32"), Tensor([3, 2, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 16, 16],"float32"), Tensor([3, 5, 3, 3],"float32"), None, output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float32"), Tensor([3, 10, 27, 27],"float32"), bias=Tensor([10],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 2, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 3, 2],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding=list[1,1,], data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 3, 7, 7],"float32"), Tensor([3, 6, 5, 5],"float32"), bias=Tensor([6],"float32"), padding=2, output_padding=list[1,1,], stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 4, 16, 16],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 4, 16, 16],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 4, 16, 16],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 4, 16, 16],"float32"), Tensor([4, 4, 3, 3],"float32"), Tensor([4],"float32"), output_size=list[18,34,], padding="valid", stride=tuple(1,2,), dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 4, 3, 3],"float64"), Tensor([4, 2, 1, 1],"float64"), groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([0, 4096, 16, 16],"float32"), Tensor([4096, 512, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([0, 512, 16, 16],"float32"), Tensor([512, 512, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([0, 512, 32, 32],"float32"), Tensor([512, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=512, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 4, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 1, 1],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,), output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="same", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=list[20,36,], data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[2,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,1,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 16, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 2, 2],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 2, 2],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 6, 2, 2],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 64, 248, 216],"float32"), Tensor([64, 128, 1, 1],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 64, 32, 32],"float32"), Tensor([64, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 64, 38, 68],"float32"), Tensor([64, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 64, 64, 64],"float32"), Tensor([64, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 64, 76, 136],"float32"), Tensor([64, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([0, 96, 2, 2],"float32"), Tensor([96, 96, 4, 4],"float32"), bias=Tensor([96],"float32"), padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 0, 128],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 0, 16],"float32"), Tensor([1024, 256, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 0, 2],"float32"), Tensor([1024, 512, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 128, 0],"float32"), Tensor([1024, 128, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 128, 128],"float32"), Tensor([1024, 0, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 128, 128],"float32"), Tensor([1024, 128, 0, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 128, 128],"float32"), Tensor([1024, 128, 3, 0],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 16, 0],"float32"), Tensor([1024, 256, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 16, 16],"float32"), Tensor([1024, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 16, 16],"float32"), Tensor([1024, 256, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 16, 16],"float32"), Tensor([1024, 256, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 2, 0],"float32"), Tensor([1024, 512, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 2, 2],"float32"), Tensor([1024, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 2, 2],"float32"), Tensor([1024, 512, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 1024, 2, 2],"float32"), Tensor([1024, 512, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 0, 128],"float32"), Tensor([128, 3, 4, 4],"float32"), bias=Tensor([3],"float32"), padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 0, 128],"float32"), Tensor([128, 64, 3, 3],"float32"), bias=Tensor([64],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 0, 80],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=Tensor([128],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 0],"float32"), Tensor([128, 3, 4, 4],"float32"), bias=Tensor([3],"float32"), padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 0],"float32"), Tensor([128, 64, 3, 3],"float32"), bias=Tensor([64],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 128],"float32"), Tensor([128, 0, 3, 3],"float32"), bias=Tensor([64],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 128],"float32"), Tensor([128, 0, 4, 4],"float32"), bias=Tensor([3],"float32"), padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 128],"float32"), Tensor([128, 3, 0, 4],"float32"), bias=Tensor([3],"float32"), padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 128],"float32"), Tensor([128, 3, 4, 0],"float32"), bias=Tensor([3],"float32"), padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 128],"float32"), Tensor([128, 64, 0, 3],"float32"), bias=Tensor([64],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 128, 128],"float32"), Tensor([128, 64, 3, 0],"float32"), bias=Tensor([64],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 80, 0],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=Tensor([128],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 80, 80],"float32"), Tensor([128, 0, 2, 2],"float32"), bias=Tensor([128],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 80, 80],"float32"), Tensor([128, 128, 0, 2],"float32"), bias=Tensor([128],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 128, 80, 80],"float32"), Tensor([128, 128, 2, 0],"float32"), bias=Tensor([128],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 0, 128],"float32"), Tensor([2048, 128, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 0, 16],"float32"), Tensor([2048, 512, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 128, 0],"float32"), Tensor([2048, 128, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 128, 128],"float32"), Tensor([2048, 0, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 128, 128],"float32"), Tensor([2048, 128, 0, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 128, 128],"float32"), Tensor([2048, 128, 3, 0],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 16, 0],"float32"), Tensor([2048, 512, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 16, 16],"float32"), Tensor([2048, 0, 3, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 16, 16],"float32"), Tensor([2048, 512, 0, 3],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 2048, 16, 16],"float32"), Tensor([2048, 512, 3, 0],"float32"), padding=0, stride=2, groups=4, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 0, 128],"float32"), Tensor([256, 128, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 0, 14],"float32"), Tensor([256, 256, 2, 2],"float32"), bias=Tensor([256],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 0, 64],"float32"), Tensor([256, 128, 3, 3],"float32"), bias=Tensor([128],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 128, 0],"float32"), Tensor([256, 128, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 128, 128],"float32"), Tensor([256, 0, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 128, 128],"float32"), Tensor([256, 128, 0, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 128, 128],"float32"), Tensor([256, 128, 3, 0],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 14, 0],"float32"), Tensor([256, 256, 2, 2],"float32"), bias=Tensor([256],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 14, 14],"float32"), Tensor([256, 0, 2, 2],"float32"), bias=Tensor([256],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 14, 14],"float32"), Tensor([256, 256, 0, 2],"float32"), bias=Tensor([256],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 14, 14],"float32"), Tensor([256, 256, 2, 0],"float32"), bias=Tensor([256],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 64, 0],"float32"), Tensor([256, 128, 3, 3],"float32"), bias=Tensor([128],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 64, 64],"float32"), Tensor([256, 0, 3, 3],"float32"), bias=Tensor([128],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 64, 64],"float32"), Tensor([256, 128, 0, 3],"float32"), bias=Tensor([128],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 256, 64, 64],"float32"), Tensor([256, 128, 3, 0],"float32"), bias=Tensor([128],"float32"), padding=1, output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([1, 4096, 0, 16],"float32"), Tensor([4096, 512, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 4096, 16, 0],"float32"), Tensor([4096, 512, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 4096, 16, 16],"float32"), Tensor([4096, 0, 3, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 4096, 16, 16],"float32"), Tensor([4096, 512, 0, 3],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 4096, 16, 16],"float32"), Tensor([4096, 512, 3, 0],"float32"), padding=0, stride=2, groups=8, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 512, 0, 16],"float32"), Tensor([512, 512, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 512, 16, 0],"float32"), Tensor([512, 512, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 512, 16, 16],"float32"), Tensor([512, 0, 3, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 512, 16, 16],"float32"), Tensor([512, 512, 0, 3],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([1, 512, 16, 16],"float32"), Tensor([512, 512, 3, 0],"float32"), padding=0, stride=2, groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 2, 6],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 0, 3, 2],"float64"), Tensor([2, 0, 1, 1],"float64"), groups=1, padding=list[1,1,], data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 128, 0, 108],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 128, 124, 0],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 128, 124, 108],"float32"), Tensor([128, 0, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 128, 124, 108],"float32"), Tensor([128, 128, 0, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 128, 124, 108],"float32"), Tensor([128, 128, 2, 0],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 3],"float64"), Tensor([2, 2, 0, 1],"float64"), groups=1, padding=list[1,0,0,1,], )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 3],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding="SAME", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 3],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding="VALID", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 6],"float32"), Tensor([6, 1, 0, 3],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 6],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 6],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 0, 6],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 1, 0, 3],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 1, 0, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 1, 3, 0],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 1, 3, 0],"float32"), bias=None, padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 1, 3, 0],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float32"), Tensor([6, 1, 3, 0],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float64"), Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float64"), Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float64"), Tensor([6, 1, 0, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float64"), Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 2, 6],"float64"), Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=1, stride=list[2,2,], dilation=list[1,1,], groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 0],"float64"), Tensor([2, 2, 1, 0],"float64"), groups=1, padding=list[1,0,0,1,], )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 0],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding="SAME", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 0],"float64"), Tensor([2, 2, 1, 1],"float64"), groups=1, padding="VALID", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 0, 1, 1],"float64"), groups=1, padding="SAME", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 0, 1, 1],"float64"), groups=1, padding="VALID", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 0, 1, 1],"float64"), groups=1, padding=list[1,0,0,1,], )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 2, 0, 1],"float64"), groups=1, padding="SAME", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 2, 0, 1],"float64"), groups=1, padding="VALID", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 2, 0, 1],"float64"), groups=1, padding=list[1,0,0,1,], )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 2, 1, 0],"float64"), groups=1, padding="SAME", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 2, 1, 0],"float64"), groups=1, padding="VALID", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 2, 3, 3],"float64"), Tensor([2, 2, 1, 0],"float64"), groups=1, padding=list[1,0,0,1,], )
paddle.nn.functional.conv2d_transpose(Tensor([2, 256, 0, 54],"float32"), Tensor([256, 128, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 256, 62, 0],"float32"), Tensor([256, 128, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 256, 62, 54],"float32"), Tensor([256, 0, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 256, 62, 54],"float32"), Tensor([256, 128, 0, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 256, 62, 54],"float32"), Tensor([256, 128, 4, 0],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float32"), Tensor([3, 10, 27, 27],"float32"), bias=Tensor([10],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float64"), Tensor([2, 2, 0, 1],"float64"), groups=1, padding=list[1,1,], data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 0, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float32"), Tensor([3, 10, 27, 27],"float32"), bias=Tensor([10],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 0],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 27, 27],"float32"), bias=Tensor([10],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=None, padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 0, 3],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 0, 3],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 0],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 0],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 0],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 0],"float32"), bias=Tensor([1],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 0],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 0],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 10, 0, 27],"float32"), bias=Tensor([10],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float32"), Tensor([3, 10, 27, 0],"float32"), bias=Tensor([10],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=1, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 2, 2],"float64"), Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 3, 2],"float64"), Tensor([2, 0, 1, 1],"float64"), groups=1, padding=list[1,1,], data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 3, 2],"float64"), Tensor([2, 2, 0, 1],"float64"), groups=1, padding=list[1,1,], data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 3, 3, 2],"float64"), Tensor([2, 2, 1, 0],"float64"), groups=1, padding=list[1,1,], data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 4, 0, 3],"float64"), Tensor([4, 2, 1, 1],"float64"), groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([2, 4, 3, 0],"float64"), Tensor([4, 2, 1, 1],"float64"), groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([2, 4, 3, 3],"float64"), Tensor([4, 0, 1, 1],"float64"), groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([2, 4, 3, 3],"float64"), Tensor([4, 2, 0, 1],"float64"), groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([2, 4, 3, 3],"float64"), Tensor([4, 2, 1, 0],"float64"), groups=1, )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 0, 2],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 0, 2],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 0, 2],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 0],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 0],"float32"), Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 0],"float64"), Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 2],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 2],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 2],"float32"), Tensor([6, 1, 3, 0],"float32"), bias=None, padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 2],"float32"), Tensor([6, 1, 3, 0],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 2],"float64"), Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 6, 2, 2],"float64"), Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 64, 0, 216],"float32"), Tensor([64, 128, 1, 1],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 64, 248, 0],"float32"), Tensor([64, 128, 1, 1],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 64, 248, 216],"float32"), Tensor([64, 0, 1, 1],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 64, 248, 216],"float32"), Tensor([64, 128, 0, 1],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 64, 248, 216],"float32"), Tensor([64, 128, 1, 0],"float32"), bias=None, padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 96, 0, 2],"float32"), Tensor([96, 96, 4, 4],"float32"), bias=Tensor([96],"float32"), padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 96, 2, 0],"float32"), Tensor([96, 96, 4, 4],"float32"), bias=Tensor([96],"float32"), padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 96, 2, 2],"float32"), Tensor([96, 0, 4, 4],"float32"), bias=Tensor([96],"float32"), padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 96, 2, 2],"float32"), Tensor([96, 96, 0, 4],"float32"), bias=Tensor([96],"float32"), padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([2, 96, 2, 2],"float32"), Tensor([96, 96, 4, 0],"float32"), bias=Tensor([96],"float32"), padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 128, 0, 68],"float32"), Tensor([128, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 128, 38, 0],"float32"), Tensor([128, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 128, 38, 68],"float32"), Tensor([128, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 128, 38, 68],"float32"), Tensor([128, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 128, 38, 68],"float32"), Tensor([128, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 256, 0, 34],"float32"), Tensor([256, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 256, 19, 0],"float32"), Tensor([256, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 256, 19, 34],"float32"), Tensor([256, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 256, 19, 34],"float32"), Tensor([256, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 256, 19, 34],"float32"), Tensor([256, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 0, 136],"float32"), Tensor([64, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 0, 68],"float32"), Tensor([64, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 38, 0],"float32"), Tensor([64, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 38, 68],"float32"), Tensor([64, 0, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 38, 68],"float32"), Tensor([64, 1, 0, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 38, 68],"float32"), Tensor([64, 1, 8, 0],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 76, 0],"float32"), Tensor([64, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 76, 136],"float32"), Tensor([64, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 76, 136],"float32"), Tensor([64, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([20, 64, 76, 136],"float32"), Tensor([64, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 0, 16, 3],"float32"), Tensor([3, 5, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 0, 16, 4],"float32"), Tensor([4, 1, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=1, groups=4, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 0, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 0, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=tuple(2,1,), groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 0, 16, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 0, 16, 6],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 0, 16, 6],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 1024, 0, 16],"float32"), Tensor([1024, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1024, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 1024, 16, 0],"float32"), Tensor([1024, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1024, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 1024, 16, 16],"float32"), Tensor([1024, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1024, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 1024, 16, 16],"float32"), Tensor([1024, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1024, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 1024, 16, 16],"float32"), Tensor([1024, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1024, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 0, 32],"float32"), Tensor([128, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 0, 70],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 32, 0],"float32"), Tensor([128, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 32, 32],"float32"), Tensor([128, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 32, 32],"float32"), Tensor([128, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 32, 32],"float32"), Tensor([128, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=128, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 94, 0],"float32"), Tensor([128, 128, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 94, 70],"float32"), Tensor([128, 0, 2, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 94, 70],"float32"), Tensor([128, 128, 0, 2],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 128, 94, 70],"float32"), Tensor([128, 128, 2, 0],"float32"), bias=None, padding=0, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 0, 3],"float32"), Tensor([3, 5, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 0, 4],"float32"), Tensor([4, 1, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=1, groups=4, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 0, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 0, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=tuple(2,1,), groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 0, 4],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 0, 6],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 3],"float32"), Tensor([3, 0, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 3],"float32"), Tensor([3, 5, 0, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 3],"float32"), Tensor([3, 5, 3, 0],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=1, groups=4, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=tuple(2,1,), groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 1, 0, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=1, groups=4, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 1, 3, 0],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=1, groups=4, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=tuple(2,1,), groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,), dilation=tuple(2,1,), groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 4],"float32"), Tensor([4, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 6],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 6],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 6],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 6],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 16, 16, 6],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[0,0,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 0, 16],"float32"), Tensor([256, 1, 16, 16],"float32"), bias=None, padding=4, output_padding=0, stride=list[8,8,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 0, 16],"float32"), Tensor([256, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 0, 32],"float32"), Tensor([256, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 0, 35],"float32"), Tensor([256, 128, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 0],"float32"), Tensor([256, 1, 16, 16],"float32"), bias=None, padding=4, output_padding=0, stride=list[8,8,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 0],"float32"), Tensor([256, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 16],"float32"), Tensor([256, 0, 16, 16],"float32"), bias=None, padding=4, output_padding=0, stride=list[8,8,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 16],"float32"), Tensor([256, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 16],"float32"), Tensor([256, 1, 0, 16],"float32"), bias=None, padding=4, output_padding=0, stride=list[8,8,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 16],"float32"), Tensor([256, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 16],"float32"), Tensor([256, 1, 16, 0],"float32"), bias=None, padding=4, output_padding=0, stride=list[8,8,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 16, 16],"float32"), Tensor([256, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 32, 0],"float32"), Tensor([256, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 32, 32],"float32"), Tensor([256, 0, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 32, 32],"float32"), Tensor([256, 1, 0, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 32, 32],"float32"), Tensor([256, 1, 8, 0],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=256, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 47, 0],"float32"), Tensor([256, 128, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 47, 35],"float32"), Tensor([256, 0, 4, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 47, 35],"float32"), Tensor([256, 128, 0, 4],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 256, 47, 35],"float32"), Tensor([256, 128, 4, 0],"float32"), bias=None, padding=0, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 0, 16],"float32"), Tensor([3, 2, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 0, 16],"float32"), Tensor([3, 5, 3, 3],"float32"), None, output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 0, 7],"float32"), Tensor([3, 6, 5, 5],"float32"), bias=Tensor([6],"float32"), padding=2, output_padding=list[1,1,], stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 0],"float32"), Tensor([3, 2, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 0],"float32"), Tensor([3, 5, 3, 3],"float32"), None, output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 16],"float32"), Tensor([3, 0, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 16],"float32"), Tensor([3, 0, 3, 3],"float32"), None, output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 16],"float32"), Tensor([3, 2, 0, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 16],"float32"), Tensor([3, 2, 3, 0],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 16],"float32"), Tensor([3, 5, 0, 3],"float32"), None, output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 16, 16],"float32"), Tensor([3, 5, 3, 0],"float32"), None, output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 7, 0],"float32"), Tensor([3, 6, 5, 5],"float32"), bias=Tensor([6],"float32"), padding=2, output_padding=list[1,1,], stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 7, 7],"float32"), Tensor([3, 0, 5, 5],"float32"), bias=Tensor([6],"float32"), padding=2, output_padding=list[1,1,], stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 7, 7],"float32"), Tensor([3, 6, 0, 5],"float32"), bias=Tensor([6],"float32"), padding=2, output_padding=list[1,1,], stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 3, 7, 7],"float32"), Tensor([3, 6, 5, 0],"float32"), bias=Tensor([6],"float32"), padding=2, output_padding=list[1,1,], stride=list[2,2,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 0, 16],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 0, 16],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 0, 16],"float32"), Tensor([4, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([4],"float32"), output_size=list[18,34,], padding="valid", stride=tuple(1,2,), dilation=1, groups=1, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 4, 16, 16],"float32"), Tensor([4, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 512, 0, 32],"float32"), Tensor([512, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=512, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 512, 32, 0],"float32"), Tensor([512, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=512, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 512, 32, 32],"float32"), Tensor([512, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=512, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 512, 32, 32],"float32"), Tensor([512, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=512, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 512, 32, 32],"float32"), Tensor([512, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=512, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 0, 16],"float32"), Tensor([6, 4, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 0, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="same", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 0, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 0, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 0, 16],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[2,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 0],"float32"), Tensor([6, 4, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 0],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="same", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 0],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 0],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 0],"float32"), Tensor([6, 8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[2,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 1, 1],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,), output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="same", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=list[20,36,], data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[2,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,1,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 4, 0, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 4, 3, 0],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 0, 1],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,), output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding="same", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[2,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,1,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 1, 0],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,), output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding="same", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,], dilation=list[2,2,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,], dilation=list[2,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,1,], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 6, 16, 16],"float32"), Tensor([6, 8, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,], dilation=list[1,1,], groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 0, 32],"float32"), Tensor([64, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 0, 64],"float32"), Tensor([64, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 32, 0],"float32"), Tensor([64, 1, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 32, 32],"float32"), Tensor([64, 0, 8, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 32, 32],"float32"), Tensor([64, 1, 0, 8],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 32, 32],"float32"), Tensor([64, 1, 8, 0],"float32"), bias=None, padding=2, output_padding=0, stride=list[4,4,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 64, 0],"float32"), Tensor([64, 1, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 64, 64],"float32"), Tensor([64, 0, 4, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 64, 64],"float32"), Tensor([64, 1, 0, 4],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(Tensor([4, 64, 64, 64],"float32"), Tensor([64, 1, 4, 0],"float32"), bias=None, padding=1, output_padding=0, stride=list[2,2,], dilation=list[1,1,], groups=64, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), output_size=list[4,6,], stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), output_size=list[4,6,], stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,0,], output_padding=1, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 4, 4],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding="vaLiD", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 8, 8],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding="sAmE", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 8, 8],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,2,3,4,], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 3, 8, 8],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[1,2,],list[3,4,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 6, 2, 2],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 6, 2, 2],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 6, 2, 2],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([0, 8, 8, 3],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[1,2,],list[3,4,],list[0,0,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 0, 2, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 0, 2, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 0, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 0, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 0, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 0, 2, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,0,], output_padding=1, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 0, 8, 3],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[1,2,],list[3,4,],list[0,0,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 0, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 0, 6],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 0, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 0, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 0, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 0, 6],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,0,], output_padding=1, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float32"), weight=Tensor([6, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float32"), weight=Tensor([6, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), output_size=list[4,6,], stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float32"), weight=Tensor([6, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float32"), weight=Tensor([6, 1, 0, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float32"), weight=Tensor([6, 1, 3, 0],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float32"), weight=Tensor([6, 1, 3, 0],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), output_size=list[4,6,], stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,0,], output_padding=1, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 1, 0, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 1, 0, 3],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,0,], output_padding=1, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, data_format="NHWC", dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 2, 2, 6],"float64"), weight=Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), stride=2, padding=list[1,0,], output_padding=1, dilation=1, groups=3, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 4],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding="vaLiD", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 8],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding="sAmE", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 8],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,2,3,4,], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 0, 8],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[1,2,],list[3,4,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,], dilation=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=1, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=1, output_padding=0, dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,0,], dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,0,], dilation=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,0,], dilation=2, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,0,], dilation=2, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 4, 0],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding="vaLiD", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 4, 4],"float64"), weight=Tensor([3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding="vaLiD", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 4, 4],"float64"), weight=Tensor([3, 1, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding="vaLiD", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 4, 4],"float64"), weight=Tensor([3, 1, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding="vaLiD", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 4, 4],"float64"), weight=Tensor([3, 1, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding="vaLiD", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 0],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding="sAmE", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 0, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding="sAmE", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 0, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,2,3,4,], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 0, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[1,2,],list[3,4,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 1, 0, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding="sAmE", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 1, 0, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,2,3,4,], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 1, 0, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[1,2,],list[3,4,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 1, 5, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding="sAmE", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 1, 5, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,2,3,4,], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 1, 5, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[0,0,],list[1,2,],list[3,4,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 3, 8, 8],"float64"), weight=Tensor([3, 1, 5, 5],"float64"), bias=Tensor([0],"float64"), stride=1, padding="sAmE", output_padding=0, dilation=1, groups=1, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 0, 2],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 0, 2],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 0, 2],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 0],"float32"), weight=Tensor([6, 1, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 0],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 0],"float64"), weight=Tensor([6, 1, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 2],"float32"), weight=Tensor([6, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 2],"float32"), weight=Tensor([6, 1, 3, 0],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 2],"float64"), weight=Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 2],"float64"), weight=Tensor([6, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 2],"float64"), weight=Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], groups=3, dilation=1, )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 6, 2, 2],"float64"), weight=Tensor([6, 1, 3, 0],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,], output_padding=0, dilation=1, groups=3, output_size=None, data_format="NCHW", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 8, 8, 3],"float64"), weight=Tensor([3, 0, 5, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[1,2,],list[3,4,],list[0,0,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 8, 8, 3],"float64"), weight=Tensor([3, 1, 0, 5],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[1,2,],list[3,4,],list[0,0,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv2d_transpose(x=Tensor([2, 8, 8, 3],"float64"), weight=Tensor([3, 1, 5, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[list[0,0,],list[1,2,],list[3,4,],list[0,0,],], output_padding=0, dilation=1, groups=1, output_size=None, data_format="NHWC", )
paddle.nn.functional.conv3d(Tensor([4, 3, 0, 8, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 3, 8, 0, 8],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 0],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 8],"float32"), Tensor([5, 3, 0, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 3, 8, 8, 8],"float32"), Tensor([5, 3, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[0,0,],list[1,1,],list[2,2,],list[2,2,],], stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 0, 8, 8],"float32"), Tensor([12, 1, 0, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 0, 8, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 0, 8],"float32"), Tensor([12, 1, 3, 0, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 0, 8],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 0],"float32"), Tensor([12, 1, 3, 3, 0],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 0],"float32"), Tensor([8, 3, 3, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([12, 1, 0, 3, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 0, 3],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([12, 1, 3, 3, 0],"float32"), None, padding="valid", stride=1, dilation=1, groups=6, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([8, 3, 0, 3, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 0, 3],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 6, 8, 8, 8],"float32"), Tensor([8, 3, 3, 3, 0],"float32"), Tensor([8],"float32"), padding="same", stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d(Tensor([4, 8, 0, 8, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,3,3,], stride=1, dilation=2, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 0, 8, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,1,], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 0, 8, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,2,3,], stride=2, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 0, 8, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[1,1,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 0, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,3,3,], stride=1, dilation=2, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 0, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,1,], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 0, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,2,3,], stride=2, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 0, 3],"float32"), Tensor([5, 3, 3, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[1,1,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 0, 3, 3],"float32"), Tensor([5],"float32"), padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 0, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,3,3,], stride=1, dilation=2, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 0, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,1,], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 0, 3, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,2,3,], stride=2, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 0, 3, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[1,1,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,3,3,], stride=1, dilation=2, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,1,], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,2,3,], stride=2, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 0, 3],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[1,1,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[1,1,2,2,3,3,], stride=1, dilation=2, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[1,2,1,], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[1,2,3,1,2,3,], stride=2, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([5, 3, 3, 3, 0],"float32"), Tensor([5],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[1,1,],list[0,0,],], stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float32"), weight=Tensor([6, 1, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 0, 4, 4],"float64"), weight=Tensor([6, 1, 3, 3, 3],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float32"), weight=Tensor([6, 1, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 0, 4],"float64"), weight=Tensor([6, 1, 3, 3, 3],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float32"), weight=Tensor([6, 1, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 0],"float64"), weight=Tensor([6, 1, 3, 3, 3],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 2, 2],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 2, 0, 2],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 2, 2, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 2, 2, 2],"float32"), bias=Tensor([0],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([1, 3, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([6, 1, 0, 3, 3],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([6, 1, 3, 0, 3],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float32"), weight=Tensor([6, 1, 3, 3, 0],"float32"), bias=Tensor([6],"float32"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=2, padding=0, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=2, padding=1, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=list[2,2,1,], padding=1, dilation=2, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=list[2,2,1,], padding=1, dilation=list[2,2,2,], )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=list[2,2,1,], padding=1, dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=list[2,2,1,], padding=list[1,2,2,], dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([1, 3, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=list[2,2,1,], padding=tuple(1,2,2,), dilation=tuple(2,2,2,), )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([6, 1, 0, 3, 3],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([6, 1, 3, 0, 3],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 3, 4, 4, 4],"float64"), weight=Tensor([6, 1, 3, 3, 0],"float64"), bias=Tensor([6],"float64"), stride=2, padding=0, groups=3, )
paddle.nn.functional.conv3d(x=Tensor([2, 4, 4, 4, 3],"float32"), weight=Tensor([2, 3, 0, 3, 3],"float32"), bias=Tensor([2],"float32"), stride=1, padding=0, data_format="NDHWC", )
paddle.nn.functional.conv3d(x=Tensor([2, 4, 4, 4, 3],"float32"), weight=Tensor([2, 3, 3, 0, 3],"float32"), bias=Tensor([2],"float32"), stride=1, padding=0, data_format="NDHWC", )
paddle.nn.functional.conv3d(x=Tensor([2, 4, 4, 4, 3],"float32"), weight=Tensor([2, 3, 3, 3, 0],"float32"), bias=Tensor([2],"float32"), stride=1, padding=0, data_format="NDHWC", )
paddle.nn.functional.conv3d(x=Tensor([2, 4, 4, 4, 3],"float64"), weight=Tensor([2, 3, 0, 3, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, data_format="NDHWC", )
paddle.nn.functional.conv3d(x=Tensor([2, 4, 4, 4, 3],"float64"), weight=Tensor([2, 3, 3, 0, 3],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, data_format="NDHWC", )
paddle.nn.functional.conv3d(x=Tensor([2, 4, 4, 4, 3],"float64"), weight=Tensor([2, 3, 3, 3, 0],"float64"), bias=Tensor([2],"float64"), stride=1, padding=0, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 2, 2, 2, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 2, 2, 2, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 2, 2, 2, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 2, 2, 2, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float32"), Tensor([3, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 8, 8, 8],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 3, 8, 8, 8],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 4, 8, 8, 8],"float32"), Tensor([4, 4, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 4, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 8, 1, 1, 1],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,1,), output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=list[12,19,12,], data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,3,2,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[2,3,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 3],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 4],"float32"), Tensor([4, 1, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 6],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([0, 8, 8, 8, 6],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[3,3,],list[0,0,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 0, 2, 2, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 0, 2, 2, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 0, 2, 2, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 0, 2, 2, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 0, 8, 8, 6],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 0, 8, 8, 6],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[3,3,],list[0,0,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 0, 2, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 0, 2, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 0, 2, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 0, 2, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 0, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 0, 3],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 0, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 0, 3],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float32"), Tensor([3, 1, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float32"), Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float32"), Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float32"), Tensor([3, 1, 3, 3, 0],"float32"), bias=Tensor([3],"float32"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float64"), Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float64"), Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float64"), Tensor([3, 1, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float64"), Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float64"), Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 2, 2, 2, 3],"float64"), Tensor([3, 1, 3, 3, 0],"float64"), bias=Tensor([3],"float64"), padding=list[1,1,1,], output_padding=1, stride=list[2,2,2,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float32"), Tensor([3, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 0, 8, 8],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float32"), Tensor([3, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 0, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float32"), Tensor([3, 12, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 0],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 0, 12, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([3],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 12, 0, 12, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 12, 12, 0, 12],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 12, 12, 12, 0],"float32"), bias=Tensor([12],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 2, 0, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 2, 3, 0, 3],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float32"), Tensor([3, 2, 3, 3, 0],"float32"), bias=Tensor([2],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([3],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=1, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 2, 2, 2],"float64"), Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), padding=list[1,0,1,], output_padding=0, stride=list[1,1,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 8, 0, 8],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 8, 8, 0],"float32"), Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 8, 8, 8],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 8, 8, 8],"float32"), Tensor([3, 2, 0, 3, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 8, 8, 8],"float32"), Tensor([3, 2, 3, 0, 3],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 3, 8, 8, 8],"float32"), Tensor([3, 2, 3, 3, 0],"float32"), bias=Tensor([6],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=3, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 0, 8, 8],"float32"), Tensor([6, 4, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 0, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 0, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 0, 8, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 0, 8],"float32"), Tensor([6, 4, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 0, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 0, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 0, 8],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 0],"float32"), Tensor([6, 4, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 0],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 0],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 0],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 1, 1, 1],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,1,), output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=list[12,19,12,], data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,3,2,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[2,3,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 4, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 4, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 4, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=2, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 0, 1, 1],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,1,), output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,3,2,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[2,3,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 1, 0, 1],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,1,), output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 1, 1, 0],"float32"), bias=Tensor([8],"float32"), padding=tuple(2,3,1,), output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,3,2,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[2,3,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding="valid", output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,2,1,], dilation=list[2,2,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[2,2,2,], dilation=list[2,1,2,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,2,3,2,1,], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 6, 8, 8, 8],"float32"), Tensor([6, 8, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[0,0,],list[2,3,],list[1,2,],list[2,1,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 0, 8, 6],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 0, 6],"float32"), Tensor([6, 8, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 0, 3, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[3,3,],list[0,0,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 8, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 8, 0, 3, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[3,3,],list[0,0,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 8, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 8, 3, 0, 3],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[3,3,],list[0,0,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 8, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=0, output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([2, 8, 8, 8, 6],"float32"), Tensor([6, 8, 3, 3, 0],"float32"), bias=Tensor([8],"float32"), padding=list[list[0,0,],list[1,1,],list[2,2,],list[3,3,],list[0,0,],], output_padding=0, stride=list[1,1,1,], dilation=list[1,1,1,], groups=1, output_size=None, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 0, 8, 8, 3],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 0, 8, 8, 4],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 0, 8, 8, 4],"float32"), Tensor([4, 1, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 0, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 0, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 0, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 3, 0, 8, 8],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 3, 8, 0, 8],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 3, 8, 8, 0],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 3, 8, 8, 8],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 3, 8, 8, 8],"float32"), Tensor([3, 5, 0, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 3, 8, 8, 8],"float32"), Tensor([3, 5, 3, 0, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 3, 8, 8, 8],"float32"), Tensor([3, 5, 3, 3, 0],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 0, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 0, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 0, 8, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 0, 8],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 0],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 0],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=tuple(10,17,10,), padding="valid", stride=tuple(1,2,1,), dilation=1, groups=1, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,1,2,2,1,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[1,2,1,], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 4, 8, 8, 8],"float32"), Tensor([4, 3, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[0,0,],list[1,1,],list[1,1,],list[2,2,],], stride=1, dilation=1, groups=2, data_format="NCDHW", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 0, 8, 3],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 0, 8, 4],"float32"), Tensor([4, 1, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 0, 8, 4],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 0, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 0, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 0, 8, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 0, 3],"float32"), Tensor([3, 5, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 0, 4],"float32"), Tensor([4, 1, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 0, 4],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 0, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 0, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 0, 4],"float32"), Tensor([4, 3, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([3, 0, 3, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([3, 5, 0, 3, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([3, 5, 3, 0, 3],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 3],"float32"), Tensor([3, 5, 3, 3, 0],"float32"), Tensor([5],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=1, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 0, 3, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 1, 0, 3, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 1, 3, 0, 3],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 1, 3, 3, 0],"float32"), Tensor([4],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=1, groups=4, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 0, 3, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 0, 3],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 0],"float32"), None, output_size=None, padding="same", stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding="valid", stride=tuple(1,2,1,), dilation=tuple(2,1,1,), groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=0, stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(Tensor([4, 8, 8, 8, 4],"float32"), Tensor([4, 3, 3, 3, 0],"float32"), Tensor([6],"float32"), output_size=None, padding=list[list[0,0,],list[1,2,],list[1,2,],list[2,1,],list[0,0,],], stride=1, dilation=1, groups=2, data_format="NDHWC", )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 2, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 2, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), output_size=list[4,4,4,], stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 2, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 2, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 2, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), output_size=list[4,4,4,], stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 2, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float32"), weight=Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([0, 3, 2, 2, 2],"float64"), weight=Tensor([3, 2, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 0, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 0, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 0, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 0, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 0, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 0, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 0, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 0, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 0, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 0, 3],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 0, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 0, 3],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), output_size=list[4,4,4,], stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float32"), weight=Tensor([3, 1, 0, 3, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float32"), weight=Tensor([3, 1, 3, 3, 0],"float32"), bias=Tensor([3],"float32"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), output_size=list[4,4,4,], stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float64"), weight=Tensor([3, 1, 0, 3, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 2, 2, 2, 3],"float64"), weight=Tensor([3, 1, 3, 3, 0],"float64"), bias=Tensor([3],"float64"), output_padding=1, stride=2, padding=list[1,1,1,], groups=3, data_format="NDHWC", dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float32"), weight=Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 0, 2, 2],"float64"), weight=Tensor([3, 2, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float32"), weight=Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 0, 2],"float64"), weight=Tensor([3, 2, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float32"), weight=Tensor([3, 2, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 0],"float64"), weight=Tensor([3, 2, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 0, 3, 3, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 0, 3],"float32"), bias=Tensor([3],"float32"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 1, 3, 3, 3],"float32"), bias=Tensor([0],"float32"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 2, 0, 3, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 2, 3, 0, 3],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float32"), weight=Tensor([3, 2, 3, 3, 0],"float32"), bias=Tensor([1],"float32"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 0, 3, 3, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 0, 3],"float64"), bias=Tensor([3],"float64"), stride=1, padding=list[1,0,1,], groups=3, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=1, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,0,1,], dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 1, 3, 3, 3],"float64"), bias=Tensor([0],"float64"), stride=1, padding=list[1,0,1,], dilation=2, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 2, 0, 3, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 2, 3, 0, 3],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.conv3d_transpose(x=Tensor([2, 3, 2, 2, 2],"float64"), weight=Tensor([3, 2, 3, 3, 0],"float64"), bias=Tensor([1],"float64"), stride=1, padding=0, dilation=1, )
paddle.nn.functional.ctc_loss(Tensor([40, 128, 6625],"float32"), Tensor([0, 25],"int32"), Tensor([128],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([40, 128, 6625],"float32"), Tensor([128, 25],"int32"), Tensor([0],"int64"), Tensor([128],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.ctc_loss(Tensor([40, 128, 6625],"float32"), Tensor([128, 25],"int32"), Tensor([128],"int64"), Tensor([0],"int64"), 0, "none", norm_by_times=False, )
paddle.nn.functional.flashmask_attention(Tensor([1, 2048, 0, 96],"float16"), Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 8, 96],"float16"), startend_row_indices=Tensor([1, 1, 2048, 1],"int32"), causal=True, )
paddle.nn.functional.flashmask_attention(Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 0, 96],"float16"), Tensor([1, 2048, 8, 96],"float16"), startend_row_indices=Tensor([1, 1, 2048, 1],"int32"), causal=True, )
paddle.nn.functional.flashmask_attention(Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 8, 0],"float16"), Tensor([1, 2048, 8, 96],"float16"), startend_row_indices=Tensor([1, 1, 2048, 1],"int32"), causal=True, )
paddle.nn.functional.flashmask_attention(Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 8, 96],"float16"), Tensor([0, 2048, 8, 96],"float16"), startend_row_indices=Tensor([1, 1, 2048, 1],"int32"), causal=True, )
paddle.nn.functional.flashmask_attention(Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 0, 8, 96],"float16"), startend_row_indices=Tensor([1, 1, 2048, 1],"int32"), causal=True, )
paddle.nn.functional.flashmask_attention(Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 0, 96],"float16"), startend_row_indices=Tensor([1, 1, 2048, 1],"int32"), causal=True, )
paddle.nn.functional.flashmask_attention(Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 8, 96],"float16"), Tensor([1, 2048, 8, 0],"float16"), startend_row_indices=Tensor([1, 1, 2048, 1],"int32"), causal=True, )
paddle.nn.functional.fractional_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=5, kernel_size=None, random_u=0.5, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[2,5,], kernel_size=None, random_u=0.7, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[3,3,], kernel_size=2, random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[3,3,], kernel_size=list[2,2,], random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([0, 3, 7, 7],"float32"), output_size=list[3,3,], kernel_size=None, random_u=0.3, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([2, 0, 7, 7],"float32"), output_size=5, kernel_size=None, random_u=0.5, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([2, 0, 7, 7],"float32"), output_size=list[2,5,], kernel_size=None, random_u=0.7, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([2, 0, 7, 7],"float32"), output_size=list[3,3,], kernel_size=2, random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([2, 0, 7, 7],"float32"), output_size=list[3,3,], kernel_size=list[2,2,], random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(Tensor([2, 0, 7, 7],"float32"), output_size=list[3,3,], kernel_size=None, random_u=0.3, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float16"), output_size=list[3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), kernel_size=2, output_size=list[3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), kernel_size=list[2,2,], output_size=list[3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=5, random_u=0.5, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[2,5,], random_u=0.7, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[3,None,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), output_size=list[None,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float32"), return_mask=False, output_size=list[3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([0, 3, 7, 7],"float64"), output_size=list[3,3,], random_u=None, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float16"), output_size=list[3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), kernel_size=2, output_size=list[3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), kernel_size=list[2,2,], output_size=list[3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), output_size=5, random_u=0.5, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), output_size=list[2,5,], random_u=0.7, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), output_size=list[3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), output_size=list[3,None,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), output_size=list[None,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float32"), return_mask=False, output_size=list[3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 0, 7, 7],"float64"), output_size=list[3,3,], random_u=None, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 3, 0, 7],"float32"), output_size=list[None,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool2d(x=Tensor([2, 3, 7, 0],"float32"), output_size=list[3,None,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(Tensor([0, 3, 7, 7, 7],"float32"), output_size=5, kernel_size=None, random_u=0.5, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[2,3,5,], kernel_size=None, random_u=0.7, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[3,3,3,], kernel_size=2, random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[3,3,3,], kernel_size=list[2,2,2,], random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[3,3,3,], kernel_size=None, random_u=0.3, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([2, 0, 7, 7, 7],"float32"), output_size=5, kernel_size=None, random_u=0.5, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[2,3,5,], kernel_size=None, random_u=0.7, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[3,3,3,], kernel_size=2, random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[3,3,3,], kernel_size=list[2,2,2,], random_u=0.6, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[3,3,3,], kernel_size=None, random_u=0.3, return_mask=False, name=None, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float16"), output_size=list[3,3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), kernel_size=2, output_size=list[3,3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), kernel_size=list[2,2,2,], output_size=list[3,3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), output_size=5, random_u=0.5, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[2,3,5,], random_u=0.7, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[3,3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[3,3,None,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[3,None,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float32"), output_size=list[None,3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([0, 3, 7, 7, 7],"float64"), output_size=list[3,3,3,], random_u=None, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float16"), output_size=list[3,3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), kernel_size=2, output_size=list[3,3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), kernel_size=list[2,2,2,], output_size=list[3,3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), output_size=5, random_u=0.5, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[2,3,5,], random_u=0.7, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[3,3,3,], random_u=0.3, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[3,3,None,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[3,None,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float32"), output_size=list[None,3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 0, 7, 7, 7],"float64"), output_size=list[3,3,3,], random_u=None, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 3, 0, 7, 7],"float32"), output_size=list[None,3,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 3, 7, 0, 7],"float32"), output_size=list[3,None,3,], random_u=0.6, )
paddle.nn.functional.fractional_max_pool3d(x=Tensor([2, 3, 7, 7, 0],"float32"), output_size=list[3,3,None,], random_u=0.6, )
paddle.nn.functional.gelu(Tensor([0, 1, 1024],"float32"), )
paddle.nn.functional.gelu(Tensor([0, 1, 128],"float32"), )
paddle.nn.functional.gelu(Tensor([0, 1, 1536],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([0, 1, 2048],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([0, 1, 37],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([0, 1, 4096],"float32"), True, None, )
paddle.nn.functional.gelu(Tensor([0, 1, 8],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([0, 1024, 7, 7],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([0, 12, 12, 4096],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([0, 13, 4096],"float32"), True, None, )
paddle.nn.functional.gelu(Tensor([0, 16, 14, 14, 1536],"float16"), False, None, )
paddle.nn.functional.gelu(Tensor([0, 16, 14, 14, 1536],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([0, 16, 64, 64],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([0, 16, 64, 64],"float16"), approximate=True, )
paddle.nn.functional.gelu(Tensor([0, 16, 64, 64],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([0, 16, 64, 64],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([0, 17],"float32"), False, )
paddle.nn.functional.gelu(Tensor([0, 17],"float32"), True, )
paddle.nn.functional.gelu(Tensor([0, 20],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([0, 3, 4],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([0, 3, 4],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([0, 3],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([0, 3],"float16"), approximate=True, )
paddle.nn.functional.gelu(Tensor([0, 3],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([0, 3],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([0, 32],"float32"), )
paddle.nn.functional.gelu(Tensor([0, 37],"float32"), )
paddle.nn.functional.gelu(Tensor([0],"float32"), )
paddle.nn.functional.gelu(Tensor([1, 0, 1024],"float32"), )
paddle.nn.functional.gelu(Tensor([1, 0, 128],"float32"), )
paddle.nn.functional.gelu(Tensor([1, 0, 14, 14, 1536],"float16"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 0, 14, 14, 1536],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 0, 1536],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 0, 2048],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 0, 37],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([1, 0, 4096],"float32"), True, None, )
paddle.nn.functional.gelu(Tensor([1, 0, 8],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([1, 0],"float32"), )
paddle.nn.functional.gelu(Tensor([1, 1, 0],"float32"), )
paddle.nn.functional.gelu(Tensor([1, 1, 0],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([1, 1, 0],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 1, 0],"float32"), True, None, )
paddle.nn.functional.gelu(Tensor([1, 13, 0],"float32"), True, None, )
paddle.nn.functional.gelu(Tensor([1, 16, 0, 14, 1536],"float16"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 16, 0, 14, 1536],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 16, 14, 0, 1536],"float16"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 16, 14, 0, 1536],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 16, 14, 14, 0],"float16"), False, None, )
paddle.nn.functional.gelu(Tensor([1, 16, 14, 14, 0],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([10, 0],"float32"), )
paddle.nn.functional.gelu(Tensor([11, 0],"float32"), False, )
paddle.nn.functional.gelu(Tensor([11, 0],"float32"), True, )
paddle.nn.functional.gelu(Tensor([124, 0, 12, 4096],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([124, 0, 7, 7],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([124, 1024, 0, 7],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([124, 1024, 7, 0],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([124, 12, 0, 4096],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([124, 12, 12, 0],"float32"), False, None, )
paddle.nn.functional.gelu(Tensor([16, 0, 64, 64],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([16, 0, 64, 64],"float16"), approximate=True, )
paddle.nn.functional.gelu(Tensor([16, 0, 64, 64],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([16, 0, 64, 64],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([16, 16, 0, 64],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([16, 16, 0, 64],"float16"), approximate=True, )
paddle.nn.functional.gelu(Tensor([16, 16, 0, 64],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([16, 16, 0, 64],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([16, 16, 64, 0],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([16, 16, 64, 0],"float16"), approximate=True, )
paddle.nn.functional.gelu(Tensor([16, 16, 64, 0],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([16, 16, 64, 0],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([2, 0, 4],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([2, 0, 4],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([2, 0],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([2, 0],"float16"), approximate=True, )
paddle.nn.functional.gelu(Tensor([2, 0],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([2, 0],"float32"), approximate=True, )
paddle.nn.functional.gelu(Tensor([2, 3, 0],"float16"), approximate=False, )
paddle.nn.functional.gelu(Tensor([2, 3, 0],"float32"), approximate=False, )
paddle.nn.functional.gelu(Tensor([3, 0],"float32"), False, None, )
paddle.nn.functional.gelu(x=Tensor([0, 3, 3],"float32"), )
paddle.nn.functional.gelu(x=Tensor([0, 3, 3],"float64"), )
paddle.nn.functional.gelu(x=Tensor([0, 3, 3],"float64"), approximate=True, )
paddle.nn.functional.gelu(x=Tensor([3, 0, 3],"float32"), )
paddle.nn.functional.gelu(x=Tensor([3, 0, 3],"float64"), )
paddle.nn.functional.gelu(x=Tensor([3, 0, 3],"float64"), approximate=True, )
paddle.nn.functional.gelu(x=Tensor([3, 3, 0],"float32"), )
paddle.nn.functional.gelu(x=Tensor([3, 3, 0],"float64"), )
paddle.nn.functional.gelu(x=Tensor([3, 3, 0],"float64"), approximate=True, )
paddle.nn.functional.group_norm(Tensor([0, 1024, 10, 26],"float32"), num_groups=32, epsilon=1e-05, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), )
paddle.nn.functional.group_norm(Tensor([0, 1024, 12, 32],"float32"), num_groups=32, epsilon=1e-05, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), )
paddle.nn.functional.group_norm(Tensor([0, 3, 2, 2, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NDHWC", )
paddle.nn.functional.group_norm(Tensor([0, 3, 2, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NHWC", )
paddle.nn.functional.group_norm(Tensor([0, 3, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NLC", )
paddle.nn.functional.group_norm(Tensor([0, 4, 3, 2, 2],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCDHW", )
paddle.nn.functional.group_norm(Tensor([0, 4, 3, 2],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCHW", )
paddle.nn.functional.group_norm(Tensor([0, 4, 3],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCL", )
paddle.nn.functional.group_norm(Tensor([1, 1024, 0, 26],"float32"), num_groups=32, epsilon=1e-05, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), )
paddle.nn.functional.group_norm(Tensor([1, 1024, 0, 32],"float32"), num_groups=32, epsilon=1e-05, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), )
paddle.nn.functional.group_norm(Tensor([1, 1024, 10, 0],"float32"), num_groups=32, epsilon=1e-05, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), )
paddle.nn.functional.group_norm(Tensor([1, 1024, 12, 0],"float32"), num_groups=32, epsilon=1e-05, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), )
paddle.nn.functional.group_norm(Tensor([2, 0, 2, 2, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NDHWC", )
paddle.nn.functional.group_norm(Tensor([2, 0, 2, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NHWC", )
paddle.nn.functional.group_norm(Tensor([2, 0, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NLC", )
paddle.nn.functional.group_norm(Tensor([2, 3, 0, 2, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NDHWC", )
paddle.nn.functional.group_norm(Tensor([2, 3, 0, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NHWC", )
paddle.nn.functional.group_norm(Tensor([2, 3, 2, 0, 4],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NDHWC", )
paddle.nn.functional.group_norm(Tensor([2, 4, 0, 2, 2],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCDHW", )
paddle.nn.functional.group_norm(Tensor([2, 4, 0, 2],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCHW", )
paddle.nn.functional.group_norm(Tensor([2, 4, 0],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCL", )
paddle.nn.functional.group_norm(Tensor([2, 4, 3, 0, 2],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCDHW", )
paddle.nn.functional.group_norm(Tensor([2, 4, 3, 0],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCHW", )
paddle.nn.functional.group_norm(Tensor([2, 4, 3, 2, 0],"float64"), num_groups=2, weight=Tensor([4],"float64"), bias=Tensor([4],"float64"), data_format="NCDHW", )
paddle.nn.functional.hardsigmoid(Tensor([0, 120, 1, 1],"float32"), slope=0.2, offset=0.5, )
paddle.nn.functional.hardsigmoid(Tensor([0, 480, 1, 1],"float32"), slope=0.2, offset=0.5, )
paddle.nn.functional.hardsigmoid(Tensor([1, 0, 1, 1],"float32"), slope=0.2, offset=0.5, )
paddle.nn.functional.hardsigmoid(Tensor([1, 120, 0, 1],"float32"), slope=0.2, offset=0.5, )
paddle.nn.functional.hardsigmoid(Tensor([1, 120, 1, 0],"float32"), slope=0.2, offset=0.5, )
paddle.nn.functional.hardsigmoid(Tensor([1, 480, 0, 1],"float32"), slope=0.2, offset=0.5, )
paddle.nn.functional.hardsigmoid(Tensor([1, 480, 1, 0],"float32"), slope=0.2, offset=0.5, )
paddle.nn.functional.hardtanh(Tensor([0, 3, 3],"float64"), 3.3, -3.3, None, )
paddle.nn.functional.hardtanh(Tensor([3, 0, 3],"float64"), 3.3, -3.3, None, )
paddle.nn.functional.hardtanh(Tensor([3, 3, 0],"float64"), 3.3, -3.3, None, )
paddle.nn.functional.hardtanh(x=Tensor([0, 3, 3],"float64"), max=-3.3, min=3.3, )
paddle.nn.functional.hardtanh(x=Tensor([3, 0, 3],"float64"), max=-3.3, min=3.3, )
paddle.nn.functional.hardtanh(x=Tensor([3, 3, 0],"float64"), max=-3.3, min=3.3, )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 10, 5],"float64"), Tensor([0, 10, 5],"float64"), reduction="none", )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 10, 5],"float64"), Tensor([0, 10, 5],"float64"), reduction="none", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 10, 5],"float64"), Tensor([0, 10, 5],"float64"), reduction="sum", )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 10, 5],"float64"), Tensor([0, 10, 5],"float64"), reduction="sum", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 3, 3, 4],"float64"), Tensor([0, 3, 3, 4],"float64"), reduction="none", margin=-4.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 3, 3, 4],"float64"), Tensor([0, 3, 3, 4],"float64"), reduction="sum", margin=-4.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 3],"float32"), Tensor([0, 3],"float32"), reduction="none", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([0, 3],"float64"), Tensor([0, 3],"float64"), reduction="none", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 0, 5],"float64"), Tensor([10, 0, 5],"float64"), reduction="none", )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 0, 5],"float64"), Tensor([10, 0, 5],"float64"), reduction="none", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 0, 5],"float64"), Tensor([10, 0, 5],"float64"), reduction="sum", )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 0, 5],"float64"), Tensor([10, 0, 5],"float64"), reduction="sum", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 10, 0],"float64"), Tensor([10, 10, 0],"float64"), reduction="none", )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 10, 0],"float64"), Tensor([10, 10, 0],"float64"), reduction="none", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 10, 0],"float64"), Tensor([10, 10, 0],"float64"), reduction="sum", )
paddle.nn.functional.hinge_embedding_loss(Tensor([10, 10, 0],"float64"), Tensor([10, 10, 0],"float64"), reduction="sum", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([3, 0],"float32"), Tensor([3, 0],"float32"), reduction="none", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([3, 0],"float64"), Tensor([3, 0],"float64"), reduction="none", margin=1.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([4, 0, 3, 4],"float64"), Tensor([4, 0, 3, 4],"float64"), reduction="none", margin=-4.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([4, 0, 3, 4],"float64"), Tensor([4, 0, 3, 4],"float64"), reduction="sum", margin=-4.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), reduction="none", margin=-4.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([4, 3, 0, 4],"float64"), Tensor([4, 3, 0, 4],"float64"), reduction="sum", margin=-4.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([4, 3, 3, 0],"float64"), Tensor([4, 3, 3, 0],"float64"), reduction="none", margin=-4.0, name=None, )
paddle.nn.functional.hinge_embedding_loss(Tensor([4, 3, 3, 0],"float64"), Tensor([4, 3, 3, 0],"float64"), reduction="sum", margin=-4.0, name=None, )
paddle.nn.functional.interpolate(x=Tensor([0, 3, 5, 7, 7],"float32"), mode="area", size=list[2,3,5,], )
paddle.nn.functional.interpolate(x=Tensor([0, 3, 7, 7],"float32"), mode="area", size=list[2,5,], )
paddle.nn.functional.interpolate(x=Tensor([2, 0, 5, 7, 7],"float32"), mode="area", size=list[2,3,5,], )
paddle.nn.functional.interpolate(x=Tensor([2, 0, 7, 7],"float32"), mode="area", size=list[2,5,], )
paddle.nn.functional.interpolate(x=Tensor([2, 3, 0, 7, 7],"float32"), mode="area", size=list[2,3,5,], )
paddle.nn.functional.interpolate(x=Tensor([2, 3, 0, 7],"float32"), mode="area", size=list[2,5,], )
paddle.nn.functional.interpolate(x=Tensor([2, 3, 5, 0, 7],"float32"), mode="area", size=list[2,3,5,], )
paddle.nn.functional.interpolate(x=Tensor([2, 3, 5, 7, 0],"float32"), mode="area", size=list[2,3,5,], )
paddle.nn.functional.interpolate(x=Tensor([2, 3, 7, 0],"float32"), mode="area", size=list[2,5,], )
paddle.nn.functional.kl_div(input=Tensor([0, 128, 128],"float32"), label=Tensor([0, 128, 128],"float32"), reduction="batchmean", )
paddle.nn.functional.kl_div(input=Tensor([32, 0, 128],"float32"), label=Tensor([32, 0, 128],"float32"), reduction="batchmean", )
paddle.nn.functional.kl_div(input=Tensor([32, 128, 0],"float32"), label=Tensor([32, 128, 0],"float32"), reduction="batchmean", )
paddle.nn.functional.kl_div(Tensor([0, 20, 50],"float32"), Tensor([0, 20, 50],"float32"), "batchmean", False, )
paddle.nn.functional.kl_div(Tensor([0, 20, 50],"float32"), Tensor([0, 20, 50],"float32"), "batchmean", True, )
paddle.nn.functional.kl_div(Tensor([0, 20, 50],"float32"), Tensor([0, 20, 50],"float32"), "none", False, )
paddle.nn.functional.kl_div(Tensor([0, 20],"float64"), Tensor([0, 20],"float64"), "batchmean", False, )
paddle.nn.functional.kl_div(Tensor([0, 20],"float64"), Tensor([0, 20],"float64"), "none", False, )
paddle.nn.functional.kl_div(Tensor([0, 20],"float64"), Tensor([0, 20],"float64"), "sum", False, )
paddle.nn.functional.kl_div(Tensor([40, 0, 50],"float32"), Tensor([40, 0, 50],"float32"), "batchmean", False, )
paddle.nn.functional.kl_div(Tensor([40, 0, 50],"float32"), Tensor([40, 0, 50],"float32"), "batchmean", True, )
paddle.nn.functional.kl_div(Tensor([40, 0, 50],"float32"), Tensor([40, 0, 50],"float32"), "none", False, )
paddle.nn.functional.kl_div(Tensor([40, 20, 0],"float32"), Tensor([40, 20, 0],"float32"), "batchmean", False, )
paddle.nn.functional.kl_div(Tensor([40, 20, 0],"float32"), Tensor([40, 20, 0],"float32"), "batchmean", True, )
paddle.nn.functional.kl_div(Tensor([40, 20, 0],"float32"), Tensor([40, 20, 0],"float32"), "none", False, )
paddle.nn.functional.kl_div(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), "batchmean", False, )
paddle.nn.functional.kl_div(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), "none", False, )
paddle.nn.functional.kl_div(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), "sum", False, )
paddle.nn.functional.l1_loss(Tensor([0, 10, 5],"float32"), Tensor([0, 10, 5],"float32"), "none", name=None, )
paddle.nn.functional.l1_loss(Tensor([0, 10, 5],"float32"), Tensor([0, 10, 5],"float32"), "sum", name=None, )
paddle.nn.functional.l1_loss(Tensor([0, 10, 5],"float32"), Tensor([0, 10, 5],"float32"), reduction="none", )
paddle.nn.functional.l1_loss(Tensor([0, 10, 5],"float32"), Tensor([0, 10, 5],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([0, 4],"float32"), Tensor([0, 4],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([0, 499, 2],"float32"), Tensor([0, 499, 2],"float32"), "sum", name=None, )
paddle.nn.functional.l1_loss(Tensor([0, 500, 10],"float32"), Tensor([0, 500, 10],"float32"), reduction="none", )
paddle.nn.functional.l1_loss(Tensor([0, 500, 2],"float16"), Tensor([0, 500, 2],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([1, 0],"float32"), Tensor([1, 0],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([1, 4],"float32"), Tensor([0, 4],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([10, 0, 2],"float32"), Tensor([10, 0, 2],"float32"), "sum", name=None, )
paddle.nn.functional.l1_loss(Tensor([10, 0, 5],"float32"), Tensor([10, 0, 5],"float32"), "none", name=None, )
paddle.nn.functional.l1_loss(Tensor([10, 0, 5],"float32"), Tensor([10, 0, 5],"float32"), "sum", name=None, )
paddle.nn.functional.l1_loss(Tensor([10, 0, 5],"float32"), Tensor([10, 0, 5],"float32"), reduction="none", )
paddle.nn.functional.l1_loss(Tensor([10, 0, 5],"float32"), Tensor([10, 0, 5],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([10, 10, 0],"float32"), Tensor([10, 10, 0],"float32"), "none", name=None, )
paddle.nn.functional.l1_loss(Tensor([10, 10, 0],"float32"), Tensor([10, 10, 0],"float32"), "sum", name=None, )
paddle.nn.functional.l1_loss(Tensor([10, 10, 0],"float32"), Tensor([10, 10, 0],"float32"), reduction="none", )
paddle.nn.functional.l1_loss(Tensor([10, 10, 0],"float32"), Tensor([10, 10, 0],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([10, 499, 0],"float32"), Tensor([10, 499, 0],"float32"), "sum", name=None, )
paddle.nn.functional.l1_loss(Tensor([100, 0],"float32"), Tensor([100, 0],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([20, 0, 2],"float16"), Tensor([20, 0, 2],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([20, 500, 0],"float16"), Tensor([20, 500, 0],"float32"), reduction="sum", )
paddle.nn.functional.l1_loss(Tensor([4, 0, 10],"float32"), Tensor([4, 0, 10],"float32"), reduction="none", )
paddle.nn.functional.l1_loss(Tensor([4, 500, 0],"float32"), Tensor([4, 500, 0],"float32"), reduction="none", )
paddle.nn.functional.label_smooth(label=Tensor([0, 10000],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(label=Tensor([0, 28, 33712],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(label=Tensor([0, 29, 33712],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(label=Tensor([104, 0, 33712],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(label=Tensor([104, 28, 0],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(label=Tensor([104, 29, 0],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(label=Tensor([128, 0],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([0, 1, 1000],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([0, 1],"float32"), prior_dist=None, epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([0, 102],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([0, 2, 2, 5],"float32"), epsilon=0.20326138379662173, )
paddle.nn.functional.label_smooth(Tensor([0, 2, 2, 5],"float32"), epsilon=0.7336344401714625, )
paddle.nn.functional.label_smooth(Tensor([0, 2, 2, 5],"float64"), epsilon=0.18833946207874966, )
paddle.nn.functional.label_smooth(Tensor([0, 2, 2, 5],"float64"), epsilon=0.7642113030841614, )
paddle.nn.functional.label_smooth(Tensor([0, 3, 1],"float32"), prior_dist=None, epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([0, 3],"float32"), epsilon=0.1858912794612338, )
paddle.nn.functional.label_smooth(Tensor([0, 3],"float32"), epsilon=0.5436483450993637, )
paddle.nn.functional.label_smooth(Tensor([0, 3],"float64"), epsilon=0.5986189939413826, )
paddle.nn.functional.label_smooth(Tensor([0, 3],"float64"), epsilon=0.8211263365048883, )
paddle.nn.functional.label_smooth(Tensor([1024, 0, 1000],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([1024, 1, 0],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([12, 0],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([124, 0],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([128, 0, 1000],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([128, 1, 0],"float32"), epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([2, 0, 1],"float32"), prior_dist=None, epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([2, 3, 0],"float32"), prior_dist=None, epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([20, 0],"float32"), prior_dist=None, epsilon=0.1, )
paddle.nn.functional.label_smooth(Tensor([3, 0, 2, 5],"float32"), epsilon=0.20326138379662173, )
paddle.nn.functional.label_smooth(Tensor([3, 0, 2, 5],"float32"), epsilon=0.7336344401714625, )
paddle.nn.functional.label_smooth(Tensor([3, 0, 2, 5],"float64"), epsilon=0.18833946207874966, )
paddle.nn.functional.label_smooth(Tensor([3, 0, 2, 5],"float64"), epsilon=0.7642113030841614, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 0, 5],"float32"), epsilon=0.20326138379662173, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 0, 5],"float32"), epsilon=0.7336344401714625, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 0, 5],"float64"), epsilon=0.18833946207874966, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 0, 5],"float64"), epsilon=0.7642113030841614, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 2, 0],"float32"), epsilon=0.20326138379662173, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 2, 0],"float32"), epsilon=0.7336344401714625, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 2, 0],"float64"), epsilon=0.18833946207874966, )
paddle.nn.functional.label_smooth(Tensor([3, 2, 2, 0],"float64"), epsilon=0.7642113030841614, )
paddle.nn.functional.label_smooth(Tensor([4, 0],"float32"), epsilon=0.1858912794612338, )
paddle.nn.functional.label_smooth(Tensor([4, 0],"float32"), epsilon=0.5436483450993637, )
paddle.nn.functional.label_smooth(Tensor([4, 0],"float64"), epsilon=0.5986189939413826, )
paddle.nn.functional.label_smooth(Tensor([4, 0],"float64"), epsilon=0.8211263365048883, )
paddle.nn.functional.layer_norm(Tensor([0, 10, 4, 4],"float32"), 4, )
paddle.nn.functional.layer_norm(Tensor([0, 10, 60, 30],"float32"), list[10,60,30,], weight=Tensor([18000],"float32"), bias=Tensor([18000],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 10, 60, 70],"float32"), list[60,70,], weight=Tensor([4200],"float32"), bias=Tensor([4200],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 165, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 186, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 2, 2],"float32"), 2, epsilon=1e-05, weight=None, bias=None, )
paddle.nn.functional.layer_norm(Tensor([0, 2, 2],"float32"), 2, epsilon=1e-05, weight=Tensor([2],"float32"), bias=Tensor([2],"float32"), )
paddle.nn.functional.layer_norm(Tensor([0, 20],"float16"), list[20,], Tensor([20],"float32"), Tensor([20],"float32"), )
paddle.nn.functional.layer_norm(Tensor([0, 209, 384],"float32"), 384, weight=Tensor([384],"float32"), bias=Tensor([384],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 3, 10, 10],"float32"), list[3,10,10,], Tensor([300],"float32"), Tensor([300],"float32"), )
paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float32"), list[6,6,3,], weight=None, bias=Tensor([108],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float32"), list[6,6,3,], weight=Tensor([108],"float32"), bias=None, epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float32"), list[6,6,3,], weight=Tensor([108],"float32"), bias=Tensor([108],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float64"), list[6,6,3,], weight=None, bias=Tensor([108],"float64"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float64"), list[6,6,3,], weight=Tensor([108],"float64"), bias=None, epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 6, 6, 3],"float64"), list[6,6,3,], weight=Tensor([108],"float64"), bias=Tensor([108],"float64"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([0, 64, 128],"float32"), list[64,128,], Tensor([8192],"float32"), Tensor([8192],"float32"), )
paddle.nn.functional.layer_norm(Tensor([1, 0, 2],"float32"), 2, epsilon=1e-05, weight=None, bias=None, )
paddle.nn.functional.layer_norm(Tensor([1, 0, 2],"float32"), 2, epsilon=1e-05, weight=Tensor([2],"float32"), bias=Tensor([2],"float32"), )
paddle.nn.functional.layer_norm(Tensor([14, 0, 384],"float32"), 384, weight=Tensor([384],"float32"), bias=Tensor([384],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([20, 0, 60, 70],"float32"), list[60,70,], weight=Tensor([4200],"float32"), bias=Tensor([4200],"float32"), epsilon=1e-05, )
paddle.nn.functional.layer_norm(Tensor([4, 0, 4, 4],"float32"), 4, )
paddle.nn.functional.layer_norm(Tensor([4, 10, 0, 4],"float32"), 4, )
paddle.nn.functional.layer_norm(Tensor([7, 0, 1024],"float32"), 1024, weight=Tensor([1024],"float32"), bias=Tensor([1024],"float32"), epsilon=1e-05, )
paddle.nn.functional.local_response_norm(Tensor([0, 3, 40, 40],"float32"), 5, 0.0001, 0.75, 1.0, "NCHW", None, )
paddle.nn.functional.local_response_norm(Tensor([0, 40, 40, 3],"float32"), 5, 0.0001, 0.75, 1.0, "NHWC", None, )
paddle.nn.functional.local_response_norm(x=Tensor([0, 3, 3, 40, 40],"float32"), size=5, data_format="NCDHW", )
paddle.nn.functional.local_response_norm(x=Tensor([0, 3, 40, 40, 3],"float32"), size=5, data_format="NDHWC", )
paddle.nn.functional.local_response_norm(x=Tensor([0, 3, 40, 40],"float32"), size=5, data_format="NCHW", )
paddle.nn.functional.local_response_norm(x=Tensor([0, 40, 40, 3],"float32"), size=5, data_format="NHWC", )
paddle.nn.functional.local_response_norm(x=Tensor([0, 40, 40],"float32"), size=5, data_format="NCL", )
paddle.nn.functional.local_response_norm(x=Tensor([0, 40, 40],"float32"), size=5, data_format="NLC", )
paddle.nn.functional.log_softmax(Tensor([0, 2, 3],"float32"), )
paddle.nn.functional.log_softmax(Tensor([0, 2],"float32"), )
paddle.nn.functional.log_softmax(Tensor([0, 3, 2, 4],"float32"), 1, )
paddle.nn.functional.log_softmax(Tensor([0, 3, 4, 5],"float32"), 1, )
paddle.nn.functional.log_softmax(Tensor([0, 3, 4, 5],"float32"), -1, )
paddle.nn.functional.log_softmax(Tensor([0, 3, 4, 5],"float32"), 1, None, )
paddle.nn.functional.log_softmax(Tensor([0, 3, 4, 5],"float32"), -1, None, )
paddle.nn.functional.log_softmax(Tensor([0, 3, 4],"float64"), 1, )
paddle.nn.functional.log_softmax(Tensor([0, 3],"float32"), 1, )
paddle.nn.functional.log_softmax(Tensor([0, 8],"float32"), axis=1, )
paddle.nn.functional.log_softmax(Tensor([100000, 0, 3],"float32"), )
paddle.nn.functional.log_softmax(Tensor([2, 0, 1],"float32"), 0, )
paddle.nn.functional.log_softmax(Tensor([2, 0, 1],"float64"), 0, )
paddle.nn.functional.log_softmax(Tensor([2, 0, 4, 5],"float32"), -1, )
paddle.nn.functional.log_softmax(Tensor([2, 0, 4, 5],"float32"), -1, None, )
paddle.nn.functional.log_softmax(Tensor([2, 2, 0],"float32"), 0, )
paddle.nn.functional.log_softmax(Tensor([2, 2, 0],"float64"), 0, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 0, 5],"float32"), 1, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 0, 5],"float32"), -1, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 0, 5],"float32"), 1, None, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 0, 5],"float32"), -1, None, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 0],"float64"), 1, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 0],"float64"), -1, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 0],"float64"), 2, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 4, 0],"float32"), -1, "float64", )
paddle.nn.functional.log_softmax(Tensor([2, 3, 4, 0],"float32"), 1, )
paddle.nn.functional.log_softmax(Tensor([2, 3, 4, 0],"float32"), 1, None, )
paddle.nn.functional.log_softmax(Tensor([5, 3, 0, 4],"float32"), 1, )
paddle.nn.functional.log_softmax(Tensor([5, 3, 2, 0],"float32"), 1, )
paddle.nn.functional.log_softmax(x=Tensor([0, 3, 4],"float64"), axis=1, )
paddle.nn.functional.log_softmax(x=Tensor([0, 3, 4],"float64"), axis=2, dtype="float32", )
paddle.nn.functional.log_softmax(x=Tensor([0, 3, 4],"float64"), axis=2, dtype=type(numpy.float32), )
paddle.nn.functional.log_softmax(x=Tensor([2, 0, 1],"float32"), axis=0, )
paddle.nn.functional.log_softmax(x=Tensor([2, 0, 1],"float64"), axis=0, )
paddle.nn.functional.log_softmax(x=Tensor([2, 0, 4],"float64"), axis=2, dtype="float32", )
paddle.nn.functional.log_softmax(x=Tensor([2, 0, 4],"float64"), axis=2, dtype=type(numpy.float32), )
paddle.nn.functional.log_softmax(x=Tensor([2, 2, 0],"float32"), axis=0, )
paddle.nn.functional.log_softmax(x=Tensor([2, 2, 0],"float64"), axis=0, )
paddle.nn.functional.log_softmax(x=Tensor([2, 3, 0],"float64"), )
paddle.nn.functional.log_softmax(x=Tensor([2, 3, 0],"float64"), axis=1, )
paddle.nn.functional.log_softmax(x=Tensor([2, 3, 0],"float64"), axis=-1, )
paddle.nn.functional.log_softmax(x=Tensor([2, 3, 0],"float64"), axis=2, )
paddle.nn.functional.log_softmax(x=Tensor([2, 3, 0],"float64"), axis=2, dtype="float64", )
paddle.nn.functional.log_softmax(x=Tensor([2, 3, 0],"float64"), axis=2, dtype=type(numpy.float64), )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float16"), 5.0, 5, 3, 0, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float16"), norm_type=5, kernel_size=5, stride=3, padding=list[0,], )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float32"), 7.0, 2, None, 1, True, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float32"), math.inf, 2, None, 1, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float32"), norm_type=4, kernel_size=3, stride=2, padding=list[1,], )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float32"), norm_type=7, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float32"), norm_type=math.inf, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float64"), 5.0, 5, 3, 0, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([0, 3, 32],"float64"), norm_type=5, kernel_size=5, stride=3, padding=list[0,], )
paddle.nn.functional.lp_pool1d(Tensor([0, 32, 3],"float32"), 7.0, 2, None, 1, False, "NLC", None, )
paddle.nn.functional.lp_pool1d(Tensor([0, 32, 3],"float32"), norm_type=7, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, data_format="NLC", )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 3],"float32"), 7.0, 2, None, 1, False, "NLC", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 3],"float32"), norm_type=7, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, data_format="NLC", )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float16"), 5.0, 5, 3, 0, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float16"), norm_type=5, kernel_size=5, stride=3, padding=list[0,], )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float32"), 7.0, 2, None, 1, True, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float32"), math.inf, 2, None, 1, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float32"), norm_type=4, kernel_size=3, stride=2, padding=list[1,], )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float32"), norm_type=7, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float32"), norm_type=math.inf, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float64"), 5.0, 5, 3, 0, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 0, 32],"float64"), norm_type=5, kernel_size=5, stride=3, padding=list[0,], )
paddle.nn.functional.lp_pool1d(Tensor([2, 3, 0],"float32"), 4.0, 3, 2, 1, False, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 3, 0],"float32"), 7.0, 2, None, 1, True, "NCL", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 3, 0],"float32"), norm_type=4, kernel_size=3, stride=2, padding=list[1,], )
paddle.nn.functional.lp_pool1d(Tensor([2, 3, 0],"float32"), norm_type=7, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, )
paddle.nn.functional.lp_pool1d(Tensor([2, 32, 0],"float32"), 7.0, 2, None, 1, False, "NLC", None, )
paddle.nn.functional.lp_pool1d(Tensor([2, 32, 0],"float32"), norm_type=7, kernel_size=2, stride=2, padding=list[1,], ceil_mode=True, data_format="NLC", )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float16"), 2, kernel_size=3, stride=2, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float16"), norm_type=2.0, kernel_size=3, stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), -math.inf, kernel_size=2, stride=2, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), math.inf, kernel_size=list[2,4,], stride=2, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), norm_type=2.0, kernel_size=2, stride=1, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), norm_type=2.0, kernel_size=2, stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), norm_type=2.0, kernel_size=5, stride=3, padding=0, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), norm_type=-math.inf, kernel_size=2, stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float32"), norm_type=math.inf, kernel_size=list[2,4,], stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float64"), 2, kernel_size=5, stride=3, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([0, 3, 32, 32],"float64"), norm_type=2.0, kernel_size=5, stride=3, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([0, 32, 32, 3],"float32"), 2, kernel_size=2, stride=2, ceil_mode=False, data_format="NHWC", )
paddle.nn.functional.lp_pool2d(Tensor([0, 32, 32, 3],"float32"), norm_type=2.0, kernel_size=2, stride=list[2,2,], padding=0, ceil_mode=False, data_format="NHWC", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float16"), 2, kernel_size=3, stride=2, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float16"), norm_type=2.0, kernel_size=3, stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), 2, kernel_size=2, stride=1, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), 2, kernel_size=2, stride=None, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), 2, kernel_size=5, stride=3, ceil_mode=True, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), -math.inf, kernel_size=2, stride=2, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), math.inf, kernel_size=list[2,4,], stride=2, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), norm_type=2.0, kernel_size=2, stride=1, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), norm_type=2.0, kernel_size=2, stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), norm_type=2.0, kernel_size=5, stride=3, padding=0, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), norm_type=-math.inf, kernel_size=2, stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float32"), norm_type=math.inf, kernel_size=list[2,4,], stride=2, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float64"), 2, kernel_size=5, stride=3, ceil_mode=False, )
paddle.nn.functional.lp_pool2d(Tensor([2, 0, 32, 32],"float64"), norm_type=2.0, kernel_size=5, stride=3, padding=0, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.lp_pool2d(Tensor([2, 32, 32, 0],"float32"), 2, kernel_size=2, stride=2, ceil_mode=False, data_format="NHWC", )
paddle.nn.functional.lp_pool2d(Tensor([2, 32, 32, 0],"float32"), norm_type=2.0, kernel_size=2, stride=list[2,2,], padding=0, ceil_mode=False, data_format="NHWC", name=None, )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.0, "none", )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.0, "none", None, )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.0, "sum", )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.0, "sum", None, )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.2, "none", )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.2, "none", None, )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.2, "sum", )
paddle.nn.functional.margin_ranking_loss(Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), Tensor([0, 10],"float64"), 0.2, "sum", None, )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.0, "none", )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.0, "none", None, )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.0, "sum", )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.0, "sum", None, )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.2, "none", )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.2, "none", None, )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.2, "sum", )
paddle.nn.functional.margin_ranking_loss(Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), Tensor([10, 0],"float64"), 0.2, "sum", None, )
paddle.nn.functional.max_pool1d(Tensor([0, 1, 2],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 16],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 16],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 16],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 32],"float32"), 2, None, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 32],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 6],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float32"), 2, 2, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 1, 1, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 2, 1, 0, False, True, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 2, 1, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 2, 1, list[1,], False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 2, 1, list[1,1,], False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 2, 2, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 2, 2, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 2, list[1,], 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), 3, 4, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 3, 8],"float64"), list[3,], 1, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([0, 32, 7],"float32"), 7, )
paddle.nn.functional.max_pool1d(Tensor([1, 0, 16],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 0, 16],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([1, 0, 16],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 0, 2],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([1, 0, 6],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 1, 0],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 0],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 0],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 0],"float64"), 2, 2, 0, True, False, None, )
paddle.nn.functional.max_pool1d(Tensor([1, 3, 0],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 32],"float32"), 2, None, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 32],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float32"), 2, 2, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 1, 1, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 2, 1, 0, False, True, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 2, 1, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 2, 1, list[1,], False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 2, 1, list[1,1,], False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 2, 2, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 2, 2, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 2, list[1,], 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), 3, 4, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 0, 8],"float64"), list[3,], 1, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 0],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 0],"float64"), 2, 1, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 0],"float64"), 2, 1, list[1,], False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 0],"float64"), 2, 1, list[1,1,], False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 0],"float64"), 2, 2, 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 0],"float64"), 2, list[1,], 1, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([2, 3, 0],"float64"), 3, 4, 0, False, False, None, )
paddle.nn.functional.max_pool1d(Tensor([91, 0, 7],"float32"), 7, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 1, 2],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=1, stride=1, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=1, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=1, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=1, padding=list[1,], )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=1, padding=list[1,1,], )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=2, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=2, stride=list[1,], padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=3, stride=4, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([0, 3, 8],"float64"), kernel_size=list[3,], stride=1, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([1, 0, 2],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool1d(x=Tensor([1, 1, 0],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=1, stride=1, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=1, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=1, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=1, padding=list[1,], )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=1, padding=list[1,1,], )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=2, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=2, stride=list[1,], padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=3, stride=4, padding=0, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 0, 8],"float64"), kernel_size=list[3,], stride=1, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=2, stride=1, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=2, stride=1, padding=list[1,], )
paddle.nn.functional.max_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=2, stride=1, padding=list[1,1,], )
paddle.nn.functional.max_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=2, stride=2, padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=2, stride=list[1,], padding=1, )
paddle.nn.functional.max_pool1d(x=Tensor([2, 3, 0],"float64"), kernel_size=3, stride=4, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([0, 1, 4, 1],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 1, 4, 4],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 1, 4, 4],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 1, 4, 5],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 1, 7, 1],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 112, 112, 64],"float16"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NHWC", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 128, 40, 40],"float16"), 3, stride=1, padding=1, data_format="NCHW", )
paddle.nn.functional.max_pool2d(Tensor([0, 128, 40, 40],"float32"), 3, stride=1, padding=1, data_format="NCHW", )
paddle.nn.functional.max_pool2d(Tensor([0, 128, 40, 40],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 128, 55, 55],"float32"), kernel_size=3, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 16, 10, 10],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 192, 20, 20],"float32"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 192, 20, 20],"float32"), kernel_size=5, stride=1, padding=2, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 192, 20, 20],"float32"), kernel_size=9, stride=1, padding=4, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 192, 27, 27],"float32"), kernel_size=3, stride=1, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 192, 27, 27],"float32"), kernel_size=3, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 2, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 24, 368, 368],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 24, 384, 384],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 24, 40, 40],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 244, 244, 2],"float32"), kernel_size=list[5,3,], stride=list[1,2,], padding=tuple(2,1,), )
paddle.nn.functional.max_pool2d(Tensor([0, 256, 20, 27],"float32"), 1, stride=2, )
paddle.nn.functional.max_pool2d(Tensor([0, 256, 20, 30],"float32"), 1, stride=2, )
paddle.nn.functional.max_pool2d(Tensor([0, 256, 27, 27],"float32"), kernel_size=3, stride=1, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 256, 7, 7],"float32"), kernel_size=1, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 224, 224],"float32"), kernel_size=1, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 224, 224],"float32"), kernel_size=2, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 224, 224],"float32"), kernel_size=3, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 224, 224],"float32"), kernel_size=list[5,3,], stride=list[1,2,], padding=tuple(2,1,), )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=1, ceil_mode=False, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[list[0,0,],list[0,0,],list[0,0,],list[0,0,],], return_mask=False, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float32"), kernel_size=list[2,2,], stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[2,2,], stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[0,0,0,0,], return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[1,1,], return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,2,], padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=tuple(1,2,), padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 33, 33],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 3, 6, 6],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([0, 32, 32, 3],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, data_format="NHWC", )
paddle.nn.functional.max_pool2d(Tensor([0, 384, 32, 32],"float32"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 384, 32, 32],"float32"), kernel_size=5, stride=1, padding=2, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 384, 32, 32],"float32"), kernel_size=9, stride=1, padding=4, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 4, 4, 4],"float16"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([0, 4, 40, 40],"float64"), kernel_size=2, stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 4, 40, 40],"float64"), kernel_size=4, stride=2, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 4, 40, 40],"float64"), kernel_size=4, stride=None, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 4, 40, 40],"float64"), kernel_size=tuple(2,4,), stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 512, 1, 40],"float16"), kernel_size=tuple(1,1,), stride=1, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([0, 512, 1, 40],"float32"), kernel_size=tuple(1,1,), stride=1, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([0, 64, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 64, 17, 17],"float32"), kernel_size=tuple(3,3,), stride=tuple(2,2,), padding=tuple(0,0,), return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 64, 17, 257],"float32"), tuple(3,3,), tuple(2,2,), tuple(0,0,), False, )
paddle.nn.functional.max_pool2d(Tensor([0, 64, 17, 273],"float32"), tuple(3,3,), tuple(2,2,), tuple(0,0,), False, )
paddle.nn.functional.max_pool2d(Tensor([0, 64, 18, 18],"float32"), kernel_size=tuple(3,3,), stride=tuple(2,2,), padding=tuple(0,0,), return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([0, 64, 288, 399],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([0, 64, 320, 432],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([0, 8, 16, 64],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 10, 10],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 112, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 17, 257],"float32"), tuple(3,3,), tuple(2,2,), tuple(0,0,), False, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 17, 273],"float32"), tuple(3,3,), tuple(2,2,), tuple(0,0,), False, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 20, 20],"float32"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 20, 20],"float32"), kernel_size=5, stride=1, padding=2, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 20, 20],"float32"), kernel_size=9, stride=1, padding=4, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 20, 27],"float32"), 1, stride=2, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 20, 30],"float32"), 1, stride=2, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 224, 224],"float32"), kernel_size=1, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 224, 224],"float32"), kernel_size=2, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 224, 224],"float32"), kernel_size=3, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 288, 399],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 32, 32],"float32"), kernel_size=13, stride=1, padding=6, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 32, 32],"float32"), kernel_size=5, stride=1, padding=2, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 32, 32],"float32"), kernel_size=9, stride=1, padding=4, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 320, 432],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 368, 368],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 384, 384],"float32"), kernel_size=2, stride=1, padding="SAME", return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 4, 4],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 4, 4],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 4, 5],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 40, 40],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 40, 40],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 0, 6, 6],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 0, 4],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 0, 4],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 0, 5],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 4, 0],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 1, 4, 0],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 2, 0, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 2, 32, 0],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 24, 0, 40],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 24, 40, 0],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 256, 0, 27],"float32"), 1, stride=2, )
paddle.nn.functional.max_pool2d(Tensor([1, 256, 0, 30],"float32"), 1, stride=2, )
paddle.nn.functional.max_pool2d(Tensor([1, 256, 20, 0],"float32"), 1, stride=2, )
paddle.nn.functional.max_pool2d(Tensor([1, 3, 0, 6],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 3, 6, 0],"float32"), kernel_size=2, stride=2, padding=0, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([1, 64, 0, 112],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 64, 0, 399],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([1, 64, 0, 432],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([1, 64, 112, 0],"float32"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([1, 64, 288, 0],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([1, 64, 320, 0],"float32"), kernel_size=3, stride=2, padding=1, )
paddle.nn.functional.max_pool2d(Tensor([12, 0, 40, 40],"float16"), 3, stride=1, padding=1, data_format="NCHW", )
paddle.nn.functional.max_pool2d(Tensor([12, 0, 40, 40],"float32"), 3, stride=1, padding=1, data_format="NCHW", )
paddle.nn.functional.max_pool2d(Tensor([13, 0, 4, 1],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([13, 0, 7, 1],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([13, 0, 7, 7],"float32"), kernel_size=1, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([13, 1, 0, 1],"float32"), tuple(2,1,), stride=tuple(2,1,), ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([13, 256, 0, 7],"float32"), kernel_size=1, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([13, 256, 7, 0],"float32"), kernel_size=1, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 16, 64],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 17, 17],"float32"), kernel_size=tuple(3,3,), stride=tuple(2,2,), padding=tuple(0,0,), return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 224, 224],"float32"), kernel_size=list[5,3,], stride=list[1,2,], padding=tuple(2,1,), )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 244, 2],"float32"), kernel_size=list[5,3,], stride=list[1,2,], padding=tuple(2,1,), )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 27, 27],"float32"), kernel_size=3, stride=1, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 27, 27],"float32"), kernel_size=3, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=1, ceil_mode=False, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[list[0,0,],list[0,0,],list[0,0,],list[0,0,],], return_mask=False, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float32"), kernel_size=list[2,2,], stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[2,2,], stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[0,0,0,0,], return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[1,1,], return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,2,], padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=tuple(1,2,), padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 33, 33],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 40, 40],"float64"), kernel_size=2, stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 40, 40],"float64"), kernel_size=4, stride=2, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 40, 40],"float64"), kernel_size=4, stride=None, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 40, 40],"float64"), kernel_size=tuple(2,4,), stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 0, 55, 55],"float32"), kernel_size=3, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 244, 244, 0],"float32"), kernel_size=list[5,3,], stride=list[1,2,], padding=tuple(2,1,), )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 0, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 0, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 0, 32],"float32"), kernel_size=2, stride=2, padding=1, ceil_mode=False, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 0, 32],"float32"), kernel_size=2, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 0, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 0, 33],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 224, 0],"float32"), kernel_size=list[5,3,], stride=list[1,2,], padding=tuple(2,1,), )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 32, 0],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 32, 0],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 32, 0],"float32"), kernel_size=2, stride=2, padding=1, ceil_mode=False, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 32, 0],"float32"), kernel_size=2, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 32, 0],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 3, 33, 0],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool2d(Tensor([2, 32, 32, 0],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, data_format="NHWC", )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 0, 40],"float64"), kernel_size=2, stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 0, 40],"float64"), kernel_size=4, stride=2, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 0, 40],"float64"), kernel_size=4, stride=None, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 0, 40],"float64"), kernel_size=tuple(2,4,), stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 0],"float64"), kernel_size=2, stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 0],"float64"), kernel_size=4, stride=2, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 0],"float64"), kernel_size=4, stride=None, padding=2, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 4, 40, 0],"float64"), kernel_size=tuple(2,4,), stride=None, padding=0, return_mask=True, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 8, 0, 64],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([2, 8, 16, 0],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=True, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([256, 0, 112, 64],"float16"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NHWC", name=None, )
paddle.nn.functional.max_pool2d(Tensor([256, 112, 0, 64],"float16"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NHWC", name=None, )
paddle.nn.functional.max_pool2d(Tensor([256, 112, 112, 0],"float16"), kernel_size=3, stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NHWC", name=None, )
paddle.nn.functional.max_pool2d(Tensor([3, 0, 18, 18],"float32"), kernel_size=tuple(3,3,), stride=tuple(2,2,), padding=tuple(0,0,), return_mask=False, ceil_mode=False, data_format="NCHW", name=None, )
paddle.nn.functional.max_pool2d(Tensor([4, 0, 4, 4],"float16"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([64, 0, 1, 40],"float16"), kernel_size=tuple(1,1,), stride=1, padding=0, )
paddle.nn.functional.max_pool2d(Tensor([64, 0, 1, 40],"float32"), kernel_size=tuple(1,1,), stride=1, padding=0, )
paddle.nn.functional.max_pool2d(x=Tensor([0, 2, 24, 24],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float32"), kernel_size=list[2,2,], )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[2,2,], )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], padding=list[1,1,], stride=list[1,1,], )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], ceil_mode=True, )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,2,], )
paddle.nn.functional.max_pool2d(x=Tensor([0, 3, 32, 32],"float64"), kernel_size=list[3,3,], stride=tuple(1,2,), )
paddle.nn.functional.max_pool2d(x=Tensor([0, 4, 8, 8],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 24, 24],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float32"), kernel_size=list[2,2,], )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[2,2,], )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], padding=list[1,1,], stride=list[1,1,], )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,1,], ceil_mode=True, )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=list[1,2,], )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 32, 32],"float64"), kernel_size=list[3,3,], stride=tuple(1,2,), )
paddle.nn.functional.max_pool2d(x=Tensor([2, 0, 8, 8],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool3d(Tensor([0, 2, 6, 33, 33],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[list[0,0,],list[0,0,],list[0,0,],list[0,0,],list[0,0,],], )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding=0, return_mask=False, ceil_mode=True, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 4, 4, 4],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=True, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 4, 4, 6],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 4, 4, 6],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 4, 4, 6],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 6, 6, 3],"float32"), 3, data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 32, 32, 32, 3],"float32"), kernel_size=2, stride=2, padding=0, data_format="NDHWC", return_mask=False, )
paddle.nn.functional.max_pool3d(Tensor([0, 4, 4, 4, 4],"float32"), list[3,3,3,], stride=1, padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([0, 4, 4, 4, 4],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([0, 5, 6, 8, 3],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=1, data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([0, 6, 7, 9, 3],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([0, 6, 9, 6, 3],"float32"), list[5,5,5,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([0, 64, 16, 112, 112],"float32"), kernel_size=tuple(3,3,3,), stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([0, 8, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NDHWC", name=None, )
paddle.nn.functional.max_pool3d(Tensor([1, 0, 4, 4, 6],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 0, 4, 4, 6],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([1, 0, 4, 4, 6],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 0, 6, 33, 33],"float32"), kernel_size=5, stride=5, padding=0, ceil_mode=True, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 0, 4, 6],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 0, 4, 6],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 0, 4, 6],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 0, 6],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 0, 6],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 0, 6],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 4, 0],"float32"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 4, 0],"float64"), kernel_size=2, stride=2, padding=0, return_mask=True, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([1, 3, 4, 4, 0],"float64"), kernel_size=2, stride=2, return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([1, 4, 4, 4, 0],"float32"), list[3,3,3,], stride=1, padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([1, 4, 4, 4, 0],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([1, 5, 6, 8, 0],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=1, data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([1, 6, 9, 6, 0],"float32"), list[5,5,5,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[list[0,0,],list[0,0,],list[0,0,],list[0,0,],list[0,0,],], )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding=0, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding=0, return_mask=False, ceil_mode=True, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 4, 4, 4],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=True, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 32, 32],"float32"), kernel_size=2, stride=None, padding=0, return_mask=False, ceil_mode=True, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 32, 0, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 32, 0, 32],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 32, 0, 32],"float32"), kernel_size=2, stride=None, padding=0, return_mask=False, ceil_mode=True, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 32, 32, 0],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 32, 32, 0],"float32"), kernel_size=2, stride=None, padding="SAME", return_mask=True, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 32, 32, 0],"float32"), kernel_size=2, stride=None, padding=0, return_mask=False, ceil_mode=True, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 6, 6, 0],"float32"), 3, data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 3, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([2, 32, 32, 32, 0],"float32"), kernel_size=2, stride=2, padding=0, data_format="NDHWC", return_mask=False, )
paddle.nn.functional.max_pool3d(Tensor([2, 6, 7, 9, 0],"float32"), list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(Tensor([2, 8, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], return_mask=False, ceil_mode=False, data_format="NDHWC", name=None, )
paddle.nn.functional.max_pool3d(Tensor([8, 0, 16, 112, 112],"float32"), kernel_size=tuple(3,3,3,), stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([8, 64, 0, 112, 112],"float32"), kernel_size=tuple(3,3,3,), stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([8, 64, 16, 0, 112],"float32"), kernel_size=tuple(3,3,3,), stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(Tensor([8, 64, 16, 112, 0],"float32"), kernel_size=tuple(3,3,3,), stride=2, padding=1, return_mask=False, ceil_mode=False, data_format="NCDHW", name=None, )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([0, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), )
paddle.nn.functional.max_pool3d(x=Tensor([0, 32, 32, 56, 56],"float32"), kernel_size=list[1,1,1,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([0, 320, 4, 56, 56],"float32"), kernel_size=list[1,1,1,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([0, 64, 4, 112, 112],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([0, 8, 32, 112, 112],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([0, 8, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 0, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 0, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 8, 0, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], )
paddle.nn.functional.max_pool3d(x=Tensor([2, 3, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, )
paddle.nn.functional.max_pool3d(x=Tensor([2, 8, 8, 8, 0],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NDHWC", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 0, 32, 112, 112],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 0, 32, 56, 56],"float32"), kernel_size=list[1,1,1,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 0, 4, 112, 112],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 0, 4, 56, 56],"float32"), kernel_size=list[1,1,1,], stride=list[1,1,1,], padding=list[0,0,0,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 64, 4, 0, 112],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 64, 4, 112, 0],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 8, 32, 0, 112],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_pool3d(x=Tensor([8, 8, 32, 112, 0],"float32"), kernel_size=list[1,3,3,], stride=list[1,2,2,], padding=list[0,1,1,], data_format="NCDHW", )
paddle.nn.functional.max_unpool1d(Tensor([0, 3, 8],"float64"), Tensor([0, 3, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
paddle.nn.functional.max_unpool1d(Tensor([0, 3, 8],"float64"), Tensor([0, 3, 8],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.max_unpool1d(Tensor([0, 3, 8],"int64"), Tensor([0, 3, 8],"int32"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
paddle.nn.functional.max_unpool1d(Tensor([0, 3, 8],"int64"), Tensor([0, 3, 8],"int32"), kernel_size=2, stride=2, output_size=tuple(1,3,16,), )
paddle.nn.functional.max_unpool1d(Tensor([1, 0, 8],"float64"), Tensor([1, 0, 8],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
paddle.nn.functional.max_unpool1d(Tensor([1, 0, 8],"float64"), Tensor([1, 0, 8],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.max_unpool1d(Tensor([1, 0, 8],"int64"), Tensor([1, 0, 8],"int32"), kernel_size=2, stride=2, output_size=list[1,3,16,], )
paddle.nn.functional.max_unpool1d(Tensor([1, 0, 8],"int64"), Tensor([1, 0, 8],"int32"), kernel_size=2, stride=2, output_size=tuple(1,3,16,), )
paddle.nn.functional.max_unpool1d(Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCL", output_size=None, name=None, )
paddle.nn.functional.max_unpool1d(Tensor([1, 3, 0],"float64"), Tensor([1, 3, 0],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.max_unpool2d(Tensor([0, 1, 2, 2],"float32"), Tensor([0, 1, 2, 2],"int32"), kernel_size=2, stride=2, output_size=tuple(5,5,), )
paddle.nn.functional.max_unpool2d(Tensor([0, 1, 2, 2],"float32"), Tensor([0, 1, 2, 2],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([0, 1, 2, 2],"float32"), Tensor([0, 1, 2, 2],"int32"), kernel_size=2, stride=None, output_size=tuple(5,5,), )
paddle.nn.functional.max_unpool2d(Tensor([0, 1, 2, 2],"float32"), Tensor([0, 1, 2, 2],"int64"), kernel_size=2, stride=None, output_size=list[1,1,4,5,], )
paddle.nn.functional.max_unpool2d(Tensor([0, 1, 2, 2],"int64"), Tensor([0, 1, 2, 2],"int32"), kernel_size=2, stride=None, output_size=list[1,1,4,5,], )
paddle.nn.functional.max_unpool2d(Tensor([0, 3, 3, 3],"float32"), Tensor([0, 3, 3, 3],"int32"), kernel_size=2, padding=0, output_size=list[1,1,7,7,], )
paddle.nn.functional.max_unpool2d(Tensor([0, 3, 3, 3],"float32"), Tensor([0, 3, 3, 3],"int32"), kernel_size=2, padding=0, output_size=list[7,7,], )
paddle.nn.functional.max_unpool2d(Tensor([0, 4, 7, 8],"float64"), Tensor([0, 4, 7, 8],"int32"), list[2,2,], stride=list[2,2,], padding=list[0,0,], data_format="NCHW", output_size=list[14,16,], name=None, )
paddle.nn.functional.max_unpool2d(Tensor([1, 0, 2, 2],"float32"), Tensor([1, 0, 2, 2],"int32"), kernel_size=2, stride=2, output_size=tuple(5,5,), )
paddle.nn.functional.max_unpool2d(Tensor([1, 0, 2, 2],"float32"), Tensor([1, 0, 2, 2],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([1, 0, 2, 2],"float32"), Tensor([1, 0, 2, 2],"int32"), kernel_size=2, stride=None, output_size=tuple(5,5,), )
paddle.nn.functional.max_unpool2d(Tensor([1, 0, 2, 2],"float32"), Tensor([1, 0, 2, 2],"int64"), kernel_size=2, stride=None, output_size=list[1,1,4,5,], )
paddle.nn.functional.max_unpool2d(Tensor([1, 0, 2, 2],"int64"), Tensor([1, 0, 2, 2],"int32"), kernel_size=2, stride=None, output_size=list[1,1,4,5,], )
paddle.nn.functional.max_unpool2d(Tensor([1, 0, 3, 3],"float32"), Tensor([1, 0, 3, 3],"int32"), kernel_size=2, padding=0, output_size=list[1,1,7,7,], )
paddle.nn.functional.max_unpool2d(Tensor([1, 0, 3, 3],"float32"), Tensor([1, 0, 3, 3],"int32"), kernel_size=2, padding=0, output_size=list[7,7,], )
paddle.nn.functional.max_unpool2d(Tensor([1, 1, 0, 2],"float32"), Tensor([1, 1, 0, 2],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([1, 1, 2, 0],"float32"), Tensor([1, 1, 2, 0],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool2d(Tensor([2, 0, 7, 8],"float64"), Tensor([2, 0, 7, 8],"int32"), list[2,2,], stride=list[2,2,], padding=list[0,0,], data_format="NCHW", output_size=list[14,16,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([0, 1, 4, 5, 6],"float64"), Tensor([0, 1, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([0, 3, 2, 2, 3],"float32"), Tensor([0, 3, 2, 2, 3],"int64"), kernel_size=2, stride=2, output_size=list[1,3,4,4,6,], )
paddle.nn.functional.max_unpool3d(Tensor([0, 3, 2, 2, 3],"float64"), Tensor([0, 3, 2, 2, 3],"int32"), kernel_size=2, stride=2, )
paddle.nn.functional.max_unpool3d(Tensor([0, 3, 2, 2, 3],"float64"), Tensor([0, 3, 2, 2, 3],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCDHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool3d(Tensor([0, 3, 2, 2, 3],"float64"), Tensor([0, 3, 2, 2, 3],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.max_unpool3d(Tensor([0, 3, 2, 2, 3],"int64"), Tensor([0, 3, 2, 2, 3],"int32"), kernel_size=2, stride=2, output_size=list[1,3,4,4,6,], )
paddle.nn.functional.max_unpool3d(Tensor([1, 0, 2, 2, 3],"float32"), Tensor([1, 0, 2, 2, 3],"int64"), kernel_size=2, stride=2, output_size=list[1,3,4,4,6,], )
paddle.nn.functional.max_unpool3d(Tensor([1, 0, 2, 2, 3],"float64"), Tensor([1, 0, 2, 2, 3],"int32"), kernel_size=2, stride=2, )
paddle.nn.functional.max_unpool3d(Tensor([1, 0, 2, 2, 3],"float64"), Tensor([1, 0, 2, 2, 3],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCDHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 0, 2, 2, 3],"float64"), Tensor([1, 0, 2, 2, 3],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 0, 2, 2, 3],"int64"), Tensor([1, 0, 2, 2, 3],"int32"), kernel_size=2, stride=2, output_size=list[1,3,4,4,6,], )
paddle.nn.functional.max_unpool3d(Tensor([1, 0, 4, 5, 6],"float64"), Tensor([1, 0, 4, 5, 6],"int64"), list[2,2,2,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NCDHW", output_size=list[8,10,12,], name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 0, 2, 3],"float64"), Tensor([1, 3, 0, 2, 3],"int32"), kernel_size=2, stride=2, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 0, 2, 3],"float64"), Tensor([1, 3, 0, 2, 3],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCDHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 0, 2, 3],"float64"), Tensor([1, 3, 0, 2, 3],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 2, 0, 3],"float64"), Tensor([1, 3, 2, 0, 3],"int32"), kernel_size=2, stride=2, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 2, 0, 3],"float64"), Tensor([1, 3, 2, 0, 3],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCDHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 2, 0, 3],"float64"), Tensor([1, 3, 2, 0, 3],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 2, 2, 0],"float64"), Tensor([1, 3, 2, 2, 0],"int32"), kernel_size=2, stride=2, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 2, 2, 0],"float64"), Tensor([1, 3, 2, 2, 0],"int32"), kernel_size=2, stride=2, padding=0, data_format="NCDHW", output_size=None, name=None, )
paddle.nn.functional.max_unpool3d(Tensor([1, 3, 2, 2, 0],"float64"), Tensor([1, 3, 2, 2, 0],"int32"), kernel_size=2, stride=None, )
paddle.nn.functional.maxout(Tensor([0, 2, 2, 6],"float64"), 2, 3, None, )
paddle.nn.functional.maxout(Tensor([0, 4, 3, 3],"float32"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([0, 4, 3, 3],"float64"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([0, 6, 5, 4],"float64"), 2, 1, )
paddle.nn.functional.maxout(Tensor([0, 6, 5, 4],"float64"), 2, -1, )
paddle.nn.functional.maxout(Tensor([0, 9, 3, 3],"float64"), 3, 1, None, )
paddle.nn.functional.maxout(Tensor([10, 0, 3, 3],"float64"), 3, 1, None, )
paddle.nn.functional.maxout(Tensor([10, 9, 0, 3],"float64"), 3, 1, None, )
paddle.nn.functional.maxout(Tensor([10, 9, 3, 0],"float64"), 3, 1, None, )
paddle.nn.functional.maxout(Tensor([100, 0, 3, 3],"float32"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([100, 0, 3, 3],"float64"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([100, 4, 0, 3],"float32"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([100, 4, 0, 3],"float64"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([100, 4, 3, 0],"float32"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([100, 4, 3, 0],"float64"), 2, 1, None, )
paddle.nn.functional.maxout(Tensor([2, 0, 5, 4],"float64"), 2, 1, )
paddle.nn.functional.maxout(Tensor([2, 0, 5, 4],"float64"), 2, -1, )
paddle.nn.functional.maxout(Tensor([2, 6, 0, 4],"float64"), 2, 1, )
paddle.nn.functional.maxout(Tensor([2, 6, 0, 4],"float64"), 2, -1, )
paddle.nn.functional.maxout(Tensor([2, 6, 5, 0],"float64"), 2, 1, )
paddle.nn.functional.maxout(Tensor([2, 6, 5, 0],"float64"), 2, -1, )
paddle.nn.functional.maxout(Tensor([9, 0, 2, 6],"float64"), 2, 3, None, )
paddle.nn.functional.maxout(Tensor([9, 2, 0, 6],"float64"), 2, 3, None, )
paddle.nn.functional.maxout(Tensor([9, 2, 2, 0],"float64"), 2, 3, None, )
paddle.nn.functional.maxout(x=Tensor([0, 2, 2, 6],"float64"), groups=2, axis=3, )
paddle.nn.functional.maxout(x=Tensor([0, 4, 3, 3],"float32"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([0, 4, 3, 3],"float64"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([0, 9, 3, 3],"float64"), groups=3, )
paddle.nn.functional.maxout(x=Tensor([10, 0, 3, 3],"float64"), groups=3, )
paddle.nn.functional.maxout(x=Tensor([10, 9, 0, 3],"float64"), groups=3, )
paddle.nn.functional.maxout(x=Tensor([10, 9, 3, 0],"float64"), groups=3, )
paddle.nn.functional.maxout(x=Tensor([100, 0, 3, 3],"float32"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([100, 0, 3, 3],"float64"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([100, 4, 0, 3],"float32"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([100, 4, 0, 3],"float64"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([100, 4, 3, 0],"float32"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([100, 4, 3, 0],"float64"), groups=2, )
paddle.nn.functional.maxout(x=Tensor([9, 0, 2, 6],"float64"), groups=2, axis=3, )
paddle.nn.functional.maxout(x=Tensor([9, 2, 0, 6],"float64"), groups=2, axis=3, )
paddle.nn.functional.maxout(x=Tensor([9, 2, 2, 0],"float64"), groups=2, axis=3, )
paddle.nn.functional.mse_loss(Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([0, 10, 10],"float32"), Tensor([0, 10, 10],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([0, 10, 10],"float32"), Tensor([0, 10, 10],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([0, 10],"float32"), Tensor([0, 10],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([0, 10],"float32"), Tensor([0, 10],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([0, 3, 10, 10],"float32"), Tensor([0, 3, 10, 10],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([0, 3, 10, 10],"float32"), Tensor([0, 3, 10, 10],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([0, 96, 2],"float32"), Tensor([0, 96, 2],"float32"), reduction="none", )
paddle.nn.functional.mse_loss(Tensor([1, 0],"float32"), Tensor([4, 0],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([1, 1],"float32"), Tensor([0, 1],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([1, 1],"float32"), Tensor([4, 0],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([16, 0, 2],"float32"), Tensor([16, 0, 2],"float32"), reduction="none", )
paddle.nn.functional.mse_loss(Tensor([16, 96, 0],"float32"), Tensor([16, 96, 0],"float32"), reduction="none", )
paddle.nn.functional.mse_loss(Tensor([2, 0, 10],"float32"), Tensor([2, 0, 10],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([2, 0, 10],"float32"), Tensor([2, 0, 10],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([2, 0, 2],"float32"), Tensor([2, 0, 2],"float32"), reduction="none", )
paddle.nn.functional.mse_loss(Tensor([2, 10, 0],"float32"), Tensor([2, 10, 0],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([2, 10, 0],"float32"), Tensor([2, 10, 0],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([2, 96, 0],"float32"), Tensor([2, 96, 0],"float32"), reduction="none", )
paddle.nn.functional.mse_loss(Tensor([3, 0, 10, 10],"float32"), Tensor([3, 0, 10, 10],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([3, 0, 10, 10],"float32"), Tensor([3, 0, 10, 10],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([3, 3, 0, 10],"float32"), Tensor([3, 3, 0, 10],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([3, 3, 0, 10],"float32"), Tensor([3, 3, 0, 10],"float32"), "sum", )
paddle.nn.functional.mse_loss(Tensor([3, 3, 10, 0],"float32"), Tensor([3, 3, 10, 0],"float32"), "none", )
paddle.nn.functional.mse_loss(Tensor([3, 3, 10, 0],"float32"), Tensor([3, 3, 10, 0],"float32"), "sum", )
paddle.nn.functional.multi_margin_loss(input=Tensor([5, 0],"float64"), label=Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", )
paddle.nn.functional.multi_margin_loss(input=Tensor([5, 0],"float64"), label=Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", )
paddle.nn.functional.multi_margin_loss(input=Tensor([5, 0],"float64"), label=Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", )
paddle.nn.functional.multi_margin_loss(Tensor([5, 0],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="mean", name=None, )
paddle.nn.functional.multi_margin_loss(Tensor([5, 0],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="none", name=None, )
paddle.nn.functional.multi_margin_loss(Tensor([5, 0],"float64"), Tensor([5],"int64"), p=1, margin=1.0, weight=None, reduction="sum", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 1, 1],"float16"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 1, 1],"float32"), list[0,0,0,0,], )
paddle.nn.functional.pad(Tensor([0, 1, 1, 1],"float32"), list[0,1,0,1,], )
paddle.nn.functional.pad(Tensor([0, 1, 1, 1],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([0, 1, 1, 13],"float32"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 10, 21],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 100, 111],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 128, 128],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([0, 1, 129, 129],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([0, 1, 16, 16],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([0, 1, 2, 1],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 2, 2],"float32"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 2, 2],"float64"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 2, 3],"float64"), pad=list[1,1,1,0,1,0,], mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 2],"float32"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 2],"float64"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 3, 2],"float64"), pad=list[1,0,1,0,0,1,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 3, 2],"float64"), pad=list[1,0,1,0,0,1,], mode="replicate", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 3, 2],"float64"), pad=list[1,0,1,2,1,0,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 2, 3],"float64"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 256, 256],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([0, 1, 256, 256],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([0, 1, 3, 1600, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 1, 3, 2],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 1, 3, 3, 1600],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 1, 3, 40, 40],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 1, 32, 128],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([0, 1, 40, 40, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 1, 40, 40],"float32"), pad=list[0,0,2,2,], )
paddle.nn.functional.pad(Tensor([0, 1, 40, 40],"float32"), pad=list[2,2,0,0,], )
paddle.nn.functional.pad(Tensor([0, 1, 96],"float32"), pad=tuple(0,8,), mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 128, 16, 104],"float32"), Tensor([4],"int32"), value=0, )
paddle.nn.functional.pad(Tensor([0, 128, 94, 70],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 14701, 3],"float32"), list[1,0,], value=4, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 14, 384],"float16"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 14, 384],"float32"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 15, 384],"float16"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 15, 384],"float16"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 15, 384],"float32"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 15, 384],"float32"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 16, 384],"float16"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 16, 384],"float32"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 17, 384],"float16"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 17, 384],"float32"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 18, 384],"float16"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 18, 384],"float32"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 19, 384],"float16"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 14, 19, 384],"float32"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 15, 14, 384],"float16"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 15, 14, 384],"float16"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 15, 14, 384],"float32"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 15, 14, 384],"float32"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 16, 14, 384],"float16"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 16, 14, 384],"float32"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 16, 64],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 18, 14, 384],"float16"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 18, 14, 384],"float32"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 31, 28, 192],"float16"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 31, 28, 192],"float32"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 16, 61, 56, 96],"float32"), tuple(0,0,0,2,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 160000, 1],"float64"), pad=list[256,256,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([0, 17980, 3],"float32"), list[1,0,], value=3, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 19780, 3],"float32"), list[1,0,], value=2, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 2, 2, 2, 2],"float64"), pad=list[1,1,1,0,1,0,], mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3, 1],"float64"), pad=list[1,1,1,0,], mode="reflect", value=0.0, data_format="NHWC", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4],"float64"), pad=list[2,1,2,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3, 4],"float64"), pad=list[2,1,2,1,], mode="replicate", value=0.0, data_format="NHWC", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float32"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float32"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float32"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float32"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float64"), pad=list[1,1,], mode="reflect", value=0.0, data_format="NLC", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float64"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float64"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float64"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float64"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NLC", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float64"), pad=list[2,1,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 2, 3],"float64"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 20524, 3],"float32"), list[1,0,], value=1, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 21955, 3],"float32"), list[1,0,], value=0, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 22071, 3],"float32"), list[1,0,], value=7, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 25, 3],"float32"), list[0,1,], "constant", 1.0, data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 25500, 1],"float32"), pad=list[1024,1024,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([0, 25500, 1],"float32"), pad=list[256,256,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([0, 25500, 1],"float32"), pad=list[512,512,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([0, 256, 64, 64],"float32"), pad=list[1,1,1,1,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 25757, 3],"float32"), list[1,0,], value=5, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 27860, 3],"float32"), list[1,0,], value=6, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 3, 100, 100],"float32"), pad=list[1,2,3,4,], mode="reflect", value=0.0, data_format="NCHW", name="shape", )
paddle.nn.functional.pad(Tensor([0, 3, 140, 160],"float64"), pad=list[40,40,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 140, 240],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 180, 200],"float64"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 184, 204],"float64"), pad=list[52,52,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 184, 308],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 200, 150],"float64"), pad=list[1,1,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 200, 150],"float64"), pad=list[10,10,10,10,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 204, 152],"float64"), pad=list[1,3,2,4,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 210, 156],"float64"), pad=list[1,1,1,1,], mode="replicate", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 224, 224],"float32"), list[0,1,0,0,], )
paddle.nn.functional.pad(Tensor([0, 3, 256, 256],"float32"), list[14,14,14,14,], )
paddle.nn.functional.pad(Tensor([0, 3, 256, 256],"float32"), list[6,6,6,6,], )
paddle.nn.functional.pad(Tensor([0, 3, 256, 256],"float32"), pad=list[3,3,3,3,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 3, 28, 24],"float32"), pad=list[1,1,1,1,], mode="reflect", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 28, 24],"float32"), pad=list[1,1,2,2,], mode="reflect", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 280, 350],"float32"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 224, 231],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 224, 238],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 224, 258],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 224, 271],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 224, 297],"float32"), tuple(0,3,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 239, 224],"float32"), tuple(0,0,0,1,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 242, 224],"float32"), tuple(0,0,0,2,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 245, 224],"float32"), tuple(0,0,0,3,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 32, 32],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4, 4],"float32"), list[1,1,1,1,1,1,], mode="circular", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4, 4],"float32"), list[1,1,1,1,1,1,], mode="reflect", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4, 4],"float32"), list[1,1,1,1,1,1,], mode="replicate", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4, 4],"float64"), list[1,1,1,1,1,1,], mode="circular", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4, 4],"float64"), list[1,1,1,1,1,1,], mode="reflect", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4, 4],"float64"), list[1,1,1,1,1,1,], mode="replicate", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4],"float32"), list[1,1,1,1,], mode="circular", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4],"float32"), list[1,1,1,1,], mode="reflect", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4],"float32"), list[1,1,1,1,], mode="replicate", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4],"float64"), list[1,1,1,1,], mode="circular", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4],"float64"), list[1,1,1,1,], mode="reflect", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4, 4],"float64"), list[1,1,1,1,], mode="replicate", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([0, 3, 4],"float32"), list[1,1,], mode="circular", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 3, 4],"float32"), list[1,1,], mode="reflect", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 3, 4],"float32"), list[1,1,], mode="replicate", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 3, 4],"float64"), list[1,1,], mode="circular", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 3, 4],"float64"), list[1,1,], mode="reflect", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 3, 4],"float64"), list[1,1,], mode="replicate", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 3, 6, 6, 6],"float32"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 3, 6, 6, 6],"float64"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 3, 686, 1024],"float32"), tuple(0,0,0,338,), )
paddle.nn.functional.pad(Tensor([0, 32, 32, 32],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex128"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="circular", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex64"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="circular", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex128"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="circular", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex64"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="circular", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5],"complex128"), pad=list[1,1,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5],"complex128"), pad=list[1,2,], mode="circular", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5],"complex128"), pad=list[1,2,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5],"complex64"), pad=list[1,1,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5],"complex64"), pad=list[1,2,], mode="circular", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 4, 5],"complex64"), pad=list[1,2,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 4410, 1],"float32"), pad=list[200,200,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([0, 48, 8, 8],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([0, 5551, 3],"float32"), list[1,0,], value=3, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 6, 6],"float32"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 6, 6],"float64"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([0, 64, 16, 112],"float32"), list[0,1,0,1,], value=-math.inf, )
paddle.nn.functional.pad(Tensor([0, 64, 16, 128],"float32"), list[0,1,0,1,], value=-math.inf, )
paddle.nn.functional.pad(Tensor([0, 64, 16, 128],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([0, 64, 16, 16],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([0, 64, 16, 16],"float32"), pad=tuple(1,1,1,1,), mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 64, 188, 140],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 64, 256, 256],"float32"), pad=list[3,3,3,3,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 64, 3],"float32"), tuple(1,0,), data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 64, 7],"float32"), tuple(-3,0,), data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 7, 16],"float32"), pad=list[1,1,], data_format="NLC", )
paddle.nn.functional.pad(Tensor([0, 7485, 3],"float32"), list[1,0,], value=2, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 7974, 3],"float32"), list[1,0,], value=1, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([0, 79949, 1],"float32"), pad=list[200,200,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([0, 8, 14, 12],"float32"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([0, 8141, 3],"float32"), list[1,0,], value=0, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 1, 1],"float16"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 1, 13],"float32"), pad=list[0,0,0,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 10, 21],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 100, 111],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 14, 12],"float32"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 14, 14, 384],"float16"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 14, 384],"float32"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 15, 384],"float16"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 15, 384],"float16"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 15, 384],"float32"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 15, 384],"float32"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 16, 384],"float16"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 16, 384],"float32"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 17, 384],"float16"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 17, 384],"float32"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 18, 384],"float16"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 18, 384],"float32"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 19, 384],"float16"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 14, 19, 384],"float32"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 140, 160],"float64"), pad=list[40,40,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 140, 240],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 15, 14, 384],"float16"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 15, 14, 384],"float16"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 15, 14, 384],"float32"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 15, 14, 384],"float32"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 16, 14, 384],"float16"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 16, 14, 384],"float32"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 18, 14, 384],"float16"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 18, 14, 384],"float32"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 180, 200],"float64"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 184, 204],"float64"), pad=list[52,52,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 184, 308],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 2, 1],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 2, 2],"float32"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 2, 2],"float64"), pad=list[2,2,2,2,2,2,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 2, 3],"float64"), pad=list[1,1,1,0,1,0,], mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 2],"float32"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 2],"float64"), pad=list[2,2,2,2,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 3, 2],"float64"), pad=list[1,0,1,0,0,1,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 3, 2],"float64"), pad=list[1,0,1,2,1,0,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 2, 3],"float64"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 200, 150],"float64"), pad=list[1,1,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 200, 150],"float64"), pad=list[10,10,10,10,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 204, 152],"float64"), pad=list[1,3,2,4,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 210, 156],"float64"), pad=list[1,1,1,1,], mode="replicate", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 224, 224],"float32"), list[0,1,0,0,], )
paddle.nn.functional.pad(Tensor([1, 0, 256, 256],"float32"), pad=list[3,3,3,3,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 28, 24],"float32"), pad=list[1,1,1,1,], mode="reflect", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 28, 24],"float32"), pad=list[1,1,2,2,], mode="reflect", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 280, 350],"float32"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 0, 3, 2],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 0, 3, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 3, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 3, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 0, 3, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 3, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 3, 4],"float64"), pad=list[2,1,2,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=0, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=1, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=2, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=3, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=4, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=5, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=6, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), list[1,0,], value=7, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float32"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float64"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float64"), pad=list[1,2,], mode="reflect", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float64"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float64"), pad=list[2,1,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 3],"float64"), pad=list[2,2,], mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 31, 28, 192],"float16"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 31, 28, 192],"float32"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 224, 231],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 224, 238],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 224, 258],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 224, 271],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 224, 297],"float32"), tuple(0,3,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 239, 224],"float32"), tuple(0,0,0,1,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 242, 224],"float32"), tuple(0,0,0,2,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 32, 245, 224],"float32"), tuple(0,0,0,3,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 0, 61, 56, 96],"float32"), tuple(0,0,0,2,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 0, 64, 64],"float32"), pad=list[1,1,1,1,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 0, 686, 1024],"float32"), tuple(0,0,0,338,), )
paddle.nn.functional.pad(Tensor([1, 1, 0, 1],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 0, 111],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 0, 2],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 0, 21],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 0, 3, 2],"float64"), pad=list[1,0,1,2,1,0,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 0, 3],"float64"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 10, 0],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 100, 0],"float32"), pad=list[0,1,0,0,], mode="constant", value=-10000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 0, 2],"float64"), pad=list[1,0,1,2,1,0,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 0],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 0],"float64"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 3, 0],"float64"), pad=list[1,0,1,0,0,1,], mode="replicate", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 2, 3, 0],"float64"), pad=list[1,0,1,2,1,0,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 1, 3, 0],"float32"), pad=list[0,1,0,0,], mode="constant", value=-1000000.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 14701, 0],"float32"), list[1,0,], value=4, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float16"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float16"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float16"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float16"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float16"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float32"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float32"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float32"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float32"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 14, 384],"float32"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 15, 384],"float16"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 15, 384],"float16"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 15, 384],"float32"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 15, 384],"float32"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 16, 384],"float16"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 16, 384],"float32"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 17, 384],"float16"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 17, 384],"float32"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 18, 384],"float16"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 18, 384],"float32"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 19, 384],"float16"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 19, 384],"float32"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 28, 192],"float16"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 28, 192],"float32"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 0, 56, 96],"float32"), tuple(0,0,0,2,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float16"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float16"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float16"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float16"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float16"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float16"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float16"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float32"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float32"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float32"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float32"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float32"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float32"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 0, 384],"float32"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 14, 0],"float16"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 14, 0],"float32"), tuple(0,0,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 15, 0],"float16"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 15, 0],"float16"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 15, 0],"float32"), tuple(0,1,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 15, 0],"float32"), tuple(0,6,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 16, 0],"float16"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 16, 0],"float32"), tuple(0,5,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 17, 0],"float16"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 17, 0],"float32"), tuple(0,4,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 18, 0],"float16"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 18, 0],"float32"), tuple(0,3,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 19, 0],"float16"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 14, 19, 0],"float32"), tuple(0,2,0,0,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 0, 384],"float16"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 0, 384],"float16"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 0, 384],"float32"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 0, 384],"float32"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 14, 0],"float16"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 14, 0],"float16"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 14, 0],"float32"), tuple(0,0,0,1,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 15, 14, 0],"float32"), tuple(0,0,0,6,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 16, 0, 384],"float16"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 16, 0, 384],"float32"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 16, 14, 0],"float16"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 16, 14, 0],"float32"), tuple(0,0,0,5,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 18, 0, 384],"float16"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 18, 0, 384],"float32"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 18, 14, 0],"float16"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 18, 14, 0],"float32"), tuple(0,0,0,3,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 31, 0, 192],"float16"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 31, 0, 192],"float32"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 31, 28, 0],"float16"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 31, 28, 0],"float32"), tuple(0,0,0,4,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 61, 0, 96],"float32"), tuple(0,0,0,2,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 16, 61, 56, 0],"float32"), tuple(0,0,0,2,0,0,), data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 160000, 0],"float64"), pad=list[256,256,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([1, 17980, 0],"float32"), list[1,0,], value=3, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 19780, 0],"float32"), list[1,0,], value=2, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 2, 0, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 2, 0, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 2, 0, 4, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 2, 0, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 2, 0, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 2, 0, 4, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 2, 0],"float32"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 0],"float64"), pad=list[1,1,], mode="reflect", value=0.0, data_format="NLC", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 0],"float64"), pad=list[1,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 0],"float64"), pad=list[1,2,], mode="replicate", value=0.0, data_format="NLC", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 2, 2, 0],"float64"), pad=list[1,1,1,0,1,0,], mode="reflect", value=0.0, data_format="NDHWC", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0, 5],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0, 5],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0],"float64"), pad=list[1,1,1,0,], mode="reflect", value=0.0, data_format="NHWC", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3, 0],"float64"), pad=list[2,1,2,1,], mode="replicate", value=0.0, data_format="NHWC", name=None, )
paddle.nn.functional.pad(Tensor([1, 2, 3, 4, 0],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 2, 3, 4, 0],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 2, 3, 4, 0],"complex128"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 2, 3, 4, 0],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, )
paddle.nn.functional.pad(Tensor([1, 2, 3, 4, 0],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 2, 3, 4, 0],"complex64"), pad=list[1,2,1,1,3,4,], mode="constant", value=100, data_format="NDHWC", )
paddle.nn.functional.pad(Tensor([1, 20524, 0],"float32"), list[1,0,], value=1, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 21955, 0],"float32"), list[1,0,], value=0, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 22071, 0],"float32"), list[1,0,], value=7, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 25757, 0],"float32"), list[1,0,], value=5, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 27860, 0],"float32"), list[1,0,], value=6, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 1024],"float32"), tuple(0,0,0,338,), )
paddle.nn.functional.pad(Tensor([1, 3, 0, 150],"float64"), pad=list[1,1,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 150],"float64"), pad=list[10,10,10,10,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 152],"float64"), pad=list[1,3,2,4,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 160],"float64"), pad=list[40,40,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 200],"float64"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 204],"float64"), pad=list[52,52,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 224, 231],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 224, 238],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 224, 258],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 224, 271],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 224, 297],"float32"), tuple(0,3,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 224],"float32"), list[0,1,0,0,], )
paddle.nn.functional.pad(Tensor([1, 3, 0, 239, 224],"float32"), tuple(0,0,0,1,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 240],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 242, 224],"float32"), tuple(0,0,0,2,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 245, 224],"float32"), tuple(0,0,0,3,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 308],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 0, 350],"float32"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 140, 0],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 140, 0],"float64"), pad=list[40,40,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 180, 0],"float64"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 184, 0],"float64"), pad=list[0,0,40,40,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 184, 0],"float64"), pad=list[52,52,0,0,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 200, 0],"float64"), pad=list[1,1,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 200, 0],"float64"), pad=list[10,10,10,10,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 204, 0],"float64"), pad=list[1,3,2,4,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 224, 0],"float32"), list[0,1,0,0,], )
paddle.nn.functional.pad(Tensor([1, 3, 280, 0],"float32"), pad=list[2,2,2,2,], mode="constant", value=0.0, data_format="NCHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 224],"float32"), tuple(0,0,0,1,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 224],"float32"), tuple(0,0,0,2,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 224],"float32"), tuple(0,0,0,3,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 231],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 238],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 258],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 271],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 0, 297],"float32"), tuple(0,3,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 224, 0],"float32"), tuple(0,1,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 224, 0],"float32"), tuple(0,2,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 224, 0],"float32"), tuple(0,3,0,0,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 239, 0],"float32"), tuple(0,0,0,1,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 242, 0],"float32"), tuple(0,0,0,2,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 32, 245, 0],"float32"), tuple(0,0,0,3,0,0,), data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([1, 3, 686, 0],"float32"), tuple(0,0,0,338,), )
paddle.nn.functional.pad(Tensor([1, 4410, 0],"float32"), pad=list[200,200,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([1, 5551, 0],"float32"), list[1,0,], value=3, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 7485, 0],"float32"), list[1,0,], value=2, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 7974, 0],"float32"), list[1,0,], value=1, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([1, 79949, 0],"float32"), pad=list[200,200,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([1, 8, 0, 12],"float32"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 8, 14, 0],"float32"), pad=list[1,0,1,2,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([1, 8141, 0],"float32"), list[1,0,], value=0, mode="constant", data_format="NCL", )
paddle.nn.functional.pad(Tensor([10, 0, 16, 112],"float32"), Tensor([4],"int32"), value=-math.inf, )
paddle.nn.functional.pad(Tensor([1024, 0, 1, 1],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([1024, 0, 129, 129],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([1024, 0, 256, 256],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([1024, 0, 256, 256],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([1024, 1, 0, 1],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([1024, 1, 0, 129],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([1024, 1, 0, 256],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([1024, 1, 0, 256],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([1024, 1, 1, 0],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([1024, 1, 129, 0],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([1024, 1, 256, 0],"float32"), list[1,1,1,1,], )
paddle.nn.functional.pad(Tensor([1024, 1, 256, 0],"float32"), list[2,2,2,2,], )
paddle.nn.functional.pad(Tensor([1048576, 0, 1, 1],"float32"), list[0,0,0,0,], )
paddle.nn.functional.pad(Tensor([1048576, 1, 0, 1],"float32"), list[0,0,0,0,], )
paddle.nn.functional.pad(Tensor([1048576, 1, 1, 0],"float32"), list[0,0,0,0,], )
paddle.nn.functional.pad(Tensor([1183744, 0, 1, 1],"float32"), list[0,0,0,0,], )
paddle.nn.functional.pad(Tensor([1183744, 1, 0, 1],"float32"), list[0,0,0,0,], )
paddle.nn.functional.pad(Tensor([1183744, 1, 1, 0],"float32"), list[0,0,0,0,], )
paddle.nn.functional.pad(Tensor([12, 0, 128, 128],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([12, 0, 16, 16],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([12, 0, 16, 64],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([12, 0, 32, 32],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([12, 1, 0, 128],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([12, 1, 0, 16],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([12, 1, 128, 0],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([12, 1, 16, 0],"float32"), list[2,1,2,1,], )
paddle.nn.functional.pad(Tensor([12, 16, 0, 64],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([12, 16, 16, 0],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([12, 32, 0, 32],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([12, 32, 32, 0],"float32"), tuple(0,0,0,0,), data_format="NHWC", )
paddle.nn.functional.pad(Tensor([12288, 0, 1, 1],"float32"), list[0,1,0,1,], )
paddle.nn.functional.pad(Tensor([12288, 1, 0, 1],"float32"), list[0,1,0,1,], )
paddle.nn.functional.pad(Tensor([12288, 1, 1, 0],"float32"), list[0,1,0,1,], )
paddle.nn.functional.pad(Tensor([13, 0, 16],"float32"), pad=list[1,1,], data_format="NLC", )
paddle.nn.functional.pad(Tensor([13, 0, 3],"float32"), tuple(1,0,), data_format="NCL", )
paddle.nn.functional.pad(Tensor([13, 0, 7],"float32"), tuple(-3,0,), data_format="NCL", )
paddle.nn.functional.pad(Tensor([13, 0, 96],"float32"), pad=tuple(0,8,), mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([13, 64, 0],"float32"), tuple(1,0,), data_format="NCL", )
paddle.nn.functional.pad(Tensor([13, 7, 0],"float32"), pad=list[1,1,], data_format="NLC", )
paddle.nn.functional.pad(Tensor([14, 0, 7],"float32"), tuple(-3,0,), data_format="NCL", )
paddle.nn.functional.pad(Tensor([1536, 0, 1, 1],"float32"), list[0,1,0,1,], )
paddle.nn.functional.pad(Tensor([1536, 1, 0, 1],"float32"), list[0,1,0,1,], )
paddle.nn.functional.pad(Tensor([1536, 1, 1, 0],"float32"), list[0,1,0,1,], )
paddle.nn.functional.pad(Tensor([16, 0, 256, 256],"float32"), list[14,14,14,14,], )
paddle.nn.functional.pad(Tensor([16, 0, 256, 256],"float32"), list[6,6,6,6,], )
paddle.nn.functional.pad(Tensor([16, 0, 96],"float32"), pad=tuple(0,8,), mode="replicate", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([16, 25500, 0],"float32"), pad=list[1024,1024,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([16, 25500, 0],"float32"), pad=list[256,256,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([16, 25500, 0],"float32"), pad=list[512,512,], mode="reflect", data_format="NLC", )
paddle.nn.functional.pad(Tensor([16, 3, 0, 256],"float32"), list[14,14,14,14,], )
paddle.nn.functional.pad(Tensor([16, 3, 0, 256],"float32"), list[6,6,6,6,], )
paddle.nn.functional.pad(Tensor([16, 3, 256, 0],"float32"), list[14,14,14,14,], )
paddle.nn.functional.pad(Tensor([16, 3, 256, 0],"float32"), list[6,6,6,6,], )
paddle.nn.functional.pad(Tensor([2, 0, 100, 100],"float32"), pad=list[1,2,3,4,], mode="reflect", value=0.0, data_format="NCHW", name="shape", )
paddle.nn.functional.pad(Tensor([2, 0, 16, 16],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([2, 0, 32, 32],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4, 4],"float32"), list[1,1,1,1,1,1,], mode="circular", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4, 4],"float32"), list[1,1,1,1,1,1,], mode="reflect", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4, 4],"float32"), list[1,1,1,1,1,1,], mode="replicate", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4, 4],"float64"), list[1,1,1,1,1,1,], mode="circular", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4, 4],"float64"), list[1,1,1,1,1,1,], mode="reflect", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4, 4],"float64"), list[1,1,1,1,1,1,], mode="replicate", data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4],"float32"), list[1,1,1,1,], mode="circular", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4],"float32"), list[1,1,1,1,], mode="reflect", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4],"float32"), list[1,1,1,1,], mode="replicate", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4],"float64"), list[1,1,1,1,], mode="circular", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4],"float64"), list[1,1,1,1,], mode="reflect", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4, 4],"float64"), list[1,1,1,1,], mode="replicate", data_format="NCHW", )
paddle.nn.functional.pad(Tensor([2, 0, 4],"float32"), list[1,1,], mode="circular", data_format="NCL", )
paddle.nn.functional.pad(Tensor([2, 0, 4],"float32"), list[1,1,], mode="reflect", data_format="NCL", )
paddle.nn.functional.pad(Tensor([2, 0, 4],"float32"), list[1,1,], mode="replicate", data_format="NCL", )
paddle.nn.functional.pad(Tensor([2, 0, 4],"float64"), list[1,1,], mode="circular", data_format="NCL", )
paddle.nn.functional.pad(Tensor([2, 0, 4],"float64"), list[1,1,], mode="reflect", data_format="NCL", )
paddle.nn.functional.pad(Tensor([2, 0, 4],"float64"), list[1,1,], mode="replicate", data_format="NCL", )
paddle.nn.functional.pad(Tensor([2, 0, 8, 8],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([2, 3, 0, 32],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([2, 3, 32, 0],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([2, 48, 0, 8],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([2, 48, 8, 0],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([2, 64, 0, 16],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([2, 64, 16, 0],"float32"), list[0,1,0,1,], value=0, )
paddle.nn.functional.pad(Tensor([3, 0, 16, 16],"float32"), pad=tuple(1,1,1,1,), mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 3, 1600, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 0, 3, 3, 1600],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 0, 3, 40, 40],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 0, 40, 40, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 0, 40, 40],"float32"), pad=list[0,0,2,2,], )
paddle.nn.functional.pad(Tensor([3, 0, 40, 40],"float32"), pad=list[2,2,0,0,], )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex128"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="circular", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex64"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="circular", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="reflect", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="replicate", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex128"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="circular", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex128"), pad=list[1,2,2,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex64"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="circular", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="reflect", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5, 6],"complex64"), pad=list[1,2,2,1,], mode="replicate", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5],"complex128"), pad=list[1,1,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5],"complex128"), pad=list[1,2,], mode="circular", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5],"complex128"), pad=list[1,2,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5],"complex64"), pad=list[1,1,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5],"complex64"), pad=list[1,2,], mode="circular", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 0, 5],"complex64"), pad=list[1,2,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 1, 0, 1600, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 0, 3, 1600],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 0, 40, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 0, 40, 40],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 0, 40],"float32"), pad=list[0,0,2,2,], )
paddle.nn.functional.pad(Tensor([3, 1, 0, 40],"float32"), pad=list[2,2,0,0,], )
paddle.nn.functional.pad(Tensor([3, 1, 3, 0, 1600],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 3, 0, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 3, 0, 40],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 3, 1600, 0],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 3, 3, 0],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 3, 40, 0],"float32"), pad=list[0,0,0,0,2,2,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 40, 0, 3],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 1, 40, 0],"float32"), pad=list[0,0,2,2,], )
paddle.nn.functional.pad(Tensor([3, 1, 40, 0],"float32"), pad=list[2,2,0,0,], )
paddle.nn.functional.pad(Tensor([3, 1, 40, 40, 0],"float32"), pad=list[2,2,0,0,0,0,], data_format="NCDHW", )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6, 7],"complex128"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6, 7],"complex64"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6],"complex128"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6],"complex128"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6],"complex64"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0, 6],"complex64"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0],"complex128"), pad=list[1,1,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0],"complex128"), pad=list[1,2,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0],"complex64"), pad=list[1,1,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 0],"complex64"), pad=list[1,2,], mode="constant", value=100, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0, 7],"complex128"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0, 7],"complex128"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0, 7],"complex64"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0, 7],"complex64"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0],"complex128"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0],"complex128"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0],"complex64"), pad=list[1,1,1,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 0],"complex64"), pad=list[1,2,2,1,], mode="constant", value=100, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 0],"complex128"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 0],"complex128"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 0],"complex64"), pad=list[1,1,1,1,1,1,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 4, 5, 6, 0],"complex64"), pad=list[1,2,2,1,1,0,], mode="constant", value=100, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 64, 0, 16],"float32"), pad=tuple(1,1,1,1,), mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([3, 64, 16, 0],"float32"), pad=tuple(1,1,1,1,), mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([30, 0, 16, 112],"float32"), list[0,1,0,1,], value=-math.inf, )
paddle.nn.functional.pad(Tensor([30, 0, 16, 128],"float32"), list[0,1,0,1,], value=-math.inf, )
paddle.nn.functional.pad(Tensor([30, 0, 32, 128],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([30, 1, 0, 128],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([30, 1, 32, 0],"float32"), list[2,3,2,3,], value=0, )
paddle.nn.functional.pad(Tensor([30, 64, 0, 112],"float32"), list[0,1,0,1,], value=-math.inf, )
paddle.nn.functional.pad(Tensor([30, 64, 0, 128],"float32"), list[0,1,0,1,], value=-math.inf, )
paddle.nn.functional.pad(Tensor([30, 64, 16, 0],"float32"), list[0,1,0,1,], value=-math.inf, )
paddle.nn.functional.pad(Tensor([4, 0, 188, 140],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 0, 6, 6, 6],"float32"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 0, 6, 6, 6],"float64"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 0, 6],"float32"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 0, 6],"float64"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 0, 94, 70],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 128, 0, 70],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 128, 94, 0],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 0, 6, 6],"float32"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 0, 6, 6],"float64"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 0, 6],"float32"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 0, 6],"float64"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 0],"float32"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 3, 6, 6, 0],"float64"), pad=list[2,2,2,2,2,2,], mode="constant", value=0.0, data_format="NCDHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 0],"float32"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 6, 0],"float64"), pad=list[2,2,], mode="constant", value=0.0, data_format="NCL", name=None, )
paddle.nn.functional.pad(Tensor([4, 64, 0, 140],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([4, 64, 188, 0],"float32"), pad=list[1,1,1,1,], mode="constant", value=0.0, data_format="NCHW", name=None, )
paddle.nn.functional.pad(Tensor([421120, 0, 3],"float32"), list[0,1,], "constant", 1.0, data_format="NCL", )
paddle.nn.functional.pad(Tensor([421120, 25, 0],"float32"), list[0,1,], "constant", 1.0, data_format="NCL", )
paddle.nn.functional.pad(Tensor([52, 0, 16],"float32"), pad=list[1,1,], data_format="NLC", )
paddle.nn.functional.pad(Tensor([52, 7, 0],"float32"), pad=list[1,1,], data_format="NLC", )
paddle.nn.functional.pad(x=Tensor([0, 1, 1, 2, 3],"float64"), pad=list[0,0,1,1,0,0,], mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([0, 1, 1, 2, 3],"float64"), pad=tuple(0,1,1,1,2,0,), mode="circular", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([0, 1, 1, 2, 3],"float64"), pad=tuple(0,1,1,1,2,0,), mode="circular", value=0, data_format="NDHWC", )
paddle.nn.functional.pad(x=Tensor([0, 1, 1, 2, 3],"float64"), pad=tuple(0,1,1,1,2,0,), mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([0, 1, 1, 2, 3],"float64"), pad=tuple(2,1,3,0,2,0,), mode="replicate", data_format="NDHWC", )
paddle.nn.functional.pad(x=Tensor([0, 1, 1, 2, 3],"float64"), pad=tuple(2,2,1,1,0,0,), mode="reflect", data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([0, 2, 1, 2],"float64"), pad=list[1,1,2,3,], mode="constant", value=2.0, data_format="NCHW", )
paddle.nn.functional.pad(x=Tensor([0, 3, 3],"float32"), pad=list[1,1,], mode="constant", value=0.0, data_format="NCL", )
paddle.nn.functional.pad(x=Tensor([0, 3, 3],"float64"), pad=list[1,1,], mode="constant", value=0.0, data_format="NCL", )
paddle.nn.functional.pad(x=Tensor([1, 0, 1, 2, 3],"float64"), pad=list[0,0,1,1,0,0,], mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 0, 1, 2, 3],"float64"), pad=tuple(0,1,1,1,2,0,), mode="circular", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 0, 1, 2, 3],"float64"), pad=tuple(0,1,1,1,2,0,), mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 0, 1, 2, 3],"float64"), pad=tuple(2,2,1,1,0,0,), mode="reflect", data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 1, 0, 2, 3],"float64"), pad=list[0,0,1,1,0,0,], mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 1, 0, 2, 3],"float64"), pad=tuple(0,1,1,1,2,0,), mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 1, 1, 0, 3],"float64"), pad=list[0,0,1,1,0,0,], mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 1, 1, 0, 3],"float64"), pad=tuple(0,1,1,1,2,0,), mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 1, 1, 2, 0],"float64"), pad=list[0,0,1,1,0,0,], mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 1, 1, 2, 0],"float64"), pad=tuple(0,1,1,1,2,0,), mode="circular", value=0, data_format="NDHWC", )
paddle.nn.functional.pad(x=Tensor([1, 1, 1, 2, 0],"float64"), pad=tuple(0,1,1,1,2,0,), mode="constant", value=0, data_format="NCDHW", )
paddle.nn.functional.pad(x=Tensor([1, 1, 1, 2, 0],"float64"), pad=tuple(2,1,3,0,2,0,), mode="replicate", data_format="NDHWC", )
paddle.nn.functional.pad(x=Tensor([3, 0, 1, 2],"float64"), pad=list[1,1,2,3,], mode="constant", value=2.0, data_format="NCHW", )
paddle.nn.functional.pad(x=Tensor([3, 0, 3],"float32"), pad=list[1,1,], mode="constant", value=0.0, data_format="NCL", )
paddle.nn.functional.pad(x=Tensor([3, 0, 3],"float64"), pad=list[1,1,], mode="constant", value=0.0, data_format="NCL", )
paddle.nn.functional.pad(x=Tensor([3, 2, 0, 2],"float64"), pad=list[1,1,2,3,], mode="constant", value=2.0, data_format="NCHW", )
paddle.nn.functional.pad(x=Tensor([3, 2, 1, 0],"float64"), pad=list[1,1,2,3,], mode="constant", value=2.0, data_format="NCHW", )
paddle.nn.functional.pad(x=Tensor([3, 3, 0],"float32"), pad=list[1,1,], mode="constant", value=0.0, data_format="NCL", )
paddle.nn.functional.pad(x=Tensor([3, 3, 0],"float64"), pad=list[1,1,], mode="constant", value=0.0, data_format="NCL", )
paddle.nn.functional.pixel_shuffle(Tensor([2, 0, 4, 4],"float32"), upscale_factor=3, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 0, 4, 4],"float64"), 3, "NCHW", )
paddle.nn.functional.pixel_shuffle(Tensor([2, 0, 4, 4],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 0, 4, 9],"float64"), 3, "NHWC", )
paddle.nn.functional.pixel_shuffle(Tensor([2, 0, 4, 9],"float64"), 3, "NHWC", None, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 4, 0, 9],"float64"), 3, "NHWC", )
paddle.nn.functional.pixel_shuffle(Tensor([2, 4, 0, 9],"float64"), 3, "NHWC", None, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 4, 4, 0],"float64"), 3, "NHWC", )
paddle.nn.functional.pixel_shuffle(Tensor([2, 4, 4, 0],"float64"), 3, "NHWC", None, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 9, 0, 4],"float32"), upscale_factor=3, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 9, 0, 4],"float64"), 3, "NCHW", )
paddle.nn.functional.pixel_shuffle(Tensor([2, 9, 0, 4],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 9, 4, 0],"float32"), upscale_factor=3, )
paddle.nn.functional.pixel_shuffle(Tensor([2, 9, 4, 0],"float64"), 3, "NCHW", )
paddle.nn.functional.pixel_shuffle(Tensor([2, 9, 4, 0],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 0, 128, 128],"float16"), 2, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 0, 128, 128],"float32"), 2, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 0, 4, 4],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 128, 0, 128],"float16"), 2, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 128, 0, 128],"float32"), 2, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 128, 128, 0],"float16"), 2, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 128, 128, 0],"float32"), 2, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 81, 0, 4],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(Tensor([4, 81, 4, 0],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_shuffle(x=Tensor([2, 0, 4, 4],"float64"), upscale_factor=3, data_format="NCHW", )
paddle.nn.functional.pixel_shuffle(x=Tensor([2, 0, 4, 9],"float64"), upscale_factor=3, data_format="NHWC", )
paddle.nn.functional.pixel_shuffle(x=Tensor([2, 4, 0, 9],"float64"), upscale_factor=3, data_format="NHWC", )
paddle.nn.functional.pixel_shuffle(x=Tensor([2, 4, 4, 0],"float64"), upscale_factor=3, data_format="NHWC", )
paddle.nn.functional.pixel_shuffle(x=Tensor([2, 9, 0, 4],"float64"), upscale_factor=3, data_format="NCHW", )
paddle.nn.functional.pixel_shuffle(x=Tensor([2, 9, 4, 0],"float64"), upscale_factor=3, data_format="NCHW", )
paddle.nn.functional.pixel_shuffle(x=Tensor([4, 0, 4, 4],"float64"), upscale_factor=3, data_format="NCHW", )
paddle.nn.functional.pixel_shuffle(x=Tensor([4, 81, 0, 4],"float64"), upscale_factor=3, data_format="NCHW", )
paddle.nn.functional.pixel_shuffle(x=Tensor([4, 81, 4, 0],"float64"), upscale_factor=3, data_format="NCHW", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 0, 12, 1],"float64"), 3, "NHWC", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 0, 12, 1],"float64"), 3, "NHWC", None, )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 0, 12, 12],"float16"), 3, "NCHW", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 0, 12, 12],"float32"), 3, "NCHW", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 0, 12, 12],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 1, 0, 12],"float16"), 3, "NCHW", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 1, 0, 12],"float32"), 3, "NCHW", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 1, 0, 12],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 1, 12, 0],"float16"), 3, "NCHW", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 1, 12, 0],"float32"), 3, "NCHW", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 1, 12, 0],"float64"), 3, "NCHW", None, )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 12, 0, 1],"float64"), 3, "NHWC", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 12, 0, 1],"float64"), 3, "NHWC", None, )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 12, 12, 0],"float64"), 3, "NHWC", )
paddle.nn.functional.pixel_unshuffle(Tensor([2, 12, 12, 0],"float64"), 3, "NHWC", None, )
paddle.nn.functional.poisson_nll_loss(Tensor([0, 2],"float32"), Tensor([0, 2],"float32"), log_input=True, full=False, epsilon=1e-08, reduction="sum", )
paddle.nn.functional.poisson_nll_loss(Tensor([0, 2],"float32"), Tensor([0, 2],"float32"), log_input=True, full=False, epsilon=1e-08, reduction="sum", name=None, )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), log_input=True, full=False, epsilon=1e-08, reduction="sum", )
paddle.nn.functional.poisson_nll_loss(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), log_input=True, full=False, epsilon=1e-08, reduction="sum", name=None, )
paddle.nn.functional.prelu(Tensor([0, 2, 3, 4],"float32"), Tensor([1],"float32"), )
paddle.nn.functional.prelu(Tensor([0, 2, 3, 4],"float32"), Tensor([1],"float32"), data_format="NCHW", )
paddle.nn.functional.prelu(Tensor([0, 2, 3, 4],"float32"), Tensor([2],"float32"), )
paddle.nn.functional.prelu(Tensor([0, 2, 3, 4],"float32"), Tensor([2],"float32"), data_format="NCHW", )
paddle.nn.functional.prelu(Tensor([1, 0, 3, 4],"float32"), Tensor([1],"float32"), )
paddle.nn.functional.prelu(Tensor([1, 0, 3, 4],"float32"), Tensor([1],"float32"), data_format="NCHW", )
paddle.nn.functional.prelu(Tensor([1, 2, 0, 4],"float32"), Tensor([1],"float32"), )
paddle.nn.functional.prelu(Tensor([1, 2, 0, 4],"float32"), Tensor([1],"float32"), data_format="NCHW", )
paddle.nn.functional.prelu(Tensor([1, 2, 0, 4],"float32"), Tensor([2],"float32"), )
paddle.nn.functional.prelu(Tensor([1, 2, 0, 4],"float32"), Tensor([2],"float32"), data_format="NCHW", )
paddle.nn.functional.prelu(Tensor([1, 2, 3, 0],"float32"), Tensor([1],"float32"), )
paddle.nn.functional.prelu(Tensor([1, 2, 3, 0],"float32"), Tensor([1],"float32"), data_format="NCHW", )
paddle.nn.functional.prelu(Tensor([1, 2, 3, 0],"float32"), Tensor([2],"float32"), )
paddle.nn.functional.prelu(Tensor([1, 2, 3, 0],"float32"), Tensor([2],"float32"), data_format="NCHW", )
paddle.nn.functional.prelu(x=Tensor([0, 2, 3, 4],"float32"), weight=Tensor([1],"float32"), )
paddle.nn.functional.prelu(x=Tensor([0, 2, 3, 4],"float64"), weight=Tensor([1],"float64"), )
paddle.nn.functional.prelu(x=Tensor([0, 3, 3],"float64"), weight=Tensor([3],"float64"), )
paddle.nn.functional.prelu(x=Tensor([1, 0, 3, 4],"float32"), weight=Tensor([1],"float32"), )
paddle.nn.functional.prelu(x=Tensor([1, 0, 3, 4],"float64"), weight=Tensor([1],"float64"), )
paddle.nn.functional.prelu(x=Tensor([1, 2, 0, 4],"float32"), weight=Tensor([1],"float32"), )
paddle.nn.functional.prelu(x=Tensor([1, 2, 0, 4],"float64"), weight=Tensor([1],"float64"), )
paddle.nn.functional.prelu(x=Tensor([1, 2, 3, 0],"float32"), weight=Tensor([1],"float32"), )
paddle.nn.functional.prelu(x=Tensor([1, 2, 3, 0],"float64"), weight=Tensor([1],"float64"), )
paddle.nn.functional.prelu(x=Tensor([3, 3, 0],"float64"), weight=Tensor([3],"float64"), )
paddle.nn.functional.scaled_dot_product_attention(query=Tensor([2, 0, 12, 64],"float16"), key=Tensor([2, 0, 12, 64],"float16"), value=Tensor([2, 0, 12, 64],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(query=Tensor([2, 0, 12, 64],"float16"), key=Tensor([2, 64, 12, 64],"float16"), value=Tensor([2, 64, 12, 64],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 1, 64],"float16"), Tensor([1, 0, 1, 64],"float16"), Tensor([1, 0, 1, 64],"float16"), attn_mask=Tensor([1, 0, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 1, 64],"float16"), Tensor([1, 0, 1, 64],"float16"), Tensor([1, 0, 1, 64],"float16"), attn_mask=Tensor([1, 0, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 2, 40],"float16"), Tensor([1, 0, 2, 40],"float16"), Tensor([1, 0, 2, 40],"float16"), attn_mask=Tensor([1, 0, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 2, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 32, 128],"bfloat16"), Tensor([1, 0, 32, 128],"bfloat16"), Tensor([1, 0, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 4, 128],"float16"), Tensor([1, 0, 4, 128],"float16"), Tensor([1, 0, 4, 128],"float16"), attn_mask=Tensor([1, 0, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 4, 128],"float16"), Tensor([1, 0, 4, 128],"float16"), Tensor([1, 0, 4, 128],"float16"), attn_mask=Tensor([1, 0, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 8, 16],"bfloat16"), Tensor([1, 0, 2, 16],"bfloat16"), Tensor([1, 0, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 8, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 0, 8, 16],"float16"), Tensor([1, 0, 2, 16],"float16"), Tensor([1, 0, 2, 16],"float16"), attn_mask=Tensor([1, 0, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 0, 40],"float16"), Tensor([1, 1, 0, 40],"float16"), Tensor([1, 1, 0, 40],"float16"), attn_mask=Tensor([1, 2, 0, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 0],"float16"), Tensor([1, 1, 2, 0],"float16"), Tensor([1, 1, 2, 0],"float16"), attn_mask=Tensor([1, 2, 1, 0],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 40],"float16"), Tensor([0, 1, 2, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 0, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 2, 0],"float16"), Tensor([1, 1, 2, 40],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), Tensor([0, 1, 2, 40],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), Tensor([1, 0, 2, 40],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 0, 40],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 2, 40],"float16"), Tensor([1, 1, 2, 0],"float16"), attn_mask=Tensor([1, 2, 1, 1],"float16"), )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 0, 128],"bfloat16"), Tensor([1, 1024, 0, 128],"bfloat16"), Tensor([1, 1024, 0, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 0, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 0, 16],"bfloat16"), Tensor([1, 1024, 0, 16],"bfloat16"), Tensor([1, 1024, 0, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 0, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 0],"bfloat16"), Tensor([1, 1024, 32, 0],"bfloat16"), Tensor([1, 1024, 32, 0],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([0, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 0, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 0, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 0],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([0, 1024, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 0, 32, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 0, 128],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 128],"bfloat16"), Tensor([1, 1024, 32, 0],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 0],"bfloat16"), Tensor([1, 1024, 2, 0],"bfloat16"), Tensor([1, 1024, 2, 0],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([0, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 0, 2, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 0, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 2, 0],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([0, 1024, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 0, 2, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 0, 16],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 1024, 8, 16],"bfloat16"), Tensor([1, 1024, 2, 16],"bfloat16"), Tensor([1, 1024, 2, 0],"bfloat16"), attn_mask=None, is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), attn_mask=Tensor([1, 1, 0, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), attn_mask=Tensor([1, 1, 0, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 16],"float16"), Tensor([1, 2048, 0, 16],"float16"), Tensor([1, 2048, 0, 16],"float16"), attn_mask=Tensor([1, 1, 0, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), attn_mask=Tensor([1, 1, 0, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), attn_mask=Tensor([1, 1, 0, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 0],"float16"), Tensor([1, 2048, 1, 0],"float16"), Tensor([1, 2048, 1, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 0],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 0],"float16"), Tensor([1, 2048, 1, 0],"float16"), Tensor([1, 2048, 1, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 0],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([0, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([0, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 0],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 0],"float16"), Tensor([1, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([0, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([0, 2048, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 0, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 0, 1, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 0, 64],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 64],"float16"), Tensor([1, 2048, 1, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 0],"float16"), Tensor([1, 2048, 4, 0],"float16"), Tensor([1, 2048, 4, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 0],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 0],"float16"), Tensor([1, 2048, 4, 0],"float16"), Tensor([1, 2048, 4, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 0],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([0, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([0, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 0],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 0],"float16"), Tensor([1, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([0, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([0, 2048, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 0, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 0, 4, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 0, 128],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 128],"float16"), Tensor([1, 2048, 4, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 0],"float16"), Tensor([1, 2048, 2, 0],"float16"), Tensor([1, 2048, 2, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 0],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 16],"float16"), Tensor([0, 2048, 2, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 16],"float16"), Tensor([1, 2048, 0, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 16],"float16"), Tensor([1, 2048, 2, 0],"float16"), Tensor([1, 2048, 2, 16],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), Tensor([0, 2048, 2, 16],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), Tensor([1, 0, 2, 16],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), Tensor([1, 2048, 0, 16],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([1, 2048, 8, 16],"float16"), Tensor([1, 2048, 2, 16],"float16"), Tensor([1, 2048, 2, 0],"float16"), attn_mask=Tensor([1, 1, 2048, 2048],"float16"), is_causal=True, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 0, 1, 64],"float16"), Tensor([2, 0, 1, 64],"float16"), Tensor([2, 0, 1, 64],"float16"), attn_mask=Tensor([2, 0, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 0, 1, 64],"float16"), Tensor([2, 0, 1, 64],"float16"), Tensor([2, 0, 1, 64],"float16"), attn_mask=Tensor([2, 0, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 0, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 0, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 0, 8, 96],"float16"), Tensor([2, 0, 8, 96],"float16"), Tensor([2, 0, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 0, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 0, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), attn_mask=Tensor([2, 1, 0, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), attn_mask=Tensor([2, 1, 0, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 96],"float16"), Tensor([2, 100, 0, 96],"float16"), Tensor([2, 100, 0, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 96],"float16"), Tensor([2, 101, 0, 96],"float16"), Tensor([2, 101, 0, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 0, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 0],"float16"), Tensor([2, 100, 1, 0],"float16"), Tensor([2, 100, 1, 0],"float16"), attn_mask=Tensor([2, 1, 1, 0],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 0],"float16"), Tensor([2, 100, 1, 0],"float16"), Tensor([2, 100, 1, 0],"float16"), attn_mask=Tensor([2, 1, 1, 0],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([0, 100, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([0, 100, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 0],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 0],"float16"), Tensor([2, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([0, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([0, 100, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 0, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 0, 1, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 0, 64],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 1, 0],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), dropout_p=0.0, training=False, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 1, 64],"float16"), Tensor([2, 100, 1, 64],"float16"), Tensor([2, 100, 1, 0],"float16"), attn_mask=Tensor([2, 1, 1, 100],"float16"), is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 0],"float16"), Tensor([2, 100, 8, 0],"float16"), Tensor([2, 100, 8, 0],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 0],"float16"), Tensor([2, 101, 8, 0],"float16"), Tensor([2, 101, 8, 0],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([0, 100, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([0, 101, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 0, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 0, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 100, 0, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 100, 8, 0],"float16"), Tensor([2, 100, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), Tensor([0, 100, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), Tensor([2, 0, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), Tensor([2, 100, 0, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 100, 8, 96],"float16"), Tensor([2, 100, 8, 0],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 101, 0, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 101, 8, 0],"float16"), Tensor([2, 101, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), Tensor([0, 101, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), Tensor([2, 0, 8, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), Tensor([2, 101, 0, 96],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([2, 1, 8, 96],"float16"), Tensor([2, 101, 8, 96],"float16"), Tensor([2, 101, 8, 0],"float16"), attn_mask=None, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 0, 4, 128],"float16"), Tensor([4, 0, 4, 128],"float16"), Tensor([4, 0, 4, 128],"float16"), attn_mask=Tensor([4, 0, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 0, 128],"float16"), Tensor([4, 134, 0, 128],"float16"), Tensor([4, 134, 0, 128],"float16"), attn_mask=Tensor([4, 1, 0, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 0, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 0],"float16"), Tensor([4, 134, 4, 0],"float16"), Tensor([4, 134, 4, 0],"float16"), attn_mask=Tensor([4, 1, 134, 0],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 128],"float16"), Tensor([0, 134, 4, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 0, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 4, 0],"float16"), Tensor([4, 134, 4, 128],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), Tensor([0, 134, 4, 128],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), Tensor([4, 0, 4, 128],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 0, 128],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.scaled_dot_product_attention(Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 4, 128],"float16"), Tensor([4, 134, 4, 0],"float16"), attn_mask=Tensor([4, 1, 134, 134],"float16"), dropout_p=0.0, training=True, is_causal=False, )
paddle.nn.functional.selu(Tensor([0, 2],"float32"), 1.0507009873554805, 1.6732632423543772, None, )
paddle.nn.functional.selu(Tensor([0, 2],"float64"), 1.0507009873554805, 1.6732632423543772, None, )
paddle.nn.functional.selu(Tensor([0, 3, 3],"float64"), 1.0507009873554805, 0, None, )
paddle.nn.functional.selu(Tensor([0, 3, 3],"float64"), 1.0507009873554805, 1.6732632423543772, None, )
paddle.nn.functional.selu(Tensor([0, 5, 5, 10],"float64"), 1.5, 2.0, )
paddle.nn.functional.selu(Tensor([0, 5, 5, 10],"float64"), 1.5, 2.0, None, )
paddle.nn.functional.selu(Tensor([2, 0],"float32"), 1.0507009873554805, 1.6732632423543772, None, )
paddle.nn.functional.selu(Tensor([2, 0],"float64"), 1.0507009873554805, 1.6732632423543772, None, )
paddle.nn.functional.selu(Tensor([3, 0, 3],"float64"), 1.0507009873554805, 0, None, )
paddle.nn.functional.selu(Tensor([3, 0, 3],"float64"), 1.0507009873554805, 1.6732632423543772, None, )
paddle.nn.functional.selu(Tensor([3, 0, 5, 10],"float64"), 1.5, 2.0, )
paddle.nn.functional.selu(Tensor([3, 0, 5, 10],"float64"), 1.5, 2.0, None, )
paddle.nn.functional.selu(Tensor([3, 3, 0],"float64"), 1.0507009873554805, 0, None, )
paddle.nn.functional.selu(Tensor([3, 3, 0],"float64"), 1.0507009873554805, 1.6732632423543772, None, )
paddle.nn.functional.selu(Tensor([3, 5, 0, 10],"float64"), 1.5, 2.0, )
paddle.nn.functional.selu(Tensor([3, 5, 0, 10],"float64"), 1.5, 2.0, None, )
paddle.nn.functional.selu(Tensor([3, 5, 5, 0],"float64"), 1.5, 2.0, )
paddle.nn.functional.selu(Tensor([3, 5, 5, 0],"float64"), 1.5, 2.0, None, )
paddle.nn.functional.selu(x=Tensor([0, 2],"float32"), )
paddle.nn.functional.selu(x=Tensor([0, 2],"float64"), )
paddle.nn.functional.selu(x=Tensor([0, 3, 3],"float64"), )
paddle.nn.functional.selu(x=Tensor([0, 3, 3],"float64"), alpha=0, scale=1.0507009873554805, )
paddle.nn.functional.selu(x=Tensor([2, 0],"float32"), )
paddle.nn.functional.selu(x=Tensor([2, 0],"float64"), )
paddle.nn.functional.selu(x=Tensor([3, 0, 3],"float64"), )
paddle.nn.functional.selu(x=Tensor([3, 0, 3],"float64"), alpha=0, scale=1.0507009873554805, )
paddle.nn.functional.selu(x=Tensor([3, 3, 0],"float64"), )
paddle.nn.functional.selu(x=Tensor([3, 3, 0],"float64"), alpha=0, scale=1.0507009873554805, )
paddle.nn.functional.sequence_mask(Tensor([0, 2, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=-1, dtype=VarType(int64), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=10, dtype=VarType(bool), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=10, dtype=VarType(float32), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=10, dtype=VarType(float64), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=10, dtype=VarType(int32), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=10, dtype=VarType(int64), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=10, dtype=VarType(uint8), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=30, dtype=type(numpy.int32), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(bool), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(float32), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(float64), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(int32), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(int64), )
paddle.nn.functional.sequence_mask(Tensor([0, 3],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(uint8), )
paddle.nn.functional.sequence_mask(Tensor([0],"float64"), maxlen=20, )
paddle.nn.functional.sequence_mask(Tensor([0],"int32"), )
paddle.nn.functional.sequence_mask(Tensor([0],"int32"), maxlen=4, dtype="float32", )
paddle.nn.functional.sequence_mask(Tensor([0],"int64"), 10, Dtype(float64), None, )
paddle.nn.functional.sequence_mask(Tensor([0],"int64"), 12, Dtype(float64), None, )
paddle.nn.functional.sequence_mask(Tensor([0],"int64"), 12, VarType(float64), None, )
paddle.nn.functional.sequence_mask(Tensor([2, 0, 3, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=-1, dtype=VarType(int64), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=10, dtype=VarType(bool), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=10, dtype=VarType(float32), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=10, dtype=VarType(float64), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=10, dtype=VarType(int32), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=10, dtype=VarType(int64), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=10, dtype=VarType(uint8), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=30, dtype=type(numpy.int32), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(bool), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(float32), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(float64), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(int32), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(int64), )
paddle.nn.functional.sequence_mask(Tensor([2, 0],"int64"), maxlen=Tensor([1],"int32"), dtype=VarType(uint8), )
paddle.nn.functional.sequence_mask(Tensor([2, 2, 0, 3, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 0, 3],"float64"), maxlen=5, dtype=type(numpy.int32), )
paddle.nn.functional.sequence_mask(Tensor([2, 2, 3, 3, 0],"float64"), maxlen=5, dtype=type(numpy.int32), )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 3, 4, 10],"float64"), Tensor([0, 3, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 4],"float32"), Tensor([0, 4],"float32"), )
paddle.nn.functional.sigmoid_focal_loss(Tensor([0, 4],"float32"), Tensor([0, 4],"float32"), alpha=0.25, gamma=2.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([108, 0],"float32"), Tensor([108, 0],"float32"), alpha=0.25, gamma=2.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([11, 0],"float32"), Tensor([11, 0],"float32"), alpha=0.25, gamma=2.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([110484, 0],"float32"), Tensor([110484, 0],"float32"), )
paddle.nn.functional.sigmoid_focal_loss(Tensor([122760, 0],"float32"), Tensor([122760, 0],"float32"), )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.25, gamma=3, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 0, 4, 10],"float64"), Tensor([2, 0, 4, 10],"float64"), None, alpha=0.5, gamma=3, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.25, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.25, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.25, gamma=3, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.5, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.5, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 0, 10],"float64"), Tensor([2, 3, 0, 10],"float64"), None, alpha=0.5, gamma=3, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.25, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.25, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.25, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.25, gamma=3, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.5, gamma=0.0, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.5, gamma=0.0, reduction="sum", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.5, gamma=3, reduction="none", )
paddle.nn.functional.sigmoid_focal_loss(Tensor([2, 3, 4, 0],"float64"), Tensor([2, 3, 4, 0],"float64"), None, alpha=0.5, gamma=3, reduction="sum", )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float32"), "none", None, )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float32"), "sum", None, )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float32"), reduction="none", )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float32"), reduction="sum", )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), "none", None, )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), "sum", None, )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), reduction="none", )
paddle.nn.functional.soft_margin_loss(Tensor([0, 5],"float64"), Tensor([0, 5],"float64"), reduction="sum", )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float32"), "none", None, )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float32"), "sum", None, )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float32"), reduction="none", )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float32"), reduction="sum", )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), "none", None, )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), "sum", None, )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), reduction="none", )
paddle.nn.functional.soft_margin_loss(Tensor([5, 0],"float64"), Tensor([5, 0],"float64"), reduction="sum", )
paddle.nn.functional.softmax(Tensor([0, 1, 100],"float32"), axis=-1, dtype=Dtype(float32), )
paddle.nn.functional.softmax(Tensor([0, 1, 101],"float32"), axis=-1, dtype=Dtype(float32), )
paddle.nn.functional.softmax(Tensor([0, 1, 16, 49, 49],"float16"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 1, 16, 49, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 1, 81, 94, 311],"float32"), axis=2, )
paddle.nn.functional.softmax(Tensor([0, 10],"float32"), )
paddle.nn.functional.softmax(Tensor([0, 10],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 100],"float32"), )
paddle.nn.functional.softmax(Tensor([0, 11, 64, 64],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([0, 16, 1, 6],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([0, 16, 128],"float64"), 1, )
paddle.nn.functional.softmax(Tensor([0, 16, 128],"float64"), 1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 16, 18, 18],"float16"), )
paddle.nn.functional.softmax(Tensor([0, 16, 18, 18],"float32"), )
paddle.nn.functional.softmax(Tensor([0, 16],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([0, 165, 126],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([0, 17, 1600, 4],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([0, 17],"float16"), axis=1, )
paddle.nn.functional.softmax(Tensor([0, 256, 1],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([0, 3, 1],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([0, 3, 2, 5, 5],"float16"), )
paddle.nn.functional.softmax(Tensor([0, 3, 4],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 3, 4],"float32"), axis=1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([0, 3, 4],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([0, 3, 4],"float32"), axis=1, dtype="float64", )
paddle.nn.functional.softmax(Tensor([0, 3, 4],"float64"), 1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 3],"float32"), axis=1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([0, 3],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([0, 4, 10, 10],"float32"), axis=-1, dtype=Dtype(float32), )
paddle.nn.functional.softmax(Tensor([0, 4, 49, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 4, 5, 1, 7],"float32"), )
paddle.nn.functional.softmax(Tensor([0, 4, 7, 7],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([0, 4, 7, 7],"float32"), axis=3, )
paddle.nn.functional.softmax(Tensor([0, 6, 49, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([0, 6, 5, 4],"float64"), axis=-3, dtype=None, name=None, )
paddle.nn.functional.softmax(Tensor([0, 7, 7],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([0, 7, 99],"float32"), )
paddle.nn.functional.softmax(Tensor([0, 8, 1, 129],"float16"), -1, )
paddle.nn.functional.softmax(Tensor([0, 8, 1, 65],"float16"), -1, )
paddle.nn.functional.softmax(Tensor([0, 8, 153, 153],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([0, 8, 153, 89],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([0, 8, 8],"float32"), )
paddle.nn.functional.softmax(Tensor([0, 8],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([0],"float64"), axis=-1, )
paddle.nn.functional.softmax(Tensor([10, 0, 153, 153],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([10, 0, 153, 89],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([10, 8, 0, 153],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([10, 8, 0, 89],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([1008, 0, 7],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([1024, 0, 49, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([1024, 4, 0, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([1024, 6, 0, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([104, 0, 18, 18],"float16"), )
paddle.nn.functional.softmax(Tensor([104, 0, 18, 18],"float32"), )
paddle.nn.functional.softmax(Tensor([104, 16, 0, 18],"float16"), )
paddle.nn.functional.softmax(Tensor([104, 16, 0, 18],"float32"), )
paddle.nn.functional.softmax(Tensor([11, 0, 7, 7],"float32"), axis=3, )
paddle.nn.functional.softmax(Tensor([11, 4, 0, 7],"float32"), axis=3, )
paddle.nn.functional.softmax(Tensor([112, 0, 126],"float32"), axis=-1, )
paddle.nn.functional.softmax(Tensor([128, 0, 16, 49, 49],"float16"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([128, 0, 16, 49, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([128, 1, 0, 49, 49],"float16"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([128, 1, 0, 49, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([128, 1, 16, 0, 49],"float16"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([128, 1, 16, 0, 49],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([13, 0, 10, 10],"float32"), axis=-1, dtype=Dtype(float32), )
paddle.nn.functional.softmax(Tensor([13, 0, 5, 1, 7],"float32"), )
paddle.nn.functional.softmax(Tensor([13, 0, 7, 7],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([13, 0, 99],"float32"), )
paddle.nn.functional.softmax(Tensor([13, 4, 0, 1, 7],"float32"), )
paddle.nn.functional.softmax(Tensor([13, 4, 0, 10],"float32"), axis=-1, dtype=Dtype(float32), )
paddle.nn.functional.softmax(Tensor([13, 4, 0, 7],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([13, 4, 5, 0, 7],"float32"), )
paddle.nn.functional.softmax(Tensor([14, 0, 7, 7],"float32"), axis=3, )
paddle.nn.functional.softmax(Tensor([14, 4, 0, 7],"float32"), axis=3, )
paddle.nn.functional.softmax(Tensor([16, 0, 128],"float64"), 0, name=None, )
paddle.nn.functional.softmax(Tensor([16, 0],"float64"), 0, name=None, )
paddle.nn.functional.softmax(Tensor([16, 0],"float64"), 1, )
paddle.nn.functional.softmax(Tensor([16, 0],"float64"), 1, name=None, )
paddle.nn.functional.softmax(Tensor([16, 11, 0, 64],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([16, 11, 64, 0],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([16, 16, 0],"float64"), 0, name=None, )
paddle.nn.functional.softmax(Tensor([16, 16, 0],"float64"), 1, )
paddle.nn.functional.softmax(Tensor([16, 16, 0],"float64"), 1, name=None, )
paddle.nn.functional.softmax(Tensor([16, 16, 0],"float64"), 2, )
paddle.nn.functional.softmax(Tensor([16, 16, 0],"float64"), 2, name=None, )
paddle.nn.functional.softmax(Tensor([182, 3, 0],"float32"), axis=1, )
paddle.nn.functional.softmax(Tensor([2, 0, 1, 129],"float16"), -1, )
paddle.nn.functional.softmax(Tensor([2, 0, 1, 6],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([2, 0, 1, 65],"float16"), -1, )
paddle.nn.functional.softmax(Tensor([2, 0, 100],"float32"), axis=-1, dtype=Dtype(float32), )
paddle.nn.functional.softmax(Tensor([2, 0, 101],"float32"), axis=-1, dtype=Dtype(float32), )
paddle.nn.functional.softmax(Tensor([2, 0, 2, 5, 5],"float16"), )
paddle.nn.functional.softmax(Tensor([2, 0, 2048],"float32"), axis=0, )
paddle.nn.functional.softmax(Tensor([2, 0, 4, 5],"float32"), 0, name=None, )
paddle.nn.functional.softmax(Tensor([2, 0, 4, 5],"float32"), axis=0, )
paddle.nn.functional.softmax(Tensor([2, 0, 4],"float32"), -1, name=None, )
paddle.nn.functional.softmax(Tensor([2, 0, 4],"float32"), axis=0, dtype="float32", )
paddle.nn.functional.softmax(Tensor([2, 0, 4],"float32"), axis=-1, dtype="float32", )
paddle.nn.functional.softmax(Tensor([2, 0, 4],"float32"), axis=-3, dtype=None, name=None, )
paddle.nn.functional.square_error_cost(input=Tensor([0, 1],"float32"), label=Tensor([0, 1],"float32"), )
paddle.nn.functional.square_error_cost(input=Tensor([2, 0],"float32"), label=Tensor([2, 0],"float32"), )
paddle.nn.functional.square_error_cost(input=Tensor([2, 1],"float32"), label=Tensor([2, 0],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([0, 100, 100],"float16"), Tensor([0, 100, 100],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([0, 100, 100],"float32"), Tensor([0, 100, 100],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([0, 2, 1, 2],"float64"), label=Tensor([0, 2, 1, 2],"float64"), )
paddle.nn.functional.square_error_cost(Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([1],"float32"), Tensor([0],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([3, 0, 1, 2],"float64"), label=Tensor([3, 0, 1, 2],"float64"), )
paddle.nn.functional.square_error_cost(Tensor([3, 2, 0, 2],"float64"), label=Tensor([3, 2, 0, 2],"float64"), )
paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 0],"float64"), label=Tensor([3, 2, 1, 0],"float64"), )
paddle.nn.functional.square_error_cost(Tensor([3, 2, 1, 2],"float64"), label=Tensor([3, 2, 0, 2],"float64"), )
paddle.nn.functional.square_error_cost(Tensor([8, 0, 100],"float16"), Tensor([8, 0, 100],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([8, 0, 100],"float32"), Tensor([8, 0, 100],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([8, 100, 0],"float16"), Tensor([8, 100, 0],"float32"), )
paddle.nn.functional.square_error_cost(Tensor([8, 100, 0],"float32"), Tensor([8, 100, 0],"float32"), )
paddle.nn.functional.swish(Tensor([0, 1024, 1, 40],"float16"), None, )
paddle.nn.functional.swish(Tensor([0, 1024, 1, 40],"float32"), None, )
paddle.nn.functional.swish(Tensor([0, 1024, 32, 32],"float32"), )
paddle.nn.functional.swish(Tensor([0, 1024, 34, 34],"float32"), )
paddle.nn.functional.swish(Tensor([0, 300, 2048],"float32"), )
paddle.nn.functional.swish(Tensor([0, 40, 240],"float16"), None, )
paddle.nn.functional.swish(Tensor([0, 40, 240],"float32"), None, )
paddle.nn.functional.swish(Tensor([1, 0, 32, 32],"float32"), )
paddle.nn.functional.swish(Tensor([1, 0, 34, 34],"float32"), )
paddle.nn.functional.swish(Tensor([1, 1024, 0, 32],"float32"), )
paddle.nn.functional.swish(Tensor([1, 1024, 0, 34],"float32"), )
paddle.nn.functional.swish(Tensor([1, 1024, 32, 0],"float32"), )
paddle.nn.functional.swish(Tensor([1, 1024, 34, 0],"float32"), )
paddle.nn.functional.swish(Tensor([128, 0, 1, 40],"float16"), None, )
paddle.nn.functional.swish(Tensor([128, 0, 1, 40],"float32"), None, )
paddle.nn.functional.swish(Tensor([128, 0, 240],"float16"), None, )
paddle.nn.functional.swish(Tensor([128, 0, 240],"float32"), None, )
paddle.nn.functional.swish(Tensor([128, 1024, 0, 40],"float16"), None, )
paddle.nn.functional.swish(Tensor([128, 1024, 0, 40],"float32"), None, )
paddle.nn.functional.swish(Tensor([128, 1024, 1, 0],"float16"), None, )
paddle.nn.functional.swish(Tensor([128, 1024, 1, 0],"float32"), None, )
paddle.nn.functional.swish(Tensor([128, 40, 0],"float16"), None, )
paddle.nn.functional.swish(Tensor([128, 40, 0],"float32"), None, )
paddle.nn.functional.swish(Tensor([2, 0, 2048],"float32"), )
paddle.nn.functional.swish(Tensor([2, 300, 0],"float32"), )
paddle.nn.functional.swish(x=Tensor([0, 10, 3, 3],"float32"), )
paddle.nn.functional.swish(x=Tensor([0, 10, 3, 3],"float64"), )
paddle.nn.functional.swish(x=Tensor([3, 0, 3, 3],"float32"), )
paddle.nn.functional.swish(x=Tensor([3, 0, 3, 3],"float64"), )
paddle.nn.functional.swish(x=Tensor([3, 10, 0, 3],"float32"), )
paddle.nn.functional.swish(x=Tensor([3, 10, 0, 3],"float64"), )
paddle.nn.functional.swish(x=Tensor([3, 10, 3, 0],"float32"), )
paddle.nn.functional.swish(x=Tensor([3, 10, 3, 0],"float64"), )
paddle.nn.functional.temporal_shift(Tensor([0, 1024, 14, 14],"float16"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([0, 1024, 14, 14],"float16"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([0, 1024, 14, 14],"float32"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([0, 1024, 14, 14],"float32"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([0, 256, 28, 28],"float32"), 16, 0.0625, )
paddle.nn.functional.temporal_shift(Tensor([128, 0, 14, 14],"float16"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([128, 0, 14, 14],"float32"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([128, 0, 28, 28],"float32"), 16, 0.0625, )
paddle.nn.functional.temporal_shift(Tensor([128, 1024, 0, 14],"float16"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([128, 1024, 0, 14],"float32"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([128, 1024, 14, 0],"float16"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([128, 1024, 14, 0],"float32"), 8, 0.125, )
paddle.nn.functional.temporal_shift(Tensor([128, 256, 0, 28],"float32"), 16, 0.0625, )
paddle.nn.functional.temporal_shift(Tensor([128, 256, 28, 0],"float32"), 16, 0.0625, )
paddle.nn.functional.temporal_shift(Tensor([240, 0, 14, 14],"float16"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([240, 0, 14, 14],"float32"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([240, 1024, 0, 14],"float16"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([240, 1024, 0, 14],"float32"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([240, 1024, 14, 0],"float16"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([240, 1024, 14, 0],"float32"), 8, 0.125, data_format="NCHW", )
paddle.nn.functional.temporal_shift(Tensor([32, 0, 28, 28],"float32"), 16, 0.0625, )
paddle.nn.functional.temporal_shift(Tensor([32, 256, 0, 28],"float32"), 16, 0.0625, )
paddle.nn.functional.temporal_shift(Tensor([32, 256, 28, 0],"float32"), 16, 0.0625, )
paddle.nn.functional.temporal_shift(x=Tensor([0, 2, 4, 3],"float32"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([0, 2, 4, 3],"float64"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([0, 4, 2, 2],"float32"), seg_num=2, shift_ratio=0.2, )
paddle.nn.functional.temporal_shift(x=Tensor([0, 4, 3, 3],"float64"), seg_num=2, shift_ratio=0.4, )
paddle.nn.functional.temporal_shift(x=Tensor([0, 4, 3, 3],"float64"), seg_num=2, shift_ratio=0.4, data_format="NHWC", )
paddle.nn.functional.temporal_shift(x=Tensor([0, 4, 3, 3],"float64"), seg_num=4, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 0, 3, 3],"float64"), seg_num=2, shift_ratio=0.4, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 0, 3, 3],"float64"), seg_num=2, shift_ratio=0.4, data_format="NHWC", )
paddle.nn.functional.temporal_shift(x=Tensor([2, 0, 4, 3],"float32"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 0, 4, 3],"float64"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 0, 3],"float32"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 0, 3],"float64"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 4, 0],"float32"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 2, 4, 0],"float64"), seg_num=2, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 4, 0, 3],"float64"), seg_num=2, shift_ratio=0.4, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 4, 0, 3],"float64"), seg_num=2, shift_ratio=0.4, data_format="NHWC", )
paddle.nn.functional.temporal_shift(x=Tensor([2, 4, 3, 0],"float64"), seg_num=2, shift_ratio=0.4, )
paddle.nn.functional.temporal_shift(x=Tensor([2, 4, 3, 0],"float64"), seg_num=2, shift_ratio=0.4, data_format="NHWC", )
paddle.nn.functional.temporal_shift(x=Tensor([4, 0, 3, 3],"float64"), seg_num=4, )
paddle.nn.functional.temporal_shift(x=Tensor([4, 4, 0, 3],"float64"), seg_num=4, )
paddle.nn.functional.temporal_shift(x=Tensor([4, 4, 3, 0],"float64"), seg_num=4, )
paddle.nn.functional.temporal_shift(x=Tensor([6, 0, 2, 2],"float32"), seg_num=2, shift_ratio=0.2, )
paddle.nn.functional.temporal_shift(x=Tensor([6, 4, 0, 2],"float32"), seg_num=2, shift_ratio=0.2, )
paddle.nn.functional.temporal_shift(x=Tensor([6, 4, 2, 0],"float32"), seg_num=2, shift_ratio=0.2, )
paddle.nn.functional.thresholded_relu(Tensor([0, 20, 1],"float32"), 1.0, )
paddle.nn.functional.thresholded_relu(Tensor([10, 0, 1],"float32"), 1.0, )
paddle.nn.functional.thresholded_relu(Tensor([10, 20, 0],"float32"), 1.0, )
paddle.nn.functional.thresholded_relu(x=Tensor([0, 1, 4, 3],"float64"), threshold=0, )
paddle.nn.functional.thresholded_relu(x=Tensor([0, 1, 4, 3],"float64"), threshold=-1, )
paddle.nn.functional.thresholded_relu(x=Tensor([0, 4, 3, 3],"float32"), )
paddle.nn.functional.thresholded_relu(x=Tensor([0, 4, 3, 3],"float64"), )
paddle.nn.functional.thresholded_relu(x=Tensor([10, 0, 4, 3],"float64"), threshold=0, )
paddle.nn.functional.thresholded_relu(x=Tensor([10, 0, 4, 3],"float64"), threshold=-1, )
paddle.nn.functional.thresholded_relu(x=Tensor([10, 1, 0, 3],"float64"), threshold=0, )
paddle.nn.functional.thresholded_relu(x=Tensor([10, 1, 0, 3],"float64"), threshold=-1, )
paddle.nn.functional.thresholded_relu(x=Tensor([10, 1, 4, 0],"float64"), threshold=0, )
paddle.nn.functional.thresholded_relu(x=Tensor([10, 1, 4, 0],"float64"), threshold=-1, )
paddle.nn.functional.thresholded_relu(x=Tensor([100, 0, 3, 3],"float32"), )
paddle.nn.functional.thresholded_relu(x=Tensor([100, 0, 3, 3],"float64"), )
paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 0, 3],"float32"), )
paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 0, 3],"float64"), )
paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 0],"float32"), )
paddle.nn.functional.thresholded_relu(x=Tensor([100, 4, 3, 0],"float64"), )
paddle.nn.functional.unfold(Tensor([3, 0, 20, 20],"float64"), kernel_sizes=list[3,3,], strides=list[1,1,], paddings=list[1,1,1,1,], dilations=list[1,1,], name=None, )
paddle.nn.functional.zeropad2d(Tensor([0, 3, 224, 224],"float32"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([0, 3, 224, 224],"float64"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 0, 224, 224],"float32"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 0, 224, 224],"float64"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 0, 224],"float32"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 0, 224],"float64"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 0],"float32"), list[2,2,2,2,], )
paddle.nn.functional.zeropad2d(Tensor([4, 3, 224, 0],"float64"), list[2,2,2,2,], )
paddle.nn.quant.weight_only_linear(Tensor([0, 1, 512],"float16"), weight=Tensor([1024, 512],"int8"), bias=Tensor([1024],"float16"), weight_scale=Tensor([1024],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([0, 1, 64],"float16"), weight=Tensor([192, 64],"int8"), bias=Tensor([192],"float16"), weight_scale=Tensor([192],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([0, 32, 128],"float16"), Tensor([288, 128],"int8"), bias=Tensor([288],"float16"), weight_scale=Tensor([288],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([0, 32, 64],"float16"), Tensor([128, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int4", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([0, 32, 64],"float16"), Tensor([256, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([0, 320],"float16"), weight=Tensor([512, 320],"int8"), weight_scale=Tensor([512],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([0, 512],"float16"), weight=Tensor([1024, 512],"int8"), bias=Tensor([1024],"float16"), weight_scale=Tensor([1024],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([0, 512],"float16"), weight=Tensor([512, 512],"int8"), weight_scale=Tensor([512],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([0, 64],"float16"), weight=Tensor([192, 64],"int8"), bias=Tensor([192],"float16"), weight_scale=Tensor([192],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([0, 768],"float16"), weight=Tensor([2304, 768],"int8"), bias=None, weight_scale=Tensor([2304],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([1, 0, 128],"float16"), Tensor([288, 128],"int8"), bias=Tensor([288],"float16"), weight_scale=Tensor([288],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 0, 64],"float16"), Tensor([128, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int4", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 0, 64],"float16"), Tensor([256, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 32, 128],"float16"), Tensor([0, 128],"int8"), bias=Tensor([288],"float16"), weight_scale=Tensor([288],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 32, 128],"float16"), Tensor([288, 128],"int8"), bias=Tensor([288],"float16"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 32, 64],"float16"), Tensor([0, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int4", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 32, 64],"float16"), Tensor([0, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([256],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 32, 64],"float16"), Tensor([128, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([0],"float16"), weight_dtype="int4", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([1, 32, 64],"float16"), Tensor([256, 64],"int8"), bias=Tensor([256],"float16"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", group_size=-1, )
paddle.nn.quant.weight_only_linear(Tensor([100, 320],"float16"), weight=Tensor([0, 320],"int8"), weight_scale=Tensor([512],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([100, 320],"float16"), weight=Tensor([512, 320],"int8"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([100, 512],"float16"), weight=Tensor([0, 512],"int8"), bias=Tensor([1024],"float16"), weight_scale=Tensor([1024],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([100, 512],"float16"), weight=Tensor([0, 512],"int8"), weight_scale=Tensor([512],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([100, 512],"float16"), weight=Tensor([1024, 512],"int8"), bias=Tensor([1024],"float16"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([100, 512],"float16"), weight=Tensor([512, 512],"int8"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([101, 64],"float16"), weight=Tensor([0, 64],"int8"), bias=Tensor([192],"float16"), weight_scale=Tensor([192],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([101, 64],"float16"), weight=Tensor([192, 64],"int8"), bias=Tensor([192],"float16"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([123, 768],"float16"), weight=Tensor([0, 768],"int8"), bias=None, weight_scale=Tensor([2304],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([123, 768],"float16"), weight=Tensor([2304, 768],"int8"), bias=None, weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([131, 768],"float16"), weight=Tensor([0, 768],"int8"), bias=None, weight_scale=Tensor([2304],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([131, 768],"float16"), weight=Tensor([2304, 768],"int8"), bias=None, weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([2, 0, 512],"float16"), weight=Tensor([1024, 512],"int8"), bias=Tensor([1024],"float16"), weight_scale=Tensor([1024],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([2, 0, 64],"float16"), weight=Tensor([192, 64],"int8"), bias=Tensor([192],"float16"), weight_scale=Tensor([192],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([2, 1, 512],"float16"), weight=Tensor([0, 512],"int8"), bias=Tensor([1024],"float16"), weight_scale=Tensor([1024],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([2, 1, 512],"float16"), weight=Tensor([1024, 512],"int8"), bias=Tensor([1024],"float16"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([2, 1, 64],"float16"), weight=Tensor([0, 64],"int8"), bias=Tensor([192],"float16"), weight_scale=Tensor([192],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_only_linear(Tensor([2, 1, 64],"float16"), weight=Tensor([192, 64],"int8"), bias=Tensor([192],"float16"), weight_scale=Tensor([0],"float16"), weight_dtype="int8", )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int4", arch=70, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int4", arch=75, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int4", arch=80, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int4", arch=86, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int4", group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int8", arch=70, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int8", arch=75, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int8", arch=80, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int8", arch=86, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 256],"float16"), algo="weight_only_int8", group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 288],"float16"), algo="weight_only_int8", arch=70, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 288],"float16"), algo="weight_only_int8", arch=75, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 288],"float16"), algo="weight_only_int8", arch=80, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 288],"float16"), algo="weight_only_int8", arch=86, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 288],"float16"), algo="weight_only_int8", group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([0, 64],"float16"), algo="weight_only_int8", )
paddle.nn.quant.weight_quantize(Tensor([0, 768],"float16"), algo="weight_only_int8", )
paddle.nn.quant.weight_quantize(Tensor([11008, 0],"float16"), algo="weight_only_int8", )
paddle.nn.quant.weight_quantize(Tensor([128, 0],"float16"), algo="weight_only_int8", arch=70, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([128, 0],"float16"), algo="weight_only_int8", arch=75, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([128, 0],"float16"), algo="weight_only_int8", arch=80, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([128, 0],"float16"), algo="weight_only_int8", arch=86, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([128, 0],"float16"), algo="weight_only_int8", group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int4", arch=70, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int4", arch=75, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int4", arch=80, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int4", arch=86, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int4", group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int8", arch=70, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int8", arch=75, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int8", arch=80, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int8", arch=86, group_size=-1, )
paddle.nn.quant.weight_quantize(Tensor([64, 0],"float16"), algo="weight_only_int8", group_size=-1, )
paddle.nonzero(Tensor([0, 10],"float32"), as_tuple=False, )
paddle.nonzero(Tensor([0, 100],"float32"), )
paddle.nonzero(Tensor([0, 192],"float32"), )
paddle.nonzero(Tensor([0, 2, 2, 2],"float64"), True, )
paddle.nonzero(Tensor([0, 2, 28, 28],"float32"), )
paddle.nonzero(Tensor([0, 3],"float32"), True, )
paddle.nonzero(Tensor([0],"bool"), )
paddle.nonzero(Tensor([0],"bool"), as_tuple=False, )
paddle.nonzero(Tensor([0],"int32"), True, )
paddle.nonzero(Tensor([1, 0, 28, 28],"float32"), )
paddle.nonzero(Tensor([1, 0],"float32"), )
paddle.nonzero(Tensor([1, 2, 0, 28],"float32"), )
paddle.nonzero(Tensor([1, 2, 28, 0],"float32"), )
paddle.nonzero(Tensor([10, 0, 28, 28],"float32"), )
paddle.nonzero(Tensor([10, 0],"float32"), as_tuple=False, )
paddle.nonzero(Tensor([10, 2, 0, 28],"float32"), )
paddle.nonzero(Tensor([10, 2, 28, 0],"float32"), )
paddle.nonzero(Tensor([3, 0, 2, 2],"float64"), True, )
paddle.nonzero(Tensor([3, 0],"float32"), True, )
paddle.nonzero(Tensor([3, 2, 0, 2],"float64"), True, )
paddle.nonzero(Tensor([3, 2, 2, 0],"float64"), True, )
paddle.nonzero(x=Tensor([0, 10, 2],"float32"), )
paddle.nonzero(x=Tensor([0, 2, 2, 2],"float64"), as_tuple=False, )
paddle.nonzero(x=Tensor([0, 3],"float32"), as_tuple=False, )
paddle.nonzero(x=Tensor([0, 3],"float64"), as_tuple=False, )
paddle.nonzero(x=Tensor([0, 4, 7],"float16"), )
paddle.nonzero(x=Tensor([0, 8],"float64"), )
paddle.nonzero(x=Tensor([0, 9],"bfloat16"), )
paddle.nonzero(x=Tensor([0],"float64"), as_tuple=False, )
paddle.nonzero(x=Tensor([12, 0],"bfloat16"), )
paddle.nonzero(x=Tensor([2, 0, 2],"float32"), )
paddle.nonzero(x=Tensor([2, 10, 0],"float32"), )
paddle.nonzero(x=Tensor([3, 0, 2, 2],"float64"), as_tuple=False, )
paddle.nonzero(x=Tensor([3, 0, 7],"float16"), )
paddle.nonzero(x=Tensor([3, 0],"float32"), as_tuple=False, )
paddle.nonzero(x=Tensor([3, 0],"float64"), as_tuple=False, )
paddle.nonzero(x=Tensor([3, 2, 0, 2],"float64"), as_tuple=False, )
paddle.nonzero(x=Tensor([3, 2, 2, 0],"float64"), as_tuple=False, )
paddle.nonzero(x=Tensor([3, 4, 0],"float16"), )
paddle.nonzero(x=Tensor([8, 0],"float64"), )
paddle.polar(Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.polar(Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.quantile(Tensor([0, 3, 4],"float64"), q=list[0.1,0.2,0.3,], axis=list[1,2,], keepdim=True, )
paddle.quantile(Tensor([0, 3, 4],"float64"), q=list[0.2,0.67,], axis=list[1,-1,], )
paddle.quantile(Tensor([0, 3, 4],"float64"), q=list[0.3,0.44,], axis=-2, )
paddle.quantile(Tensor([0, 3],"float32"), list[0.3,0.7,], 1, )
paddle.quantile(Tensor([0, 7, 6],"float64"), q=0.1, axis=list[1,2,], keepdim=True, )
paddle.quantile(Tensor([4, 0, 6],"float64"), q=0.75, axis=list[0,2,], )
paddle.quantile(Tensor([5, 3, 0],"float64"), q=list[0.3,0.44,], axis=-2, )
paddle.reverse(Tensor([0, 1, 2],"float32"), axis=list[0,], )
paddle.reverse(Tensor([0, 1, 3],"float32"), axis=0, )
paddle.reverse(Tensor([0, 1, 4],"float32"), axis=1, )
paddle.reverse(Tensor([0, 12, 32],"float64"), axis=1, )
paddle.reverse(Tensor([0, 13, 3],"int64"), list[0,], )
paddle.reverse(Tensor([0, 4, 16],"float64"), axis=list[0,], )
paddle.reverse(Tensor([0, 4, 8],"float64"), axis=0, )
paddle.reverse(Tensor([0, 4],"float64"), axis=list[0,], )
paddle.reverse(Tensor([0, 7],"int64"), list[1,], )
paddle.reverse(Tensor([1, 0, 2],"float32"), axis=list[0,], )
paddle.reverse(Tensor([1, 0, 4],"float32"), axis=1, )
paddle.reverse(Tensor([1, 1, 0],"float32"), axis=1, )
paddle.reverse(Tensor([1, 1, 0],"float32"), axis=list[0,], )
paddle.reverse(Tensor([12, 0, 16],"float64"), axis=list[0,], )
paddle.reverse(Tensor([12, 0, 8],"float64"), axis=0, )
paddle.reverse(Tensor([12, 0],"float64"), axis=list[0,], )
paddle.reverse(Tensor([12, 4, 0],"float64"), axis=0, )
paddle.reverse(Tensor([12, 4, 0],"float64"), axis=list[0,], )
paddle.reverse(Tensor([13, 0],"int64"), list[1,], )
paddle.reverse(Tensor([2, 0, 3],"float32"), axis=0, )
paddle.reverse(Tensor([2, 1, 0],"float32"), axis=0, )
paddle.reverse(Tensor([4, 0, 32],"float64"), axis=1, )
paddle.reverse(Tensor([4, 12, 0],"float64"), axis=1, )
paddle.reverse(Tensor([6, 0, 3],"int64"), list[0,], )
paddle.reverse(Tensor([6, 13, 0],"int64"), list[0,], )
paddle.roll(Tensor([0, 3],"int64"), shifts=Tensor([2],"int64"), axis=list[0,1,], )
paddle.roll(Tensor([0, 4, 2],"float64"), Tensor([3],"int64"), list[0,1,2,], name=None, )
paddle.roll(Tensor([0, 5, 4, 4],"complex128"), Tensor([1],"int64"), 3, name=None, )
paddle.roll(Tensor([0, 5, 4, 4],"complex128"), Tensor([2],"int64"), tuple(0,3,), name=None, )
paddle.roll(Tensor([0, 5, 4, 4],"complex128"), Tensor([2],"int64"), tuple(1,3,), name=None, )
paddle.roll(Tensor([0, 5, 4, 4],"complex128"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.roll(Tensor([0, 5, 4, 4],"float64"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.roll(Tensor([0, 5, 4],"float64"), Tensor([3],"int64"), list[0,1,2,], name=None, )
paddle.roll(Tensor([0],"float32"), Tensor([1],"int64"), list[0,], name=None, )
paddle.roll(Tensor([0],"float64"), Tensor([1],"int64"), list[0,], name=None, )
paddle.roll(Tensor([2, 0, 2],"float64"), Tensor([3],"int64"), list[0,1,2,], name=None, )
paddle.roll(Tensor([2, 4, 0],"float64"), Tensor([3],"int64"), list[0,1,2,], name=None, )
paddle.roll(Tensor([3, 0],"int64"), shifts=Tensor([2],"int64"), axis=list[0,1,], )
paddle.roll(Tensor([4, 0, 4, 4],"complex128"), Tensor([1],"int64"), 3, name=None, )
paddle.roll(Tensor([4, 0, 4, 4],"complex128"), Tensor([2],"int64"), tuple(0,3,), name=None, )
paddle.roll(Tensor([4, 0, 4, 4],"complex128"), Tensor([2],"int64"), tuple(1,3,), name=None, )
paddle.roll(Tensor([4, 0, 4, 4],"complex128"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.roll(Tensor([4, 0, 4, 4],"float64"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.roll(Tensor([4, 0, 4],"float64"), Tensor([3],"int64"), list[0,1,2,], name=None, )
paddle.roll(Tensor([4, 5, 0, 4],"complex128"), Tensor([1],"int64"), 3, name=None, )
paddle.roll(Tensor([4, 5, 0, 4],"complex128"), Tensor([2],"int64"), tuple(0,3,), name=None, )
paddle.roll(Tensor([4, 5, 0, 4],"complex128"), Tensor([2],"int64"), tuple(1,3,), name=None, )
paddle.roll(Tensor([4, 5, 0, 4],"complex128"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.roll(Tensor([4, 5, 0, 4],"float64"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.roll(Tensor([4, 5, 0],"float64"), Tensor([3],"int64"), list[0,1,2,], name=None, )
paddle.roll(Tensor([4, 5, 4, 0],"complex128"), Tensor([1],"int64"), 3, name=None, )
paddle.roll(Tensor([4, 5, 4, 0],"complex128"), Tensor([2],"int64"), tuple(0,3,), name=None, )
paddle.roll(Tensor([4, 5, 4, 0],"complex128"), Tensor([2],"int64"), tuple(1,3,), name=None, )
paddle.roll(Tensor([4, 5, 4, 0],"complex128"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.roll(Tensor([4, 5, 4, 0],"float64"), Tensor([4],"int64"), list[0,1,2,3,], name=None, )
paddle.round(Tensor([0, 128],"float32"), )
paddle.round(Tensor([0, 3, 4],"float64"), )
paddle.round(Tensor([0, 512],"float16"), )
paddle.round(Tensor([0, 8, 64, 64],"float16"), )
paddle.round(Tensor([0],"float32"), )
paddle.round(Tensor([0],"float64"), )
paddle.round(Tensor([1, 0, 4],"float64"), )
paddle.round(Tensor([1, 3, 0],"float64"), )
paddle.round(Tensor([128, 0],"float16"), )
paddle.round(Tensor([128, 0],"float32"), )
paddle.round(Tensor([2, 0, 64, 64],"float16"), )
paddle.round(Tensor([2, 8, 0, 64],"float16"), )
paddle.round(Tensor([2, 8, 64, 0],"float16"), )
paddle.round(x=Tensor([0, 3, 3],"float32"), )
paddle.round(x=Tensor([0, 3, 3],"float64"), )
paddle.round(x=Tensor([3, 0, 3],"float32"), )
paddle.round(x=Tensor([3, 0, 3],"float64"), )
paddle.round(x=Tensor([3, 3, 0],"float32"), )
paddle.round(x=Tensor([3, 3, 0],"float64"), )
paddle.searchsorted(sorted_sequence=Tensor([0, 5],"float32"), values=Tensor([0, 3],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([0, 5],"float64"), values=Tensor([0, 3],"float64"), )
paddle.searchsorted(sorted_sequence=Tensor([0],"float32"), values=Tensor([0],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([2, 0],"float32"), values=Tensor([2, 0],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([2, 0],"float64"), values=Tensor([2, 0],"float64"), )
paddle.searchsorted(sorted_sequence=Tensor([2, 5],"float32"), values=Tensor([2, 0],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([2, 5],"float64"), values=Tensor([2, 0],"float64"), )
paddle.searchsorted(sorted_sequence=Tensor([5],"float32"), values=Tensor([0, 2],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([5],"float32"), values=Tensor([0, 3],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([5],"float32"), values=Tensor([0],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([5],"float32"), values=Tensor([2, 0],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([5],"float32"), values=Tensor([4, 0],"float32"), )
paddle.searchsorted(sorted_sequence=Tensor([7],"float32"), values=Tensor([0, 2, 2],"float32"), right=True, )
paddle.searchsorted(sorted_sequence=Tensor([7],"float32"), values=Tensor([2, 0, 2],"float32"), right=True, )
paddle.searchsorted(sorted_sequence=Tensor([7],"float32"), values=Tensor([2, 2, 0],"float32"), right=True, )
paddle.searchsorted(sorted_sequence=Tensor([7],"float64"), values=Tensor([0, 2, 2],"float64"), right=True, )
paddle.searchsorted(sorted_sequence=Tensor([7],"float64"), values=Tensor([2, 0, 2],"float64"), right=True, )
paddle.searchsorted(sorted_sequence=Tensor([7],"float64"), values=Tensor([2, 2, 0],"float64"), right=True, )
paddle.searchsorted(Tensor([0],"bfloat16"), Tensor([0],"bfloat16"), )
paddle.searchsorted(Tensor([0],"float16"), Tensor([0],"float16"), )
paddle.searchsorted(Tensor([0],"float32"), Tensor([0],"float32"), right=True, )
paddle.searchsorted(Tensor([0],"float64"), Tensor([0],"float64"), right=True, )
paddle.searchsorted(Tensor([1024],"bfloat16"), Tensor([0],"bfloat16"), )
paddle.searchsorted(Tensor([1024],"float16"), Tensor([0],"float16"), )
paddle.searchsorted(Tensor([2],"float64"), Tensor([0],"float64"), right=True, )
paddle.searchsorted(Tensor([3],"float32"), Tensor([0],"float32"), right=True, )
paddle.searchsorted(Tensor([5],"float64"), Tensor([0, 3],"float64"), out_int32=True, )
paddle.searchsorted(Tensor([5],"float64"), Tensor([0, 3],"float64"), right=True, )
paddle.searchsorted(Tensor([5],"float64"), Tensor([2, 0],"float64"), out_int32=True, )
paddle.searchsorted(Tensor([5],"float64"), Tensor([2, 0],"float64"), right=True, )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,16,], list[13,1,32,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,16,], list[16,1,32,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,16,], list[3,1,32,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,24,], list[13,1,40,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,24,], list[16,1,40,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,24,], list[3,1,40,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,32,], list[13,1,48,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,32,], list[16,1,48,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,32,], list[3,1,48,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,40,], list[13,1,56,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,40,], list[16,1,56,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,40,], list[3,1,56,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,48,], list[13,1,64,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,48,], list[16,1,64,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,48,], list[3,1,64,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,56,], list[13,1,72,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,56,], list[16,1,72,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,56,], list[3,1,72,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,64,], list[13,1,80,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,64,], list[16,1,80,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,64,], list[3,1,80,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,72,], list[13,1,88,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,72,], list[16,1,88,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,72,], list[3,1,88,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,8,], list[13,1,24,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,8,], list[16,1,24,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,8,], list[3,1,24,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,80,], list[13,1,96,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,80,], list[16,1,96,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,80,], list[3,1,96,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,88,], list[13,1,104,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,88,], list[16,1,104,], )
paddle.slice(Tensor([0, 1, 104],"float32"), list[0,1,2,], list[0,0,88,], list[3,1,104,], )
paddle.slice(Tensor([0, 1, 4],"float32"), axes=list[2,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0, 1, 4],"float32"), axes=list[2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 1, 4],"float32"), axes=list[2,], starts=list[3,], ends=list[4,], )
paddle.slice(Tensor([0, 2, 100, 100],"float16"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0, 2, 100, 100],"float32"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,16,], list[16,2,32,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,16,], list[2,2,32,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,24,], list[16,2,40,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,24,], list[2,2,40,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,32,], list[16,2,48,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,32,], list[2,2,48,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,40,], list[16,2,56,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,40,], list[2,2,56,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,48,], list[16,2,64,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,48,], list[2,2,64,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,56,], list[16,2,72,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,56,], list[2,2,72,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,64,], list[16,2,80,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,64,], list[2,2,80,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,72,], list[16,2,88,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,72,], list[2,2,88,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,8,], list[16,2,24,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,8,], list[2,2,24,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,80,], list[16,2,96,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,80,], list[2,2,96,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,88,], list[16,2,104,], )
paddle.slice(Tensor([0, 2, 104],"float32"), list[0,1,2,], list[0,0,88,], list[2,2,104,], )
paddle.slice(Tensor([0, 3, 4, 5, 6],"float32"), axes=list[0,1,2,], starts=list[1,0,2,], ends=list[3,3,4,], )
paddle.slice(Tensor([0, 3, 4, 5, 6],"int64"), list[0,1,2,4,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([0, 3, 4, 5],"int64"), list[0,1,2,3,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([0, 3, 6],"int64"), axes=list[2,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([0, 3, 6],"int64"), axes=list[2,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([0, 3, 6],"int64"), axes=list[2,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([0, 3, 6],"int64"), axes=list[2,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([0, 3, 6],"int64"), axes=list[2,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([0, 3, 8],"float32"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0, 3, 8],"float32"), axes=list[1,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 3],"float16"), axes=list[1,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 4, 4, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 4, 4, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([0, 4, 4, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([0, 4, 4, 7],"int64"), axes=list[3,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([0, 4, 4, 7],"int64"), axes=list[3,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([0, 4, 4, 7],"int64"), axes=list[3,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([0, 4, 5, 6],"float64"), axes=list[-2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 4, 5],"bool"), list[0,1,2,], list[0,1,2,], list[3,5,4,], )
paddle.slice(Tensor([0, 4, 5],"int64"), list[0,1,2,], list[0,1,2,], list[3,3,4,], )
paddle.slice(Tensor([0, 4, 5],"int64"), list[0,2,], list[2,2,], list[3,4,], )
paddle.slice(Tensor([0, 4, 5],"int64"), list[1,], list[2,], list[3,], )
paddle.slice(Tensor([0, 4, 5],"int64"), list[1,2,], list[2,2,], list[3,4,], )
paddle.slice(Tensor([0, 4, 5],"int64"), list[-3,-2,-1,], list[1,-3,2,], list[3,3,4,], )
paddle.slice(Tensor([0, 4, 7, 4],"int64"), axes=list[-2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 4, 7, 4],"int64"), axes=list[-2,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([0, 4, 7, 4],"int64"), axes=list[-2,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([0, 4, 7, 4],"int64"), axes=list[-2,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([0, 4, 7, 4],"int64"), axes=list[-2,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([0, 4, 7, 4],"int64"), axes=list[-2,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([0, 4, 7],"int64"), axes=list[2,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([0, 4, 7],"int64"), axes=list[2,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([0, 4, 7],"int64"), axes=list[2,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([0, 4, 7],"int64"), axes=list[2,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([0, 4, 7],"int64"), axes=list[2,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([0, 4],"int64"), axes=list[1,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 4],"int64"), axes=list[1,], starts=list[3,], ends=list[4,], )
paddle.slice(Tensor([0, 4],"int64"), list[0,1,], list[0,1,], list[2,3,], )
paddle.slice(Tensor([0, 4],"int64"), list[1,], list[-3,], list[2,], )
paddle.slice(Tensor([0, 5, 6],"float32"), axes=list[0,1,2,], starts=list[-3,0,2,], ends=list[3,2,4,], )
paddle.slice(Tensor([0, 51],"float32"), axes=list[1,], starts=list[49,], ends=list[50,], )
paddle.slice(Tensor([0, 51],"int64"), axes=list[1,], starts=list[49,], ends=list[50,], )
paddle.slice(Tensor([0, 6, 3],"int64"), axes=list[1,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([0, 6, 3],"int64"), axes=list[1,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([0, 6, 3],"int64"), axes=list[1,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([0, 6, 3],"int64"), axes=list[1,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([0, 6, 3],"int64"), axes=list[1,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([0, 6],"float32"), axes=list[1,], starts=list[4,], ends=list[5,], )
paddle.slice(Tensor([0, 6],"int64"), axes=list[1,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([0, 6],"int64"), axes=list[1,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([0, 6],"int64"), axes=list[1,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([0, 6],"int64"), axes=list[1,], starts=list[4,], ends=list[5,], )
paddle.slice(Tensor([0, 6],"int64"), axes=list[1,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([0, 6],"int64"), axes=list[1,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([0, 7],"int64"), axes=list[1,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([0, 7],"int64"), axes=list[1,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([0, 7],"int64"), axes=list[1,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([0, 7],"int64"), axes=list[1,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([0, 7],"int64"), axes=list[1,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([0, 78],"int64"), list[0,-1,], list[32,58,], list[-2,-1,], )
paddle.slice(Tensor([0, 8, 24],"float32"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([0, 8, 24],"float32"), axes=list[1,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([0, 8, 24],"float32"), axes=list[1,], starts=list[3,], ends=list[4,], )
paddle.slice(Tensor([0, 8, 24],"float32"), axes=list[1,], starts=list[4,], ends=list[5,], )
paddle.slice(Tensor([0, 8, 24],"float32"), axes=list[1,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([0, 8, 24],"float32"), axes=list[1,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([0, 8, 24],"float32"), axes=list[1,], starts=list[7,], ends=list[8,], )
paddle.slice(Tensor([0, 9, 16],"float32"), axes=list[1,], starts=list[1,], ends=list[8,], )
paddle.slice(Tensor([0, 9, 16],"float32"), axes=list[1,], starts=list[2,], ends=list[9,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[128,], ends=list[256,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[256,], ends=list[384,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[256,], ends=list[512,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[384,], ends=list[512,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[512,], ends=list[640,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[512,], ends=list[768,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[640,], ends=list[768,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[768,], ends=list[1024,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[768,], ends=list[896,], )
paddle.slice(Tensor([1024, 0, 1024],"float16"), axes=list[0,], starts=list[896,], ends=list[1024,], )
paddle.slice(Tensor([1024, 16, 0],"float16"), axes=list[0,], starts=list[128,], ends=list[256,], )
paddle.slice(Tensor([1024, 16, 0],"float16"), axes=list[0,], starts=list[256,], ends=list[384,], )
paddle.slice(Tensor([1024, 16, 0],"float16"), axes=list[0,], starts=list[384,], ends=list[512,], )
paddle.slice(Tensor([1024, 16, 0],"float16"), axes=list[0,], starts=list[512,], ends=list[640,], )
paddle.slice(Tensor([1024, 16, 0],"float16"), axes=list[0,], starts=list[640,], ends=list[768,], )
paddle.slice(Tensor([1024, 16, 0],"float16"), axes=list[0,], starts=list[768,], ends=list[896,], )
paddle.slice(Tensor([1024, 16, 0],"float16"), axes=list[0,], starts=list[896,], ends=list[1024,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[128,], ends=list[256,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[256,], ends=list[384,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[256,], ends=list[512,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[384,], ends=list[512,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[512,], ends=list[640,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[512,], ends=list[768,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[640,], ends=list[768,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[768,], ends=list[1024,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[768,], ends=list[896,], )
paddle.slice(Tensor([1024, 2, 0],"float16"), axes=list[0,], starts=list[896,], ends=list[1024,], )
paddle.slice(Tensor([11, 0, 4],"float32"), axes=list[2,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([11, 0, 4],"float32"), axes=list[2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([11, 0, 4],"float32"), axes=list[2,], starts=list[3,], ends=list[4,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,16,], list[13,1,32,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,24,], list[13,1,40,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,32,], list[13,1,48,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,40,], list[13,1,56,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,48,], list[13,1,64,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,56,], list[13,1,72,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,64,], list[13,1,80,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,72,], list[13,1,88,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,8,], list[13,1,24,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,80,], list[13,1,96,], )
paddle.slice(Tensor([13, 0, 104],"float32"), list[0,1,2,], list[0,0,88,], list[13,1,104,], )
paddle.slice(Tensor([13, 9, 0],"float32"), axes=list[1,], starts=list[1,], ends=list[8,], )
paddle.slice(Tensor([13, 9, 0],"float32"), axes=list[1,], starts=list[2,], ends=list[9,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,16,], list[16,1,32,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,16,], list[16,2,32,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,24,], list[16,1,40,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,24,], list[16,2,40,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,32,], list[16,1,48,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,32,], list[16,2,48,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,40,], list[16,1,56,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,40,], list[16,2,56,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,48,], list[16,1,64,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,48,], list[16,2,64,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,56,], list[16,1,72,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,56,], list[16,2,72,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,64,], list[16,1,80,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,64,], list[16,2,80,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,72,], list[16,1,88,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,72,], list[16,2,88,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,8,], list[16,1,24,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,8,], list[16,2,24,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,80,], list[16,1,96,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,80,], list[16,2,96,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,88,], list[16,1,104,], )
paddle.slice(Tensor([16, 0, 104],"float32"), list[0,1,2,], list[0,0,88,], list[16,2,104,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,16,], list[2,2,32,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,24,], list[2,2,40,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,32,], list[2,2,48,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,40,], list[2,2,56,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,48,], list[2,2,64,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,56,], list[2,2,72,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,64,], list[2,2,80,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,72,], list[2,2,88,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,8,], list[2,2,24,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,80,], list[2,2,96,], )
paddle.slice(Tensor([2, 0, 104],"float32"), list[0,1,2,], list[0,0,88,], list[2,2,104,], )
paddle.slice(Tensor([2, 0, 2],"float32"), axes=list[0,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 0, 2],"float64"), axes=list[0,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 0, 4, 5, 6],"float32"), axes=list[0,1,2,], starts=list[1,0,2,], ends=list[3,3,4,], )
paddle.slice(Tensor([2, 0, 4, 5, 6],"int64"), list[0,1,2,4,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([2, 0, 4, 5],"int64"), list[0,1,2,3,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([2, 0, 5],"float32"), list[0,], list[1,], list[2,], )
paddle.slice(Tensor([2, 0],"float16"), axes=list[0,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 0],"float32"), axes=list[0,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 10, 0],"float32"), list[0,], list[1,], list[2,], )
paddle.slice(Tensor([2, 3, 0, 5, 6],"float32"), axes=list[0,1,2,], starts=list[1,0,2,], ends=list[3,3,4,], )
paddle.slice(Tensor([2, 3, 0, 5, 6],"int64"), list[0,1,2,4,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([2, 3, 0, 5],"int64"), list[0,1,2,3,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([2, 3, 0],"float32"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 3, 0],"float32"), axes=list[1,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([2, 3, 4, 0, 6],"float32"), axes=list[0,1,2,], starts=list[1,0,2,], ends=list[3,3,4,], )
paddle.slice(Tensor([2, 3, 4, 0, 6],"int64"), list[0,1,2,4,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([2, 3, 4, 0],"int64"), list[0,1,2,3,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([2, 3, 4, 5, 0],"float32"), axes=list[0,1,2,], starts=list[1,0,2,], ends=list[3,3,4,], )
paddle.slice(Tensor([2, 3, 4, 5, 0],"int64"), list[0,1,2,4,], list[0,1,2,-4,], list[3,3,4,-2,], )
paddle.slice(Tensor([2, 4, 0],"float32"), axes=list[0,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 4, 0],"float64"), axes=list[0,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 8, 0],"float32"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([2, 8, 0],"float32"), axes=list[1,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([2, 8, 0],"float32"), axes=list[1,], starts=list[3,], ends=list[4,], )
paddle.slice(Tensor([2, 8, 0],"float32"), axes=list[1,], starts=list[4,], ends=list[5,], )
paddle.slice(Tensor([2, 8, 0],"float32"), axes=list[1,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([2, 8, 0],"float32"), axes=list[1,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([2, 8, 0],"float32"), axes=list[1,], starts=list[7,], ends=list[8,], )
paddle.slice(Tensor([21, 0, 4],"float32"), axes=list[2,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([21, 0, 4],"float32"), axes=list[2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([21, 0, 4],"float32"), axes=list[2,], starts=list[3,], ends=list[4,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,16,], list[3,1,32,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,24,], list[3,1,40,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,32,], list[3,1,48,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,40,], list[3,1,56,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,48,], list[3,1,64,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,56,], list[3,1,72,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,64,], list[3,1,80,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,72,], list[3,1,88,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,8,], list[3,1,24,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,80,], list[3,1,96,], )
paddle.slice(Tensor([3, 0, 104],"float32"), list[0,1,2,], list[0,0,88,], list[3,1,104,], )
paddle.slice(Tensor([3, 0, 4],"float32"), axes=list[0,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([3, 0, 5, 6],"float64"), axes=list[-2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([3, 0, 5],"bool"), list[0,1,2,], list[0,1,2,], list[3,5,4,], )
paddle.slice(Tensor([3, 0],"float32"), axes=list[0,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([3, 0],"float64"), axes=list[0,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([3, 4, 0],"bool"), list[0,1,2,], list[0,1,2,], list[3,5,4,], )
paddle.slice(Tensor([3, 4, 0],"float32"), axes=list[0,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([3, 4, 5, 0],"float64"), axes=list[-2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([4, 0, 20],"float16"), list[0,], list[2,], list[4,], )
paddle.slice(Tensor([4, 0, 4, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([4, 0, 4, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([4, 0, 4, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 4, 7],"int64"), axes=list[3,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([4, 0, 4, 7],"int64"), axes=list[3,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 4, 7],"int64"), axes=list[3,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([4, 0, 5],"float32"), list[0,], list[2,], list[4,], )
paddle.slice(Tensor([4, 0, 5],"int64"), list[0,], list[1,], list[2,], )
paddle.slice(Tensor([4, 0, 5],"int64"), list[0,1,2,], list[0,1,2,], list[3,3,4,], )
paddle.slice(Tensor([4, 0, 5],"int64"), list[0,2,], list[2,2,], list[3,4,], )
paddle.slice(Tensor([4, 0, 5],"int64"), list[1,2,], list[2,2,], list[3,4,], )
paddle.slice(Tensor([4, 0, 5],"int64"), list[-3,-2,-1,], list[1,-3,2,], list[3,3,4,], )
paddle.slice(Tensor([4, 0, 6],"float32"), axes=list[0,1,2,], starts=list[-3,0,2,], ends=list[3,2,4,], )
paddle.slice(Tensor([4, 0, 6],"int64"), axes=list[2,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([4, 0, 6],"int64"), axes=list[2,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([4, 0, 6],"int64"), axes=list[2,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 6],"int64"), axes=list[2,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 6],"int64"), axes=list[2,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 7, 4],"int64"), axes=list[-2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([4, 0, 7, 4],"int64"), axes=list[-2,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([4, 0, 7, 4],"int64"), axes=list[-2,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 7, 4],"int64"), axes=list[-2,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([4, 0, 7, 4],"int64"), axes=list[-2,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 7, 4],"int64"), axes=list[-2,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([4, 0, 7],"int64"), axes=list[2,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([4, 0, 7],"int64"), axes=list[2,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 7],"int64"), axes=list[2,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([4, 0, 7],"int64"), axes=list[2,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([4, 0, 7],"int64"), axes=list[2,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([4, 10, 0],"float32"), list[0,], list[2,], list[4,], )
paddle.slice(Tensor([4, 20, 0],"float16"), list[0,], list[2,], list[4,], )
paddle.slice(Tensor([4, 4, 0, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([4, 4, 0, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([4, 4, 0, 7],"int64"), axes=list[3,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([4, 4, 0, 7],"int64"), axes=list[3,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([4, 4, 0, 7],"int64"), axes=list[3,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([4, 4, 0, 7],"int64"), axes=list[3,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([4, 4, 0],"int64"), list[0,], list[1,], list[2,], )
paddle.slice(Tensor([4, 4, 0],"int64"), list[0,1,2,], list[0,1,2,], list[3,3,4,], )
paddle.slice(Tensor([4, 4, 0],"int64"), list[0,2,], list[2,2,], list[3,4,], )
paddle.slice(Tensor([4, 4, 0],"int64"), list[1,], list[2,], list[3,], )
paddle.slice(Tensor([4, 4, 0],"int64"), list[1,2,], list[2,2,], list[3,4,], )
paddle.slice(Tensor([4, 4, 0],"int64"), list[-3,-2,-1,], list[1,-3,2,], list[3,3,4,], )
paddle.slice(Tensor([4, 4, 7, 0],"int64"), axes=list[-2,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([4, 4, 7, 0],"int64"), axes=list[-2,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([4, 4, 7, 0],"int64"), axes=list[-2,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([4, 4, 7, 0],"int64"), axes=list[-2,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([4, 4, 7, 0],"int64"), axes=list[-2,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([4, 4, 7, 0],"int64"), axes=list[-2,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([4, 5, 0],"float32"), axes=list[0,1,2,], starts=list[-3,0,2,], ends=list[3,2,4,], )
paddle.slice(Tensor([4, 6, 0],"int64"), axes=list[1,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([4, 6, 0],"int64"), axes=list[1,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([4, 6, 0],"int64"), axes=list[1,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([4, 6, 0],"int64"), axes=list[1,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([4, 6, 0],"int64"), axes=list[1,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([52, 9, 0],"float32"), axes=list[1,], starts=list[1,], ends=list[8,], )
paddle.slice(Tensor([52, 9, 0],"float32"), axes=list[1,], starts=list[2,], ends=list[9,], )
paddle.slice(Tensor([6, 0, 3],"int64"), axes=list[0,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([6, 0, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([6, 0, 3],"int64"), axes=list[0,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([6, 0, 3],"int64"), axes=list[0,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([6, 0, 3],"int64"), axes=list[0,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([6, 0],"int64"), axes=list[0,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([6, 0],"int64"), axes=list[0,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([6, 0],"int64"), axes=list[0,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([6, 0],"int64"), axes=list[0,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([6, 0],"int64"), axes=list[0,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([6, 4, 0],"int64"), axes=list[0,], starts=list[1,], ends=list[3,], )
paddle.slice(Tensor([6, 4, 0],"int64"), axes=list[0,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([6, 4, 0],"int64"), axes=list[0,], starts=list[3,], ends=list[6,], )
paddle.slice(Tensor([6, 4, 0],"int64"), axes=list[0,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([6, 4, 0],"int64"), axes=list[0,], starts=list[5,], ends=list[6,], )
paddle.slice(Tensor([7, 0, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([7, 0, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([7, 0, 3],"int64"), axes=list[0,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([7, 0, 3],"int64"), axes=list[0,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([7, 0, 3],"int64"), axes=list[0,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([7, 0, 3],"int64"), axes=list[0,], starts=list[4,], ends=list[7,], )
paddle.slice(Tensor([7, 0, 3],"int64"), axes=list[0,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([7, 0],"int64"), axes=list[0,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([7, 0],"int64"), axes=list[0,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([7, 0],"int64"), axes=list[0,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([7, 0],"int64"), axes=list[0,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([7, 0],"int64"), axes=list[0,], starts=list[4,], ends=list[7,], )
paddle.slice(Tensor([7, 0],"int64"), axes=list[0,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([7, 4, 0],"int64"), axes=list[0,], starts=list[2,], ends=list[3,], )
paddle.slice(Tensor([7, 4, 0],"int64"), axes=list[0,], starts=list[2,], ends=list[4,], )
paddle.slice(Tensor([7, 4, 0],"int64"), axes=list[0,], starts=list[2,], ends=list[6,], )
paddle.slice(Tensor([7, 4, 0],"int64"), axes=list[0,], starts=list[3,], ends=list[7,], )
paddle.slice(Tensor([7, 4, 0],"int64"), axes=list[0,], starts=list[4,], ends=list[6,], )
paddle.slice(Tensor([7, 4, 0],"int64"), axes=list[0,], starts=list[4,], ends=list[7,], )
paddle.slice(Tensor([7, 4, 0],"int64"), axes=list[0,], starts=list[6,], ends=list[7,], )
paddle.slice(Tensor([78, 0],"int64"), list[0,-1,], list[32,58,], list[-2,-1,], )
paddle.slice(Tensor([8, 0, 20],"float16"), list[0,], list[4,], list[8,], )
paddle.slice(Tensor([8, 2, 0, 100],"float16"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([8, 2, 0, 100],"float32"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([8, 2, 100, 0],"float16"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([8, 2, 100, 0],"float32"), axes=list[1,], starts=list[1,], ends=list[2,], )
paddle.slice(Tensor([8, 20, 0],"float16"), list[0,], list[4,], list[8,], )
paddle.sort(Tensor([0, 10],"float64"), )
paddle.sort(Tensor([0, 10],"float64"), axis=-1, )
paddle.sort(Tensor([0, 3, 4],"float64"), 1, )
paddle.sort(Tensor([0, 3],"float32"), 1, )
paddle.sort(Tensor([0, 30000],"float32"), descending=True, )
paddle.sort(Tensor([0, 32000],"float16"), descending=True, )
paddle.sort(Tensor([0, 42],"float64"), 1, )
paddle.sort(Tensor([0, 6, 3, 4, 2, 5],"float64"), 3, )
paddle.sort(Tensor([0, 6, 3, 4, 2, 5],"float64"), 4, )
paddle.sort(Tensor([0, 6, 3, 4, 2, 5],"float64"), 4, )
paddle.sort(Tensor([0, 6, 3, 4, 2, 5],"float64"), 5, )
paddle.sort(Tensor([0, 7, 6],"float64"), 1, )
paddle.sort(Tensor([0, 7, 6],"float64"), 2, )
paddle.sort(Tensor([2, 0, 4],"float64"), 0, )
paddle.sort(Tensor([2, 0],"float64"), 0, )
paddle.sort(Tensor([2, 3, 0],"float64"), 0, )
paddle.sort(Tensor([3, 0, 3, 4, 2, 5],"float64"), 3, )
paddle.sort(Tensor([3, 0, 3, 4, 2, 5],"float64"), 4, )
paddle.sort(Tensor([3, 0, 3, 4, 2, 5],"float64"), 5, )
paddle.sort(Tensor([3, 0, 3],"float32"), 0, )
paddle.sort(Tensor([3, 3, 0],"float32"), 0, )
paddle.sort(Tensor([3, 6, 0, 4, 2, 5],"float64"), 3, )
paddle.sort(Tensor([3, 6, 0, 4, 2, 5],"float64"), 4, )
paddle.sort(Tensor([3, 6, 0, 4, 2, 5],"float64"), 5, )
paddle.sort(Tensor([3, 6, 3, 0, 2, 5],"float64"), 4, )
paddle.sort(Tensor([3, 6, 3, 0, 2, 5],"float64"), 5, )
paddle.sort(Tensor([3, 6, 3, 4, 0, 5],"float64"), 3, )
paddle.sort(Tensor([3, 6, 3, 4, 0, 5],"float64"), 5, )
paddle.sort(Tensor([3, 6, 3, 4, 2, 0],"float64"), 3, )
paddle.sort(Tensor([3, 6, 3, 4, 2, 0],"float64"), 4, )
paddle.sort(Tensor([4, 0, 6],"float64"), 2, )
paddle.split(Tensor([0, 1, 10285],"float32"), list[7744,1936,484,121,], axis=-1, )
paddle.split(Tensor([0, 1, 16, 192],"float32"), num_or_sections=3, axis=-1, )
paddle.split(Tensor([0, 1, 2577],"float32"), list[1936,484,121,36,], axis=-1, )
paddle.split(Tensor([0, 1, 3598],"float32"), list[2704,676,169,49,], axis=-1, )
paddle.split(Tensor([0, 1, 36858],"float32"), list[27648,6912,1728,432,108,30,], axis=-1, )
paddle.split(Tensor([0, 1, 38402],"float32"), list[28800,7200,1800,450,117,35,], axis=-1, )
paddle.split(Tensor([0, 1, 4, 24],"float32"), 3, axis=-1, )
paddle.split(Tensor([0, 1, 4],"float32"), 2, axis=-1, )
paddle.split(Tensor([0, 1, 4],"float32"), num_or_sections=4, axis=-1, )
paddle.split(Tensor([0, 1, 400, 176, 176],"float32"), list[100,300,], axis=2, )
paddle.split(Tensor([0, 1, 400, 184, 184],"float32"), list[100,300,], axis=2, )
paddle.split(Tensor([0, 1, 400, 2],"float32"), list[100,300,], axis=2, )
paddle.split(Tensor([0, 1, 400, 4],"float32"), list[100,300,], axis=2, )
paddle.split(Tensor([0, 1, 4165],"float32"), list[3136,784,196,49,], axis=-1, )
paddle.split(Tensor([0, 1, 492, 11],"float32"), list[192,300,], axis=2, )
paddle.split(Tensor([0, 1, 492, 4],"float32"), list[192,300,], axis=2, )
paddle.split(Tensor([0, 1, 496, 11],"float32"), list[196,300,], axis=2, )
paddle.split(Tensor([0, 1, 496, 4],"float32"), list[196,300,], axis=2, )
paddle.split(Tensor([0, 1, 500, 11],"float32"), list[200,300,], axis=2, )
paddle.split(Tensor([0, 1, 5440],"float32"), list[4096,1024,256,64,], axis=-1, )
paddle.split(Tensor([0, 1, 6150],"float32"), list[4624,1156,289,81,], axis=-1, )
paddle.split(Tensor([0, 1, 6400],"float32"), list[4800,1200,300,80,20,], axis=-1, )
paddle.split(Tensor([0, 1, 6885],"float32"), list[5184,1296,324,81,], axis=-1, )
paddle.split(Tensor([0, 1, 8500],"float32"), list[6400,1600,400,100,], axis=-1, )
paddle.split(Tensor([0, 1, 8580],"float32"), list[6408,1620,414,108,30,], axis=-1, )
paddle.split(Tensor([0, 1, 96],"float32"), num_or_sections=3, axis=-1, )
paddle.stanh(x=Tensor([0, 2],"float32"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([0, 2],"float32"), scale_a=1.43, scale_b=4.56, )
paddle.stanh(x=Tensor([0, 2],"float32"), scale_a=6.42, scale_b=3.58, )
paddle.stanh(x=Tensor([0, 2],"float64"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([0, 2],"float64"), scale_a=1.43, scale_b=4.56, )
paddle.stanh(x=Tensor([0, 2],"float64"), scale_a=6.42, scale_b=3.58, )
paddle.stanh(x=Tensor([0, 3, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([0],"float32"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([0],"float64"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([1, 0],"float32"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([1, 0],"float32"), scale_a=1.43, scale_b=4.56, )
paddle.stanh(x=Tensor([1, 0],"float64"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([1, 0],"float64"), scale_a=1.43, scale_b=4.56, )
paddle.stanh(x=Tensor([2, 0, 2, 2],"float64"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([2, 0],"float32"), scale_a=6.42, scale_b=3.58, )
paddle.stanh(x=Tensor([2, 0],"float64"), scale_a=6.42, scale_b=3.58, )
paddle.stanh(x=Tensor([2, 3, 0, 2],"float64"), scale_a=0.67, scale_b=1.72, )
paddle.stanh(x=Tensor([2, 3, 2, 0],"float64"), scale_a=0.67, scale_b=1.72, )
paddle.strided_slice(Tensor([0, 6],"int64"), axes=list[0,1,], starts=list[8,-1,], ends=list[1,-5,], strides=list[-2,-3,], )
paddle.strided_slice(Tensor([0, 7, 8],"int64"), axes=list[0,2,], starts=list[7,-1,], ends=list[2,-5,], strides=list[-2,-3,], )
paddle.strided_slice(Tensor([6, 0, 8],"int64"), axes=list[0,2,], starts=list[7,-1,], ends=list[2,-5,], strides=list[-2,-3,], )
paddle.strided_slice(Tensor([6, 0],"int64"), axes=list[0,1,], starts=list[8,-1,], ends=list[1,-5,], strides=list[-2,-3,], )
paddle.strided_slice(Tensor([6, 7, 0],"int64"), axes=list[0,2,], starts=list[7,-1,], ends=list[2,-5,], strides=list[-2,-3,], )
paddle.strided_slice(x=Tensor([0, 4, 5, 6],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([0, 4, 5, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([0, 6],"float32"), axes=list[0,1,], starts=list[3,4,], ends=list[5,2,], strides=list[1,-2,], )
paddle.strided_slice(x=Tensor([0, 6],"float32"), axes=list[0,1,], starts=list[3,4,], ends=list[5,2,], strides=list[4,-2,], )
paddle.strided_slice(x=Tensor([0, 8, 6, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[-3,3,4,], ends=list[3,0,1,], strides=list[-1,-1,-2,], )
paddle.strided_slice(x=Tensor([0, 8, 6, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[6,5,4,], ends=list[2,0,1,], strides=list[-1,-2,-3,], )
paddle.strided_slice(x=Tensor([3, 0, 5, 6],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([3, 0, 5, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([3, 4, 0, 6],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([3, 4, 0, 6],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([3, 4, 5, 0],"float32"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([3, 4, 5, 0],"float64"), axes=list[1,2,3,], starts=list[-3,0,2,], ends=list[3,2,4,], strides=list[1,1,1,], )
paddle.strided_slice(x=Tensor([5, 0, 6, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[-3,3,4,], ends=list[3,0,1,], strides=list[-1,-1,-2,], )
paddle.strided_slice(x=Tensor([5, 0, 6, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[6,5,4,], ends=list[2,0,1,], strides=list[-1,-2,-3,], )
paddle.strided_slice(x=Tensor([5, 8, 0, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[-3,3,4,], ends=list[3,0,1,], strides=list[-1,-1,-2,], )
paddle.strided_slice(x=Tensor([5, 8, 0, 4, 2, 6],"float64"), axes=list[1,2,5,], starts=list[6,5,4,], ends=list[2,0,1,], strides=list[-1,-2,-3,], )
paddle.strided_slice(x=Tensor([5, 8, 6, 0, 2, 6],"float64"), axes=list[1,2,5,], starts=list[-3,3,4,], ends=list[3,0,1,], strides=list[-1,-1,-2,], )
paddle.strided_slice(x=Tensor([5, 8, 6, 0, 2, 6],"float64"), axes=list[1,2,5,], starts=list[6,5,4,], ends=list[2,0,1,], strides=list[-1,-2,-3,], )
paddle.strided_slice(x=Tensor([5, 8, 6, 4, 0, 6],"float64"), axes=list[1,2,5,], starts=list[-3,3,4,], ends=list[3,0,1,], strides=list[-1,-1,-2,], )
paddle.strided_slice(x=Tensor([5, 8, 6, 4, 0, 6],"float64"), axes=list[1,2,5,], starts=list[6,5,4,], ends=list[2,0,1,], strides=list[-1,-2,-3,], )
paddle.strided_slice(x=Tensor([5, 8, 6, 4, 2, 0],"float64"), axes=list[1,2,5,], starts=list[-3,3,4,], ends=list[3,0,1,], strides=list[-1,-1,-2,], )
paddle.strided_slice(x=Tensor([5, 8, 6, 4, 2, 0],"float64"), axes=list[1,2,5,], starts=list[6,5,4,], ends=list[2,0,1,], strides=list[-1,-2,-3,], )
paddle.strided_slice(x=Tensor([6, 0],"float32"), axes=list[0,1,], starts=list[3,4,], ends=list[5,2,], strides=list[1,-2,], )
paddle.strided_slice(x=Tensor([6, 0],"float32"), axes=list[0,1,], starts=list[3,4,], ends=list[5,2,], strides=list[4,-2,], )
paddle.subtract(Tensor([0, 1, 30, 30],"float32"), Tensor([0, 1, 30, 30],"float32"), )
paddle.subtract(Tensor([0, 1],"float32"), Tensor([0, 1],"float32"), )
paddle.subtract(Tensor([0, 10],"float32"), Tensor([0, 10],"float32"), )
paddle.subtract(Tensor([0, 3, 256, 256],"float32"), Tensor([0, 3, 256, 256],"float32"), )
paddle.subtract(Tensor([0, 3],"complex128"), Tensor([0, 3],"float64"), name="Normal_log_prob", )
paddle.subtract(Tensor([0, 3],"complex64"), Tensor([0, 3],"float32"), name="Normal_log_prob", )
paddle.subtract(Tensor([0, 96, 1],"float32"), Tensor([0, 96, 1],"float32"), )
paddle.subtract(Tensor([0, 96, 2],"float32"), Tensor([0, 96, 2],"float32"), )
paddle.subtract(Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.subtract(Tensor([0],"float32"), Tensor([0],"float32"), name="Cauchy_kl_divergence", )
paddle.subtract(Tensor([0],"float32"), Tensor([0],"float32"), name="Cauchy_log_prob", )
paddle.subtract(Tensor([0],"float64"), Tensor([0],"float64"), )
paddle.subtract(Tensor([0],"float64"), Tensor([0],"float64"), name="Cauchy_log_prob", )
paddle.subtract(Tensor([0],"float64"), Tensor([0],"float64"), name="Normal_log_prob", )
paddle.subtract(Tensor([1, 0, 256, 256],"float32"), Tensor([1, 0, 256, 256],"float32"), )
paddle.subtract(Tensor([1, 0, 30, 30],"float32"), Tensor([1, 0, 30, 30],"float32"), )
paddle.subtract(Tensor([1, 1, 0, 30],"float32"), Tensor([1, 1, 0, 30],"float32"), )
paddle.subtract(Tensor([1, 1, 30, 0],"float32"), Tensor([1, 1, 30, 0],"float32"), )
paddle.subtract(Tensor([1, 3, 0, 256],"float32"), Tensor([1, 3, 0, 256],"float32"), )
paddle.subtract(Tensor([1, 3, 256, 0],"float32"), Tensor([1, 3, 256, 0],"float32"), )
paddle.subtract(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), )
paddle.subtract(Tensor([16, 0, 1],"float32"), Tensor([16, 0, 1],"float32"), )
paddle.subtract(Tensor([16, 0, 2],"float32"), Tensor([16, 0, 2],"float32"), )
paddle.subtract(Tensor([16, 96, 0],"float32"), Tensor([16, 96, 0],"float32"), )
paddle.subtract(Tensor([2, 0],"complex128"), Tensor([2, 0],"float64"), name="Normal_log_prob", )
paddle.subtract(Tensor([2, 0],"complex64"), Tensor([2, 0],"float32"), name="Normal_log_prob", )
paddle.subtract(x=Tensor([0, 2],"float32"), y=Tensor([0, 2],"float32"), )
paddle.subtract(x=Tensor([0, 2],"float64"), y=Tensor([0, 2],"float64"), )
paddle.subtract(x=Tensor([0],"float64"), y=Tensor([0],"float64"), )
paddle.subtract(x=Tensor([2, 0],"float32"), y=Tensor([2, 0],"float32"), )
paddle.subtract(x=Tensor([2, 0],"float64"), y=Tensor([2, 0],"float64"), )
paddle.take(Tensor([0, 4],"float32"), Tensor([2, 3],"int64"), mode="raise", )
paddle.take(Tensor([0, 4],"float64"), Tensor([2, 3],"int64"), mode="raise", )
paddle.take(Tensor([0, 4],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
paddle.take(Tensor([3, 0],"float32"), Tensor([2, 3],"int64"), mode="raise", )
paddle.take(Tensor([3, 0],"float64"), Tensor([2, 3],"int64"), mode="raise", )
paddle.take(Tensor([3, 0],"float64"), Tensor([5, 8],"int64"), mode="wrap", )
paddle.tanh(Tensor([0, 1, 128],"float32"), )
paddle.tanh(Tensor([0, 1, 1792],"float32"), )
paddle.tanh(Tensor([0, 26, 512, 1, 40],"float16"), )
paddle.tanh(Tensor([0, 26, 512, 1, 40],"float32"), )
paddle.tanh(Tensor([0, 3, 256, 256],"float32"), )
paddle.tanh(Tensor([0, 3, 32, 32],"float32"), )
paddle.tanh(Tensor([0, 32],"float32"), )
paddle.tanh(Tensor([0, 32],"float64"), )
paddle.tanh(Tensor([0],"float32"), )
paddle.tanh(Tensor([0],"float64"), )
paddle.tanh(Tensor([1, 0, 128],"float32"), )
paddle.tanh(Tensor([1, 0, 1792],"float32"), )
paddle.tanh(Tensor([1, 0, 256, 256],"float32"), )
paddle.tanh(Tensor([1, 0, 32, 32],"float32"), )
paddle.tanh(Tensor([1, 0],"float32"), )
paddle.tanh(Tensor([1, 0],"float64"), )
paddle.tanh(Tensor([1, 1, 0],"float32"), )
paddle.tanh(Tensor([1, 3, 0, 256],"float32"), )
paddle.tanh(Tensor([1, 3, 0, 32],"float32"), )
paddle.tanh(Tensor([1, 3, 256, 0],"float32"), )
paddle.tanh(Tensor([1, 3, 32, 0],"float32"), )
paddle.tanh(Tensor([64, 0, 512, 1, 40],"float16"), )
paddle.tanh(Tensor([64, 0, 512, 1, 40],"float32"), )
paddle.tanh(Tensor([64, 26, 0, 1, 40],"float16"), )
paddle.tanh(Tensor([64, 26, 0, 1, 40],"float32"), )
paddle.tanh(Tensor([64, 26, 512, 0, 40],"float16"), )
paddle.tanh(Tensor([64, 26, 512, 0, 40],"float32"), )
paddle.tanh(Tensor([64, 26, 512, 1, 0],"float16"), )
paddle.tanh(Tensor([64, 26, 512, 1, 0],"float32"), )
paddle.tanh(x=Tensor([0, 3, 4],"float64"), )
paddle.tanh(x=Tensor([0, 5],"float64"), )
paddle.tanh(x=Tensor([0, 8, 8],"float32"), )
paddle.tanh(x=Tensor([0],"float64"), )
paddle.tanh(x=Tensor([2, 0, 4],"float64"), )
paddle.tanh(x=Tensor([2, 0, 8],"float32"), )
paddle.tanh(x=Tensor([2, 3, 0],"float64"), )
paddle.tanh(x=Tensor([2, 8, 0],"float32"), )
paddle.Tensor.__abs__(Tensor([0, 1024],"complex64"), )
paddle.Tensor.__abs__(Tensor([0, 1024],"float32"), )
paddle.Tensor.__abs__(Tensor([0],"float32"), )
paddle.Tensor.__abs__(Tensor([10, 0],"complex64"), )
paddle.Tensor.__abs__(Tensor([10, 0],"float32"), )
paddle.Tensor.__getitem__(Tensor([0, 3, 3],"float32"), tuple(slice(1,-1,None),slice(0,2,None),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([0, 3, 3],"float32"), tuple(slice(1,2,None),slice(2,None,None),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([0, 3, 3],"float32"), tuple(slice(None,-1,None),slice(None,None,-1),slice(-1,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 3, 3],"float32"), tuple(slice(None,None,-1),slice(None,None,-1),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 4, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([0, 5, 4, 3],"bool"), list[list[2,3,4,],list[1,2,5,],], )
paddle.Tensor.__getitem__(Tensor([0, 5, 4, 3],"bool"), list[list[2,-3,-4,],list[-1,2,5,],], )
paddle.Tensor.__getitem__(Tensor([0, 5, 4, 3],"complex128"), list[list[2,3,4,],list[1,2,5,],], )
paddle.Tensor.__getitem__(Tensor([0, 5, 4, 3],"complex128"), list[list[2,-3,-4,],list[-1,2,5,],], )
paddle.Tensor.__getitem__(Tensor([3, 0, 3],"float32"), slice(None,None,-1), )
paddle.Tensor.__getitem__(Tensor([3, 0, 3],"float32"), tuple(slice(1,-1,None),slice(0,2,None),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([3, 0, 3],"float32"), tuple(slice(1,2,None),slice(2,None,None),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([3, 0, 3],"float32"), tuple(slice(None,-1,None),slice(None,None,-1),slice(-1,None,None),), )
paddle.Tensor.__getitem__(Tensor([3, 0, 3],"float32"), tuple(slice(None,None,-1),slice(None,1,None),slice(None,-1,None),), )
paddle.Tensor.__getitem__(Tensor([3, 0, 3],"float32"), tuple(slice(None,None,-1),slice(None,None,-1),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([3, 3, 0],"float32"), slice(None,None,-1), )
paddle.Tensor.__getitem__(Tensor([3, 3, 0],"float32"), tuple(slice(1,-1,None),slice(0,2,None),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([3, 3, 0],"float32"), tuple(slice(1,2,None),slice(2,None,None),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([3, 3, 0],"float32"), tuple(slice(None,-1,None),slice(None,None,-1),slice(-1,None,None),), )
paddle.Tensor.__getitem__(Tensor([3, 3, 0],"float32"), tuple(slice(None,None,-1),slice(None,1,None),slice(None,-1,None),), )
paddle.Tensor.__getitem__(Tensor([3, 3, 0],"float32"), tuple(slice(None,None,-1),slice(None,None,-1),slice(None,None,-1),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 3, 2],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 0, 4],"int64"), slice(None,None,-2), )
paddle.Tensor.__getitem__(Tensor([5, 4, 0],"int64"), slice(None,None,-2), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(1,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-1,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(2,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(-2,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(3,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,0,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,1,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-2,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,-3,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-1),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-2),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([5, 4, 3, 0],"int64"), tuple(slice(None,None,None),slice(None,None,None),slice(None,None,-3),slice(None,None,None),), )
paddle.Tensor.__getitem__(Tensor([512, 0],"float32"), slice(None,None,-1), )
paddle.Tensor.__pow__(Tensor([0, 1024],"float32"), Tensor([0, 1024],"float32"), )
paddle.Tensor.__pow__(Tensor([0, 3, 2],"float16"), Tensor([0, 3, 2],"float32"), )
paddle.Tensor.__pow__(Tensor([0, 3, 2],"float16"), Tensor([0, 3, 2],"float64"), )
paddle.Tensor.__pow__(Tensor([0],"int64"), Tensor([0],"int64"), )
paddle.Tensor.__pow__(Tensor([10, 0],"float32"), Tensor([10, 0],"float32"), )
paddle.Tensor.__pow__(Tensor([4, 0, 2],"float16"), Tensor([4, 0, 2],"float32"), )
paddle.Tensor.__pow__(Tensor([4, 0, 2],"float16"), Tensor([4, 0, 2],"float64"), )
paddle.Tensor.__pow__(Tensor([4, 3, 0],"float16"), Tensor([4, 3, 0],"float32"), )
paddle.Tensor.__pow__(Tensor([4, 3, 0],"float16"), Tensor([4, 3, 0],"float64"), )
paddle.Tensor.__rpow__(Tensor([0, 12],"float32"), 2, )
paddle.Tensor.__rpow__(Tensor([0, 12],"float64"), 2, )
paddle.Tensor.__rpow__(Tensor([0, 16],"float32"), 10000.0, )
paddle.Tensor.__rpow__(Tensor([0, 2, 2],"float32"), 3, )
paddle.Tensor.__rpow__(Tensor([0, 2, 2],"float32"), 3.0, )
paddle.Tensor.__rpow__(Tensor([0, 2, 2],"int64"), 3, )
paddle.Tensor.__rpow__(Tensor([0, 2, 2],"int64"), 3.0, )
paddle.Tensor.__rpow__(Tensor([0, 5, 2],"float32"), 2, )
paddle.Tensor.__rpow__(Tensor([0, 5, 2],"float64"), 2, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 10000, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 10000.0, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 1000000.0, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 107177664400.00002, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 20, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 500000.0, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 550134.0076769129, )
paddle.Tensor.__rpow__(Tensor([0],"float32"), 63496.04207872797, )
paddle.Tensor.__rpow__(Tensor([0],"float64"), 2, )
paddle.Tensor.__rpow__(Tensor([1, 0],"float32"), 10000.0, )
paddle.Tensor.__rpow__(Tensor([10, 0],"float32"), 2, )
paddle.Tensor.__rpow__(Tensor([10, 0],"float64"), 2, )
paddle.Tensor.__rpow__(Tensor([2, 0, 2],"float32"), 3, )
paddle.Tensor.__rpow__(Tensor([2, 0, 2],"float32"), 3.0, )
paddle.Tensor.__rpow__(Tensor([2, 0, 2],"int64"), 3, )
paddle.Tensor.__rpow__(Tensor([2, 0, 2],"int64"), 3.0, )
paddle.Tensor.__rpow__(Tensor([2, 2, 0],"float32"), 3, )
paddle.Tensor.__rpow__(Tensor([2, 2, 0],"float32"), 3.0, )
paddle.Tensor.__rpow__(Tensor([2, 2, 0],"int64"), 3, )
paddle.Tensor.__rpow__(Tensor([2, 2, 0],"int64"), 3.0, )
paddle.Tensor.__rpow__(Tensor([4, 0, 2],"float32"), 2, )
paddle.Tensor.__rpow__(Tensor([4, 0, 2],"float64"), 2, )
paddle.Tensor.__rpow__(Tensor([4, 5, 0],"float32"), 2, )
paddle.Tensor.__rpow__(Tensor([4, 5, 0],"float64"), 2, )
paddle.Tensor.__setitem__(Tensor([0, 5, 4, 3],"bool"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__setitem__(Tensor([0, 5, 4, 3],"complex128"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__setitem__(Tensor([6, 0, 4, 3],"bool"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__setitem__(Tensor([6, 0, 4, 3],"complex128"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__setitem__(Tensor([6, 5, 0, 3],"bool"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__setitem__(Tensor([6, 5, 0, 3],"complex128"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__setitem__(Tensor([6, 5, 4, 0],"bool"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__setitem__(Tensor([6, 5, 4, 0],"complex128"), list[list[2,3,4,],list[1,2,5,],], 100, )
paddle.Tensor.__sub__(Tensor([0, 1, 10285],"float32"), Tensor([0, 1, 10285],"float32"), )
paddle.Tensor.__sub__(Tensor([0, 1001],"float32"), Tensor([0, 1001],"float32"), )
paddle.Tensor.__sub__(Tensor([0, 1002],"float32"), Tensor([0, 1002],"float32"), )
paddle.Tensor.__sub__(Tensor([0, 3, 10, 10, 1],"float32"), Tensor([0, 3, 10, 10, 1],"float32"), )
paddle.Tensor.__sub__(Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([1, 0, 10285],"float32"), Tensor([1, 0, 10285],"float32"), )
paddle.Tensor.__sub__(Tensor([1, 0],"float32"), Tensor([1, 0],"float32"), )
paddle.Tensor.__sub__(Tensor([1, 1, 0, 1],"float32"), Tensor([1, 1, 0, 1],"float32"), )
paddle.Tensor.__sub__(Tensor([1, 1, 0],"float32"), Tensor([1, 1, 0],"float32"), )
paddle.Tensor.__sub__(Tensor([12, 0, 10, 10, 1],"float32"), Tensor([12, 0, 10, 10, 1],"float32"), )
paddle.Tensor.__sub__(Tensor([12, 3, 0, 10, 1],"float32"), Tensor([12, 3, 0, 10, 1],"float32"), )
paddle.Tensor.__sub__(Tensor([12, 3, 10, 0, 1],"float32"), Tensor([12, 3, 10, 0, 1],"float32"), )
paddle.Tensor.__sub__(Tensor([12, 3, 10, 10, 0],"float32"), Tensor([12, 3, 10, 10, 0],"float32"), )
paddle.Tensor.__sub__(Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), )
paddle.Tensor.__sub__(Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), )
paddle.Tensor.abs(Tensor([0, 1, 192],"float32"), )
paddle.Tensor.abs(Tensor([0, 10, 25, 2],"float32"), )
paddle.Tensor.abs(Tensor([0, 12],"float64"), )
paddle.Tensor.abs(Tensor([0, 2],"float32"), )
paddle.Tensor.abs(Tensor([0, 257, 192],"float32"), )
paddle.Tensor.abs(Tensor([0, 65536, 25, 2],"float32"), )
paddle.Tensor.abs(Tensor([0],"float32"), )
paddle.Tensor.abs(Tensor([0],"float64"), )
paddle.Tensor.abs(Tensor([1, 0, 192],"float32"), )
paddle.Tensor.abs(Tensor([1, 0, 25, 2],"float32"), )
paddle.Tensor.abs(Tensor([1, 0],"float32"), )
paddle.Tensor.abs(Tensor([1, 0],"float64"), )
paddle.Tensor.abs(Tensor([1, 1, 0],"float32"), )
paddle.Tensor.abs(Tensor([1, 257, 0],"float32"), )
paddle.Tensor.abs(Tensor([1, 65536, 0, 2],"float32"), )
paddle.Tensor.abs(Tensor([1, 65536, 25, 0],"float32"), )
paddle.Tensor.abs(Tensor([16, 0, 25, 2],"float32"), )
paddle.Tensor.abs(Tensor([16, 10, 0, 2],"float32"), )
paddle.Tensor.abs(Tensor([16, 10, 25, 0],"float32"), )
paddle.Tensor.atanh(Tensor([0, 2, 3],"float32"), )
paddle.Tensor.atanh(Tensor([0, 2, 3],"float64"), )
paddle.Tensor.atanh(Tensor([0, 3],"float32"), )
paddle.Tensor.atanh(Tensor([0, 3],"float64"), )
paddle.Tensor.atanh(Tensor([0],"float32"), )
paddle.Tensor.atanh(Tensor([0],"float64"), )
paddle.Tensor.atanh(Tensor([1, 0, 3],"float32"), )
paddle.Tensor.atanh(Tensor([1, 0, 3],"float64"), )
paddle.Tensor.atanh(Tensor([1, 2, 0],"float32"), )
paddle.Tensor.atanh(Tensor([1, 2, 0],"float64"), )
paddle.Tensor.atanh(Tensor([2, 0],"float32"), )
paddle.Tensor.atanh(Tensor([2, 0],"float64"), )
paddle.Tensor.ceil(Tensor([0, 2],"float32"), )
paddle.Tensor.ceil(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.ceil(Tensor([0, 20],"float32"), )
paddle.Tensor.ceil(Tensor([1, 0],"float32"), )
paddle.Tensor.ceil(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.ceil(Tensor([10, 0],"float32"), )
paddle.Tensor.ceil(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.cos(Tensor([0, 10, 8, 64],"float32"), )
paddle.Tensor.cos(Tensor([0, 11, 4, 64],"float32"), )
paddle.Tensor.cos(Tensor([0, 1100, 64],"float32"), )
paddle.Tensor.cos(Tensor([0, 18, 64],"float32"), )
paddle.Tensor.cos(Tensor([0, 256],"float32"), )
paddle.Tensor.cos(Tensor([0, 4],"float32"), )
paddle.Tensor.cos(Tensor([0],"float32"), )
paddle.Tensor.cos(Tensor([1, 0, 4, 64],"float32"), )
paddle.Tensor.cos(Tensor([1, 0, 64],"float32"), )
paddle.Tensor.cos(Tensor([1, 0, 8, 64],"float32"), )
paddle.Tensor.cos(Tensor([1, 10, 0, 64],"float32"), )
paddle.Tensor.cos(Tensor([1, 10, 8, 0],"float32"), )
paddle.Tensor.cos(Tensor([1, 11, 0, 64],"float32"), )
paddle.Tensor.cos(Tensor([1, 11, 4, 0],"float32"), )
paddle.Tensor.cos(Tensor([1, 1100, 0],"float32"), )
paddle.Tensor.cos(Tensor([1, 18, 0],"float32"), )
paddle.Tensor.cos(Tensor([10, 0],"float32"), )
paddle.Tensor.digamma(Tensor([0, 3],"float32"), )
paddle.Tensor.digamma(Tensor([0, 5],"float64"), )
paddle.Tensor.digamma(Tensor([0, 7, 8, 10],"float64"), )
paddle.Tensor.digamma(Tensor([0, 7, 8],"float64"), )
paddle.Tensor.digamma(Tensor([0],"float32"), )
paddle.Tensor.digamma(Tensor([2, 0],"float32"), )
paddle.Tensor.digamma(Tensor([4, 0],"float64"), )
paddle.Tensor.digamma(Tensor([5, 0, 8, 10],"float64"), )
paddle.Tensor.digamma(Tensor([5, 0, 8],"float64"), )
paddle.Tensor.digamma(Tensor([5, 7, 0, 10],"float64"), )
paddle.Tensor.digamma(Tensor([5, 7, 0],"float64"), )
paddle.Tensor.digamma(Tensor([5, 7, 8, 0],"float64"), )
paddle.Tensor.erfinv(x=Tensor([0, 2, 3, 5, 4],"float64"), )
paddle.Tensor.erfinv(x=Tensor([0, 2, 3, 5],"float64"), )
paddle.Tensor.erfinv(x=Tensor([0, 2, 3],"float64"), )
paddle.Tensor.erfinv(x=Tensor([0, 2],"float64"), )
paddle.Tensor.erfinv(x=Tensor([0],"float32"), )
paddle.Tensor.erfinv(x=Tensor([0],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 0, 3, 5, 4],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 0, 3, 5],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 0, 3],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 0],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 2, 0, 5, 4],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 2, 0, 5],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 2, 0],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 0, 4],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 0],"float64"), )
paddle.Tensor.erfinv(x=Tensor([4, 2, 3, 5, 0],"float64"), )
paddle.Tensor.exp(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.exp(Tensor([0, 20],"float32"), )
paddle.Tensor.exp(Tensor([0, 3, 2],"float64"), )
paddle.Tensor.exp(Tensor([0, 4],"float64"), )
paddle.Tensor.exp(Tensor([0],"float32"), )
paddle.Tensor.exp(Tensor([0],"float32"), name="Cauchy_prob", )
paddle.Tensor.exp(Tensor([0],"float64"), )
paddle.Tensor.exp(Tensor([0],"float64"), name="Cauchy_prob", )
paddle.Tensor.exp(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.exp(Tensor([10, 0],"float32"), )
paddle.Tensor.exp(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.exp(Tensor([1000000, 0],"float64"), )
paddle.Tensor.exp(Tensor([2, 0, 2],"float64"), )
paddle.Tensor.exp(Tensor([2, 3, 0],"float64"), )
paddle.Tensor.fill_diagonal_(Tensor([0, 2, 2],"float32"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([0, 2, 2],"float64"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3, 3],"float32"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3, 3],"float64"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"bool"), 0, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float32"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float32"), 1, offset=0, wrap=False, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float32"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float32"), 1, offset=2, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float32"), 4, 0, True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float32"), 4, 1, False, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float64"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float64"), 1, offset=0, wrap=False, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float64"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float64"), 1, offset=2, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float64"), 4, 0, True, )
paddle.Tensor.fill_diagonal_(Tensor([0, 3],"float64"), 4, 1, False, )
paddle.Tensor.fill_diagonal_(Tensor([2, 0, 2],"float32"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([2, 0, 2],"float64"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([2, 2, 0],"float32"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([2, 2, 0],"float64"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0, 3],"float32"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0, 3],"float64"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"bool"), 0, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float32"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float32"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float32"), 1, offset=2, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float32"), 4, 1, False, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float64"), 1, 0, False, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float64"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float64"), 1, offset=2, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 0],"float64"), 4, 1, False, )
paddle.Tensor.fill_diagonal_(Tensor([3, 3, 0],"float32"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([3, 3, 0],"float64"), 1, offset=0, wrap=True, )
paddle.Tensor.fill_diagonal_(Tensor([7, 0],"float32"), 1, offset=0, wrap=False, )
paddle.Tensor.fill_diagonal_(Tensor([7, 0],"float32"), 4, 0, True, )
paddle.Tensor.fill_diagonal_(Tensor([7, 0],"float64"), 1, offset=0, wrap=False, )
paddle.Tensor.fill_diagonal_(Tensor([7, 0],"float64"), 4, 0, True, )
paddle.Tensor.flip(Tensor([0, 2, 64, 64],"float32"), 1, )
paddle.Tensor.flip(Tensor([0, 2],"float32"), 1, )
paddle.Tensor.flip(Tensor([0, 3, 224, 224],"float32"), 0, )
paddle.Tensor.flip(Tensor([0, 3],"float32"), 0, )
paddle.Tensor.flip(Tensor([0],"int64"), 0, )
paddle.Tensor.flip(Tensor([16, 0, 224, 224],"float32"), 0, )
paddle.Tensor.flip(Tensor([16, 3, 0, 224],"float32"), 0, )
paddle.Tensor.flip(Tensor([16, 3, 224, 0],"float32"), 0, )
paddle.Tensor.flip(Tensor([2, 0],"float32"), 0, )
paddle.Tensor.flip(Tensor([2, 0],"float32"), 1, )
paddle.Tensor.flip(Tensor([4, 0, 64, 64],"float32"), 1, )
paddle.Tensor.flip(Tensor([4, 0],"float32"), 1, )
paddle.Tensor.flip(Tensor([4, 2, 0, 64],"float32"), 1, )
paddle.Tensor.flip(Tensor([4, 2, 64, 0],"float32"), 1, )
paddle.Tensor.floor(Tensor([0, 2],"float32"), )
paddle.Tensor.floor(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.floor(Tensor([0, 4],"float32"), )
paddle.Tensor.floor(Tensor([0, 8, 8],"float32"), )
paddle.Tensor.floor(Tensor([1, 0],"float32"), )
paddle.Tensor.floor(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.floor(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.floor(Tensor([2, 0, 8],"float32"), )
paddle.Tensor.floor(Tensor([2, 8, 0],"float32"), )
paddle.Tensor.frexp(Tensor([0, 12],"float32"), )
paddle.Tensor.frexp(Tensor([0, 12],"float64"), )
paddle.Tensor.frexp(Tensor([0, 5, 2],"float32"), )
paddle.Tensor.frexp(Tensor([0, 5, 2],"float64"), )
paddle.Tensor.frexp(Tensor([10, 0],"float32"), )
paddle.Tensor.frexp(Tensor([10, 0],"float64"), )
paddle.Tensor.frexp(Tensor([4, 0, 2],"float32"), )
paddle.Tensor.frexp(Tensor([4, 0, 2],"float64"), )
paddle.Tensor.frexp(Tensor([4, 5, 0],"float32"), )
paddle.Tensor.frexp(Tensor([4, 5, 0],"float64"), )
paddle.Tensor.imag(Tensor([0, 1025, 107],"complex64"), )
paddle.Tensor.imag(Tensor([0, 20, 2, 3],"complex128"), )
paddle.Tensor.imag(Tensor([0, 20, 2, 3],"complex64"), )
paddle.Tensor.imag(Tensor([0, 257, 511],"complex64"), )
paddle.Tensor.imag(Tensor([0, 4],"complex128"), )
paddle.Tensor.imag(Tensor([0, 784],"complex64"), )
paddle.Tensor.imag(Tensor([0],"complex128"), )
paddle.Tensor.imag(Tensor([1000, 0],"complex64"), )
paddle.Tensor.imag(Tensor([100000, 0],"complex128"), )
paddle.Tensor.imag(Tensor([16, 0, 107],"complex64"), )
paddle.Tensor.imag(Tensor([16, 0, 511],"complex64"), )
paddle.Tensor.imag(Tensor([16, 1025, 0],"complex64"), )
paddle.Tensor.imag(Tensor([16, 257, 0],"complex64"), )
paddle.Tensor.imag(Tensor([2, 0, 2, 3],"complex128"), )
paddle.Tensor.imag(Tensor([2, 0, 2, 3],"complex64"), )
paddle.Tensor.imag(Tensor([2, 20, 0, 3],"complex128"), )
paddle.Tensor.imag(Tensor([2, 20, 0, 3],"complex64"), )
paddle.Tensor.imag(Tensor([2, 20, 2, 0],"complex128"), )
paddle.Tensor.imag(Tensor([2, 20, 2, 0],"complex64"), )
paddle.Tensor.isnan(Tensor([0, 3, 3],"float32"), )
paddle.Tensor.isnan(Tensor([0, 3, 4],"float64"), )
paddle.Tensor.isnan(Tensor([0, 3],"float32"), )
paddle.Tensor.isnan(Tensor([0, 3],"float64"), )
paddle.Tensor.isnan(Tensor([0, 6, 3, 4, 2, 5],"float64"), )
paddle.Tensor.isnan(Tensor([0],"float32"), )
paddle.Tensor.isnan(Tensor([2, 0, 4],"float64"), )
paddle.Tensor.isnan(Tensor([2, 0],"float32"), )
paddle.Tensor.isnan(Tensor([2, 0],"float64"), )
paddle.Tensor.isnan(Tensor([2, 3, 0],"float64"), )
paddle.Tensor.isnan(Tensor([3, 0, 3, 4, 2, 5],"float64"), )
paddle.Tensor.isnan(Tensor([3, 0, 3],"float32"), )
paddle.Tensor.isnan(Tensor([3, 3, 0],"float32"), )
paddle.Tensor.isnan(Tensor([3, 6, 0, 4, 2, 5],"float64"), )
paddle.Tensor.isnan(Tensor([3, 6, 3, 0, 2, 5],"float64"), )
paddle.Tensor.isnan(Tensor([3, 6, 3, 4, 0, 5],"float64"), )
paddle.Tensor.isnan(Tensor([3, 6, 3, 4, 2, 0],"float64"), )
paddle.Tensor.lgamma(Tensor([0, 100, 100],"float64"), )
paddle.Tensor.lgamma(Tensor([0, 3],"float32"), )
paddle.Tensor.lgamma(Tensor([0, 5],"float64"), )
paddle.Tensor.lgamma(Tensor([0, 7, 8, 10],"float64"), )
paddle.Tensor.lgamma(Tensor([0, 7, 8],"float64"), )
paddle.Tensor.lgamma(Tensor([0],"float32"), )
paddle.Tensor.lgamma(Tensor([100, 0, 100],"float64"), )
paddle.Tensor.lgamma(Tensor([100, 100, 0],"float64"), )
paddle.Tensor.lgamma(Tensor([2, 0],"float32"), )
paddle.Tensor.lgamma(Tensor([4, 0],"float64"), )
paddle.Tensor.lgamma(Tensor([5, 0, 8, 10],"float64"), )
paddle.Tensor.lgamma(Tensor([5, 0, 8],"float64"), )
paddle.Tensor.lgamma(Tensor([5, 7, 0, 10],"float64"), )
paddle.Tensor.lgamma(Tensor([5, 7, 0],"float64"), )
paddle.Tensor.lgamma(Tensor([5, 7, 8, 0],"float64"), )
paddle.Tensor.log(Tensor([0, 1],"float32"), )
paddle.Tensor.log(Tensor([0, 2],"float32"), )
paddle.Tensor.log(Tensor([0, 200, 100],"float64"), )
paddle.Tensor.log(Tensor([0, 5, 3],"float64"), )
paddle.Tensor.log(Tensor([0],"float32"), )
paddle.Tensor.log(Tensor([0],"float64"), )
paddle.Tensor.log(Tensor([1, 0],"float32"), )
paddle.Tensor.log(Tensor([10, 0],"float32"), )
paddle.Tensor.log(Tensor([100, 0, 100],"float64"), )
paddle.Tensor.log(Tensor([100, 200, 0],"float64"), )
paddle.Tensor.log(Tensor([10000, 0, 3],"float64"), )
paddle.Tensor.log(Tensor([10000, 5, 0],"float64"), )
paddle.Tensor.log10(Tensor([0, 499],"float32"), )
paddle.Tensor.log10(Tensor([80, 0],"float32"), )
paddle.Tensor.log1p(Tensor([0, 3, 2],"float64"), )
paddle.Tensor.log1p(Tensor([0, 3],"float32"), )
paddle.Tensor.log1p(Tensor([0, 3],"float64"), )
paddle.Tensor.log1p(Tensor([0],"float32"), )
paddle.Tensor.log1p(Tensor([0],"float64"), )
paddle.Tensor.log1p(Tensor([2, 0, 2],"float64"), )
paddle.Tensor.log1p(Tensor([2, 0],"float32"), )
paddle.Tensor.log1p(Tensor([2, 0],"float64"), )
paddle.Tensor.log1p(Tensor([2, 3, 0],"float64"), )
paddle.Tensor.nonzero(Tensor([0, 10],"bool"), )
paddle.Tensor.nonzero(Tensor([0, 11],"bool"), )
paddle.Tensor.nonzero(Tensor([0],"bool"), )
paddle.Tensor.nonzero(Tensor([52640, 0],"bool"), )
paddle.Tensor.quantile(Tensor([0, 6, 3, 4, 2, 5],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([0, 6, 3, 4, 2, 5],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 0, 3, 4, 2, 5],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 0, 3, 4, 2, 5],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 0, 4, 2, 5],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 0, 4, 2, 5],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 3, 0, 2, 5],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 0, 5],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 0],"float64"), q=list[0.25,0.5,0.75,], axis=3, keepdim=False, )
paddle.Tensor.quantile(Tensor([3, 6, 3, 4, 2, 0],"float64"), q=tuple(0.11,0.5,0.73,0.9,), axis=4, keepdim=False, )
paddle.Tensor.reciprocal(Tensor([0, 12],"float32"), )
paddle.Tensor.reciprocal(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.reciprocal(Tensor([0, 20],"float32"), )
paddle.Tensor.reciprocal(Tensor([0],"float32"), )
paddle.Tensor.reciprocal(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.reciprocal(Tensor([10, 0],"float32"), )
paddle.Tensor.reciprocal(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.round(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.round(Tensor([0, 20],"float32"), )
paddle.Tensor.round(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.round(Tensor([10, 0],"float32"), )
paddle.Tensor.round(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.rsqrt(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.rsqrt(Tensor([0, 20],"float32"), )
paddle.Tensor.rsqrt(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.rsqrt(Tensor([10, 0],"float32"), )
paddle.Tensor.rsqrt(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.sigmoid(Tensor([0, 11, 4],"float32"), )
paddle.Tensor.sigmoid(Tensor([0, 1100, 4],"float32"), )
paddle.Tensor.sigmoid(Tensor([1, 0, 4],"float32"), )
paddle.Tensor.sigmoid(Tensor([1, 11, 0],"float32"), )
paddle.Tensor.sigmoid(Tensor([1, 1100, 0],"float32"), )
paddle.Tensor.sin(Tensor([0, 10, 8, 64],"float32"), )
paddle.Tensor.sin(Tensor([0, 11, 4, 64],"float32"), )
paddle.Tensor.sin(Tensor([0, 1100, 64],"float32"), )
paddle.Tensor.sin(Tensor([0, 18, 64],"float32"), )
paddle.Tensor.sin(Tensor([0, 256],"float32"), )
paddle.Tensor.sin(Tensor([0, 4],"float32"), )
paddle.Tensor.sin(Tensor([0],"float32"), )
paddle.Tensor.sin(Tensor([1, 0, 4, 64],"float32"), )
paddle.Tensor.sin(Tensor([1, 0, 64],"float32"), )
paddle.Tensor.sin(Tensor([1, 0, 8, 64],"float32"), )
paddle.Tensor.sin(Tensor([1, 10, 0, 64],"float32"), )
paddle.Tensor.sin(Tensor([1, 10, 8, 0],"float32"), )
paddle.Tensor.sin(Tensor([1, 11, 0, 64],"float32"), )
paddle.Tensor.sin(Tensor([1, 11, 4, 0],"float32"), )
paddle.Tensor.sin(Tensor([1, 1100, 0],"float32"), )
paddle.Tensor.sin(Tensor([1, 18, 0],"float32"), )
paddle.Tensor.sin(Tensor([10, 0],"float32"), )
paddle.Tensor.split(Tensor([0, 1, 64],"float32"), list[32,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([0, 1, 96],"float32"), list[64,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([0, 1],"float32"), list[1,], -1, )
paddle.Tensor.split(Tensor([0, 101],"float32"), list[1,2,2,5,8,22,5,5,18,3,9,4,1,2,11,3,], -1, )
paddle.Tensor.split(Tensor([0, 10164, 8, 32],"float32"), list[7744,1936,484,], axis=1, )
paddle.Tensor.split(Tensor([0, 1100, 4],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([0, 11109, 8, 32],"float32"), list[8464,2116,529,], axis=1, )
paddle.Tensor.split(Tensor([0, 11645, 8, 32],"float16"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([0, 11645, 8, 32],"float32"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([0, 12096, 8, 32],"float32"), list[9216,2304,576,], axis=1, )
paddle.Tensor.split(Tensor([0, 13, 2],"float32"), 2, axis=-1, )
paddle.Tensor.split(Tensor([0, 16],"float32"), list[12,4,], -1, )
paddle.Tensor.split(Tensor([0, 17, 3072],"float32"), 17, 1, )
paddle.Tensor.split(Tensor([0, 17, 768],"float32"), 17, 1, )
paddle.Tensor.split(Tensor([0, 18, 4],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([0, 192, 4],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([0, 196, 4],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([0, 2, 1024],"float16"), list[512,256,256,], axis=-1, )
paddle.Tensor.split(Tensor([0, 2, 16],"float32"), list[8,4,4,], axis=-1, )
paddle.Tensor.split(Tensor([0, 2],"float32"), list[1,1,], -1, )
paddle.Tensor.split(Tensor([0, 25, 4, 2],"float32"), 4, axis=2, )
paddle.Tensor.split(Tensor([0, 32, 2],"float32"), 2, axis=-1, )
paddle.Tensor.split(Tensor([0, 36828, 8, 32],"float32"), list[27648,6912,1728,432,108,], axis=1, )
paddle.Tensor.split(Tensor([0, 38367, 8, 32],"float32"), list[28800,7200,1800,450,117,], axis=1, )
paddle.Tensor.split(Tensor([0, 4, 1024],"float16"), list[512,256,256,], axis=-1, )
paddle.Tensor.split(Tensor([0, 4, 16],"float32"), list[8,4,4,], axis=-1, )
paddle.Tensor.split(Tensor([0, 4],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([0, 4],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([0, 4],"float32"), list[1,1,1,1,], -1, )
paddle.Tensor.split(Tensor([0, 4],"float32"), list[1,3,], -1, )
paddle.Tensor.split(Tensor([0, 4],"float32"), list[2,2,], -1, )
paddle.Tensor.split(Tensor([0, 4725, 8, 32],"float32"), list[3600,900,225,], axis=1, )
paddle.Tensor.split(Tensor([0, 5],"float32"), list[5,], -1, )
paddle.Tensor.split(Tensor([0, 5376, 8, 32],"float32"), list[4096,1024,256,], axis=1, )
paddle.Tensor.split(Tensor([0, 6069, 8, 32],"float32"), list[4624,1156,289,], axis=1, )
paddle.Tensor.split(Tensor([0, 6380, 8, 32],"float32"), list[4800,1200,300,80,], axis=1, )
paddle.Tensor.split(Tensor([0, 6804, 8, 32],"float32"), list[5184,1296,324,], axis=1, )
paddle.Tensor.split(Tensor([0, 7],"float32"), list[7,], -1, )
paddle.Tensor.split(Tensor([0, 8],"float32"), list[1,1,1,1,1,1,1,1,], -1, )
paddle.Tensor.split(Tensor([0, 8],"float32"), list[8,], -1, )
paddle.Tensor.split(Tensor([0, 8400, 8, 32],"float32"), list[6400,1600,400,], axis=1, )
paddle.Tensor.split(Tensor([0, 8550, 8, 32],"float32"), list[6408,1620,414,108,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 1024],"float16"), list[512,256,256,], axis=-1, )
paddle.Tensor.split(Tensor([1, 0, 16],"float32"), list[8,4,4,], axis=-1, )
paddle.Tensor.split(Tensor([1, 0, 4, 2],"float32"), 4, axis=2, )
paddle.Tensor.split(Tensor([1, 0, 4],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([1, 0, 4],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([1, 0, 64],"float32"), list[32,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[27648,6912,1728,432,108,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[28800,7200,1800,450,117,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[4800,1200,300,80,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[5184,1296,324,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[6400,1600,400,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[6408,1620,414,108,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[7744,1936,484,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[8464,2116,529,], axis=1, )
paddle.Tensor.split(Tensor([1, 0, 8, 32],"float32"), list[9216,2304,576,], axis=1, )
paddle.Tensor.split(Tensor([1, 0],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([1, 0],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([1, 1, 0],"float32"), list[32,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([1, 10164, 0, 32],"float32"), list[7744,1936,484,], axis=1, )
paddle.Tensor.split(Tensor([1, 10164, 8, 0],"float32"), list[7744,1936,484,], axis=1, )
paddle.Tensor.split(Tensor([1, 1100, 0],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([1, 11109, 0, 32],"float32"), list[8464,2116,529,], axis=1, )
paddle.Tensor.split(Tensor([1, 11109, 8, 0],"float32"), list[8464,2116,529,], axis=1, )
paddle.Tensor.split(Tensor([1, 12096, 0, 32],"float32"), list[9216,2304,576,], axis=1, )
paddle.Tensor.split(Tensor([1, 12096, 8, 0],"float32"), list[9216,2304,576,], axis=1, )
paddle.Tensor.split(Tensor([1, 18, 0],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([1, 192, 0],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([1, 196, 0],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([1, 2, 0],"float16"), list[512,256,256,], axis=-1, )
paddle.Tensor.split(Tensor([1, 2, 0],"float32"), list[8,4,4,], axis=-1, )
paddle.Tensor.split(Tensor([1, 25, 0, 2],"float32"), 4, axis=2, )
paddle.Tensor.split(Tensor([1, 25, 4, 0],"float32"), 4, axis=2, )
paddle.Tensor.split(Tensor([1, 36828, 0, 32],"float32"), list[27648,6912,1728,432,108,], axis=1, )
paddle.Tensor.split(Tensor([1, 36828, 8, 0],"float32"), list[27648,6912,1728,432,108,], axis=1, )
paddle.Tensor.split(Tensor([1, 38367, 0, 32],"float32"), list[28800,7200,1800,450,117,], axis=1, )
paddle.Tensor.split(Tensor([1, 38367, 8, 0],"float32"), list[28800,7200,1800,450,117,], axis=1, )
paddle.Tensor.split(Tensor([1, 4, 0],"float32"), list[8,4,4,], axis=-1, )
paddle.Tensor.split(Tensor([1, 6380, 0, 32],"float32"), list[4800,1200,300,80,], axis=1, )
paddle.Tensor.split(Tensor([1, 6380, 8, 0],"float32"), list[4800,1200,300,80,], axis=1, )
paddle.Tensor.split(Tensor([1, 6804, 0, 32],"float32"), list[5184,1296,324,], axis=1, )
paddle.Tensor.split(Tensor([1, 6804, 8, 0],"float32"), list[5184,1296,324,], axis=1, )
paddle.Tensor.split(Tensor([1, 8400, 0, 32],"float32"), list[6400,1600,400,], axis=1, )
paddle.Tensor.split(Tensor([1, 8400, 8, 0],"float32"), list[6400,1600,400,], axis=1, )
paddle.Tensor.split(Tensor([1, 8550, 0, 32],"float32"), list[6408,1620,414,108,], axis=1, )
paddle.Tensor.split(Tensor([1, 8550, 8, 0],"float32"), list[6408,1620,414,108,], axis=1, )
paddle.Tensor.split(Tensor([100, 0],"float32"), 4, -1, )
paddle.Tensor.split(Tensor([100, 0],"float32"), list[1,1,1,1,], -1, )
paddle.Tensor.split(Tensor([101, 0],"float32"), 4, axis=-1, )
paddle.Tensor.split(Tensor([13, 0, 2],"float32"), 2, axis=-1, )
paddle.Tensor.split(Tensor([13, 13, 0],"float32"), 2, axis=-1, )
paddle.Tensor.split(Tensor([13, 32, 0],"float32"), 2, axis=-1, )
paddle.Tensor.split(Tensor([134, 0, 1024],"float16"), list[512,256,256,], axis=-1, )
paddle.Tensor.split(Tensor([134, 4, 0],"float16"), list[512,256,256,], axis=-1, )
paddle.Tensor.split(Tensor([16, 0, 3072],"float32"), 17, 1, )
paddle.Tensor.split(Tensor([16, 0, 768],"float32"), 17, 1, )
paddle.Tensor.split(Tensor([16, 0, 8, 32],"float32"), list[6400,1600,400,], axis=1, )
paddle.Tensor.split(Tensor([16, 17, 0],"float32"), 17, 1, )
paddle.Tensor.split(Tensor([16, 8400, 0, 32],"float32"), list[6400,1600,400,], axis=1, )
paddle.Tensor.split(Tensor([16, 8400, 8, 0],"float32"), list[6400,1600,400,], axis=1, )
paddle.Tensor.split(Tensor([2, 0, 8, 32],"float16"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([2, 0, 8, 32],"float32"), list[3600,900,225,], axis=1, )
paddle.Tensor.split(Tensor([2, 0, 8, 32],"float32"), list[4624,1156,289,], axis=1, )
paddle.Tensor.split(Tensor([2, 0, 8, 32],"float32"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([2, 11645, 0, 32],"float16"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([2, 11645, 0, 32],"float32"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([2, 11645, 8, 0],"float16"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([2, 11645, 8, 0],"float32"), list[8740,2204,551,150,], axis=1, )
paddle.Tensor.split(Tensor([2, 4725, 0, 32],"float32"), list[3600,900,225,], axis=1, )
paddle.Tensor.split(Tensor([2, 4725, 8, 0],"float32"), list[3600,900,225,], axis=1, )
paddle.Tensor.split(Tensor([2, 6069, 0, 32],"float32"), list[4624,1156,289,], axis=1, )
paddle.Tensor.split(Tensor([2, 6069, 8, 0],"float32"), list[4624,1156,289,], axis=1, )
paddle.Tensor.split(Tensor([20, 0, 64],"float32"), list[32,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([20, 1, 0],"float32"), list[32,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[1,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[1,1,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[1,1,1,1,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[1,1,1,1,1,1,1,1,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[1,2,2,5,8,22,5,5,18,3,9,4,1,2,11,3,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[1,3,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[12,4,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[2,2,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[5,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[7,], -1, )
paddle.Tensor.split(Tensor([300, 0],"float32"), list[8,], -1, )
paddle.Tensor.split(Tensor([4, 0, 8, 32],"float32"), list[4096,1024,256,], axis=1, )
paddle.Tensor.split(Tensor([4, 5376, 0, 32],"float32"), list[4096,1024,256,], axis=1, )
paddle.Tensor.split(Tensor([4, 5376, 8, 0],"float32"), list[4096,1024,256,], axis=1, )
paddle.Tensor.split(Tensor([58, 0, 96],"float32"), list[64,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([58, 1, 0],"float32"), list[64,16,16,], axis=-1, )
paddle.Tensor.split(Tensor([8, 0, 8, 32],"float32"), list[4624,1156,289,], axis=1, )
paddle.Tensor.split(Tensor([8, 6069, 0, 32],"float32"), list[4624,1156,289,], axis=1, )
paddle.Tensor.split(Tensor([8, 6069, 8, 0],"float32"), list[4624,1156,289,], axis=1, )
paddle.Tensor.split(Tensor([900, 0],"float32"), list[2,2,], -1, )
paddle.Tensor.sqrt(Tensor([0, 1, 2],"float32"), )
paddle.Tensor.sqrt(Tensor([0, 10],"float32"), )
paddle.Tensor.sqrt(Tensor([0, 11, 10, 10],"float32"), )
paddle.Tensor.sqrt(Tensor([0, 11, 11, 11],"float32"), )
paddle.Tensor.sqrt(Tensor([0, 2],"float32"), )
paddle.Tensor.sqrt(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.sqrt(Tensor([0],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 0, 10, 10],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 0, 11, 11],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 0, 2],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 0],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 1, 0],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 11, 0, 10],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 11, 0, 11],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 11, 10, 0],"float32"), )
paddle.Tensor.sqrt(Tensor([1, 11, 11, 0],"float32"), )
paddle.Tensor.sqrt(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.sqrt(Tensor([10, 0],"float32"), )
paddle.Tensor.sqrt(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.square(Tensor([0, 128],"float32"), )
paddle.Tensor.square(Tensor([0, 20, 1],"float32"), )
paddle.Tensor.square(Tensor([0],"float32"), )
paddle.Tensor.square(Tensor([10, 0, 1],"float32"), )
paddle.Tensor.square(Tensor([10, 20, 0],"float32"), )
paddle.Tensor.square(Tensor([2, 0],"float32"), )
paddle.Tensor.square(Tensor([8, 0],"float32"), )
paddle.Tensor.subtract(Tensor([0, 3, 4],"float32"), Tensor([0, 3, 4],"float32"), )
paddle.Tensor.subtract(Tensor([0],"float32"), Tensor([0],"float32"), )
paddle.Tensor.subtract(Tensor([2, 0, 4],"float32"), Tensor([2, 0, 4],"float32"), )
paddle.Tensor.subtract(Tensor([2, 3, 0],"float32"), Tensor([2, 3, 0],"float32"), )
paddle.Tensor.tanh(Tensor([0, 2, 3],"float32"), )
paddle.Tensor.tanh(Tensor([0, 2, 3],"float64"), )
paddle.Tensor.tanh(Tensor([0, 2],"float32"), )
paddle.Tensor.tanh(Tensor([0, 3],"float32"), )
paddle.Tensor.tanh(Tensor([0],"float32"), )
paddle.Tensor.tanh(Tensor([0],"float64"), )
paddle.Tensor.tanh(Tensor([1, 0, 3],"float32"), )
paddle.Tensor.tanh(Tensor([1, 0, 3],"float64"), )
paddle.Tensor.tanh(Tensor([1, 2, 0],"float32"), )
paddle.Tensor.tanh(Tensor([1, 2, 0],"float64"), )
paddle.Tensor.tanh(Tensor([2, 0],"float32"), )
paddle.Tensor.tile(Tensor([0, 4],"float32"), list[2,1,1,], )
paddle.Tensor.tile(Tensor([0, 4],"float32"), list[24,1,1,], )
paddle.Tensor.tile(Tensor([0, 4],"float32"), list[32,1,1,], )
paddle.Tensor.tile(Tensor([0, 4],"float32"), list[4,1,1,], )
paddle.Tensor.tile(Tensor([0, 4],"float32"), list[48,1,1,], )
paddle.Tensor.tile(Tensor([0, 4],"float32"), list[64,1,1,], )
paddle.Tensor.tile(Tensor([0, 4],"float32"), list[90,1,1,], )
paddle.Tensor.tile(Tensor([0],"int64"), tuple(12,2,), )
paddle.Tensor.tile(Tensor([1, 0, 1],"bool"), list[1,1,16,], )
paddle.Tensor.tile(Tensor([1, 0, 1],"bool"), list[1,1,5,], )
paddle.Tensor.tile(Tensor([1, 0, 1],"bool"), list[1,1,91,], )
paddle.Tensor.tile(Tensor([1, 0, 1],"float32"), list[1,100,1,], )
paddle.Tensor.tile(Tensor([1, 0, 1],"int32"), list[1,1,4,], )
paddle.Tensor.tile(Tensor([1, 0, 1],"int32"), list[1,1,68,], )
paddle.Tensor.tile(Tensor([1, 0, 1],"int32"), list[1,1,88,], )
paddle.Tensor.tile(Tensor([1, 0, 128, 2],"float32"), list[4,1,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 2, 1, 16],"float16"), list[1,1,1,4,1,], )
paddle.Tensor.tile(Tensor([1, 0, 2, 1, 16],"float32"), list[1,1,1,4,1,], )
paddle.Tensor.tile(Tensor([1, 0, 2, 1, 8],"float32"), list[1,1,1,2,1,], )
paddle.Tensor.tile(Tensor([1, 0, 2],"float32"), list[1,1,2,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,108,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,12,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,145,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,150,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,17,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,18,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,19,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,24,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,28,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,30,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,31,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,38,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,40,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,42,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,43,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,46,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,47,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,56,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,59,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,62,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,65,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,7,1,], )
paddle.Tensor.tile(Tensor([1, 0, 21504],"bool"), list[1,80,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,107,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,131,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,146,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,15,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,16,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,17,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,19,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,20,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,21,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,218,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,23,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,25,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,27,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,29,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,296,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,30,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,31,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,32,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,33,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,34,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,38,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,40,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,42,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,43,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,44,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,46,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,47,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,52,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,56,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,6,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,60,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,62,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,65,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,66,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,67,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,70,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,75,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,78,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,79,1,], )
paddle.Tensor.tile(Tensor([1, 0, 24276],"bool"), list[1,96,1,], )
paddle.Tensor.tile(Tensor([1, 0, 256, 2],"float32"), list[4,1,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 256],"float16"), list[2,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 256],"float32"), list[2,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 256],"float32"), list[4,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,119,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,12,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,132,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,15,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,150,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,21,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,255,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,27,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,28,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,29,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,33,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,34,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,35,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,37,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,44,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,45,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,48,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,49,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,52,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,53,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,54,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,57,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,59,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,63,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,64,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,77,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,80,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,9,1,], )
paddle.Tensor.tile(Tensor([1, 0, 27216],"bool"), list[1,99,1,], )
paddle.Tensor.tile(Tensor([1, 0, 28, 28],"float32"), list[1,3,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 280, 350],"float32"), list[1,3,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,10,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,112,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,113,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,117,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,140,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,142,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,149,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,156,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,23,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,252,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,37,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,41,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,45,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,48,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,55,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,57,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,63,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,71,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,78,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,9,1,], )
paddle.Tensor.tile(Tensor([1, 0, 30324],"bool"), list[1,92,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,109,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,123,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,13,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,20,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,209,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,215,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,22,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,24,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,25,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,32,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,329,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,36,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,39,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,49,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,50,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,71,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,85,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,86,1,], )
paddle.Tensor.tile(Tensor([1, 0, 33600],"bool"), list[1,91,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,102,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,13,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,14,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,172,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,22,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,26,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,303,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,35,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,36,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,41,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,51,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,58,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,6,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,68,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,72,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,85,1,], )
paddle.Tensor.tile(Tensor([1, 0, 37044],"bool"), list[1,93,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4, 4],"float32"), tuple(4,1,1,1,), )
paddle.Tensor.tile(Tensor([1, 0, 4, 4],"float32"), tuple(8,1,1,1,), )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1,100,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1,200,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1003,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1021,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1038,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1041,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1043,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[105,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[106,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[107,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1078,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1082,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[109,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[110,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1119,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[114,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[115,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1155,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[116,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[117,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[121,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[122,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[123,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[124,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1268,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[128,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[130,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[131,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1312,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1328,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[134,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[135,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[137,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1376,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1388,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[140,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[141,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[142,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[143,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1434,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[144,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[145,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1466,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1470,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[148,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[150,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[155,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[156,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[158,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[159,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[161,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[162,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[164,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[165,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[166,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1662,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[167,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1685,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[171,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[172,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[173,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[175,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[176,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1763,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[179,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1799,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[182,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1833,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[184,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[187,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[1892,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[192,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[193,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[195,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[197,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[198,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[200,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[201,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[2019,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[2026,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[205,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[206,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[208,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[210,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[216,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[220,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[222,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[223,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[224,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[225,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[228,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[2297,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[230,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[231,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[233,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[238,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[241,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[250,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 4],"float32"), list[254,1,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,101,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,116,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,168,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,169,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,26,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,333,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,70,1,], )
paddle.Tensor.tile(Tensor([1, 0, 40656],"bool"), list[1,8,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,139,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,14,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,18,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,225,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,39,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,51,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,55,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,58,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,61,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,64,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,69,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,7,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,73,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,76,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,8,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,87,1,], )
paddle.Tensor.tile(Tensor([1, 0, 44436],"bool"), list[1,97,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,11,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,124,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,16,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,249,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,50,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,53,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,54,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,72,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,75,1,], )
paddle.Tensor.tile(Tensor([1, 0, 48384],"bool"), list[1,81,1,], )
paddle.Tensor.trunc(Tensor([0, 28],"float32"), )
paddle.Tensor.trunc(Tensor([0, 8, 8],"float32"), )
paddle.Tensor.trunc(Tensor([0, 8],"float32"), )
paddle.Tensor.trunc(Tensor([2, 0, 8],"float32"), )
paddle.Tensor.trunc(Tensor([2, 8, 0],"float32"), )
paddle.Tensor.trunc(Tensor([28, 0],"float32"), )
paddle.Tensor.trunc(Tensor([8, 0],"float32"), )
paddle.tensor_split(Tensor([0, 4, 4, 7],"int64"), 2, axis=3, )
paddle.tensor_split(Tensor([0, 4, 4, 7],"int64"), 3, axis=3, )
paddle.tensor_split(Tensor([0, 4, 6],"bool"), 3, axis=2, )
paddle.tensor_split(Tensor([0, 4, 6],"float16"), 3, axis=2, )
paddle.tensor_split(Tensor([0, 4, 7, 4],"int64"), 2, axis=-2, )
paddle.tensor_split(Tensor([0, 4, 7, 4],"int64"), 3, axis=-2, )
paddle.tensor_split(Tensor([0, 4, 7],"int64"), 2, axis=2, )
paddle.tensor_split(Tensor([0, 6],"bool"), 3, axis=1, )
paddle.trace(x=Tensor([0, 3, 2],"float64"), offset=-1, axis1=2, axis2=-2, )
paddle.trace(x=Tensor([2, 0, 2],"float64"), offset=1, axis1=0, axis2=2, )
paddle.trace(x=Tensor([2, 3, 0],"float64"), offset=0, axis1=-3, axis2=-2, )
paddle.unique(Tensor([0, 5, 5],"float32"), return_index=True, return_inverse=True, return_counts=True, axis=0, )
paddle.unique(Tensor([0],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", )
paddle.vision.ops.box_coder(prior_box=Tensor([80, 4],"float32"), prior_box_var=Tensor([80, 4],"float32"), target_box=Tensor([0, 80, 4],"float32"), code_type="decode_center_size", box_normalized=False, )
paddle.vision.ops.box_coder(prior_box=Tensor([80, 4],"float32"), prior_box_var=tuple(1,2,3,4,), target_box=Tensor([0, 80, 4],"float32"), code_type="decode_center_size", box_normalized=False, )
paddle.vision.ops.box_coder(Tensor([30, 4],"float32"), list[0.12371375411748886,0.7415851950645447,0.40236398577690125,0.6756224632263184,], Tensor([30, 0, 4],"float32"), "decode_center_size", False, axis=1, )
paddle.vision.ops.generate_proposals(Tensor([0, 15, 40, 60],"float32"), Tensor([1, 60, 40, 60],"float32"), Tensor([1, 2],"float32"), Tensor([36000, 4],"float32"), Tensor([36000, 4],"float32"), pre_nms_top_n=12000, post_nms_top_n=2000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([0, 15, 42, 63],"float32"), Tensor([1, 60, 42, 63],"float32"), Tensor([1, 2],"float32"), Tensor([39690, 4],"float32"), Tensor([39690, 4],"float32"), pre_nms_top_n=12000, post_nms_top_n=2000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([0, 3, 10, 14],"float32"), Tensor([1, 12, 10, 14],"float32"), Tensor([1, 2],"float32"), Tensor([420, 4],"float32"), Tensor([420, 4],"float32"), pre_nms_top_n=2000, post_nms_top_n=2000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([0, 3, 10, 15],"float32"), Tensor([1, 12, 10, 15],"float32"), Tensor([1, 2],"float32"), Tensor([450, 4],"float32"), Tensor([450, 4],"float32"), pre_nms_top_n=2000, post_nms_top_n=2000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([0, 3, 4, 4],"float32"), Tensor([2, 12, 4, 4],"float32"), Tensor([2, 3],"float32"), Tensor([4, 4, 3, 4],"float32"), Tensor([4, 4, 3, 4],"float32"), pre_nms_top_n=10, post_nms_top_n=5, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([0, 4, 16, 16],"float32"), Tensor([1, 16, 16, 16],"float32"), Tensor([1, 2],"float32"), Tensor([16, 16, 4, 4],"float32"), Tensor([16, 16, 4, 4],"float32"), pre_nms_top_n=12000, post_nms_top_n=5000, nms_thresh=0.7, min_size=3.0, eta=1.0, pixel_offset=True, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([0, 9, 10, 8],"float32"), Tensor([1, 36, 10, 8],"float32"), Tensor([1, 2],"float32"), Tensor([720, 4],"float32"), Tensor([720, 4],"float32"), pre_nms_top_n=4000, post_nms_top_n=4000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([0, 9, 12, 9],"float32"), Tensor([1, 36, 12, 9],"float32"), Tensor([1, 2],"float32"), Tensor([972, 4],"float32"), Tensor([972, 4],"float32"), pre_nms_top_n=4000, post_nms_top_n=4000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([1, 0, 10, 14],"float32"), Tensor([1, 12, 10, 14],"float32"), Tensor([1, 2],"float32"), Tensor([420, 4],"float32"), Tensor([420, 4],"float32"), pre_nms_top_n=2000, post_nms_top_n=2000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([1, 0, 10, 15],"float32"), Tensor([1, 12, 10, 15],"float32"), Tensor([1, 2],"float32"), Tensor([450, 4],"float32"), Tensor([450, 4],"float32"), pre_nms_top_n=2000, post_nms_top_n=2000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.generate_proposals(Tensor([1, 0, 10, 8],"float32"), Tensor([1, 36, 10, 8],"float32"), Tensor([1, 2],"float32"), Tensor([720, 4],"float32"), Tensor([720, 4],"float32"), pre_nms_top_n=4000, post_nms_top_n=4000, nms_thresh=0.7, min_size=0.0, eta=1.0, return_rois_num=True, )
paddle.vision.ops.prior_box(input=Tensor([2, 10, 0, 32],"float32"), image=Tensor([2, 10, 0, 40],"float32"), min_sizes=list[2.0,4.0,], clip=True, flip=True, )
paddle.vision.ops.prior_box(input=Tensor([2, 10, 0, 32],"float32"), image=Tensor([2, 10, 40, 40],"float32"), min_sizes=list[2.0,4.0,], clip=True, flip=True, )
paddle.vision.ops.prior_box(input=Tensor([2, 10, 32, 0],"float32"), image=Tensor([2, 10, 40, 0],"float32"), min_sizes=list[2.0,4.0,], clip=True, flip=True, )
paddle.vision.ops.prior_box(input=Tensor([2, 10, 32, 0],"float32"), image=Tensor([2, 10, 40, 40],"float32"), min_sizes=list[2.0,4.0,], clip=True, flip=True, )
paddle.vision.ops.prior_box(Tensor([4, 48, 0, 40],"float32"), Tensor([4, 3, 0, 640],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 48, 0, 40],"float32"), Tensor([4, 3, 640, 640],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 48, 0, 80],"float32"), Tensor([4, 3, 0, 640],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 48, 0, 80],"float32"), Tensor([4, 3, 640, 640],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 48, 40, 0],"float32"), Tensor([4, 3, 640, 0],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 48, 40, 0],"float32"), Tensor([4, 3, 640, 640],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 48, 80, 0],"float32"), Tensor([4, 3, 640, 0],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 48, 80, 0],"float32"), Tensor([4, 3, 640, 640],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 0, 40],"float32"), Tensor([4, 3, 0, 640],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 0, 40],"float32"), Tensor([4, 3, 640, 640],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 0, 80],"float32"), Tensor([4, 3, 0, 640],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 0, 80],"float32"), Tensor([4, 3, 640, 640],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 40, 0],"float32"), Tensor([4, 3, 640, 0],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 40, 0],"float32"), Tensor([4, 3, 640, 640],"float32"), list[32.0,48.0,64.0,80.0,96.0,128.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[16.0,16.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 80, 0],"float32"), Tensor([4, 3, 640, 0],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.prior_box(Tensor([4, 96, 80, 0],"float32"), Tensor([4, 3, 640, 640],"float32"), list[16.0,24.0,], list[], list[1.0,], list[0.1,0.1,0.2,0.2,], False, False, list[8.0,8.0,], 0.5, False, None, )
paddle.vision.ops.yolo_box(Tensor([2, 14, 0, 8],"float32"), img_size=Tensor([2, 2],"int32"), anchors=list[10,13,16,30,], class_num=2, conf_thresh=0.01, downsample_ratio=8, clip_bbox=True, scale_x_y=1.0, )
paddle.vision.ops.yolo_box(Tensor([2, 14, 8, 0],"float32"), img_size=Tensor([2, 2],"int32"), anchors=list[10,13,16,30,], class_num=2, conf_thresh=0.01, downsample_ratio=8, clip_bbox=True, scale_x_y=1.0, )
paddle.vision.ops.yolo_box(Tensor([2, 16, 0, 8],"float32"), img_size=Tensor([2, 2],"int32"), anchors=list[10,13,16,30,], class_num=2, conf_thresh=0.01, downsample_ratio=8, clip_bbox=True, scale_x_y=1.0, iou_aware=True, iou_aware_factor=0.5, )
paddle.vision.ops.yolo_box(Tensor([2, 16, 8, 0],"float32"), img_size=Tensor([2, 2],"int32"), anchors=list[10,13,16,30,], class_num=2, conf_thresh=0.01, downsample_ratio=8, clip_bbox=True, scale_x_y=1.0, iou_aware=True, iou_aware_factor=0.5, )
paddle.where(Tensor([0, 1, 1, 1],"bool"), Tensor([0, 1, 1, 1],"float32"), Tensor([0, 1, 1, 1],"float32"), )
paddle.where(Tensor([0, 1, 1, 1],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([0, 1, 1, 100],"bool"), 0.0, -65504.0, )
paddle.where(Tensor([0, 1, 1, 101],"bool"), 0.0, -65504.0, )
paddle.where(Tensor([0, 1, 1, 23],"bool"), Tensor([0, 1, 1, 23],"float32"), Tensor([0, 1, 1, 23],"float32"), )
paddle.where(Tensor([0, 1, 1, 23],"bool"), Tensor([1, 1, 1, 23],"float32"), Tensor([1, 1, 1, 23],"float32"), )
paddle.where(Tensor([0, 1, 1],"bool"), Tensor([0, 1, 24276],"float32"), Tensor([0, 1, 24276],"float32"), )
paddle.where(Tensor([0, 1, 1],"bool"), Tensor([1, 1, 24276],"float32"), Tensor([1, 1, 24276],"float32"), )
paddle.where(Tensor([0, 1, 10285],"bool"), Tensor([0, 1, 10285],"float32"), Tensor([0, 1, 10285],"float32"), )
paddle.where(Tensor([0, 1, 10285],"bool"), Tensor([1, 1, 10285],"float32"), Tensor([1, 1, 10285],"float32"), )
paddle.where(Tensor([0, 1, 114, 114],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([0, 1, 2048, 2048],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([0, 1, 302, 302],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([0, 1, 58, 58],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([0, 1],"bool"), 9.99999993922529e-09, Tensor([0, 1],"float32"), )
paddle.where(Tensor([0, 10],"bool"), )
paddle.where(Tensor([0, 10],"bool"), 0, 1, )
paddle.where(Tensor([0, 100],"bool"), 0, 1, )
paddle.where(Tensor([0, 1001],"bool"), Tensor([0, 1001],"float32"), Tensor([0, 1001],"float32"), )
paddle.where(Tensor([0, 1001],"bool"), Tensor([0, 1001],"int32"), Tensor([0, 1001],"int32"), )
paddle.where(Tensor([0, 1001],"bool"), Tensor([1, 1001],"float32"), Tensor([1, 1001],"float32"), )
paddle.where(Tensor([0, 1001],"bool"), Tensor([1, 1001],"int32"), Tensor([1, 1001],"int32"), )
paddle.where(Tensor([0, 120],"bool"), Tensor([120],"float32"), Tensor([1],"float32"), )
paddle.where(Tensor([0, 123904],"bool"), 1.0, 0.0, )
paddle.where(Tensor([0, 13091],"float32"), )
paddle.where(Tensor([0, 135424],"bool"), 1.0, 0.0, )
paddle.where(Tensor([0, 2, 2, 4],"bool"), Tensor([2, 2, 1],"float32"), Tensor([2, 2, 1],"float32"), )
paddle.where(Tensor([0, 2, 2, 4],"bool"), Tensor([2, 2, 4],"float32"), Tensor([2, 2, 4],"float32"), )
paddle.where(Tensor([0, 2, 3, 4, 5, 1, 2],"bool"), Tensor([0, 2, 3, 4, 5, 1, 2],"float64"), Tensor([0, 2, 3, 4, 5, 1, 2],"float64"), )
paddle.where(Tensor([0, 20],"bool"), 1, 0, )
paddle.where(Tensor([0, 280, 376, 25, 1],"bool"), Tensor([0, 280, 376, 25, 1],"float32"), Tensor([0, 280, 376, 25, 1],"float32"), )
paddle.where(Tensor([0, 280, 376, 25, 3],"bool"), Tensor([0, 280, 376, 25, 3],"float32"), Tensor([0, 280, 376, 25, 3],"float32"), )
paddle.where(Tensor([0, 4, 2],"bool"), 0, 1, )
paddle.where(Tensor([0, 6, 3, 1, 2, 5],"bool"), Tensor([0, 6, 3, 1, 2, 5],"float64"), Tensor([0, 6, 3, 1, 2, 5],"float64"), )
paddle.where(Tensor([0, 6, 3, 4, 1, 5],"bool"), Tensor([0, 6, 3, 4, 1, 5],"float64"), Tensor([0, 6, 3, 4, 1, 5],"float64"), )
paddle.where(Tensor([0],"bool"), 1.0, 2.0, )
paddle.where(Tensor([0],"bool"), Tensor([0],"int32"), Tensor([0],"int32"), )
paddle.where(Tensor([1, 0, 1, 1],"bool"), Tensor([1, 0, 1, 1],"float32"), Tensor([1, 0, 1, 1],"float32"), )
paddle.where(Tensor([1, 0, 1, 1],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 0, 1, 100],"bool"), 0.0, -65504.0, )
paddle.where(Tensor([1, 0, 1, 101],"bool"), 0.0, -65504.0, )
paddle.where(Tensor([1, 0, 1, 23],"bool"), Tensor([1, 0, 1, 23],"float32"), Tensor([1, 0, 1, 23],"float32"), )
paddle.where(Tensor([1, 0, 1, 23],"bool"), Tensor([1, 1, 1, 23],"float32"), Tensor([1, 1, 1, 23],"float32"), )
paddle.where(Tensor([1, 0, 1],"bool"), Tensor([1, 0, 24276],"float32"), Tensor([1, 0, 24276],"float32"), )
paddle.where(Tensor([1, 0, 1],"bool"), Tensor([1, 1, 24276],"float32"), Tensor([1, 1, 24276],"float32"), )
paddle.where(Tensor([1, 0, 10285],"bool"), Tensor([1, 0, 10285],"float32"), Tensor([1, 0, 10285],"float32"), )
paddle.where(Tensor([1, 0, 10285],"bool"), Tensor([1, 1, 10285],"float32"), Tensor([1, 1, 10285],"float32"), )
paddle.where(Tensor([1, 0, 2048, 2048],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([1, 0, 58, 58],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([1, 0],"bool"), 1, 0, )
paddle.where(Tensor([1, 0],"bool"), 1.0, 0.0, )
paddle.where(Tensor([1, 0],"bool"), Tensor([1, 0],"float32"), Tensor([1, 0],"float32"), )
paddle.where(Tensor([1, 0],"bool"), Tensor([1, 0],"int32"), Tensor([1, 0],"int32"), )
paddle.where(Tensor([1, 1, 0, 1],"bool"), Tensor([1, 1, 0, 1],"float32"), Tensor([1, 1, 0, 1],"float32"), )
paddle.where(Tensor([1, 1, 0, 1],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 0, 100],"bool"), 0.0, -65504.0, )
paddle.where(Tensor([1, 1, 0, 101],"bool"), 0.0, -65504.0, )
paddle.where(Tensor([1, 1, 0, 2048],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([1, 1, 0, 23],"bool"), Tensor([1, 1, 0, 23],"float32"), Tensor([1, 1, 0, 23],"float32"), )
paddle.where(Tensor([1, 1, 0, 23],"bool"), Tensor([1, 1, 1, 23],"float32"), Tensor([1, 1, 1, 23],"float32"), )
paddle.where(Tensor([1, 1, 0, 58],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([1, 1, 0],"bool"), Tensor([1, 1, 0],"float32"), Tensor([1, 1, 0],"float32"), )
paddle.where(Tensor([1, 1, 1, 0],"bool"), 0.0, -65504.0, )
paddle.where(Tensor([1, 1, 1, 0],"bool"), Tensor([1, 1, 1, 0],"float32"), Tensor([1, 1, 1, 0],"float32"), )
paddle.where(Tensor([1, 1, 1, 0],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([0, 1, 1, 1],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([1, 0, 1, 1],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([1, 1, 0, 1],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([1, 1, 1, 0],"float32"), Tensor([1, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([0, 1, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([1, 0, 1, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([1, 1, 0, 1],"float32"), )
paddle.where(Tensor([1, 1, 1, 1],"bool"), Tensor([1, 1, 1, 1],"float32"), Tensor([1, 1, 1, 0],"float32"), )
paddle.where(Tensor([1, 1, 1, 23],"bool"), Tensor([0, 1, 1, 23],"float32"), Tensor([1, 1, 1, 23],"float32"), )
paddle.where(Tensor([1, 1, 1, 23],"bool"), Tensor([1, 0, 1, 23],"float32"), Tensor([1, 1, 1, 23],"float32"), )
paddle.where(Tensor([1, 1, 1, 23],"bool"), Tensor([1, 1, 0, 23],"float32"), Tensor([1, 1, 1, 23],"float32"), )
paddle.where(Tensor([1, 1, 1, 23],"bool"), Tensor([1, 1, 1, 23],"float32"), Tensor([0, 1, 1, 23],"float32"), )
paddle.where(Tensor([1, 1, 1, 23],"bool"), Tensor([1, 1, 1, 23],"float32"), Tensor([1, 0, 1, 23],"float32"), )
paddle.where(Tensor([1, 1, 1, 23],"bool"), Tensor([1, 1, 1, 23],"float32"), Tensor([1, 1, 0, 23],"float32"), )
paddle.where(Tensor([1, 1, 1],"bool"), Tensor([0, 1, 24276],"float32"), Tensor([1, 1, 24276],"float32"), )
paddle.where(Tensor([1, 1, 1],"bool"), Tensor([1, 0, 24276],"float32"), Tensor([1, 1, 24276],"float32"), )
paddle.where(Tensor([1, 1, 1],"bool"), Tensor([1, 1, 24276],"float32"), Tensor([0, 1, 24276],"float32"), )
paddle.where(Tensor([1, 1, 1],"bool"), Tensor([1, 1, 24276],"float32"), Tensor([1, 0, 24276],"float32"), )
paddle.where(Tensor([1, 1, 10285],"bool"), Tensor([0, 1, 10285],"float32"), Tensor([1, 1, 10285],"float32"), )
paddle.where(Tensor([1, 1, 10285],"bool"), Tensor([1, 0, 10285],"float32"), Tensor([1, 1, 10285],"float32"), )
paddle.where(Tensor([1, 1, 10285],"bool"), Tensor([1, 1, 10285],"float32"), Tensor([0, 1, 10285],"float32"), )
paddle.where(Tensor([1, 1, 10285],"bool"), Tensor([1, 1, 10285],"float32"), Tensor([1, 0, 10285],"float32"), )
paddle.where(Tensor([1, 1, 2048, 0],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([1, 1, 58, 0],"bool"), 0.0, -3.4028234663852886e+38, )
paddle.where(Tensor([1, 1001],"bool"), Tensor([0, 1001],"float32"), Tensor([1, 1001],"float32"), )
paddle.where(Tensor([1, 1001],"bool"), Tensor([0, 1001],"int32"), Tensor([1, 1001],"int32"), )
paddle.where(Tensor([1, 1001],"bool"), Tensor([1, 1001],"float32"), Tensor([0, 1001],"float32"), )
paddle.where(Tensor([1, 1001],"bool"), Tensor([1, 1001],"int32"), Tensor([0, 1001],"int32"), )
paddle.where(Tensor([1, 3],"bool"), Tensor([0, 3],"float32"), Tensor([1],"float32"), )
paddle.where(Tensor([128, 0],"bool"), 9.99999993922529e-09, Tensor([128, 0],"float32"), )
paddle.where(Tensor([128, 0],"bool"), 9.99999993922529e-09, Tensor([128, 1],"float32"), )
paddle.where(Tensor([128, 1],"bool"), 9.99999993922529e-09, Tensor([128, 0],"float32"), )
paddle.where(Tensor([2, 0, 114, 114],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([2, 0, 302, 302],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([2, 0],"bool"), )
paddle.where(Tensor([2, 0],"bool"), 0, 1, )
paddle.where(Tensor([2, 0],"bool"), 1, 0, )
paddle.where(Tensor([2, 0],"float32"), )
paddle.where(Tensor([2, 1, 0, 114],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([2, 1, 0, 302],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([2, 1, 114, 0],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([2, 1, 302, 0],"bool"), 0.0, -3.3895313892515355e+38, )
paddle.where(Tensor([3, 0, 2],"bool"), 0, 1, )
paddle.where(Tensor([3, 0, 3, 1, 2, 5],"bool"), Tensor([3, 0, 3, 1, 2, 5],"float64"), Tensor([3, 0, 3, 1, 2, 5],"float64"), )
paddle.where(Tensor([3, 0, 3, 4, 1, 5],"bool"), Tensor([3, 0, 3, 4, 1, 5],"float64"), Tensor([3, 0, 3, 4, 1, 5],"float64"), )
paddle.where(Tensor([3, 0, 3, 4, 5, 1, 2],"bool"), Tensor([3, 0, 3, 4, 5, 1, 2],"float64"), Tensor([3, 0, 3, 4, 5, 1, 2],"float64"), )
paddle.where(Tensor([3, 0],"bool"), 0, 1, )
paddle.where(Tensor([3, 1],"bool"), Tensor([3, 0],"float16"), Tensor([1],"float16"), )
paddle.where(Tensor([3, 2, 0, 4, 5, 1, 2],"bool"), Tensor([3, 2, 0, 4, 5, 1, 2],"float64"), Tensor([3, 2, 0, 4, 5, 1, 2],"float64"), )
paddle.where(Tensor([3, 2, 2, 0],"bool"), Tensor([2, 2, 1],"float32"), Tensor([2, 2, 1],"float32"), )
paddle.where(Tensor([3, 2, 3, 0, 5, 1, 2],"bool"), Tensor([3, 2, 3, 0, 5, 1, 2],"float64"), Tensor([3, 2, 3, 0, 5, 1, 2],"float64"), )
paddle.where(Tensor([3, 2, 3, 4, 0, 1, 2],"bool"), Tensor([3, 2, 3, 4, 0, 1, 2],"float64"), Tensor([3, 2, 3, 4, 0, 1, 2],"float64"), )
paddle.where(Tensor([3, 2, 3, 4, 5, 0, 2],"bool"), Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), )
paddle.where(Tensor([3, 2, 3, 4, 5, 0, 2],"bool"), Tensor([3, 2, 3, 4, 5, 1, 2],"float64"), Tensor([3, 2, 3, 4, 5, 1, 2],"float64"), )
paddle.where(Tensor([3, 2, 3, 4, 5, 1, 0],"bool"), Tensor([3, 2, 3, 4, 5, 1, 0],"float64"), Tensor([3, 2, 3, 4, 5, 1, 0],"float64"), )
paddle.where(Tensor([3, 2, 3, 4, 5, 1, 2],"bool"), Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), Tensor([3, 2, 3, 4, 5, 1, 2],"float64"), )
paddle.where(Tensor([3, 2, 3, 4, 5, 1, 2],"bool"), Tensor([3, 2, 3, 4, 5, 1, 2],"float64"), Tensor([3, 2, 3, 4, 5, 0, 2],"float64"), )
paddle.where(Tensor([3, 4, 0],"bool"), 0, 1, )
paddle.where(Tensor([3, 6, 0, 1, 2, 5],"bool"), Tensor([3, 6, 0, 1, 2, 5],"float64"), Tensor([3, 6, 0, 1, 2, 5],"float64"), )
paddle.where(Tensor([3, 6, 0, 4, 1, 5],"bool"), Tensor([3, 6, 0, 4, 1, 5],"float64"), Tensor([3, 6, 0, 4, 1, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 0, 1, 5],"bool"), Tensor([3, 6, 3, 0, 1, 5],"float64"), Tensor([3, 6, 3, 0, 1, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 0, 2, 5],"bool"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 0, 2, 5],"bool"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 1, 0, 5],"bool"), Tensor([3, 6, 3, 1, 0, 5],"float64"), Tensor([3, 6, 3, 1, 0, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 1, 2, 0],"bool"), Tensor([3, 6, 3, 1, 2, 0],"float64"), Tensor([3, 6, 3, 1, 2, 0],"float64"), )
paddle.where(Tensor([3, 6, 3, 1, 2, 5],"bool"), Tensor([3, 6, 3, 0, 2, 5],"float64"), Tensor([3, 6, 3, 1, 2, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 1, 2, 5],"bool"), Tensor([3, 6, 3, 1, 2, 5],"float64"), Tensor([3, 6, 3, 0, 2, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 4, 0, 5],"bool"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 4, 0, 5],"bool"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 4, 1, 0],"bool"), Tensor([3, 6, 3, 4, 1, 0],"float64"), Tensor([3, 6, 3, 4, 1, 0],"float64"), )
paddle.where(Tensor([3, 6, 3, 4, 1, 5],"bool"), Tensor([3, 6, 3, 4, 0, 5],"float64"), Tensor([3, 6, 3, 4, 1, 5],"float64"), )
paddle.where(Tensor([3, 6, 3, 4, 1, 5],"bool"), Tensor([3, 6, 3, 4, 1, 5],"float64"), Tensor([3, 6, 3, 4, 0, 5],"float64"), )
paddle.where(Tensor([4, 0, 376, 25, 1],"bool"), Tensor([4, 0, 376, 25, 1],"float32"), Tensor([4, 0, 376, 25, 1],"float32"), )
paddle.where(Tensor([4, 0, 376, 25, 3],"bool"), Tensor([4, 0, 376, 25, 3],"float32"), Tensor([4, 0, 376, 25, 3],"float32"), )
paddle.where(Tensor([4, 280, 0, 25, 1],"bool"), Tensor([4, 280, 0, 25, 1],"float32"), Tensor([4, 280, 0, 25, 1],"float32"), )
paddle.where(Tensor([4, 280, 0, 25, 3],"bool"), Tensor([4, 280, 0, 25, 3],"float32"), Tensor([4, 280, 0, 25, 3],"float32"), )
paddle.where(Tensor([4, 280, 376, 0, 1],"bool"), Tensor([4, 280, 376, 0, 1],"float32"), Tensor([4, 280, 376, 0, 1],"float32"), )
paddle.where(Tensor([4, 280, 376, 0, 3],"bool"), Tensor([4, 280, 376, 0, 3],"float32"), Tensor([4, 280, 376, 0, 3],"float32"), )
paddle.where(Tensor([4, 280, 376, 25, 0],"bool"), Tensor([4, 280, 376, 25, 0],"float32"), Tensor([4, 280, 376, 25, 0],"float32"), )
paddle.where(Tensor([4, 280, 376, 25, 0],"bool"), Tensor([4, 280, 376, 25, 1],"float32"), Tensor([4, 280, 376, 25, 1],"float32"), )
paddle.where(Tensor([4, 280, 376, 25, 1],"bool"), Tensor([4, 280, 376, 25, 0],"float32"), Tensor([4, 280, 376, 25, 1],"float32"), )
paddle.where(Tensor([4, 280, 376, 25, 1],"bool"), Tensor([4, 280, 376, 25, 1],"float32"), Tensor([4, 280, 376, 25, 0],"float32"), )
paddle.where(Tensor([40],"bool"), Tensor([0, 40],"float32"), Tensor([1],"float32"), )