paddle.nn.functional.avg_pool2d(x=Tensor([2, 67108865, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=tuple(0,0,), )
paddle.nn.functional.avg_pool2d(x=Tensor([44739243, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[0,0,], )
paddle.nn.functional.avg_pool2d(x=Tensor([44739243, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[1,1,], padding=list[1,1,], exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([44739243, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,], ceil_mode=True, exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([44739243, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=list[3,3,], padding=list[0,0,0,0,], ceil_mode=False, exclusive=False, )
paddle.nn.functional.avg_pool2d(x=Tensor([44739243, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=list[0,0,], )
paddle.nn.functional.avg_pool2d(x=Tensor([44739243, 3, 4, 4],"float64"), kernel_size=list[3,3,], stride=tuple(1,1,), padding=tuple(0,0,), )
paddle.nn.functional.avg_pool2d(x=Tensor([699051, 3, 32, 32],"float64"), kernel_size=list[2,2,], )
paddle.nn.functional.avg_pool2d(x=Tensor([699051, 3, 32, 32],"float64"), kernel_size=list[3,3,], )
paddle.nn.functional.avg_pool3d(Tensor([127827, 1, 3, 1600, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([127827, 1, 7, 3, 1600],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([1398102, 8, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NDHWC", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 11184811, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 32, 699051],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 32, 699051],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 32, 699051],"float32"), kernel_size=2, stride=2, padding=0, divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 32, 699051],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 32, 699051],"float32"), kernel_size=2, stride=None, padding="SAME", ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 699051, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 699051, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 699051, 32],"float32"), kernel_size=2, stride=2, padding=0, divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 699051, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 32, 699051, 32],"float32"), kernel_size=2, stride=None, padding="SAME", ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 699051, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 699051, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 699051, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 699051, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 699051, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 11184811, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 11184811],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 4194304, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 5592406, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NDHWC", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 65536, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool3d(Tensor([2, 65536, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 65536, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 65536, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([2, 65536, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 8, 5592406, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NDHWC", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 8, 8, 5592406, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NDHWC", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2, 8, 8, 8, 2097153],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NDHWC", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([2796203, 3, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], ceil_mode=False, exclusive=False, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 127827, 1600, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 298262, 3, 1600],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 3, 1600, 298262],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 3, 68174085, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 40, 40, 894785],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 40, 5113057, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 5113057, 40, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 7, 127827, 1600],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 7, 3, 68174085],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 7, 40, 5113057],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 7, 5113057, 40],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 1, 894785, 40, 40],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 127827, 40, 40, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 127827, 7, 40, 40],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 42609, 3, 1600, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([3, 42609, 7, 3, 1600],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([383480, 1, 40, 40, 7],"float32"), kernel_size=tuple(1,1,5,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([383480, 1, 7, 40, 40],"float32"), kernel_size=tuple(5,1,1,), stride=1, )
paddle.nn.functional.avg_pool3d(Tensor([43691, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding="SAME", )
paddle.nn.functional.avg_pool3d(Tensor([43691, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(Tensor([43691, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=0, divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([43691, 3, 32, 32, 32],"float32"), kernel_size=2, stride=2, padding=list[0,0,0,0,0,0,], divisor_override=8, )
paddle.nn.functional.avg_pool3d(Tensor([43691, 3, 32, 32, 32],"float32"), kernel_size=2, stride=None, padding="SAME", ceil_mode=False, exclusive=True, divisor_override=None, data_format="NCDHW", name=None, )
paddle.nn.functional.avg_pool3d(x=Tensor([10700, 2048, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([10700, 256, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 3, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([1398102, 8, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NDHWC", exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 2097153, 8, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 11184811, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 5592406, 8, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 11184811, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 5592406, 8],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 11184811],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=2, padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[1,2,3,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], ceil_mode=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=1, exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[0,0,0,], exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,1,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=list[3,2,1,], padding=list[1,2,1,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=list[1,0,0,], exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 3, 8, 8, 5592406],"float64"), kernel_size=list[3,3,3,], stride=tuple(3,2,1,), padding=tuple(1,0,0,), exclusive=True, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 4194304, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 5592406, 8, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NDHWC", exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 8, 5592406, 8, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NDHWC", exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 8, 8, 5592406, 3],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NDHWC", exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2, 8, 8, 8, 2097153],"float64"), kernel_size=list[3,3,3,], stride=list[2,2,2,], padding=list[0,0,0,], data_format="NDHWC", exclusive=False, )
paddle.nn.functional.avg_pool3d(x=Tensor([2796203, 3, 8, 8, 8],"float32"), kernel_size=list[3,3,3,], stride=list[1,1,1,], padding=list[0,0,0,], )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 7, 9363],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 4, 9363, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 2048, 5350, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 7, 9363],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 32, 9363, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 256, 42800, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 2739138, 4, 7, 7],"float32"), kernel_size=list[4,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.avg_pool3d(x=Tensor([8, 342393, 32, 7, 7],"float32"), kernel_size=list[32,7,7,], stride=1, data_format="NCDHW", )
paddle.nn.functional.batch_norm(Tensor([1, 1024, 4194304],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1, 128, 33554432],"float32"), Tensor([128],"float32"), Tensor([128],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1, 16777216, 256],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1, 16777216, 256],"float32"), Tensor([128],"float32"), Tensor([128],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1, 3728271, 1152],"float32"), Tensor([128],"float32"), Tensor([128],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1, 8388608, 512],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1, 8388608, 512],"float32"), Tensor([128],"float32"), Tensor([128],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1048576, 8, 16, 32],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1048577, 16, 16, 8],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([1048577, 16, 16, 8],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1048577, 8, 16, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([107374183, 40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([1242757, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1242757, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1242757, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([1242757, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([1242757, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([1242757, 6, 12, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([131072, 128, 256],"float32"), Tensor([128],"float32"), Tensor([128],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([1398102, 24, 16, 8],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 1048577, 8],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 1048577, 8],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-06, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 1048576],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 524289],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 16, 524289],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-06, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 16, 2097152, 8],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 24, 1398102, 8],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16, 24, 16, 699051],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), Tensor([24],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16384, 1024, 256],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([16777216, 256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), Tensor([256],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([16777216, 8, 32],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 1, 2, 1073741824],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2, 1, 2, 1073741824],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2, 1, 715827883, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2, 1, 715827883, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2, 119304648, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 119304648, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2, 119304648, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2, 119304648, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 119304648, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2, 119304648, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2, 3, 4, 89478486],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 3, 4, 89478486],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 3, 89478486, 4],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 3, 89478486, 4],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 3, 89478486, 4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 3, 89478486, 4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 89478486, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 89478486, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 89478486, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 89478486, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 89478486, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2, 4, 89478486, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2, 67108865, 4, 4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2, 67108865, 4, 4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float16"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-06, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2097152, 16, 16, 8],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2097152, 8, 16, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2485514, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2485514, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2485514, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([2485514, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([2485514, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([2485514, 6, 12, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([29128, 128, 1152],"float32"), Tensor([128],"float32"), Tensor([128],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 71583],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), )
paddle.nn.functional.batch_norm(Tensor([30, 40, 50, 71583],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([30, 40, 59653, 60],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), )
paddle.nn.functional.batch_norm(Tensor([30, 40, 59653, 60],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([30, 40, 59653, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), data_format="NHWC", )
paddle.nn.functional.batch_norm(Tensor([30, 47722, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), data_format="NHWC", )
paddle.nn.functional.batch_norm(Tensor([30, 47722, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
paddle.nn.functional.batch_norm(Tensor([35792, 40, 50, 60],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), )
paddle.nn.functional.batch_norm(Tensor([35792, 40, 50, 60],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), Tensor([40],"float32"), use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([35792, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), data_format="NHWC", )
paddle.nn.functional.batch_norm(Tensor([35792, 40, 50, 60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), Tensor([60],"float32"), use_global_stats=True, data_format="NHWC", )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 14913081],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 14913081],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 14913081],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 14913081],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 14913081],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 14913081],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7456541],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7456541],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7456541],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7456541],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7456541],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 12, 7456541],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 3728271, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 3728271, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 3728271, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 3728271, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 3728271, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 3728271, 24],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), Tensor([6],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 7456541, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 7456541, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 7456541, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 7456541, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 7456541, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([4, 6, 7456541, 24],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), Tensor([6],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([4, 8, 134217728],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 8, 16, 8388608],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([4, 8, 4194304, 32],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([44739243, 3, 4, 4],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([44739243, 3, 4, 4],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([44739243, 3, 4, 4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([44739243, 3, 4, 4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), Tensor([4],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([59652324, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([59652324, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([59652324, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([59652324, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([59652324, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([59652324, 4, 3, 3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), Tensor([3],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([65536, 128, 512],"float32"), Tensor([128],"float32"), Tensor([128],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(Tensor([715827883, 1, 2, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([715827883, 1, 2, 3],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), Tensor([1],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 1048577, 16, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 2097152, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 2097152, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 2097152, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 2097152, 16, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 2097153],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 2097153],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 2097153],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 2097153],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 2097153],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 4194304],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 4194304],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 4194304],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 4194304],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 16, 4194304],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), Tensor([16],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=False, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 2097153, 16],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), Tensor([8],"float64"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), Tensor([16],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NHWC", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=False, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=False, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.1, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=None, )
paddle.nn.functional.batch_norm(Tensor([8, 8, 4194304, 16],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), Tensor([8],"float32"), training=True, momentum=0.9, epsilon=1e-05, data_format="NCHW", use_global_stats=True, )
paddle.nn.functional.batch_norm(Tensor([8192, 1024, 512],"float32"), Tensor([1024],"float32"), Tensor([1024],"float32"), training=True, momentum=0.0, epsilon=1e-06, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 1073741825],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 1073741825],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 1073741825],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, data_format="NCL", )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 2, 1073741824],"float32"), running_mean=Tensor([1],"float32"), running_var=Tensor([1],"float32"), weight=Tensor([1],"float32"), bias=Tensor([1],"float32"), )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 2, 536870913],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 2, 536870913],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 2, 536870913],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.1, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 2, 536870913],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.1, data_format="NCHW", )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 2, 536870913],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.9, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 357913942, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 357913942, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 357913942, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.1, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 357913942, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.1, data_format="NCHW", )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 357913942, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.9, )
paddle.nn.functional.batch_norm(x=Tensor([2, 1, 715827883, 3],"float32"), running_mean=Tensor([1],"float32"), running_var=Tensor([1],"float32"), weight=Tensor([1],"float32"), bias=Tensor([1],"float32"), )
paddle.nn.functional.batch_norm(x=Tensor([357913942, 1, 2, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), )
paddle.nn.functional.batch_norm(x=Tensor([357913942, 1, 2, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, )
paddle.nn.functional.batch_norm(x=Tensor([357913942, 1, 2, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.1, )
paddle.nn.functional.batch_norm(x=Tensor([357913942, 1, 2, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.1, data_format="NCHW", )
paddle.nn.functional.batch_norm(x=Tensor([357913942, 1, 2, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, momentum=0.9, )
paddle.nn.functional.batch_norm(x=Tensor([715827883, 1, 2, 3],"float32"), running_mean=Tensor([1],"float32"), running_var=Tensor([1],"float32"), weight=Tensor([1],"float32"), bias=Tensor([1],"float32"), )
paddle.nn.functional.batch_norm(x=Tensor([715827883, 1, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), )
paddle.nn.functional.batch_norm(x=Tensor([715827883, 1, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, )
paddle.nn.functional.batch_norm(x=Tensor([715827883, 1, 3],"float64"), running_mean=Tensor([1],"float64"), running_var=Tensor([1],"float64"), weight=Tensor([1],"float64"), bias=Tensor([1],"float64"), epsilon=1e-05, data_format="NCL", )
paddle.nn.functional.class_center_sample(Tensor([4294967295],"int32"), 10, 8, )
paddle.nn.functional.class_center_sample(Tensor([4294967295],"int32"), 20, 6, )
paddle.nn.functional.class_center_sample(Tensor([4294967295],"int32"), 20, 8, )
paddle.nn.functional.class_center_sample(Tensor([4294967295],"int32"), num_classes=10, num_samples=6, group=None, )
paddle.nn.functional.conv1d(Tensor([1, 1024, 3000],"float32"), Tensor([1398102, 1024, 3],"float32"), bias=Tensor([1024],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 1024, 4194304],"float32"), Tensor([1024, 1024, 3],"float32"), bias=Tensor([1024],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([11184811, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([11184811, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([11184811, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([3050403, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([3050403, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([3050403, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([4793491, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([4793491, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 112],"float32"), Tensor([4793491, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 128, 33554432],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 1280, 3000],"float32"), Tensor([1118482, 1280, 3],"float32"), bias=Tensor([1280],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 1280, 3000],"float32"), Tensor([1280, 1280, 2622],"float32"), bias=Tensor([1280],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 1280, 3355444],"float32"), Tensor([1280, 1280, 3],"float32"), bias=Tensor([1280],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 20, 7],"float32"), Tensor([30678338, 20, 7],"float32"), bias=Tensor([512],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 16777216],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([1525202, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([1525202, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([1525202, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([2396746, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([2396746, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([2396746, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([5592406, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([5592406, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 256, 28],"float32"), Tensor([5592406, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 3, 1431655765],"float32"), Tensor([4, 3, 3],"float32"), bias=Tensor([4],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 3, 5],"float32"), Tensor([477218589, 3, 3],"float32"), bias=Tensor([4],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([1, 32, 7],"float32"), bias=Tensor([1],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 11],"float32"), bias=Tensor([32],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 11],"float32"), bias=Tensor([32],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 11],"float32"), bias=Tensor([32],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 3],"float32"), bias=Tensor([32],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 3],"float32"), bias=Tensor([32],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 3],"float32"), bias=Tensor([32],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 7],"float32"), bias=Tensor([32],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 7],"float32"), bias=Tensor([32],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 32, 134217728],"float32"), Tensor([32, 32, 7],"float32"), bias=Tensor([32],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 384, 11184811],"float32"), Tensor([384, 384, 3],"float32"), bias=Tensor([384],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 384, 3000],"float32"), Tensor([3728271, 384, 3],"float32"), bias=Tensor([384],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 512, 3000],"float32"), Tensor([2796203, 512, 3],"float32"), bias=Tensor([512],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 512, 8388608],"float32"), Tensor([512, 512, 3],"float32"), bias=Tensor([512],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([22369622, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([22369622, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([22369622, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([6100806, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([6100806, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([6100806, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([9586981, 64, 7],"float32"), bias=Tensor([64],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 448],"float32"), Tensor([9586981, 64, 7],"float32"), bias=Tensor([64],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 7],"float32"), bias=Tensor([64],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 64, 67108864],"float32"), Tensor([64, 64, 7],"float32"), bias=Tensor([64],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 768, 3000],"float32"), Tensor([1864136, 768, 3],"float32"), bias=Tensor([768],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1, 768, 5592406],"float32"), Tensor([768, 768, 3],"float32"), bias=Tensor([768],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([107375, 400, 100],"float32"), Tensor([256, 100, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1119, 1280, 3000],"float32"), Tensor([1280, 1280, 3],"float32"), bias=Tensor([1280],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([12782641, 24, 14],"float32"), Tensor([24, 12, 16],"float32"), bias=Tensor([24],"float32"), padding=8, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 10324441, 32],"float32"), Tensor([16, 32, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([13, 1295617, 255],"float32"), Tensor([32, 1295617, 8],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 161320, 2048],"float32"), Tensor([20, 161320, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 161320, 2048],"float32"), Tensor([256, 161320, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 24, 13765921],"float32"), Tensor([24, 12, 16],"float32"), bias=Tensor([24],"float32"), padding=8, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 24, 14],"float32"), Tensor([22369622, 12, 16],"float32"), bias=Tensor([24],"float32"), padding=8, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 256, 1290556],"float32"), Tensor([20, 256, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 256, 1290556],"float32"), Tensor([256, 256, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 10324441],"float32"), Tensor([32, 16, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 10324441],"float32"), Tensor([32, 32, 8],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 10324441],"float32"), Tensor([64, 8, 1],"float32"), bias=Tensor([64],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 32, 62],"float32"), Tensor([16777216, 32, 8],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 322639, 1024],"float32"), Tensor([32, 322639, 8],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 5328744, 62],"float32"), Tensor([32, 5328744, 8],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 64, 5162221],"float32"), Tensor([32, 64, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([13, 64, 7],"float32"), Tensor([67108864, 64, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([1399, 1024, 3000],"float32"), Tensor([1024, 1024, 3],"float32"), bias=Tensor([1024],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 11],"float32"), bias=Tensor([64],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 3],"float32"), bias=Tensor([64],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 7],"float32"), bias=Tensor([64],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([149797, 64, 448],"float32"), Tensor([64, 64, 7],"float32"), bias=Tensor([64],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 10527, 25500],"float32"), Tensor([128, 10527, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 3016129, 89],"float32"), Tensor([80, 3016129, 5],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=128, stride=list[1,], dilation=list[128,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=16, stride=list[1,], dilation=list[16,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=2, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=256, stride=list[1,], dilation=list[256,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=32, stride=list[1,], dilation=list[32,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=4, stride=list[1,], dilation=list[4,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=512, stride=list[1,], dilation=list[512,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=64, stride=list[1,], dilation=list[64,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=8, stride=list[1,], dilation=list[8,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 64, 4194304],"float32"), Tensor([64, 64, 1],"float32"), bias=Tensor([64],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 80, 3355444],"float32"), Tensor([128, 80, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([16, 80, 3355444],"float32"), Tensor([80, 80, 5],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([167773, 256, 100],"float16"), Tensor([256, 64, 3],"float16"), bias=Tensor([256],"float16"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([167773, 256, 100],"float32"), Tensor([256, 64, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([178956971, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([178956971, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([178956971, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([178956971, 3, 4],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([178956971, 3, 4],"float64"), Tensor([6, 1, 3],"float64"), bias=Tensor([6],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([178956971, 4, 3],"float64"), Tensor([2, 3, 3],"float64"), bias=Tensor([2],"float64"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([1865, 768, 3000],"float32"), Tensor([768, 768, 3],"float32"), bias=Tensor([768],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([19173962, 32, 7],"float32"), Tensor([32, 16, 1],"float32"), bias=Tensor([32],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([19173962, 32, 7],"float32"), Tensor([64, 8, 1],"float32"), bias=Tensor([64],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([19173962, 7, 32],"float32"), Tensor([16, 32, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([2, 128, 112],"float32"), Tensor([11184811, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 112],"float32"), Tensor([11184811, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 112],"float32"), Tensor([3050403, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 112],"float32"), Tensor([3050403, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 112],"float32"), Tensor([3050403, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 112],"float32"), Tensor([4793491, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 112],"float32"), Tensor([4793491, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 16777216],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 16777216],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 16777216],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 16777216],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 16777216],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 16777216],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 128, 16777216],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 357913942],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 357913942],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 357913942],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 357913942],"float64"), Tensor([1, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 1431655765],"float32"), bias=Tensor([1],"float32"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 1431655765],"float32"), bias=Tensor([1],"float32"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([1, 3, 1431655765],"float32"), bias=Tensor([1],"float32"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([477218589, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([477218589, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([477218589, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float32"), Tensor([477218589, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([238609295, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([238609295, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([238609295, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 4],"float64"), Tensor([238609295, 3, 3],"float64"), bias=Tensor([1],"float64"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 715827883],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 715827883],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 715827883],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 3, 715827883],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2, 357913942, 3],"float64"), Tensor([2, 3, 3],"float64"), bias=Tensor([2],"float64"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([2, 4, 3],"float32"), Tensor([477218589, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([2, 4, 3],"float64"), Tensor([238609295, 3, 3],"float64"), bias=Tensor([2],"float64"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([2, 715827883, 3],"float32"), Tensor([2, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([2106, 80, 25500],"float32"), Tensor([128, 80, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2164803, 32, 62],"float32"), Tensor([32, 32, 8],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([1, 64, 1],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=128, stride=list[1,], dilation=list[128,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=16, stride=list[1,], dilation=list[16,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=2, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=256, stride=list[1,], dilation=list[256,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=32, stride=list[1,], dilation=list[32,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=4, stride=list[1,], dilation=list[4,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=512, stride=list[1,], dilation=list[512,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=64, stride=list[1,], dilation=list[64,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([128, 64, 3],"float32"), bias=Tensor([128],"float32"), padding=8, stride=list[1,], dilation=list[8,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2632, 64, 25500],"float32"), Tensor([64, 64, 1],"float32"), bias=Tensor([64],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([2797, 512, 3000],"float32"), Tensor([512, 512, 3],"float32"), bias=Tensor([512],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([286331153, 3, 5],"float32"), Tensor([4, 3, 3],"float32"), bias=Tensor([4],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 11],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 3],"float32"), bias=Tensor([128],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([299594, 128, 112],"float32"), Tensor([128, 128, 7],"float32"), bias=Tensor([128],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([357913942, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([357913942, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=1, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([357913942, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=list[1,], stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([357913942, 3, 4],"float32"), Tensor([1, 3, 3],"float32"), bias=Tensor([1],"float32"), padding=tuple(1,), stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([357913942, 3, 4],"float32"), Tensor([6, 1, 3],"float32"), bias=Tensor([6],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=3, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([357913942, 4, 3],"float32"), Tensor([2, 3, 3],"float32"), bias=Tensor([2],"float32"), padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([3729, 384, 3000],"float32"), Tensor([384, 384, 3],"float32"), bias=Tensor([384],"float32"), padding=1, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 178956971, 6],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([238609295, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=0, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([238609295, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 16],"float32"), Tensor([8, 6, 89478486],"float32"), bias=Tensor([8],"float32"), padding="same", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding="same", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=0, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([4, 6, 178956971],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 3, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=2, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding="same", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding="valid", stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=0, stride=list[1,], dilation=list[2,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=0, stride=list[2,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([44739243, 6, 16],"float32"), Tensor([8, 6, 3],"float32"), bias=Tensor([8],"float32"), padding=list[1,2,], stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([52, 2581111, 32],"float32"), Tensor([16, 32, 1],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NLC", )
paddle.nn.functional.conv1d(Tensor([526345, 32, 255],"float32"), Tensor([32, 32, 8],"float32"), bias=None, padding=0, stride=list[4,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 11],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 3],"float32"), bias=Tensor([256],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([599187, 256, 28],"float32"), Tensor([256, 256, 7],"float32"), bias=Tensor([256],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([603226, 80, 89],"float32"), Tensor([80, 80, 5],"float32"), bias=None, padding=0, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([1, 32, 7],"float32"), bias=Tensor([1],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 11],"float32"), bias=Tensor([32],"float32"), padding=15, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 11],"float32"), bias=Tensor([32],"float32"), padding=25, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 11],"float32"), bias=Tensor([32],"float32"), padding=5, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 3],"float32"), bias=Tensor([32],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 3],"float32"), bias=Tensor([32],"float32"), padding=3, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 3],"float32"), bias=Tensor([32],"float32"), padding=5, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 7],"float32"), bias=Tensor([32],"float32"), padding=15, stride=list[1,], dilation=list[5,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 7],"float32"), bias=Tensor([32],"float32"), padding=3, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([74899, 32, 1792],"float32"), Tensor([32, 32, 7],"float32"), bias=Tensor([32],"float32"), padding=9, stride=list[1,], dilation=list[3,], groups=1, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([8, 256, 2097152],"float16"), Tensor([256, 64, 3],"float16"), bias=Tensor([256],"float16"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([8, 256, 2097152],"float32"), Tensor([256, 64, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([8, 400, 1342178],"float32"), Tensor([256, 100, 3],"float32"), bias=Tensor([256],"float32"), padding=1, stride=list[1,], dilation=list[1,], groups=4, data_format="NCL", )
paddle.nn.functional.conv1d(Tensor([8192, 256, 2048],"float32"), Tensor([20, 256, 5],"float32"), bias=None, padding=2, stride=list[1,], dilation=list[1,], groups=1, data_format="NCL", )
